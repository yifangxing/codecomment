{
  "org.apache.hadoop.io.SequenceFile$Writer$FileOption:<init>(org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.ipc.Server$MetricsUpdateRunner:run()" : [ "monotonicNow" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.net.NetUtils:canonicalizeHost(java.lang.String)" : [ "getByName" ],
  "org.apache.hadoop.crypto.key.KeyProvider:options(org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.crypto.CryptoCodec:getCodecClasses(org.apache.hadoop.conf.Configuration,org.apache.hadoop.crypto.CipherSuite)" : [ "newArrayList", "getConfigSuffix", "get", "getClassByName" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:setStoragePolicy(org.apache.hadoop.fs.Path,java.lang.String)" : [ "setStoragePolicy" ],
  "org.apache.hadoop.io.ByteWritable$Comparator:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.PathData:<init>(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getLocal" ],
  "org.apache.hadoop.util.bloom.BloomFilter:write(java.io.DataOutput)" : [ "write", "getNBytes" ],
  "org.apache.hadoop.fs.FilterFs:getAclStatus(org.apache.hadoop.fs.Path)" : [ "getAclStatus" ],
  "org.apache.hadoop.fs.shell.Delete$Expunge:processOptions(java.util.LinkedList)" : [ "<init>", "addOptionWithValue", "parse", "getOpt", "getOptValue" ],
  "org.apache.hadoop.ipc.metrics.RpcDetailedMetrics:addDeferredProcessingTime(java.lang.String,long)" : [ "add" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:maximums()" : [ "getInnerStatistics" ],
  "org.apache.hadoop.util.VersionInfo:<init>(java.lang.String)" : [ "getResourceAsStream", "closeStream" ],
  "org.apache.hadoop.ha.ZKFCRpcServer:<init>(org.apache.hadoop.conf.Configuration,java.net.InetSocketAddress,org.apache.hadoop.ha.ZKFailoverController,org.apache.hadoop.security.authorize.PolicyProvider)" : [ "<init>", "setProtocolEngine", "setProtocol", "setInstance", "setBindAddress", "setPort", "setNumHandlers", "setVerbose", "build", "getBoolean" ],
  "org.apache.hadoop.fs.FilterFileSystem:setPermission(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "setPermission" ],
  "org.apache.hadoop.fs.Path:normalizePath(java.lang.String,java.lang.String)" : [ "hasWindowsDrive", "startPositionWithoutWindowsDrive" ],
  "org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:getTokenInfo(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier)" : [ "getTokenInfoFromZK", "getSequenceNumber" ],
  "org.apache.hadoop.io.retry.RetryProxy:create(java.lang.Class,java.lang.Object,org.apache.hadoop.io.retry.RetryPolicy)" : [ "<init>", "create" ],
  "org.apache.hadoop.security.authorize.DefaultImpersonationProvider:getTestProvider()" : [ "<init>", "setConf", "init" ],
  "org.apache.hadoop.fs.viewfs.ViewFsFileStatus:<init>(org.apache.hadoop.fs.FileStatus,org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:close()" : [ "shutdown", "destroy" ],
  "org.apache.hadoop.io.BytesWritable:<init>(byte[])" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:removeXAttr(org.apache.hadoop.fs.Path,java.lang.String)" : [ "removeXAttr", "fullPath" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:newCounter(java.lang.String,java.lang.String,int)" : [ "newCounter", "info" ],
  "org.apache.hadoop.io.erasurecode.coder.ErasureDecoder:getNumErasedBlocks(org.apache.hadoop.io.erasurecode.ECBlockGroup)" : [ "getNumErasedBlocks", "getParityBlocks", "getDataBlocks" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockData:getStateString()" : [ "getState" ],
  "org.apache.hadoop.fs.FilterFileSystem:setReplication(org.apache.hadoop.fs.Path,short)" : [ "setReplication" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreImpl:setMinimum(java.lang.String,long)" : [ "setAtomicLong" ],
  "org.apache.hadoop.fs.viewfs.InodeTree:getRootDir()" : [ "checkState" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RawErasureEncoder:allowVerboseDump()" : [ "allowVerboseDump" ],
  "org.apache.hadoop.fs.viewfs.ConfigUtil:addLinkNfly(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String,java.lang.String,java.net.URI[])" : [ "addLinkNfly", "uriToString" ],
  "org.apache.hadoop.util.ReflectionUtils:setConf(java.lang.Object,org.apache.hadoop.conf.Configuration)" : [ "setJobConf" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:setupNoRandPartA()" : [ "updateCRC", "endBlock", "initBlock" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:snapshotMetrics(org.apache.hadoop.metrics2.impl.MetricsSourceAdapter,org.apache.hadoop.metrics2.impl.MetricsBufferBuilder)" : [ "monotonicNow", "add", "name", "getMetrics", "clear" ],
  "org.apache.hadoop.io.nativeio.SharedFileDescriptorFactory:create(java.lang.String,java.lang.String[])" : [ "<init>", "getLoadingFailureReason" ],
  "org.apache.hadoop.security.KDiag$KerberosDiagsFailure:<init>(java.lang.String,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem:createFileSystem(java.net.URI[],org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.hadoop.fs.viewfs.FsGetter)" : [ "<init>", "split" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:setMaximum(java.lang.String,long)" : [ "getInnerStatistics" ],
  "org.apache.hadoop.crypto.OpensslSm4CtrCryptoCodec:calculateIV(byte[],long,byte[])" : [ "calculateIV", "getCipherSuite", "getAlgorithmBlockSize" ],
  "org.apache.hadoop.conf.Configuration:getSocketAddr(java.lang.String,java.lang.String,java.lang.String,int)" : [ "getSocketAddr", "get", "createSocketAddr" ],
  "org.apache.hadoop.fs.impl.FutureDataInputStreamBuilderImpl:initFromFS()" : [ "getInt" ],
  "org.apache.hadoop.tools.TableListing$Builder:build()" : [ "<init>" ],
  "org.apache.hadoop.io.SequenceFile$Reader:next(org.apache.hadoop.io.Writable)" : [ "next", "getKeyClass", "reset", "getData", "getLength", "getPosition", "readBlock", "readVInt" ],
  "org.apache.hadoop.ha.ZKFailoverController:fenceOldActive(byte[])" : [ "<init>", "doFence", "recordActiveAttempt", "stringifyException" ],
  "org.apache.hadoop.io.MapWritable:putAll(java.util.Map)" : [ "put" ],
  "org.apache.hadoop.tools.protocolPB.GetUserMappingsProtocolClientSideTranslatorPB:close()" : [ "stopProxy" ],
  "org.apache.hadoop.fs.shell.find.Print$Print0:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:getStoragePolicy(org.apache.hadoop.fs.Path)" : [ "getStoragePolicy" ],
  "org.apache.hadoop.fs.permission.FsPermission:getDirDefault()" : [ "<init>" ],
  "org.apache.hadoop.io.retry.AsyncCallHandler$AsyncCallQueue$Processor:tryStop(org.apache.hadoop.util.Daemon)" : [ "isEmpty", "kill" ],
  "org.apache.hadoop.conf.ReconfigurationException:<init>(java.lang.String,java.lang.String,java.lang.String,java.lang.Throwable)" : [ "constructMessage" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RawErasureDecoder:decode(java.nio.ByteBuffer[],int[],java.nio.ByteBuffer[])" : [ "<init>", "convertToByteArrayState" ],
  "org.apache.hadoop.io.MapFile$Writer:close()" : [ "close" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:setReplication(org.apache.hadoop.fs.Path,short)" : [ "setReplication", "resolve", "getUriPath" ],
  "org.apache.hadoop.ipc.Server:wrapWithSasl(org.apache.hadoop.ipc.Server$RpcCall)" : [ "wrap", "setupResponse" ],
  "org.apache.hadoop.security.KDiag:validateShortName()" : [ "<init>", "failif", "warn", "error", "stringifyException" ],
  "org.apache.hadoop.util.curator.ZKCuratorManager:getStringData(java.lang.String)" : [ "getData" ],
  "org.apache.hadoop.fs.shell.PathData:getPathDataForChild(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "checkIfExists", "getStringForChildPath" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:flush()" : [ "flush", "getKMSUrl" ],
  "org.apache.hadoop.service.ServiceStateException:convert(java.lang.Throwable)" : [ "<init>" ],
  "org.apache.hadoop.io.erasurecode.codec.ErasureCodec:createBlockGrouper()" : [ "setSchema", "getSchema" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:getMaximumReference(java.lang.String)" : [ "getInnerStatistics" ],
  "org.apache.hadoop.util.KMSUtil:createKeyProvider(org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "getKeyProviderUri", "createKeyProviderFromUri" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:numOpenConnectionsPerUser()" : [ "getNumOpenConnectionsPerUser" ],
  "org.apache.hadoop.security.ShellBasedUnixGroupsNetgroupMapping:cacheGroupsRefresh()" : [ "getNetgroupNames", "clear", "cacheGroupsAdd" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:createSnapshot(org.apache.hadoop.fs.Path,java.lang.String)" : [ "createSnapshot" ],
  "org.apache.hadoop.fs.shell.find.Find:buildDescription(org.apache.hadoop.fs.shell.find.ExpressionFactory)" : [ "<init>", "createExpression" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:reset()" : [ "getInnerStatistics" ],
  "org.apache.hadoop.metrics2.sink.ganglia.GangliaSink31:emitMetric(java.lang.String,java.lang.String,java.lang.String,java.lang.String,org.apache.hadoop.metrics2.sink.ganglia.GangliaConf,org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink$GangliaSlope)" : [ "getUnits", "getTmax", "getDmax" ],
  "org.apache.hadoop.ha.protocolPB.HAServiceProtocolServerSideTranslatorPB:transitionToStandby(org.apache.hadoop.thirdparty.protobuf.RpcController,org.apache.hadoop.ha.proto.HAServiceProtocolProtos$TransitionToStandbyRequestProto)" : [ "convert" ],
  "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter:doFilter(javax.servlet.FilterChain,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)" : [ "toLowerCase", "createRemoteUser", "createProxyUser", "authorize", "createServletExceptionResponse" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:isFile(org.apache.commons.net.ftp.FTPClient,org.apache.hadoop.fs.Path)" : [ "<init>", "isFile", "getFileStatus" ],
  "org.apache.hadoop.io.serializer.SerializationFactory:getDeserializer(java.lang.Class)" : [ "getSerialization" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner:upperBound(byte[],int,int)" : [ "<init>", "seekTo" ],
  "org.apache.hadoop.fs.ChecksumFileSystem:createNonRecursive(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,boolean,int,short,long,org.apache.hadoop.util.Progressable)" : [ "create" ],
  "org.apache.hadoop.ha.SshFenceByTcpPort:createSession(java.lang.String,org.apache.hadoop.ha.SshFenceByTcpPort$Args)" : [ "getKeyFiles" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner$Entry:getKey(byte[])" : [ "getKey" ],
  "org.apache.hadoop.fs.ChecksumFileSystem$FsOperation:run(org.apache.hadoop.fs.Path)" : [ "getChecksumFile", "exists" ],
  "org.apache.hadoop.metrics2.lib.MutableCounterLong:incr()" : [ "incr" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenManager:renewToken(org.apache.hadoop.security.token.Token,java.lang.String)" : [ "renewToken" ],
  "org.apache.hadoop.security.SecurityUtil:setTokenService(org.apache.hadoop.security.token.Token,java.net.InetSocketAddress)" : [ "buildTokenService", "setService" ],
  "org.apache.hadoop.metrics2.impl.MBeanInfoBuilder:newAttrInfo(java.lang.String,java.lang.String,java.lang.String)" : [ "getAttrName" ],
  "org.apache.hadoop.conf.ReconfigurableBase:getChangedProperties(org.apache.hadoop.conf.Configuration,org.apache.hadoop.conf.Configuration)" : [ "parseChangedProperties" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker:invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[])" : [ "now", "curThreadTracer", "newScope", "methodToTraceString", "call", "constructRpcRequest", "addTimelineAnnotation", "close", "isAsynchronousMode", "getAsyncRpcResponse", "getReturnMessage" ],
  "org.apache.hadoop.util.SysInfoLinux:readProcStatFile()" : [ "updateElapsedJiffies", "getCurrentTime" ],
  "org.apache.hadoop.conf.Configuration:toString()" : [ "toString" ],
  "org.apache.hadoop.util.bloom.RetouchedBloomFilter:addFalsePositive(java.util.Collection)" : [ "addFalsePositive" ],
  "org.apache.hadoop.security.http.RestCsrfPreventionFilter:init(javax.servlet.FilterConfig)" : [ "parseMethodsToIgnore", "parseBrowserUserAgents" ],
  "org.apache.hadoop.util.WeakReferenceMap:create(java.lang.Object)" : [ "resolve", "warn", "noteLost" ],
  "org.apache.hadoop.fs.FileContext:getFileContext(org.apache.hadoop.fs.AbstractFileSystem)" : [ "<init>", "getFileContext" ],
  "org.apache.hadoop.conf.Configuration:getStrings(java.lang.String)" : [ "getStrings", "get" ],
  "org.apache.hadoop.io.file.tfile.ByteArray:<init>(byte[])" : [ "<init>" ],
  "org.apache.hadoop.io.compress.ZStandardCodec:createOutputStream(java.io.OutputStream)" : [ "createOutputStreamWithCodecPool" ],
  "org.apache.hadoop.io.Text:set(byte[])" : [ "set" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:truncate(org.apache.hadoop.fs.Path,long)" : [ "truncate" ],
  "org.apache.hadoop.fs.shell.CommandFormat:parse(java.lang.String[],int)" : [ "parse" ],
  "org.apache.hadoop.conf.Configuration:getPropsWithPrefix(java.lang.String)" : [ "getProps", "get" ],
  "org.apache.hadoop.io.SequenceFile$Reader:getKeyClass()" : [ "getClass", "getKeyClassName" ],
  "org.apache.hadoop.ipc.FairCallQueue$MetricsProxy:getOverflowedCalls()" : [ "getOverflowedCalls", "getCallQueue" ],
  "org.apache.hadoop.fs.impl.CombinedFileRange:<init>(long,long,org.apache.hadoop.fs.FileRange)" : [ "<init>", "append" ],
  "org.apache.hadoop.fs.FileUtil:canRead(java.io.File)" : [ "access" ],
  "org.apache.hadoop.conf.Configuration:getInstances(java.lang.String,java.lang.Class)" : [ "getClasses", "newInstance" ],
  "org.apache.hadoop.fs.HarFileSystem$HarFSDataInputStream$HarFsInputStream:read()" : [ "read" ],
  "org.apache.hadoop.fs.HarFileSystem:getUsed()" : [ "getUsed" ],
  "org.apache.hadoop.fs.FileContext:getDelegationTokens(org.apache.hadoop.fs.Path,java.lang.String)" : [ "getDelegationTokens", "resolveAbstractFileSystems" ],
  "org.apache.hadoop.fs.FileUtil:write(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,java.lang.CharSequence)" : [ "write" ],
  "org.apache.hadoop.fs.Path:makeQualified(java.net.URI,org.apache.hadoop.fs.Path)" : [ "<init>", "isAbsolute", "toUri", "normalizePath" ],
  "org.apache.hadoop.io.wrappedio.WrappedStatistics:iostatisticsSnapshot_fromJsonString(java.lang.String)" : [ "uncheckIOExceptions" ],
  "org.apache.hadoop.fs.FilterFs:renameSnapshot(org.apache.hadoop.fs.Path,java.lang.String,java.lang.String)" : [ "renameSnapshot" ],
  "org.apache.hadoop.conf.Configuration:getStrings(java.lang.String,java.lang.String[])" : [ "getStrings", "get" ],
  "org.apache.hadoop.http.HttpServer2:addDefaultApps(org.eclipse.jetty.server.handler.ContextHandlerCollection,java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "getBoolean", "setContextAttributes", "addNoCacheFilter" ],
  "org.apache.hadoop.security.ShellBasedIdMapping:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.security.ShellBasedUnixGroupsMapping:getGroupsSet(java.lang.String)" : [ "getUnixGroups" ],
  "org.apache.hadoop.io.BloomMapFile$Reader:<init>(org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.io.WritableComparator,org.apache.hadoop.conf.Configuration,boolean)" : [ "<init>" ],
  "org.apache.hadoop.io.DefaultStringifier:storeArray(org.apache.hadoop.conf.Configuration,java.lang.Object[],java.lang.String)" : [ "<init>", "getClass", "toString", "set", "close" ],
  "org.apache.hadoop.fs.shell.TouchCommands$Touch:touch(org.apache.hadoop.fs.shell.PathData)" : [ "exists", "create", "close", "updateTime" ],
  "org.apache.hadoop.util.SysInfoLinux:getNumVCoresUsed()" : [ "readProcStatFile", "getCpuTrackerUsagePercent" ],
  "org.apache.hadoop.util.KMSUtil:parseJSONEncKeyVersion(java.lang.String,java.util.Map)" : [ "<init>", "checkNotNull" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsLogging:logIOStatisticsAtLevel(org.slf4j.Logger,java.lang.String,java.lang.Object)" : [ "retrieveIOStatistics", "ioStatisticsToPrettyString", "logIOStatisticsAtDebug" ],
  "org.apache.hadoop.fs.AbstractFileSystem:hasPathCapability(org.apache.hadoop.fs.Path,java.lang.String)" : [ "validatePathCapabilityArgs", "makeQualified", "supportsSymlinks" ],
  "org.apache.hadoop.ipc.Server:getPriorityLevel()" : [ "getPriorityLevel" ],
  "org.apache.hadoop.ha.NodeFencer:parseMethods(org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "newArrayList", "parseMethod" ],
  "org.apache.hadoop.fs.statistics.MeanStatistic:set(org.apache.hadoop.fs.statistics.MeanStatistic)" : [ "setSamplesAndSum", "getSamples", "getSum" ],
  "org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor:executeTrailerState()" : [ "copyBytesToLocal", "readUIntLE" ],
  "org.apache.hadoop.fs.FileSystem:getStatistics()" : [ "getScheme" ],
  "org.apache.hadoop.io.DoubleWritable$Comparator:<init>()" : [ "<init>" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:getMetrics(org.apache.hadoop.metrics2.MetricsCollector,boolean)" : [ "addDecayedCallVolume", "addUniqueIdentityCount", "addTopNCallerSummary", "addAvgResponseTimePerPriority", "addCallVolumePerPriority", "addRawCallVolume", "addServiceUserDecayedCallVolume", "addServiceUserRawCallVolume" ],
  "org.apache.hadoop.fs.shell.PathData:openForSequentialIO()" : [ "openFile" ],
  "org.apache.hadoop.service.AbstractService:stop()" : [ "isInState", "enterState", "serviceStop", "noteFailure", "convert", "notifyListeners" ],
  "org.apache.hadoop.service.CompositeService:addIfService(java.lang.Object)" : [ "addService" ],
  "org.apache.hadoop.fs.permission.AclEntry:aclSpecToString(java.util.List)" : [ "toString" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:getXAttrs(org.apache.hadoop.fs.Path,java.util.List)" : [ "getXAttrs", "fullPath" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:setWorkingDirectory(org.apache.hadoop.fs.Path)" : [ "getUriPath", "makeAbsolute" ],
  "org.apache.hadoop.io.file.tfile.TFile$TFileIndex:lowerBound(org.apache.hadoop.io.file.tfile.RawComparable)" : [ "lowerBound" ],
  "org.apache.hadoop.net.NetUtils:getInputStream(java.net.Socket)" : [ "getInputStream" ],
  "org.apache.hadoop.metrics2.sink.RollingFileSystemSink:initFs()" : [ "<init>", "getFileSystem", "mkdirs", "stringifySecurityProperty", "checkAppend", "setInitialFlushTime" ],
  "org.apache.hadoop.ha.HAAdmin:getServiceState(org.apache.commons.cli.CommandLine)" : [ "printUsage", "getProxy", "getState" ],
  "org.apache.hadoop.io.ObjectWritable$NullInstance:write(java.io.DataOutput)" : [ "writeString" ],
  "org.apache.hadoop.ha.HAAdmin:confirmForceManual()" : [ "confirmPrompt" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:getCanonicalServiceName()" : [ "toString" ],
  "org.apache.hadoop.security.SaslOutputStream:write(byte[])" : [ "write" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:removeDefaultAcl(org.apache.hadoop.fs.Path)" : [ "removeDefaultAcl" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:fullPath(org.apache.hadoop.fs.Path)" : [ "<init>", "checkPath", "isAbsolute", "isRoot", "toUri" ],
  "org.apache.hadoop.fs.shell.AclCommands$GetfaclCommand:printExtendedAclEntry(org.apache.hadoop.fs.permission.AclStatus,org.apache.hadoop.fs.permission.FsPermission,org.apache.hadoop.fs.permission.AclEntry)" : [ "getName", "getType", "getPermission", "getEffectivePermission", "toStringStable" ],
  "org.apache.hadoop.io.compress.BZip2Codec$BZip2CompressionOutputStream:close()" : [ "close" ],
  "org.apache.hadoop.conf.Configuration:getTimeDuration(java.lang.String,java.lang.String,java.util.concurrent.TimeUnit,java.util.concurrent.TimeUnit)" : [ "get", "getTimeDurationHelper" ],
  "org.apache.hadoop.ipc.protocolPB.RefreshCallQueueProtocolClientSideTranslatorPB:close()" : [ "stopProxy" ],
  "org.apache.hadoop.fs.AbstractFileSystem:getUri(java.net.URI,java.lang.String,boolean,int)" : [ "<init>", "checkScheme" ],
  "org.apache.hadoop.util.VersionInfo:getBuildVersion()" : [ "_getBuildVersion" ],
  "org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider:createCredentialEntry(java.lang.String,char[])" : [ "innerSetCredential" ],
  "org.apache.hadoop.security.UserGroupInformation:getAuthenticationMethod()" : [ "getAuthenticationMethod" ],
  "org.apache.hadoop.fs.FileSystem:getServerDefaults(org.apache.hadoop.fs.Path)" : [ "getServerDefaults" ],
  "org.apache.hadoop.fs.FileSystem:getStatus()" : [ "getStatus" ],
  "org.apache.hadoop.io.BloomMapFile$Reader:initBloomFilter(org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getFileSystem", "open", "readFields", "closeStream" ],
  "org.apache.hadoop.metrics2.lib.MutableRollingAverages:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext:ifExists(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "<init>", "exists" ],
  "org.apache.hadoop.security.ProviderUtils:unnestUri(java.net.URI)" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:extractKMSPath(java.net.URI)" : [ "unnestUri" ],
  "org.apache.hadoop.http.HttpServer2$Builder:createHttpsChannelConnector(org.eclipse.jetty.server.Server,org.eclipse.jetty.server.HttpConfiguration)" : [ "createHttpChannelConnector", "getTrimmedStrings", "setEnabledProtocols", "getLong", "makeConfigurationChangeMonitor" ],
  "org.apache.hadoop.fs.FilterFs:getCanonicalServiceName()" : [ "getCanonicalServiceName" ],
  "org.apache.hadoop.fs.Options$HandleOpt:reference()" : [ "changed", "moved" ],
  "org.apache.hadoop.fs.FSOutputSummer:convertToByteStream(java.util.zip.Checksum,int)" : [ "int2byte" ],
  "org.apache.hadoop.fs.shell.CommandFactory:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.FilterFs:getLinkTarget(org.apache.hadoop.fs.Path)" : [ "getLinkTarget" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkRequired(boolean,java.lang.String)" : [ "checkArgument" ],
  "org.apache.hadoop.util.IntrusiveCollection:retainAll(java.util.Collection)" : [ "iterator" ],
  "org.apache.hadoop.service.AbstractService:resetGlobalListeners()" : [ "reset" ],
  "org.apache.hadoop.crypto.OpensslSm4CtrCryptoCodec:createEncryptor()" : [ "<init>", "getCipherSuite" ],
  "org.apache.hadoop.security.UserGroupInformation:loginUserFromKeytab(java.lang.String,java.lang.String)" : [ "isSecurityEnabled", "loginUserFromKeytabAndReturnUGI", "isKerberosKeyTabLoginRenewalEnabled", "spawnAutoRenewalThreadForKeytab", "setLoginUser" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:listStatus(org.apache.commons.net.ftp.FTPClient,org.apache.hadoop.fs.Path)" : [ "<init>", "makeAbsolute", "getFileStatus", "isFile", "toUri" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:bsR(long)" : [ "readAByte" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:getFsAction(int,org.apache.commons.net.ftp.FTPFile)" : [ "or" ],
  "org.apache.hadoop.fs.FileSystem:getFileBlockLocations(org.apache.hadoop.fs.Path,long,long)" : [ "getFileBlockLocations" ],
  "org.apache.hadoop.fs.impl.FutureDataInputStreamBuilderImpl:<init>(org.apache.hadoop.fs.FileContext,org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.conf.Configuration:getTrimmed(java.lang.String,java.lang.String)" : [ "getTrimmed" ],
  "org.apache.hadoop.io.wrappedio.WrappedStatistics:iostatisticsContext_aggregate(java.lang.Object)" : [ "retrieveIOStatistics", "getCurrentIOStatisticsContext" ],
  "org.apache.hadoop.ipc.Client:getRpcTimeout(org.apache.hadoop.conf.Configuration)" : [ "getInt" ],
  "org.apache.hadoop.util.SysInfoLinux:getCumulativeCpuTime()" : [ "getCumulativeCpuTime", "readProcStatFile" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker:getReturnMessage(java.lang.reflect.Method,org.apache.hadoop.ipc.RpcWritable$Buffer)" : [ "getReturnProtoType", "getValue" ],
  "org.apache.hadoop.io.compress.CompressionCodecFactory:getCodecByName(java.lang.String)" : [ "getCodecByClassName", "toLowerCase" ],
  "org.apache.hadoop.fs.FileUtil:fullyDelete(java.io.File,boolean)" : [ "grantPermissions", "deleteImpl" ],
  "org.apache.hadoop.fs.ChecksumFs$ChecksumFSInputChecker:<init>(org.apache.hadoop.fs.ChecksumFs,org.apache.hadoop.fs.Path,int)" : [ "<init>", "getReplication", "getRawFs", "getChecksumFile", "getBytesPerSum", "newCrc32" ],
  "org.apache.hadoop.io.VIntWritable:<init>(int)" : [ "set" ],
  "org.apache.hadoop.conf.Configuration:substituteVars(java.lang.String)" : [ "findSubVariable", "getenv", "getProperty", "getRaw" ],
  "org.apache.hadoop.ipc.RPC:getProxy(java.lang.Class,long,java.net.InetSocketAddress,org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory)" : [ "getProxy", "getProtocolProxy" ],
  "org.apache.hadoop.ha.HAServiceTarget:getProxy(org.apache.hadoop.conf.Configuration,int)" : [ "getProxyForAddress" ],
  "org.apache.hadoop.security.SaslPlainServer:getNegotiatedProperty(java.lang.String)" : [ "throwIfNotComplete" ],
  "org.apache.hadoop.fs.FileUtil:write(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,java.lang.Iterable,java.nio.charset.Charset)" : [ "createFile", "overwrite", "close" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.io.DefaultStringifier:store(org.apache.hadoop.conf.Configuration,java.lang.Object,java.lang.String)" : [ "<init>", "getClass", "set", "toString", "close" ],
  "org.apache.hadoop.service.ServiceStateModel:isValidStateTransition(org.apache.hadoop.service.Service$STATE,org.apache.hadoop.service.Service$STATE)" : [ "getValue" ],
  "org.apache.hadoop.io.compress.snappy.SnappyCompressor:<init>()" : [ "<init>" ],
  "org.apache.hadoop.util.PriorityQueue:adjustTop()" : [ "downHeap" ],
  "org.apache.hadoop.fs.FileSystem:isFile(org.apache.hadoop.fs.Path)" : [ "isFile" ],
  "org.apache.hadoop.fs.GlobFilter:init(java.lang.String,org.apache.hadoop.fs.PathFilter)" : [ "<init>" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:truncate(org.apache.hadoop.fs.Path,long)" : [ "<init>", "getFileStatus", "isDirectory", "getLen", "pathToFile" ],
  "org.apache.hadoop.fs.FileSystem:primitiveCreate(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,java.util.EnumSet,int,short,long,org.apache.hadoop.util.Progressable,org.apache.hadoop.fs.Options$ChecksumOpt)" : [ "exists", "validate" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:<init>(org.apache.hadoop.fs.viewfs.InodeTree$INodeDir,long,org.apache.hadoop.security.UserGroupInformation,java.net.URI,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.viewfs.InodeTree)" : [ "<init>", "getBoolean" ],
  "org.apache.hadoop.fs.store.DataBlocks$ByteBufferBlockFactory$ByteBufferBlock:write(byte[],int,int)" : [ "write", "remainingCapacity" ],
  "org.apache.hadoop.fs.FileSystem:getReplication(org.apache.hadoop.fs.Path)" : [ "getReplication" ],
  "org.apache.hadoop.fs.RawLocalFileSystem$DeprecatedRawLocalFileStatus:getOwner()" : [ "getOwner", "isPermissionLoaded", "loadPermissionInfo" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler$MetricsProxy:getResponseTimeCountInLastWindow()" : [ "getResponseTimeCountInLastWindow" ],
  "org.apache.hadoop.metrics2.impl.MetricsSourceAdapter:setAttrCacheTag(org.apache.hadoop.metrics2.MetricsTag,int)" : [ "tagName", "name", "value" ],
  "org.apache.hadoop.conf.Configuration:getProps()" : [ "loadProps" ],
  "org.apache.hadoop.io.file.tfile.Compression$Algorithm$2:getCodec()" : [ "setConf" ],
  "org.apache.hadoop.io.VIntWritable:write(java.io.DataOutput)" : [ "writeVInt" ],
  "org.apache.hadoop.util.bloom.RetouchedBloomFilter:clearBit(int)" : [ "removeKey" ],
  "org.apache.hadoop.fs.shell.Command:processPaths(org.apache.hadoop.fs.shell.PathData,org.apache.hadoop.fs.shell.PathData[])" : [ "processPathInternal", "displayError" ],
  "org.apache.hadoop.io.SecureIOUtils:forceSecureOpenForRead(java.io.File,java.lang.String,java.lang.String)" : [ "getFstat", "checkStat", "getOwner", "getGroup" ],
  "org.apache.hadoop.util.dynamic.DynMethods$StaticMethod:invokeChecked(java.lang.Object[])" : [ "invokeChecked" ],
  "org.apache.hadoop.util.dynamic.DynMethods$UnboundMethod:invoke(java.lang.Object,java.lang.Object[])" : [ "invokeChecked", "throwIfInstance" ],
  "org.apache.hadoop.util.GenericOptionsParser:expandWildcard(java.util.List,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.FileSystem)" : [ "isDirectory", "getJarsInDirectory", "toString", "getLocal", "makeQualified" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:setStoragePolicy(org.apache.hadoop.fs.Path,java.lang.String)" : [ "setStoragePolicy", "fullPath" ],
  "org.apache.hadoop.fs.http.HttpsFileSystem:getUri()" : [ "getUri" ],
  "org.apache.hadoop.util.Shell:getGroupsForUserCommand(java.lang.String)" : [ "getWinUtilsPath", "bashQuote" ],
  "org.apache.hadoop.security.ssl.SSLFactory:configure(java.net.HttpURLConnection)" : [ "createSSLSocketFactory", "getHostnameVerifier" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsContextIntegration:createNewInstance(java.lang.Long)" : [ "<init>" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:rename(org.apache.commons.net.ftp.FTPClient,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "<init>", "makeAbsolute", "exists", "getName", "getParent", "toUri", "isParentOf" ],
  "org.apache.hadoop.util.functional.RemoteIterators$MaybeClose:<init>(java.lang.Object)" : [ "<init>" ],
  "org.apache.hadoop.io.SequenceFile$Reader$FileOption:<init>(org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:bindCommandOptions()" : [ "createOptions" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:<init>(java.io.InputStream)" : [ "<init>" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:<init>()" : [ "<init>", "getInitialWorkingDirectory" ],
  "org.apache.hadoop.security.WhitelistBasedResolver:getServerProperties(java.net.InetAddress)" : [ "isIn" ],
  "org.apache.hadoop.io.MapFile$Reader:getClosest(org.apache.hadoop.io.WritableComparable,org.apache.hadoop.io.Writable,boolean)" : [ "seekInternal", "getCurrentValue" ],
  "org.apache.hadoop.io.SequenceFile$Writer$BufferSizeOption:<init>(int)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getStatus()" : [ "getStatus" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:handleEmptyDstDirectoryOnWindows(org.apache.hadoop.fs.Path,java.io.File,org.apache.hadoop.fs.Path,java.io.File)" : [ "getFileStatus", "isDirectory", "delete" ],
  "org.apache.hadoop.ipc.WeightedRoundRobinMultiplexer:<init>(int,java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "getInts", "getDefaultQueueWeights" ],
  "org.apache.hadoop.util.GenericOptionsParser:<init>(org.apache.commons.cli.Options,java.lang.String[])" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFsLocatedFileStatus:equals(java.lang.Object)" : [ "equals" ],
  "org.apache.hadoop.ipc.Server:setClientBackoffEnabled(boolean)" : [ "setClientBackoffEnabled" ],
  "org.apache.hadoop.metrics2.impl.MetricsSourceAdapter:<init>(java.lang.String,java.lang.String,java.lang.String,org.apache.hadoop.metrics2.MetricsSource,java.lang.Iterable,org.apache.hadoop.metrics2.MetricsFilter,org.apache.hadoop.metrics2.MetricsFilter,long,boolean)" : [ "<init>", "checkNotNull", "checkArg" ],
  "org.apache.hadoop.metrics2.lib.MetricsAnnotations:newSourceBuilder(java.lang.Object)" : [ "<init>", "getAnnotatedMetricsFactory" ],
  "org.apache.hadoop.util.ZKUtil:parseACLs(java.lang.String)" : [ "<init>", "newArrayList", "getPermFromString" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:<init>(java.io.InputStream,org.apache.hadoop.io.compress.SplittableCompressionCodec$READ_MODE,boolean)" : [ "<init>", "init", "skipToNextBlockMarker", "changeStateToProcessABlock" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:addServiceUserDecayedCallVolume(org.apache.hadoop.metrics2.MetricsRecordBuilder)" : [ "info", "getTotalServiceUserCallVolume" ],
  "org.apache.hadoop.fs.crypto.CryptoFSDataInputStream:<init>(org.apache.hadoop.fs.FSDataInputStream,org.apache.hadoop.crypto.CryptoCodec,byte[],byte[])" : [ "<init>" ],
  "org.apache.hadoop.ipc.Server:bind(java.net.ServerSocket,java.net.InetSocketAddress,int)" : [ "bind" ],
  "org.apache.hadoop.fs.FsShell:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.security.SaslInputStream:read(byte[])" : [ "read" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:getAclStatus(org.apache.hadoop.fs.Path)" : [ "getAclStatus", "fullPath" ],
  "org.apache.hadoop.io.DataOutputOutputStream:constructOutputStream(java.io.DataOutput)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem:getNflyTmpPath(org.apache.hadoop.fs.Path)" : [ "<init>", "getParent", "getName" ],
  "org.apache.hadoop.util.JsonSerialization:toString(java.lang.Object)" : [ "checkArgument", "toJson" ],
  "org.apache.hadoop.security.HttpCrossOriginFilterInitializer:getEnabledConfigKey()" : [ "getPrefix" ],
  "org.apache.hadoop.util.MachineList:<init>(java.lang.String,org.apache.hadoop.util.MachineList$InetAddressFactory)" : [ "<init>", "getTrimmedStringCollection" ],
  "org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation:addMetricIfNotExists(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.security.SecurityUtil$QualifiedHostResolver:getByNameWithSearch(java.lang.String)" : [ "getByExactName" ],
  "org.apache.hadoop.security.authorize.ProxyUsers:authorize(org.apache.hadoop.security.UserGroupInformation,java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "authorize" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:getDataWithRetries(java.lang.String,boolean,org.apache.zookeeper.data.Stat)" : [ "zkDoWithRetries" ],
  "org.apache.hadoop.fs.FileSystem$Statistics:getLargeReadOps()" : [ "<init>", "visitAll" ],
  "org.apache.hadoop.fs.FileSystem:openFile(org.apache.hadoop.fs.PathHandle)" : [ "createDataInputStreamBuilder" ],
  "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker:<init>(org.apache.hadoop.fs.ChecksumFileSystem,org.apache.hadoop.fs.Path,int)" : [ "<init>", "getReplication", "getRawFileSystem", "getChecksumFile", "getBytesPerSum", "newCrc32" ],
  "org.apache.hadoop.io.compress.ZStandardCodec:getCompressorType()" : [ "checkNativeCodeLoaded" ],
  "org.apache.hadoop.net.ScriptBasedMapping:getConf()" : [ "getRawMapping" ],
  "org.apache.hadoop.metrics2.lib.MethodMetric$1:snapshot(org.apache.hadoop.metrics2.MetricsRecordBuilder,boolean)" : [ "isInt" ],
  "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker:checkBytes(java.nio.ByteBuffer,long,java.nio.ByteBuffer,long,int,org.apache.hadoop.fs.Path)" : [ "<init>", "findChecksumOffset" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:mkdirs(org.apache.hadoop.fs.Path)" : [ "mkdirsWithOptionalPermission" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:reencryptEncryptedKey(org.apache.hadoop.crypto.key.KeyProviderCryptoExtension$EncryptedKeyVersion)" : [ "checkNotNull", "getEncryptionKeyVersionName", "getEncryptedKeyIv", "getEncryptedKeyVersion", "checkArgument", "getVersionName", "getEncryptionKeyName", "getMaterial", "createURL", "createConnection", "call", "parseJSONEncKeyVersion" ],
  "org.apache.hadoop.log.LogLevel$CLI:parseProtocolArgs(java.lang.String[],int)" : [ "<init>", "isValidProtocol" ],
  "org.apache.hadoop.security.LdapGroupsMapping:lookupGroup(javax.naming.directory.SearchResult,javax.naming.directory.DirContext,int)" : [ "resolveCustomGroupFilterArgs", "lookupPosixGroup", "getGroupNames", "goUpGroupHierarchy" ],
  "org.apache.hadoop.security.alias.KeyStoreProvider:stashOriginalFilePermissions()" : [ "getPermission" ],
  "org.apache.hadoop.fs.BufferedFSInputStream:maxReadSizeForVectorReads()" : [ "maxReadSizeForVectorReads" ],
  "org.apache.hadoop.metrics2.impl.MetricsSinkAdapter:putMetrics(org.apache.hadoop.metrics2.impl.MetricsBuffer,long)" : [ "enqueue", "refreshQueueSizeGauge", "incr" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:addAvgResponseTimePerPriority(org.apache.hadoop.metrics2.MetricsRecordBuilder)" : [ "info" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:compareKeys(byte[],int,int,byte[],int,int)" : [ "isSorted", "compare" ],
  "org.apache.hadoop.security.CompositeGroupsMapping:addMappingProvider(java.lang.String,java.lang.Class)" : [ "prepareConf", "newInstance" ],
  "org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider:getAliases()" : [ "getPathAsString" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RSLegacyRawDecoder:<init>(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>", "getFieldSize", "getPrimitivePower" ],
  "org.apache.hadoop.util.functional.LazyAtomicReference:apply()" : [ "eval" ],
  "org.apache.hadoop.fs.impl.prefetch.SingleFilePerBlockCache:getTempFilePath(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.LocalDirAllocator)" : [ "getLocalPathForWrite", "getParent", "toUri", "getName" ],
  "org.apache.hadoop.io.WritableName:getClass(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "getClassByName" ],
  "org.apache.hadoop.conf.Configuration:readFields(java.io.DataInput)" : [ "clear", "readVInt", "readString", "set", "readCompressedStringArray", "putIntoUpdatingResource" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:addDeferredRpcProcessingTime(long)" : [ "add" ],
  "org.apache.hadoop.fs.FileSystem$Cache$Key:equals(java.lang.Object)" : [ "isEqual" ],
  "org.apache.hadoop.fs.shell.Display$Checksum:processOptions(java.util.LinkedList)" : [ "<init>", "parse", "getOpt" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:getMetaBlock(java.lang.String)" : [ "getMetaBlock" ],
  "org.apache.hadoop.security.KDiag:printConfOpt(java.lang.String)" : [ "println", "get" ],
  "org.apache.hadoop.fs.FilterFs:createSymlink(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,boolean)" : [ "createSymlink" ],
  "org.apache.hadoop.fs.FileSystem:createDataInputStreamBuilder(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.PathHandle)" : [ "<init>" ],
  "org.apache.hadoop.http.HttpServer2:userHasAdministratorAccess(javax.servlet.ServletContext,java.lang.String)" : [ "createRemoteUser", "isUserAllowed" ],
  "org.apache.hadoop.util.ReflectionUtils:logThreadInfo(org.slf4j.Logger,java.lang.String,long)" : [ "monotonicNow", "printThreadInfo" ],
  "org.apache.hadoop.util.DiskChecker:doDiskIo(java.io.File)" : [ "<init>", "getFileNameForDiskIoCheck", "diskIoCheckWithoutNativeIo" ],
  "org.apache.hadoop.security.KDiag:usage()" : [ "arg" ],
  "org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor:processBasicHeader()" : [ "readUShortLE", "readUByte" ],
  "org.apache.hadoop.fs.BlockLocation:<init>(java.lang.String[],java.lang.String[],long,long)" : [ "<init>" ],
  "org.apache.hadoop.crypto.OpensslSm4CtrCryptoCodec:createDecryptor()" : [ "<init>", "getCipherSuite" ],
  "org.apache.hadoop.fs.ContentSummary:hashCode()" : [ "hashCode", "getLength", "getFileCount", "getDirectoryCount", "getSnapshotLength", "getSnapshotFileCount", "getSnapshotDirectoryCount", "getSnapshotSpaceConsumed", "getErasureCodingPolicy" ],
  "org.apache.hadoop.io.OutputBuffer:<init>()" : [ "<init>" ],
  "org.apache.hadoop.io.WritableUtils:readStringArray(java.io.DataInput)" : [ "readString" ],
  "org.apache.hadoop.conf.Configuration:loadResource(java.util.Properties,org.apache.hadoop.conf.Configuration$Resource,boolean)" : [ "<init>", "getResource", "getName", "overlay", "getStreamReader", "parse", "loadProperty", "isParserRestricted" ],
  "org.apache.hadoop.fs.DF:getMount()" : [ "verifyExitCode", "parseOutput" ],
  "org.apache.hadoop.fs.impl.StoreImplementationUtils:hasCapability(java.io.InputStream,java.lang.String)" : [ "objectHasCapability" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier:equals(java.lang.Object)" : [ "isEqual" ],
  "org.apache.hadoop.security.SaslInputStream:readMoreData()" : [ "unsignedBytesToInt", "disposeSasl" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.NativeRSRawErasureCoderFactory:createEncoder(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.DummyRawDecoder:<init>(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.io.BytesWritable:readFields(java.io.DataInput)" : [ "setSize" ],
  "org.apache.hadoop.fs.shell.find.Find:processOptions(java.util.LinkedList)" : [ "<init>", "parse", "getOpt", "getOptions", "setFollowLink", "setFollowArgLink", "parseExpression", "getExpression", "setRootExpression" ],
  "org.apache.hadoop.util.FindClass:loadClass(java.lang.String)" : [ "getClass", "loadedClass", "printStack" ],
  "org.apache.hadoop.security.AuthenticationFilterInitializer:initFilter(org.apache.hadoop.http.FilterContainer,org.apache.hadoop.conf.Configuration)" : [ "getFilterConfigMap" ],
  "org.apache.hadoop.io.MapFile$Merger:open(org.apache.hadoop.fs.Path[],org.apache.hadoop.fs.Path)" : [ "<init>", "getKeyClass", "getValueClass", "get", "keyClass", "valueClass" ],
  "org.apache.hadoop.security.authorize.AccessControlList:isUserInList(org.apache.hadoop.security.UserGroupInformation)" : [ "getShortUserName", "getGroupsSet", "getRealUser" ],
  "org.apache.hadoop.fs.LocalFileSystem:copyToLocalFile(boolean,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "copy" ],
  "org.apache.hadoop.ipc.Client$Connection:updateAddress()" : [ "createSocketAddrForHost", "setAddress", "getTicket", "getUserName" ],
  "org.apache.hadoop.fs.FileSystemStorageStatistics:getLong(java.lang.String)" : [ "fetch", "getData" ],
  "org.apache.hadoop.security.UserGroupInformation:getTGT()" : [ "isOriginalTGT" ],
  "org.apache.hadoop.security.token.Token:privateClone(org.apache.hadoop.io.Text)" : [ "<init>" ],
  "org.apache.hadoop.ipc.Client:close()" : [ "stop" ],
  "org.apache.hadoop.fs.shell.XAttrCommands$SetfattrCommand:processOptions(java.util.LinkedList)" : [ "<init>", "popOptionWithArgument", "decodeValue" ],
  "org.apache.hadoop.security.LdapGroupsMapping:getPasswordForBindUser(java.lang.String)" : [ "get", "getPasswordFromCredentialProviders", "getPassword", "extractPassword" ],
  "org.apache.hadoop.ipc.ProtocolSignature:getProtocolSignature(org.apache.hadoop.ipc.VersionedProtocol,java.lang.String,long,int)" : [ "getProtocolSignature" ],
  "org.apache.hadoop.util.StringUtils:byteToHexString(byte)" : [ "byteToHexString" ],
  "org.apache.hadoop.crypto.key.KeyProviderCryptoExtension$DefaultCryptoExtension:decryptEncryptedKey(org.apache.hadoop.crypto.key.KeyProviderCryptoExtension$EncryptedKeyVersion)" : [ "decryptEncryptedKey", "getEncryptionKeyVersionName", "checkNotNull", "checkArgument", "getEncryptedKeyVersion", "getVersionName", "getInstance", "getConf" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Reader$BlockReader:<init>(org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState)" : [ "getInputStream" ],
  "org.apache.hadoop.util.bloom.CountingBloomFilter:or(org.apache.hadoop.util.bloom.Filter)" : [ "buckets2words" ],
  "org.apache.hadoop.fs.XAttrCodec:encodeValue(byte[],org.apache.hadoop.fs.XAttrCodec)" : [ "checkNotNull" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:addRpcResponseTime(long)" : [ "add" ],
  "org.apache.hadoop.security.token.Token:copyToken()" : [ "<init>" ],
  "org.apache.hadoop.util.Shell:getHadoopHome()" : [ "getHadoopHomeDir" ],
  "org.apache.hadoop.fs.permission.FsPermission$ImmutableFsPermission:<init>(short)" : [ "<init>" ],
  "org.apache.hadoop.fs.FsShell:registerCommands(org.apache.hadoop.fs.shell.CommandFactory)" : [ "registerCommands" ],
  "org.apache.hadoop.io.SequenceFile:createWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.util.Progressable,org.apache.hadoop.io.SequenceFile$Metadata)" : [ "createWriter", "file", "keyClass", "valueClass", "compression", "progressable", "metadata" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:launchService(org.apache.hadoop.conf.Configuration,java.util.List,boolean,boolean)" : [ "launchService" ],
  "org.apache.hadoop.net.DomainNameResolverFactory:newInstance(org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "newInstance", "getClass" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:getEnclosingRoot(org.apache.hadoop.fs.Path)" : [ "<init>", "getEnclosingRoot", "resolve", "toString", "depth" ],
  "org.apache.hadoop.ha.HAServiceProtocolHelper:monitorHealth(org.apache.hadoop.ha.HAServiceProtocol,org.apache.hadoop.ha.HAServiceProtocol$StateChangeRequestInfo)" : [ "unwrapRemoteException" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2:getProxy(java.lang.Class,long,java.net.InetSocketAddress,org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory,int)" : [ "getProxy" ],
  "org.apache.hadoop.io.retry.RetryProxy:create(java.lang.Class,org.apache.hadoop.io.retry.FailoverProxyProvider,java.util.Map,org.apache.hadoop.io.retry.RetryPolicy)" : [ "<init>" ],
  "org.apache.hadoop.util.GenericOptionsParser:processGeneralOptions(org.apache.commons.cli.CommandLine)" : [ "<init>", "setDefaultUri", "set", "addResource", "validateFiles", "getLibJars", "setClassLoader", "getClassLoader", "setBoolean", "getLocal", "getCurrentUser", "addCredentials", "readTokenStorageFile", "toString" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedIO:pathCapabilities_hasPathCapability(java.lang.Object,org.apache.hadoop.fs.Path,java.lang.String)" : [ "available", "invoke" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RawErasureEncoder:encode(java.nio.ByteBuffer[],java.nio.ByteBuffer[])" : [ "<init>", "convertToByteArrayState" ],
  "org.apache.hadoop.service.ServiceStateModel:enterState(org.apache.hadoop.service.Service$STATE)" : [ "checkStateTransition" ],
  "org.apache.hadoop.fs.FileSystem:setDefaultUri(org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "setDefaultUri", "fixName" ],
  "org.apache.hadoop.security.token.DtFileOperations:printCredentials(org.apache.hadoop.security.Credentials,org.apache.hadoop.io.Text,java.io.PrintStream)" : [ "getAllTokens", "matchAlias", "decodeIdentifier", "getKind", "getService", "getRenewer", "formatDate", "getMaxDate", "encodeToUrlString" ],
  "org.apache.hadoop.ipc.Server$Connection:close()" : [ "disposeSasl", "cleanupWithLogger" ],
  "org.apache.hadoop.util.GcTimeMonitor:run()" : [ "setValues", "calculateGCTimePercentageWithinObservedInterval", "clone" ],
  "org.apache.hadoop.fs.LocalDirAllocator:getAllLocalPathsToRead(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "getAllLocalPathsToRead", "obtainContext" ],
  "org.apache.hadoop.conf.Configuration:writeXml(java.io.Writer)" : [ "writeXml" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory:createProviders(org.apache.hadoop.conf.Configuration,java.net.URL,int,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.security.SaslRpcClient:getServerToken(org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth)" : [ "getTokenInfo", "buildTokenService", "getTokens" ],
  "org.apache.hadoop.ipc.RPC$Server:registerProtocolAndImpl(org.apache.hadoop.ipc.RPC$RpcKind,java.lang.Class,java.lang.Object)" : [ "<init>", "getProtocolName", "getProtocolVersion", "getProtocolImplMap", "getClientPrincipal", "createRemoteUser" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:init()" : [ "<init>", "bsPutUByte", "initBlock" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:getXAttr(org.apache.hadoop.fs.Path,java.lang.String)" : [ "getXAttr", "fullPath" ],
  "org.apache.hadoop.fs.shell.FsUsage$Df:processArguments(java.util.LinkedList)" : [ "<init>", "setUsagesTable", "getUsagesTable", "setRightAlign", "isEmpty", "printToStream" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL:getDelegationToken(java.net.URL,org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL$Token,java.lang.String)" : [ "getDelegationToken" ],
  "org.apache.hadoop.security.UserGroupInformation:reloginFromTicketCache()" : [ "reloginFromTicketCache" ],
  "org.apache.hadoop.http.HttpServer2Metrics:remove()" : [ "removeSourceName" ],
  "org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory:init(org.apache.hadoop.security.ssl.SSLFactory$Mode)" : [ "getBoolean", "getLong", "resolvePropertyName", "get", "createKeyManagersFromConfiguration", "createTrustManagersFromConfiguration" ],
  "org.apache.hadoop.fs.FilterFileSystem:msync()" : [ "msync" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:modifyAclEntries(org.apache.hadoop.fs.Path,java.util.List)" : [ "modifyAclEntries", "resolve", "getUriPath" ],
  "org.apache.hadoop.fs.statistics.MeanStatistic:toString()" : [ "mean" ],
  "org.apache.hadoop.metrics2.util.MBeans:register(java.lang.String,java.lang.String,java.util.Map,java.lang.Object)" : [ "checkNotNull", "getMBeanName" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:removeDefaultAcl(org.apache.hadoop.fs.Path)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.crypto.key.KeyProviderCryptoExtension$DefaultCryptoExtension:decryptEncryptedKey(org.apache.hadoop.crypto.Decryptor,org.apache.hadoop.crypto.key.KeyProvider$KeyVersion,org.apache.hadoop.crypto.key.KeyProviderCryptoExtension$EncryptedKeyVersion)" : [ "<init>", "deriveIV", "getEncryptedKeyIv", "getMaterial", "getEncryptedKeyVersion", "getName" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Reader$BlockReader:getStartPos()" : [ "getBlockRegion", "getOffset" ],
  "org.apache.hadoop.ipc.CallerContext$Builder:append(java.lang.String,java.lang.String)" : [ "isValid" ],
  "org.apache.hadoop.fs.store.DataBlocks$ByteBufferBlockFactory$ByteBufferBlock:dataSize()" : [ "bufferCapacityUsed" ],
  "org.apache.hadoop.fs.FSInputChecker:<init>(org.apache.hadoop.fs.Path,int,boolean,java.util.zip.Checksum,int,int)" : [ "<init>", "set" ],
  "org.apache.hadoop.fs.HarFileSystem:decodeHarURI(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "getDefaultUri" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:createInternal(org.apache.hadoop.fs.Path,java.util.EnumSet,org.apache.hadoop.fs.permission.FsPermission,int,short,long,org.apache.hadoop.util.Progressable,org.apache.hadoop.fs.Options$ChecksumOpt,boolean)" : [ "readOnlyMountTable" ],
  "org.apache.hadoop.security.KDiag:exec(org.apache.hadoop.conf.Configuration,java.lang.String[])" : [ "<init>", "run", "close" ],
  "org.apache.hadoop.util.AutoCloseableLock:close()" : [ "release" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:setAcl(org.apache.hadoop.fs.Path,java.util.List)" : [ "setAcl", "fullPath" ],
  "org.apache.hadoop.io.MapFile$Merger:close()" : [ "close", "closeStream" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:getServerDefaults(org.apache.hadoop.fs.Path)" : [ "getServerDefaults" ],
  "org.apache.hadoop.fs.shell.FsUsage$Du:processArguments(java.util.LinkedList)" : [ "<init>", "setUsagesTable", "getUsagesTable", "isEmpty", "printToStream" ],
  "org.apache.hadoop.io.SequenceFile$Writer:hflush()" : [ "hflush" ],
  "org.apache.hadoop.io.compress.CodecPool:returnCompressor(org.apache.hadoop.io.compress.Compressor)" : [ "payback", "updateLeaseCount" ],
  "org.apache.hadoop.fs.HarFileSystem:initialize(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>", "initializeMetadataCache", "decodeHarURI", "archivePath", "get", "toUri", "getHarAuth", "exists", "getModificationTime", "getMasterIndexTimestamp", "getArchiveIndexTimestamp" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Reader:getBlockCount()" : [ "getBlockRegionList" ],
  "org.apache.hadoop.util.bloom.DynamicBloomFilter:<init>(int,int,int,int)" : [ "<init>" ],
  "org.apache.hadoop.io.erasurecode.grouper.BlockGrouper:anyRecoverable(org.apache.hadoop.io.erasurecode.ECBlockGroup)" : [ "getErasedCount", "getRequiredNumParityBlocks" ],
  "org.apache.hadoop.io.InputBuffer:getPosition()" : [ "getPosition" ],
  "org.apache.hadoop.security.http.RestCsrfPreventionFilter:handleHttpInteraction(org.apache.hadoop.security.http.RestCsrfPreventionFilter$HttpInteraction)" : [ "isBrowser" ],
  "org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread:<init>(org.apache.hadoop.fs.CachingGetSpaceUsed,boolean)" : [ "run" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:reJoinElectionAfterFailureToBecomeActive()" : [ "reJoinElection" ],
  "org.apache.hadoop.util.dynamic.DynMethods$UnboundMethod:invokeStatic(java.lang.Object[])" : [ "checkState", "isStatic", "toString", "invoke" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker:close()" : [ "stopClient" ],
  "org.apache.hadoop.io.SequenceFile$Reader:close()" : [ "returnDecompressor" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:initializeMountedFileSystems(java.util.List)" : [ "getTargetFileSystem" ],
  "org.apache.hadoop.io.compress.zlib.ZlibDecompressor$ZlibDirectDecompressor:reset()" : [ "reset" ],
  "org.apache.hadoop.security.SaslRpcServer:create(org.apache.hadoop.ipc.Server$Connection,java.util.Map,org.apache.hadoop.security.token.SecretManager)" : [ "<init>", "getCurrentUser", "getUserName", "doAs" ],
  "org.apache.hadoop.metrics2.lib.MutableMetricsFactory:getInfo(java.lang.Class,org.apache.hadoop.metrics2.annotation.Metrics)" : [ "info" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine$RpcProtobufRequest:<init>(org.apache.hadoop.ipc.protobuf.ProtobufRpcEngineProtos$RequestHeaderProto,com.google.protobuf.Message)" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.kms.ValueQueue:readUnlock(java.lang.String)" : [ "getLock" ],
  "org.apache.hadoop.fs.shell.find.BaseExpression:addArguments(java.util.Deque,int)" : [ "addArgument" ],
  "org.apache.hadoop.crypto.key.KeyProviderExtension:invalidateCache(java.lang.String)" : [ "invalidateCache" ],
  "org.apache.hadoop.io.WeakReferencedElasticByteBufferPool:getBuffer(boolean,int)" : [ "<init>", "getBufferTree" ],
  "org.apache.hadoop.util.OperationDuration:asDuration()" : [ "value" ],
  "org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext$PathIterator:<init>(org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.fs.Path[])" : [ "advance" ],
  "org.apache.hadoop.metrics2.lib.MutableGaugeFloat:incr()" : [ "incr" ],
  "org.apache.hadoop.io.SequenceFile$Reader:readBlock()" : [ "seek", "readVInt", "getPos", "readBuffer" ],
  "org.apache.hadoop.security.KDiag:dumpKeytab(java.io.File)" : [ "title", "verifyFileIsValid", "println", "endln" ],
  "org.apache.hadoop.fs.ContentSummary$Builder:build()" : [ "fileAndDirectoryCount" ],
  "org.apache.hadoop.ipc.WritableRpcEngine:getProxy(java.lang.Class,long,java.net.InetSocketAddress,org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory,int,org.apache.hadoop.io.retry.RetryPolicy,java.util.concurrent.atomic.AtomicBoolean,org.apache.hadoop.ipc.AlignmentContext)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.SnapshotCommands:registerCommands(org.apache.hadoop.fs.shell.CommandFactory)" : [ "addClass" ],
  "org.apache.hadoop.fs.FileSystem:create(org.apache.hadoop.fs.Path,boolean,int,short,long,org.apache.hadoop.util.Progressable)" : [ "applyUMask", "getFileDefault", "getUMask" ],
  "org.apache.hadoop.fs.viewfs.ConfigUtil:setIsNestedMountPointSupported(org.apache.hadoop.conf.Configuration,boolean)" : [ "setBoolean" ],
  "org.apache.hadoop.crypto.key.kms.ValueQueue:drain(java.lang.String)" : [ "deleteByName", "writeLock", "writeUnlock" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding:wrap(org.apache.hadoop.fs.statistics.IOStatistics)" : [ "<init>" ],
  "org.apache.hadoop.io.SetFile$Writer:append(org.apache.hadoop.io.WritableComparable)" : [ "get" ],
  "org.apache.hadoop.io.Text:readFields(java.io.DataInput)" : [ "readVInt", "readWithKnownLength" ],
  "org.apache.hadoop.io.ElasticByteBufferPool:putBuffer(java.nio.ByteBuffer)" : [ "<init>", "getBufferTree" ],
  "org.apache.hadoop.util.CrcUtil:intToBytes(int)" : [ "writeInt" ],
  "org.apache.hadoop.fs.impl.prefetch.BufferPool:find(int)" : [ "getBlockNumber", "stateEqualsOneOf" ],
  "org.apache.hadoop.ha.protocolPB.HAServiceProtocolServerSideTranslatorPB:convert(org.apache.hadoop.ha.proto.HAServiceProtocolProtos$HAStateChangeRequestInfoProto)" : [ "<init>" ],
  "org.apache.hadoop.fs.RawPathHandle:hashCode()" : [ "bytes" ],
  "org.apache.hadoop.io.ArrayWritable:<init>(java.lang.String[])" : [ "<init>" ],
  "org.apache.hadoop.fs.http.HttpFileSystem:getUri()" : [ "getUri" ],
  "org.apache.hadoop.ipc.Client:call(org.apache.hadoop.ipc.RPC$RpcKind,org.apache.hadoop.io.Writable,org.apache.hadoop.ipc.Client$ConnectionId,int,java.util.concurrent.atomic.AtomicBoolean)" : [ "call" ],
  "org.apache.hadoop.io.Text:set(byte[],int,int)" : [ "ensureCapacity" ],
  "org.apache.hadoop.crypto.CryptoInputStream:read(org.apache.hadoop.io.ByteBufferPool,int,java.util.EnumSet)" : [ "checkStream", "getPos", "resetStreamOffset", "decrypt" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Writer$DataBlockRegister:register(long,long,long)" : [ "<init>", "addBlockRegion" ],
  "org.apache.hadoop.fs.FilterFileSystem:openFileWithOptions(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.impl.OpenFileParameters)" : [ "openFileWithOptions" ],
  "org.apache.hadoop.conf.Configuration:getTimeDurationHelper(java.lang.String,java.lang.String,java.util.concurrent.TimeUnit,java.util.concurrent.TimeUnit)" : [ "toLowerCase", "unitFor", "logDeprecation" ],
  "org.apache.hadoop.fs.FileContext:setVerifyChecksum(boolean,org.apache.hadoop.fs.Path)" : [ "resolve", "fixRelativePart", "getFSofPath" ],
  "org.apache.hadoop.metrics2.source.JvmMetrics:initSingleton(java.lang.String,java.lang.String)" : [ "init" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.ByteBufferDecodingState:checkInputBuffers(java.nio.ByteBuffer[])" : [ "<init>", "getNumDataUnits" ],
  "org.apache.hadoop.ha.protocolPB.HAServiceProtocolClientSideTranslatorPB:<init>(java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory,int)" : [ "setProtocolEngine", "getProxy", "getProtocolVersion", "getCurrentUser" ],
  "org.apache.hadoop.fs.DU:main(java.lang.String[])" : [ "<init>", "setPath", "setConf", "build" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem:mkdirs(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "mkdirs" ],
  "org.apache.hadoop.fs.FilterFileSystem:close()" : [ "close" ],
  "org.apache.hadoop.io.SortedMapWritable:equals(java.lang.Object)" : [ "size", "entrySet" ],
  "org.apache.hadoop.metrics2.sink.GraphiteSink:flush()" : [ "<init>", "flush", "close" ],
  "org.apache.hadoop.security.Credentials:readProto(java.io.DataInput)" : [ "<init>", "addToken", "tokenFromProto", "addSecretKey" ],
  "org.apache.hadoop.fs.FileContext:create(org.apache.hadoop.fs.Path,java.util.EnumSet,org.apache.hadoop.fs.Options$CreateOpts[])" : [ "fixRelativePart", "getOpt", "getValue", "applyUMask", "getUMask", "perms" ],
  "org.apache.hadoop.fs.FSInputStream:read(long,byte[],int,int)" : [ "validatePositionedReadArgs" ],
  "org.apache.hadoop.fs.permission.FsPermission:getUMask(org.apache.hadoop.conf.Configuration)" : [ "<init>", "getUMask", "get" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:checkIoStatisticsContextAvailable()" : [ "checkAvailable" ],
  "org.apache.hadoop.util.Progress:addPhase(float)" : [ "<init>", "setParent" ],
  "org.apache.hadoop.ha.ZKFailoverController:recheckElectability()" : [ "scheduleRecheck", "joinElection", "quitElection", "fatalError" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenIdentifier:<init>(org.apache.hadoop.io.Text,org.apache.hadoop.io.Text,org.apache.hadoop.io.Text,org.apache.hadoop.io.Text)" : [ "<init>" ],
  "org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream:readVectored(java.util.List,java.util.function.IntFunction)" : [ "<init>", "sortRangeList", "validateRangeRequest", "getAsyncChannel" ],
  "org.apache.hadoop.fs.PathIsDirectoryException:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.DelegationTokenRenewer:getInstance()" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.find.Find:registerExpressions(org.apache.hadoop.fs.shell.find.ExpressionFactory)" : [ "registerExpression" ],
  "org.apache.hadoop.io.retry.RetryInvocationHandler$RetryInfo:<init>(long,org.apache.hadoop.io.retry.RetryPolicy$RetryAction,long,java.lang.Exception)" : [ "monotonicNow" ],
  "org.apache.hadoop.fs.FileContext:getFileContext(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "getFileContext", "getCurrentUser", "getAbstractFileSystem" ],
  "org.apache.hadoop.net.InnerNodeImpl:hashCode()" : [ "hashCode" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:rollNewVersionInternal(java.lang.String,byte[])" : [ "checkNotEmpty", "createURL", "createConnection", "call", "parseJSONKeyVersion", "invalidateCache" ],
  "org.apache.hadoop.security.Groups:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.util.Timer)" : [ "<init>", "newInstance", "getClass", "getLong", "getBoolean", "getInt", "parseStaticMapping" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:finish()" : [ "writeRun", "endBlock", "endCompression" ],
  "org.apache.hadoop.util.dynamic.DynConstructors$Ctor:<init>(java.lang.reflect.Constructor,java.lang.Class)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.Ls:registerCommands(org.apache.hadoop.fs.shell.CommandFactory)" : [ "addClass" ],
  "org.apache.hadoop.util.SysInfoLinux:getCpuUsagePercentage()" : [ "readProcStatFile", "getCpuTrackerUsagePercent", "getNumProcessors" ],
  "org.apache.hadoop.security.Groups:getUserToGroupsMappingServiceWithLoadedConfiguration(org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.util.OperationDuration:finished()" : [ "time" ],
  "org.apache.hadoop.io.compress.CompressorStream:finish()" : [ "compress" ],
  "org.apache.hadoop.io.MapFile$Merger:merge(org.apache.hadoop.fs.Path[],boolean,org.apache.hadoop.fs.Path)" : [ "open", "mergePass", "close", "delete", "getFileSystem", "toString" ],
  "org.apache.hadoop.log.LogLevel$CLI:doSetLevel()" : [ "process" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:getMinimumReference(java.lang.String)" : [ "getInnerStatistics" ],
  "org.apache.hadoop.log.LogLevel$CLI:parseArguments(java.lang.String[])" : [ "<init>", "parseGetLevelArgs", "parseSetLevelArgs", "parseProtocolArgs" ],
  "org.apache.hadoop.ipc.CallQueueManager:add(org.apache.hadoop.ipc.Schedulable)" : [ "addInternal" ],
  "org.apache.hadoop.ha.protocolPB.ZKFCProtocolClientSideTranslatorPB:gracefulFailover()" : [ "ipc" ],
  "org.apache.hadoop.fs.ContentSummary:toString(boolean,boolean,boolean)" : [ "toString" ],
  "org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator:mlock(java.lang.String,java.nio.ByteBuffer,long)" : [ "mlock" ],
  "org.apache.hadoop.fs.ChecksumFs:isDirectory(org.apache.hadoop.fs.Path)" : [ "isDirectory" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:getTokenTrackingId(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier)" : [ "getTokenInfo", "getTrackingId" ],
  "org.apache.hadoop.net.unix.DomainSocket:recvFileInputStreams(java.io.FileInputStream[],byte[],int,int)" : [ "reference", "unreference" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:createNonRecursive(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,java.util.EnumSet,int,short,long,org.apache.hadoop.util.Progressable)" : [ "createNonRecursive", "fullPath" ],
  "org.apache.hadoop.io.SecureIOUtils:openFSDataInputStream(java.io.File,java.lang.String,java.lang.String)" : [ "<init>", "isSecurityEnabled", "open", "forceSecureOpenFSDataInputStream" ],
  "org.apache.hadoop.fs.FileUtil:fullyDeleteContents(java.io.File,boolean)" : [ "grantPermissions", "deleteImpl", "fullyDelete" ],
  "org.apache.hadoop.util.Lists:computeArrayListCapacity(int)" : [ "checkNonnegative", "saturatedCast" ],
  "org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor:afterExecute(java.lang.Runnable,java.lang.Throwable)" : [ "logThrowableFromAfterExecute" ],
  "org.apache.hadoop.fs.http.HttpFileSystem:open(org.apache.hadoop.fs.Path,int)" : [ "open" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:checkTFileDataIndex()" : [ "<init>", "getMetaBlock", "getBlockCount", "getComparator", "close" ],
  "org.apache.hadoop.ipc.Client$Connection:setupSaslConnection(org.apache.hadoop.ipc.Client$IpcStreams)" : [ "<init>", "getTicket", "getProtocol", "getAddress", "saslConnect" ],
  "org.apache.hadoop.fs.FileSystem:open(org.apache.hadoop.fs.Path)" : [ "getInt" ],
  "org.apache.hadoop.metrics2.MetricStringBuilder:add(org.apache.hadoop.metrics2.MetricsInfo,java.lang.Object)" : [ "tuple" ],
  "org.apache.hadoop.security.alias.UserProvider:createCredentialEntry(java.lang.String,char[])" : [ "<init>", "getSecretKey", "addSecretKey" ],
  "org.apache.hadoop.util.ExitUtil:halt(int,java.lang.String)" : [ "<init>", "halt" ],
  "org.apache.hadoop.net.DNSDomainNameResolver:getAllResolvedHostnameByDomainName(java.lang.String,boolean)" : [ "getAllByDomainName", "getHostnameByIP" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.XORRawDecoder:<init>(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:rollNewVersion(java.lang.String,byte[])" : [ "doOp", "nextIdx", "invalidateCache" ],
  "org.apache.hadoop.fs.FSDataOutputStreamBuilder:checksumOpt(org.apache.hadoop.fs.Options$ChecksumOpt)" : [ "checkNotNull", "getThisBuilder" ],
  "org.apache.hadoop.fs.ChecksumFileSystem:openFileWithOptions(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.impl.OpenFileParameters)" : [ "rejectUnknownMandatoryKeys", "getMandatoryKeys", "eval" ],
  "org.apache.hadoop.util.ConfTest:main(java.lang.String[])" : [ "<init>", "getRemainingArgs", "terminate", "listFiles", "checkConf" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:getDelegationToken(java.lang.String)" : [ "doOp", "nextIdx" ],
  "org.apache.hadoop.security.authorize.ProxyServers:refresh(org.apache.hadoop.conf.Configuration)" : [ "getTrimmedStrings" ],
  "org.apache.hadoop.security.UserGroupInformation$HadoopLoginContext:login()" : [ "getSubjectLock", "monotonicNow" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockData:setState(int,org.apache.hadoop.fs.impl.prefetch.BlockData$State)" : [ "throwIfInvalidBlockNumber" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine:getProtocolMetaInfoProxy(org.apache.hadoop.ipc.Client$ConnectionId,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.CompressionOutputStream:close()" : [ "returnCompressor" ],
  "org.apache.hadoop.net.NetUtils:connect(java.net.Socket,java.net.SocketAddress,int)" : [ "connect" ],
  "org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:processTokenRemoved(org.apache.curator.framework.recipes.cache.ChildData)" : [ "readFields" ],
  "org.apache.hadoop.util.ProtoUtil:makeIpcConnectionContext(java.lang.String,org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.security.SaslRpcServer$AuthMethod)" : [ "getUserName", "getRealUser" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreBuilderImpl:withDurationTracking(java.lang.String[])" : [ "withCounters", "withMinimums", "withMaximums", "withMeanStatistics" ],
  "org.apache.hadoop.fs.shell.CommandFactory:getInstance(java.lang.String)" : [ "getInstance" ],
  "org.apache.hadoop.io.compress.CompressorStream:close()" : [ "close" ],
  "org.apache.hadoop.fs.Options$HandleOpt:path()" : [ "changed", "moved" ],
  "org.apache.hadoop.security.authorize.DefaultImpersonationProvider:getProxyHosts()" : [ "getCollection" ],
  "org.apache.hadoop.fs.FilterFileSystem:getTrashRoots(boolean)" : [ "getTrashRoots" ],
  "org.apache.hadoop.io.file.tfile.CompareUtils$MemcmpRawComparator:compare(byte[],int,int,byte[],int,int)" : [ "compareBytes" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockOperations:fromSummary(java.lang.String)" : [ "<init>", "setDebug", "fromShortName", "add" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:getEntryCount()" : [ "getRecordCount" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getMountPoints()" : [ "<init>", "getMountPoints" ],
  "org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:startThreads()" : [ "startThreads", "incrSharedCount", "createPersistentNode", "loadFromZKCache" ],
  "org.apache.hadoop.io.erasurecode.coder.HHXORErasureDecodingStep:performCoding(org.apache.hadoop.io.erasurecode.ECChunk[],org.apache.hadoop.io.erasurecode.ECChunk[])" : [ "performCoding", "toBuffers" ],
  "org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue:deleteByName(java.lang.String)" : [ "cancel" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:create(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,boolean,int,short,long,org.apache.hadoop.util.Progressable)" : [ "create" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier:write(java.io.DataOutput)" : [ "getLength", "writeImpl" ],
  "org.apache.hadoop.fs.ChecksumFs$ChecksumFSInputChecker:readChunk(long,byte[],int,int,byte[])" : [ "<init>", "getChecksumFilePos", "getPos", "seek" ],
  "org.apache.hadoop.fs.AbstractFileSystem:getEnclosingRoot(org.apache.hadoop.fs.Path)" : [ "<init>", "makeQualified" ],
  "org.apache.hadoop.ipc.Server:refreshServiceAclWithLoadedConfiguration(org.apache.hadoop.conf.Configuration,org.apache.hadoop.security.authorize.PolicyProvider)" : [ "refreshWithLoadedConfiguration" ],
  "org.apache.hadoop.metrics2.impl.MBeanInfoBuilder:get()" : [ "tags", "newAttrInfo", "name", "description", "metrics" ],
  "org.apache.hadoop.net.unix.DomainSocket$DomainInputStream:read()" : [ "reference" ],
  "org.apache.hadoop.fs.FileSystem:listStatus(org.apache.hadoop.fs.Path[])" : [ "listStatus" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RSRawDecoder:generateDecodeMatrix(int[])" : [ "gfInvertMatrix", "gfMul" ],
  "org.apache.hadoop.metrics2.util.MetricsCache:update(org.apache.hadoop.metrics2.MetricsRecord)" : [ "update" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:tag(org.apache.hadoop.metrics2.MetricsInfo,java.lang.String)" : [ "tag" ],
  "org.apache.hadoop.io.retry.DefaultFailoverProxyProvider:getProxy()" : [ "<init>" ],
  "org.apache.hadoop.metrics2.MetricsTag:equals(java.lang.Object)" : [ "info", "value" ],
  "org.apache.hadoop.fs.FileContext:getLocalFSFileContext()" : [ "getFileContext" ],
  "org.apache.hadoop.fs.TrashPolicy:getInstance(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem)" : [ "getClass", "newInstance", "initialize" ],
  "org.apache.hadoop.fs.PositionedReadable:readVectored(java.util.List,java.util.function.IntFunction)" : [ "readVectored" ],
  "org.apache.hadoop.http.HttpServer2:addFilter(java.lang.String,java.lang.String,java.util.Map)" : [ "getFilterHolder", "getFilterMapping", "defineFilter" ],
  "org.apache.hadoop.conf.Configuration:getPattern(java.lang.String,java.util.regex.Pattern)" : [ "get" ],
  "org.apache.hadoop.fs.FilterFileSystem:getFileChecksum(org.apache.hadoop.fs.Path)" : [ "getFileChecksum" ],
  "org.apache.hadoop.util.StringUtils:camelize(java.lang.String)" : [ "split", "toLowerCase" ],
  "org.apache.hadoop.conf.Configuration:getTrimmedStrings(java.lang.String)" : [ "getTrimmedStrings", "get" ],
  "org.apache.hadoop.fs.impl.prefetch.SingleFilePerBlockCache:addToLinkedListHead(org.apache.hadoop.fs.impl.prefetch.SingleFilePerBlockCache$Entry)" : [ "addToHeadOfLinkedList" ],
  "org.apache.hadoop.fs.FileContext:getLocalFSFileContext(org.apache.hadoop.conf.Configuration)" : [ "getFileContext" ],
  "org.apache.hadoop.io.retry.AsyncCallHandler$AsyncCallQueue:checkCalls()" : [ "monotonicNow", "iterator", "isDone", "checkEmpty" ],
  "org.apache.hadoop.fs.AvroFSInput:tell()" : [ "getPos" ],
  "org.apache.hadoop.fs.FileContext:printStatistics()" : [ "printStatistics" ],
  "org.apache.hadoop.ipc.CallQueueManager:parseNumLevels(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "getInt" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkNotNull(java.lang.Object,java.lang.String)" : [ "checkArgument" ],
  "org.apache.hadoop.io.ObjectWritable:<init>(java.lang.Object)" : [ "set" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.ipc.RPC:getProtocolProxy(java.lang.Class,long,java.net.InetSocketAddress,org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory,int,org.apache.hadoop.io.retry.RetryPolicy)" : [ "getProtocolProxy" ],
  "org.apache.hadoop.net.NetworkTopologyWithNodeGroup:sortByDistance(org.apache.hadoop.net.Node,org.apache.hadoop.net.Node[],int)" : [ "sortByDistance" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:renameSnapshot(org.apache.hadoop.fs.Path,java.lang.String,java.lang.String)" : [ "renameSnapshot", "fullPath" ],
  "org.apache.hadoop.ha.HAServiceTarget:getProxyForAddress(org.apache.hadoop.conf.Configuration,int,java.net.InetSocketAddress)" : [ "getProxyForAddress" ],
  "org.apache.hadoop.metrics2.impl.MetricsSourceAdapter:getMetrics(org.apache.hadoop.metrics2.impl.MetricsCollectorImpl,boolean)" : [ "setRecordFilter", "setMetricFilter", "add", "getRecords", "iterator" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem:repairAndOpen(org.apache.hadoop.fs.viewfs.NflyFSystem$MRNflyNode[],org.apache.hadoop.fs.Path,int)" : [ "getLen", "getModificationTime", "compareTo", "setPath", "getNflyTmpPath", "copy", "delete", "rename", "setTimes", "getAccessTime", "sortByDistance", "open", "getUri" ],
  "org.apache.hadoop.util.Progress:get()" : [ "getParent", "getInternal" ],
  "org.apache.hadoop.ipc.Server$Listener$Reader:run()" : [ "doRunLoop" ],
  "org.apache.hadoop.security.token.Token:readFields(java.io.DataInput)" : [ "readFields", "readVInt" ],
  "org.apache.hadoop.metrics2.impl.MetricsSourceAdapter:getMBeanInfo()" : [ "updateJmxCache" ],
  "org.apache.hadoop.security.UserGroupInformation:loginUserFromSubject(javax.security.auth.Subject)" : [ "setLoginUser", "createLoginUser" ],
  "org.apache.hadoop.fs.shell.SnapshotCommands$DeleteSnapshot:processArguments(java.util.LinkedList)" : [ "deleteSnapshot" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkNotNullAndNotEmpty(java.lang.Object[],java.lang.String)" : [ "checkNotNull", "checkNotEmpty" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:setVerifyChecksum(boolean)" : [ "setVerifyChecksum" ],
  "org.apache.hadoop.fs.FilterFileSystem:<init>()" : [ "<init>" ],
  "org.apache.hadoop.util.SysInfoLinux:getAvailablePhysicalMemorySize()" : [ "readProcMemInfoFile" ],
  "org.apache.hadoop.fs.FilterFileSystem:getDefaultReplication(org.apache.hadoop.fs.Path)" : [ "getDefaultReplication" ],
  "org.apache.hadoop.security.KDiag:isSimpleAuthentication(org.apache.hadoop.conf.Configuration)" : [ "getAuthenticationMethod" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:createScannerByRecordNum(long,long)" : [ "<init>", "getEntryCount", "getLocationByRecordNum" ],
  "org.apache.hadoop.io.DataInputByteBuffer:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.FileUtil:write(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,byte[])" : [ "createFile", "overwrite", "close" ],
  "org.apache.hadoop.fs.FilterFs:getFileChecksum(org.apache.hadoop.fs.Path)" : [ "checkPath" ],
  "org.apache.hadoop.fs.FSOutputSummer:setChecksumBufSize(int)" : [ "getChecksumSize" ],
  "org.apache.hadoop.io.compress.zstd.ZStandardDecompressor:reset()" : [ "checkStream" ],
  "org.apache.hadoop.fs.EmptyStorageStatistics:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:getMetadata(java.lang.String)" : [ "checkNotEmpty", "createURL", "createConnection", "call", "parseJSONMetadata" ],
  "org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer:deserialize(org.apache.hadoop.io.Writable)" : [ "newInstance" ],
  "org.apache.hadoop.io.nativeio.NativeIO$POSIX:mlock(java.nio.ByteBuffer,long)" : [ "assertCodeLoaded" ],
  "org.apache.hadoop.util.InstrumentedReadWriteLock:<init>(boolean,java.lang.String,org.slf4j.Logger,long,long)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:newRate(java.lang.String,java.lang.String,boolean,boolean)" : [ "<init>", "checkMetricName" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:removeExpiredToken()" : [ "now", "getCandidateTokensForCleanup", "getRenewDate", "removeTokenForOwnerStats", "logExpireTokens" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:setXAttr(org.apache.hadoop.fs.Path,java.lang.String,byte[],java.util.EnumSet)" : [ "setXAttr", "fullPath" ],
  "org.apache.hadoop.fs.FileSystem:setQuotaByStorageType(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.StorageType,long)" : [ "methodNotSupported" ],
  "org.apache.hadoop.service.ServiceOperations:stopQuietly(org.slf4j.Logger,org.apache.hadoop.service.Service)" : [ "stop" ],
  "org.apache.hadoop.io.retry.RetryPolicies$TryOnceThenFail:shouldRetry(java.lang.Exception,int,int,boolean)" : [ "<init>" ],
  "org.apache.hadoop.security.token.Token$PrivateToken:<init>(org.apache.hadoop.security.token.Token,org.apache.hadoop.io.Text)" : [ "<init>", "isPrivate" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:warmUpEncryptedKeys(java.lang.String[])" : [ "warmUpEncryptedKeys", "checkArgument", "getKMSUrl" ],
  "org.apache.hadoop.io.file.tfile.Chunk$SingleChunkEncoder:write(byte[])" : [ "write" ],
  "org.apache.hadoop.fs.shell.FsCommand:<init>()" : [ "<init>" ],
  "org.apache.hadoop.service.launcher.InterruptEscalator:toString()" : [ "toString" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:getBlockReader(int)" : [ "getDataBlock" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:removeDefaultAcl(org.apache.hadoop.fs.Path)" : [ "removeDefaultAcl", "fullPath" ],
  "org.apache.hadoop.security.authorize.ServiceAuthorizationManager:authorize(org.apache.hadoop.security.UserGroupInformation,java.lang.Class,org.apache.hadoop.conf.Configuration,java.net.InetAddress)" : [ "<init>", "isSecurityEnabled", "getClientPrincipal", "getServerPrincipal", "getUserName", "isUserAllowed", "includes" ],
  "org.apache.hadoop.fs.FsShell:printUsage(java.io.PrintStream,java.lang.String)" : [ "printInfo" ],
  "org.apache.hadoop.crypto.key.kms.ValueQueue:<init>(int,float,long,int,org.apache.hadoop.crypto.key.kms.ValueQueue$QueueRefiller)" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.FileSystemMultipartUploaderBuilder:getFlags()" : [ "getFlags" ],
  "org.apache.hadoop.fs.shell.Test:testAccess(org.apache.hadoop.fs.shell.PathData,org.apache.hadoop.fs.permission.FsAction)" : [ "access" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:create(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,boolean,int,short,long,org.apache.hadoop.util.Progressable)" : [ "<init>", "connect", "makeAbsolute", "getFileStatus", "isDirectory", "delete", "disconnect", "getParent", "mkdirs", "getDirDefault", "toUri", "getName", "closeStream" ],
  "org.apache.hadoop.util.JsonSerialization:writeJsonAsBytes(java.lang.Object,java.io.OutputStream)" : [ "toBytes" ],
  "org.apache.hadoop.service.AbstractService:registerServiceListener(org.apache.hadoop.service.ServiceStateChangeListener)" : [ "add" ],
  "org.apache.hadoop.fs.HarFileSystem:getHomeDirectory()" : [ "<init>" ],
  "org.apache.hadoop.fs.FileSystemStorageStatistics:fetch(org.apache.hadoop.fs.FileSystem$Statistics$StatisticsData,java.lang.String)" : [ "checkArgument", "getBytesRead", "getBytesWritten", "getReadOps", "getLargeReadOps", "getWriteOps", "getBytesReadLocalHost", "getBytesReadDistanceOfOneOrTwo", "getBytesReadDistanceOfThreeOrFour", "getBytesReadDistanceOfFiveOrLarger", "getBytesReadErasureCoded", "getRemoteReadTimeMS" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsSnapshot:setMaximum(java.lang.String,long)" : [ "maximums" ],
  "org.apache.hadoop.ipc.RpcWritable$Buffer:newInstance(java.lang.Class,org.apache.hadoop.conf.Configuration)" : [ "getValue" ],
  "org.apache.hadoop.security.HttpCrossOriginFilterInitializer:initFilter(org.apache.hadoop.http.FilterContainer,org.apache.hadoop.conf.Configuration)" : [ "getEnabledConfigKey", "getBoolean", "getFilterParameters", "getPrefix" ],
  "org.apache.hadoop.fs.permission.PermissionStatus:write(java.io.DataOutput)" : [ "write" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:joinElection(byte[])" : [ "<init>", "joinElectionInternal" ],
  "org.apache.hadoop.fs.http.AbstractHttpFileSystem:getFileStatus(org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:incrementMaximum(java.lang.String,long)" : [ "getInnerStatistics" ],
  "org.apache.hadoop.fs.permission.FsPermission:getFileDefault()" : [ "<init>" ],
  "org.apache.hadoop.ipc.Server$ConnectionManager:closeAll()" : [ "toArray", "close" ],
  "org.apache.hadoop.tools.GetGroupsBase:getUgmProtocol()" : [ "getProxy", "getCurrentUser", "getSocketFactory" ],
  "org.apache.hadoop.util.StringUtils:join(char,java.lang.Iterable)" : [ "join" ],
  "org.apache.hadoop.fs.FileSystem:copyToLocalFile(boolean,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "copyToLocalFile" ],
  "org.apache.hadoop.net.SocksSocketFactory:createSocket(java.net.InetAddress,int)" : [ "createSocket" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationHandler:getDelegationToken(javax.servlet.http.HttpServletRequest)" : [ "getParameter" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:getWorkingDirectory()" : [ "getHomeDirectory" ],
  "org.apache.hadoop.io.SequenceFile$Sorter$SortPass$SeqFileComparator:compare(org.apache.hadoop.io.IntWritable,org.apache.hadoop.io.IntWritable)" : [ "get" ],
  "org.apache.hadoop.service.launcher.ServiceLaunchException:<init>(int,java.lang.String,java.lang.Object[])" : [ "<init>" ],
  "org.apache.hadoop.conf.Configuration:handleDeprecation()" : [ "handleDeprecation", "getProps" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:setAcl(org.apache.hadoop.fs.Path,java.util.List)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.crypto.key.KeyProvider:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>", "get" ],
  "org.apache.hadoop.io.retry.LossyRetryInvocationHandler:invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[])" : [ "invoke" ],
  "org.apache.hadoop.util.SysInfoWindows:getAvailablePhysicalMemorySize()" : [ "refreshIfNeeded" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:getXAttr(org.apache.hadoop.fs.Path,java.lang.String)" : [ "getXAttr" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:getServerDefaults(org.apache.hadoop.fs.Path)" : [ "getServerDefaults" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL:openConnection(java.net.URL,org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL$Token)" : [ "openConnection" ],
  "org.apache.hadoop.io.erasurecode.coder.HHXORErasureEncodingStep:performCoding(java.nio.ByteBuffer[],java.nio.ByteBuffer[])" : [ "getNumDataUnits", "getNumParityUnits", "doEncode" ],
  "org.apache.hadoop.util.HostsFileReader:getHostDetails(java.util.Set,java.util.Map)" : [ "getIncludedHosts", "getExcludedMap" ],
  "org.apache.hadoop.util.dynamic.DynConstructors$Ctor:invokeChecked(java.lang.Object,java.lang.Object[])" : [ "checkArgument", "newInstanceChecked" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getDefaultBlockSize(org.apache.hadoop.fs.Path)" : [ "<init>", "getDefaultBlockSize", "resolve", "getUriPath" ],
  "org.apache.hadoop.io.BinaryComparable:compareTo(org.apache.hadoop.io.BinaryComparable)" : [ "compareBytes" ],
  "org.apache.hadoop.io.MD5Hash:digest(byte[],int,int)" : [ "<init>", "getDigester" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:deleteSnapshot(org.apache.hadoop.fs.Path,java.lang.String)" : [ "deleteSnapshot", "fullPath" ],
  "org.apache.hadoop.ipc.RPC:getProtocolProxy(java.lang.Class,long,java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory)" : [ "getProtocolProxy", "getCurrentUser" ],
  "org.apache.hadoop.ipc.RPC:waitForProtocolProxy(java.lang.Class,long,java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration)" : [ "waitForProtocolProxy" ],
  "org.apache.hadoop.io.retry.RetryInvocationHandler$Call:invokeOnce()" : [ "<init>", "processWaitTimeAndRetryInfo", "invoke", "toString" ],
  "org.apache.hadoop.fs.FileSystem:get(java.net.URI,org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "get", "getBestUGI", "doAs" ],
  "org.apache.hadoop.ipc.metrics.RetryCacheMetrics:incrCacheUpdated()" : [ "incr" ],
  "org.apache.hadoop.ipc.Server:getClientBackoffEnable(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "getBoolean" ],
  "org.apache.hadoop.conf.StorageUnit$4:getDefault(double)" : [ "toGBs" ],
  "org.apache.hadoop.util.bloom.BloomFilter:<init>()" : [ "<init>" ],
  "org.apache.hadoop.io.compress.BZip2Codec$BZip2CompressionInputStream:close()" : [ "close" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:getServerDefaults(org.apache.hadoop.fs.Path)" : [ "getServerDefaults", "fullPath" ],
  "org.apache.hadoop.ipc.Server$RpcCall:run()" : [ "monotonicNowNanos", "populateResponseParamsOnError", "set", "get", "setResponseFields", "setReturnStatus" ],
  "org.apache.hadoop.fs.permission.AclEntry:toStringStable()" : [ "toStringStable", "toLowerCase" ],
  "org.apache.hadoop.fs.store.DataBlocks$DiskBlock:<init>(java.io.File,int,long,org.apache.hadoop.fs.store.BlockUploadStatistics)" : [ "<init>" ],
  "org.apache.hadoop.conf.Configuration:addResource(java.net.URL)" : [ "<init>", "addResourceObject" ],
  "org.apache.hadoop.net.SocksSocketFactory:createSocket(java.net.InetAddress,int,java.net.InetAddress,int)" : [ "createSocket" ],
  "org.apache.hadoop.security.UserGroupInformation$RealUser:getName()" : [ "getUserName" ],
  "org.apache.hadoop.util.JsonSerialization:save(java.io.File,java.lang.Object)" : [ "writeJsonAsBytes" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Factory:setBlockSize(org.apache.hadoop.conf.Configuration,int)" : [ "setInt" ],
  "org.apache.hadoop.metrics2.source.JvmMetrics$Singleton:init(java.lang.String,java.lang.String)" : [ "create", "instance" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyOutputStream:commit()" : [ "delete", "rename", "osException", "createIOException", "setTimes" ],
  "org.apache.hadoop.io.BloomMapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.io.WritableComparator,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.util.Progressable)" : [ "<init>" ],
  "org.apache.hadoop.io.SequenceFile$Sorter:merge(org.apache.hadoop.fs.Path[],boolean,int,org.apache.hadoop.fs.Path)" : [ "merge", "getLen", "preserveInput", "doSync" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Compressor:needsInput()" : [ "setInputFromSavedData" ],
  "org.apache.hadoop.fs.FSDataOutputStream$PositionCache:write(byte[],int,int)" : [ "incrementBytesWritten" ],
  "org.apache.hadoop.fs.impl.MultipartUploaderBuilderImpl:getFS()" : [ "checkNotNull" ],
  "org.apache.hadoop.ha.ZKFCRpcServer:gracefulFailover()" : [ "gracefulFailoverToYou" ],
  "org.apache.hadoop.security.token.DelegationTokenIssuer:addDelegationTokens(java.lang.String,org.apache.hadoop.security.Credentials)" : [ "<init>", "collectDelegationTokens" ],
  "org.apache.hadoop.io.erasurecode.ECBlock:<init>()" : [ "<init>" ],
  "org.apache.hadoop.io.erasurecode.CodecUtil:createRawEncoder(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "checkNotNull", "createRawEncoderWithFallback" ],
  "org.apache.hadoop.fs.impl.FutureIOSupport:propagateOptions(org.apache.hadoop.fs.FSBuilder,org.apache.hadoop.conf.Configuration,java.lang.String,boolean)" : [ "propagateOptions" ],
  "org.apache.hadoop.ipc.Server:setupResponse(org.apache.hadoop.ipc.Server$RpcCall,org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$RpcStatusProto,org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$RpcErrorCodeProto,org.apache.hadoop.io.Writable,java.lang.String,java.lang.String)" : [ "setupResponse", "setShouldClose", "stringifyException" ],
  "org.apache.hadoop.crypto.CryptoInputStream:skip(long)" : [ "checkArgument", "checkStream", "resetStreamOffset" ],
  "org.apache.hadoop.conf.Configuration:unset(java.lang.String)" : [ "isDeprecated", "getAlternativeNames", "handleDeprecation", "getOverlay", "getProps" ],
  "org.apache.hadoop.fs.FilterFs:hasPathCapability(org.apache.hadoop.fs.Path,java.lang.String)" : [ "hasPathCapability" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenManager:destroy()" : [ "stopThreads" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine:getProxy(java.lang.Class,long,java.net.InetSocketAddress,org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory,int,org.apache.hadoop.io.retry.RetryPolicy)" : [ "getProxy" ],
  "org.apache.hadoop.metrics2.sink.RollingFileSystemSink:close()" : [ "checkForErrors" ],
  "org.apache.hadoop.util.HostsFileReader:readFileToMapWithFileInputStream(java.lang.String,java.lang.String,java.io.InputStream,java.util.Map)" : [ "readXmlFileToMapWithFileInputStream", "readFileToSetWithFileInputStream" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:createPassword(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier)" : [ "<init>", "now", "incrementDelegationTokenSeqNum", "setIssueDate", "setMaxDate", "setMasterKeyId", "getKeyId", "setSequenceNumber", "formatTokenId", "getKey", "getTrackingIdIfEnabled", "trackStoreToken" ],
  "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker:findChecksumRanges(java.util.List,int,int,int)" : [ "<init>", "findChecksumOffset", "merge" ],
  "org.apache.hadoop.security.LdapGroupsMapping:goUpGroupHierarchy(java.util.Set,int,java.util.Set)" : [ "getDirContext", "getGroupNames" ],
  "org.apache.hadoop.util.Shell$ShellCommandExecutor:toString()" : [ "getExecString" ],
  "org.apache.hadoop.fs.PathNotFoundException:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.security.Credentials:write(java.io.DataOutput)" : [ "write", "writeVInt" ],
  "org.apache.hadoop.http.HttpServer2:initSpnego(org.apache.hadoop.conf.Configuration,java.lang.String,java.util.Properties,java.lang.String,java.lang.String)" : [ "get", "getServerPrincipal", "defineFilter" ],
  "org.apache.hadoop.service.launcher.ServiceLaunchException:<init>(int,java.lang.Throwable,java.lang.String,java.lang.Object[])" : [ "<init>" ],
  "org.apache.hadoop.fs.FileContext$Util:getContentSummary(org.apache.hadoop.fs.Path)" : [ "<init>", "getFileStatus", "isFile", "getLen", "length", "fileCount", "directoryCount", "spaceConsumed", "build", "listStatus", "isDirectory", "getPath", "getLength", "getFileCount", "getDirectoryCount" ],
  "org.apache.hadoop.fs.store.DataBlocks$ByteArrayBlock:hasCapacity(long)" : [ "dataSize" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:setAcl(org.apache.hadoop.fs.Path,java.util.List)" : [ "setAcl", "fullPath" ],
  "org.apache.hadoop.conf.Configuration:getTimeDuration(java.lang.String,long,java.util.concurrent.TimeUnit)" : [ "getTimeDuration" ],
  "org.apache.hadoop.security.SecurityUtil:getHostFromPrincipal(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.net.StandardSocketFactory:createSocket(java.net.InetAddress,int,java.net.InetAddress,int)" : [ "createSocket" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem:create(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,boolean,int,short,long,org.apache.hadoop.util.Progressable)" : [ "<init>" ],
  "org.apache.hadoop.fs.local.RawLocalFs:<init>(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.util.GaloisField:divide(int,int)" : [ "getFieldSize" ],
  "org.apache.hadoop.io.wrappedio.WrappedStatistics:iostatisticsSnapshot_toJsonString(java.io.Serializable)" : [ "applyToIOStatisticsSnapshot", "serializer", "toJson" ],
  "org.apache.hadoop.conf.Configuration:appendJSONProperty(com.fasterxml.jackson.core.JsonGenerator,org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.hadoop.conf.ConfigRedactor)" : [ "redact", "get" ],
  "org.apache.hadoop.io.retry.RetryProxy:create(java.lang.Class,org.apache.hadoop.io.retry.FailoverProxyProvider,org.apache.hadoop.io.retry.RetryPolicy)" : [ "<init>" ],
  "org.apache.hadoop.fs.statistics.impl.WrappedIOStatistics:toString()" : [ "ioStatisticsToString" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:exit(org.apache.hadoop.util.ExitUtil$ExitException)" : [ "terminate" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockManager:requestPrefetch(int)" : [ "checkNotNegative" ],
  "org.apache.hadoop.io.WritableComparator:<init>(java.lang.Class,org.apache.hadoop.conf.Configuration,boolean)" : [ "<init>", "newKey" ],
  "org.apache.hadoop.http.HttpServer2$XFrameOption:getEnum(java.lang.String)" : [ "checkState", "toString" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$DelegationTokenInformation:<init>()" : [ "<init>" ],
  "org.apache.hadoop.conf.Configuration:loadProperty(java.util.Properties,java.lang.String,java.lang.String,java.lang.String,boolean,java.lang.String[])" : [ "putIntoUpdatingResource", "checkForOverride" ],
  "org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation:collectThreadLocalStates()" : [ "aggregateLocalStatesToGlobalMetrics" ],
  "org.apache.hadoop.conf.Configuration:getPropertySources(java.lang.String)" : [ "getProps" ],
  "org.apache.hadoop.ipc.Server:setPriorityLevel(org.apache.hadoop.security.UserGroupInformation,int)" : [ "setPriorityLevel" ],
  "org.apache.hadoop.fs.viewfs.InodeTree$INodeDir:addLink(java.lang.String,org.apache.hadoop.fs.viewfs.InodeTree$INodeLink)" : [ "<init>" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RawErasureDecoder:getNumDataUnits()" : [ "getNumDataUnits" ],
  "org.apache.hadoop.security.KDiag:validateNTPConf()" : [ "verifyFileIsValid", "title", "dump", "endln" ],
  "org.apache.hadoop.util.Shell:destroyAllShellProcesses()" : [ "getProcess" ],
  "org.apache.hadoop.crypto.key.KeyProvider:rollNewVersion(java.lang.String)" : [ "generateKey", "getBitLength", "getCipher" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider$KeyMetadata:writeObject(java.io.ObjectOutputStream)" : [ "serialize" ],
  "org.apache.hadoop.security.token.Token:toString()" : [ "toString", "identifierToString" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:createScanner(byte[],byte[])" : [ "createScannerByKey" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RSLegacyRawDecoder:doDecode(org.apache.hadoop.io.erasurecode.rawcoder.ByteArrayDecodingState)" : [ "<init>", "resetOutputBuffers", "getNullIndexes", "resetBuffer", "checkGetBytesArrayBuffer", "doDecodeImpl" ],
  "org.apache.hadoop.crypto.key.kms.ValueQueue:getNext(java.lang.String)" : [ "getAtMost" ],
  "org.apache.hadoop.crypto.CryptoInputStream:unbuffer()" : [ "unbuffer", "cleanBufferPool", "cleanDecryptorPool" ],
  "org.apache.hadoop.fs.ContentSummary:toString(boolean)" : [ "toString" ],
  "org.apache.hadoop.io.DataInputByteBuffer:getLength()" : [ "getLength" ],
  "org.apache.hadoop.fs.VectoredReadUtils:validateVectoredReadRanges(java.util.List)" : [ "validateAndSortRanges" ],
  "org.apache.hadoop.io.OutputBuffer:reset()" : [ "reset" ],
  "org.apache.hadoop.security.SecurityUtil:doAsUser(org.apache.hadoop.security.UserGroupInformation,java.security.PrivilegedExceptionAction)" : [ "doAs" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:getDelegationTokens(java.lang.String)" : [ "getDelegationTokens" ],
  "org.apache.hadoop.io.compress.zstd.ZStandardCompressor:<init>(int,int)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:delete(org.apache.hadoop.fs.Path,boolean)" : [ "resolve", "getUriPath", "isInternalDir", "readOnlyMountTable" ],
  "org.apache.hadoop.fs.shell.Ls:adjustColumnWidths(org.apache.hadoop.fs.shell.PathData[])" : [ "maxLength", "getReplication", "getLen", "getOwner", "getGroup", "getContentSummary", "getErasureCodingPolicy" ],
  "org.apache.hadoop.fs.impl.prefetch.FilePosition:buffer()" : [ "throwIfInvalidBuffer" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:rename(com.jcraft.jsch.ChannelSftp,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "<init>", "makeAbsolute", "exists", "toUri" ],
  "org.apache.hadoop.fs.permission.PermissionParser:<init>(java.lang.String,java.util.regex.Pattern,java.util.regex.Pattern)" : [ "applyNormalPattern", "applyOctalPattern" ],
  "org.apache.hadoop.ipc.RPC:waitForProtocolProxy(java.lang.Class,long,java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration,long)" : [ "waitForProtocolProxy", "getRpcTimeout" ],
  "org.apache.hadoop.security.SecurityUtil:getServerPrincipal(java.lang.String,java.lang.String)" : [ "getComponents", "replacePattern" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:invalidateCache(java.lang.String)" : [ "invalidateCache" ],
  "org.apache.hadoop.fs.TrashPolicyDefault:getCurrentTrashDir()" : [ "<init>", "getTrashRoot" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockAppender:getCompressedSize()" : [ "getCompressedSize" ],
  "org.apache.hadoop.util.functional.RemoteIterators$HaltableRemoteIterator:sourceHasNext()" : [ "sourceHasNext" ],
  "org.apache.hadoop.fs.statistics.impl.DynamicIOStatistics:addMeanStatisticFunction(java.lang.String,java.util.function.Function)" : [ "addFunction" ],
  "org.apache.hadoop.util.LightWeightResizableGSet:expandIfNecessary()" : [ "resize" ],
  "org.apache.hadoop.io.compress.ZStandardCodec:createDecompressor()" : [ "<init>", "checkNativeCodeLoaded", "getDecompressionBufferSize" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:iostatistics_gauges(java.io.Serializable)" : [ "invoke" ],
  "org.apache.hadoop.util.functional.TaskPool$Builder:runParallel(org.apache.hadoop.util.functional.TaskPool$Task)" : [ "getCurrentIOStatisticsContext" ],
  "org.apache.hadoop.util.InstrumentedLock:<init>(java.lang.String,org.slf4j.Logger,java.util.concurrent.locks.Lock,long,long)" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.AbstractMultipartUploader:checkPartHandles(java.util.Map)" : [ "checkArgument" ],
  "org.apache.hadoop.security.Credentials:readFields(java.io.DataInput)" : [ "<init>", "readFields", "readVInt" ],
  "org.apache.hadoop.util.HeapSort:sort(org.apache.hadoop.util.IndexedSortable,int,int)" : [ "sort" ],
  "org.apache.hadoop.net.TableMapping:setConf(org.apache.hadoop.conf.Configuration)" : [ "getRawMapping" ],
  "org.apache.hadoop.fs.AbstractFileSystem:checkScheme(java.net.URI,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:createSymlink(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,boolean)" : [ "createSymlink", "fullPath" ],
  "org.apache.hadoop.fs.shell.Display$Checksum:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "isDirectory", "toString", "getFileChecksum", "byteToHexString", "getBlockSize" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner:initBlock(int)" : [ "close", "getBlockReader", "set" ],
  "org.apache.hadoop.util.curator.ZKCuratorManager:start()" : [ "start" ],
  "org.apache.hadoop.ipc.Client$ConnectionId:getConnectionId(java.net.InetSocketAddress,java.lang.Class,org.apache.hadoop.security.UserGroupInformation,int,org.apache.hadoop.io.retry.RetryPolicy,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getInt", "retryUpToMaximumCountWithFixedSleep" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.DummyRawEncoder:<init>(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.zstd.ZStandardCompressor:compress(byte[],int,int)" : [ "checkStream" ],
  "org.apache.hadoop.io.SequenceFile$Sorter:sortAndIterate(org.apache.hadoop.fs.Path[],org.apache.hadoop.fs.Path,boolean)" : [ "<init>", "exists", "sortPass", "merge", "suffix" ],
  "org.apache.hadoop.io.compress.ZStandardCodec:getDecompressionBufferSize(org.apache.hadoop.conf.Configuration)" : [ "getBufferSize", "getRecommendedBufferSize" ],
  "org.apache.hadoop.ipc.ProtocolMetaInfoServerSideTranslatorPB:getProtocolVersions(org.apache.hadoop.thirdparty.protobuf.RpcController,org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolVersionsRequestProto)" : [ "getProtocolVersionForRpcKind" ],
  "org.apache.hadoop.fs.VectoredReadUtils:validateRangeRequest(org.apache.hadoop.fs.FileRange)" : [ "checkArgument" ],
  "org.apache.hadoop.io.compress.ZStandardCodec:getCompressionLevel(org.apache.hadoop.conf.Configuration)" : [ "getInt" ],
  "org.apache.hadoop.metrics2.lib.MethodMetric:metricInfo(java.lang.reflect.Method)" : [ "info", "nameFrom" ],
  "org.apache.hadoop.security.UserGroupInformation:getRealUser()" : [ "getRealUser" ],
  "org.apache.hadoop.util.StringUtils:startupShutdownMessage(java.lang.Class,java.lang.String[],org.slf4j.Logger)" : [ "getHostname", "createStartupShutdownMessage", "register", "get", "addShutdownHook" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter:doFilter(javax.servlet.FilterChain,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)" : [ "createRemoteUser", "getDoAs", "createProxyUser", "authorize", "createServletExceptionResponse" ],
  "org.apache.hadoop.util.BlockingThreadPoolExecutorService:newInstance(int,int,long,java.util.concurrent.TimeUnit,java.lang.String)" : [ "<init>", "newDaemonThreadFactory" ],
  "org.apache.hadoop.security.UserGroupInformation:reset()" : [ "setLoginUser" ],
  "org.apache.hadoop.io.retry.FailoverProxyProvider$ProxyInfo:toString()" : [ "proxyName" ],
  "org.apache.hadoop.io.file.tfile.Chunk$ChunkEncoder:writeChunk(byte[],int,int,boolean)" : [ "writeVInt" ],
  "org.apache.hadoop.ipc.RpcClientUtil:putVersionSignatureMap(java.net.InetSocketAddress,java.lang.String,java.lang.String,java.util.Map)" : [ "<init>" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreImpl:addMaximumSample(java.lang.String,long)" : [ "maybeUpdateMaximum" ],
  "org.apache.hadoop.io.file.tfile.TFile$TFileIndexEntry:<init>(java.io.DataInput)" : [ "readVInt", "readVLong" ],
  "org.apache.hadoop.io.SequenceFile$Reader:next(java.lang.Object)" : [ "next", "getKeyClass", "reset", "getData", "getLength", "deserializeKey", "getPosition", "readBlock", "readVInt" ],
  "org.apache.hadoop.metrics2.MetricsJsonBuilder:tag(org.apache.hadoop.metrics2.MetricsInfo,java.lang.String)" : [ "tuple" ],
  "org.apache.hadoop.fs.Options$HandleOpt$Location:<init>(boolean)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileUtil:makeShellPath(java.io.File)" : [ "makeShellPath" ],
  "org.apache.hadoop.fs.HarFileSystem:getWorkingDirectory()" : [ "<init>" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:createScanner(org.apache.hadoop.io.file.tfile.RawComparable,org.apache.hadoop.io.file.tfile.RawComparable)" : [ "createScannerByKey" ],
  "org.apache.hadoop.fs.impl.prefetch.SingleFilePerBlockCache:getEntry(int)" : [ "checkNotNegative", "addToLinkedListHead" ],
  "org.apache.hadoop.metrics2.impl.MetricsSourceAdapter:startMBeans()" : [ "register" ],
  "org.apache.hadoop.fs.BatchedRemoteIterator:makeRequestIfNeeded()" : [ "makeRequest" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedIO:requireAllMethodsAvailable()" : [ "available" ],
  "org.apache.hadoop.io.MD5Hash:digest(byte[][],int,int)" : [ "<init>", "getDigester" ],
  "org.apache.hadoop.ipc.Client:checkResponse(org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto)" : [ "byteToHexString" ],
  "org.apache.hadoop.security.KDiag:verify(boolean,java.lang.String,java.lang.String,java.lang.Object[])" : [ "fail", "error" ],
  "org.apache.hadoop.io.Text$Comparator:compare(byte[],int,int,byte[],int,int)" : [ "decodeVIntSize" ],
  "org.apache.hadoop.ipc.FairCallQueue:drainTo(java.util.Collection)" : [ "drainTo" ],
  "org.apache.hadoop.net.NetUtils:getConnectAddress(java.net.InetSocketAddress)" : [ "createSocketAddrForHost" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreImpl:addTimedOperation(java.lang.String,long)" : [ "addMeanStatisticSample", "addMinimumSample", "addMaximumSample" ],
  "org.apache.hadoop.security.Groups:refresh()" : [ "isNegativeCacheEnabled" ],
  "org.apache.hadoop.metrics2.lib.MutableRollingAverages:collectThreadLocalStates()" : [ "collectThreadLocalStates" ],
  "org.apache.hadoop.io.erasurecode.coder.HHXORErasureDecoder:checkCreateXorRawEncoder()" : [ "createRawEncoder" ],
  "org.apache.hadoop.io.BinaryComparable:hashCode()" : [ "hashBytes" ],
  "org.apache.hadoop.metrics2.impl.MetricsConfigException:<init>(java.lang.Throwable)" : [ "<init>" ],
  "org.apache.hadoop.fs.store.audit.HttpReferrerAuditHeader$Builder:<init>()" : [ "getGlobalContextEntries" ],
  "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker:seekToNewSource(long)" : [ "seekToNewSource", "getChecksumFilePos", "reportChecksumFailure" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:cancelDelegationToken(org.apache.hadoop.security.token.Token)" : [ "doOp", "nextIdx" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RawErasureDecoder:decode(byte[][],int[],byte[][])" : [ "<init>" ],
  "org.apache.hadoop.service.AbstractService:noteFailure(java.lang.Exception)" : [ "getServiceState", "getName" ],
  "org.apache.hadoop.fs.impl.prefetch.CachingBlockManager:close()" : [ "close", "cancelPrefetches", "cleanupWithLogger", "end", "getSummary" ],
  "org.apache.hadoop.http.HttpServer2:getFilterInitializers(org.apache.hadoop.conf.Configuration)" : [ "getClasses", "newInstance" ],
  "org.apache.hadoop.io.erasurecode.coder.RSErasureEncoder:<init>(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.fs.FilterFileSystem:getDefaultReplication()" : [ "getDefaultReplication" ],
  "org.apache.hadoop.fs.FileSystem:getDefaultBlockSize(org.apache.hadoop.fs.Path)" : [ "getDefaultBlockSize" ],
  "org.apache.hadoop.security.alias.KeyStoreProvider:initFileSystem(java.net.URI)" : [ "initFileSystem", "getFileSystem" ],
  "org.apache.hadoop.util.dynamic.DynMethods$Builder:impl(java.lang.String,java.lang.String,java.lang.Class[])" : [ "impl" ],
  "org.apache.hadoop.crypto.key.kms.ValueQueue:writeUnlock(java.lang.String)" : [ "getLock" ],
  "org.apache.hadoop.fs.FilterFileSystem:copyFromLocalFile(boolean,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "copyFromLocalFile" ],
  "org.apache.hadoop.security.token.DtFileOperations:importTokenFile(java.io.File,java.lang.String,org.apache.hadoop.io.Text,java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "<init>", "readTokenStorageFile", "decodeFromUrlString", "setService", "addToken", "getService", "doFormattedWrite" ],
  "org.apache.hadoop.util.KMSUtil:parseJSONEncKeyVersions(java.lang.String,java.util.List)" : [ "checkNotNull", "parseJSONEncKeyVersion" ],
  "org.apache.hadoop.ha.protocolPB.HAServiceProtocolServerSideTranslatorPB:getProtocolSignature(java.lang.String,long,int)" : [ "getProtocolSignature", "getProtocolName", "getProtocolVersion" ],
  "org.apache.hadoop.security.SecurityUtil:buildTokenService(java.net.URI)" : [ "buildTokenService", "createSocketAddr" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.util.GaloisField:multiply(int[],int[])" : [ "multiply", "add" ],
  "org.apache.hadoop.fs.FileEncryptionInfo:<init>(org.apache.hadoop.crypto.CipherSuite,org.apache.hadoop.crypto.CryptoProtocolVersion,byte[],byte[],java.lang.String,java.lang.String)" : [ "checkNotNull", "checkArgument", "getAlgorithmBlockSize" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.util.GaloisField:getInstance(int,int)" : [ "<init>" ],
  "org.apache.hadoop.util.VersionUtil:compareVersions(java.lang.String,java.lang.String)" : [ "<init>", "compareTo" ],
  "org.apache.hadoop.security.UserGroupInformation:reloginFromKeytab(boolean,boolean)" : [ "<init>", "shouldRelogin", "isFromKeytab", "getLogin", "getTGT", "now", "getRefreshTime", "relogin" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Factory:getLibraryName(org.apache.hadoop.conf.Configuration)" : [ "isNativeBzip2Loaded" ],
  "org.apache.hadoop.util.Progress:getInternal()" : [ "phase", "getProgressWeightage" ],
  "org.apache.hadoop.fs.FileContext:getFileChecksum(org.apache.hadoop.fs.Path)" : [ "fixRelativePart" ],
  "org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream:flush()" : [ "flushBuffer" ],
  "org.apache.hadoop.ipc.Server$RpcCall:populateResponseParamsOnError(java.lang.Throwable,org.apache.hadoop.ipc.Server$RpcCall$ResponseParams)" : [ "logException", "getRpcStatusProto", "getRpcErrorCodeProto", "stringifyException" ],
  "org.apache.hadoop.fs.FilterFileSystem:modifyAclEntries(org.apache.hadoop.fs.Path,java.util.List)" : [ "modifyAclEntries" ],
  "org.apache.hadoop.io.file.tfile.Compression$Algorithm$2:createCompressionStream(java.io.OutputStream,org.apache.hadoop.io.compress.Compressor,int)" : [ "<init>", "getConf", "createOutputStream", "setInt" ],
  "org.apache.hadoop.security.Credentials:writeTokenStorageFile(org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration)" : [ "writeTokenStorageFile" ],
  "org.apache.hadoop.security.authorize.AccessControlList:<init>()" : [ "<init>", "getUserToGroupsMappingService" ],
  "org.apache.hadoop.util.DataChecksum:writeValue(byte[],int,boolean)" : [ "reset" ],
  "org.apache.hadoop.util.InstrumentedLock:tryLock()" : [ "startLockTiming" ],
  "org.apache.hadoop.ipc.metrics.RpcDetailedMetrics:shutdown()" : [ "instance" ],
  "org.apache.hadoop.io.compress.CompressorStream:write(byte[],int,int)" : [ "compress" ],
  "org.apache.hadoop.fs.FilterFileSystem:getCanonicalUri()" : [ "getCanonicalUri" ],
  "org.apache.hadoop.util.LightWeightGSet$SetIterator:hasNext()" : [ "ensureNext" ],
  "org.apache.hadoop.net.SocketInputWrapper:<init>(java.net.Socket,java.io.InputStream)" : [ "checkArgument" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter:getProxyuserConfiguration(javax.servlet.FilterConfig)" : [ "<init>", "set" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:removeAclEntries(org.apache.hadoop.fs.Path,java.util.List)" : [ "removeAclEntries" ],
  "org.apache.hadoop.io.file.tfile.TFile$Writer:append(byte[],byte[])" : [ "append" ],
  "org.apache.hadoop.security.ShellBasedUnixGroupsMapping:handleExecutorTimeout(org.apache.hadoop.util.Shell$ShellCommandExecutor,java.lang.String)" : [ "getExecString" ],
  "org.apache.hadoop.security.authorize.AccessControlList:addGroup(java.lang.String)" : [ "isWildCardACLValue", "isAllAllowed", "cacheGroupsAdd" ],
  "org.apache.hadoop.security.protocolPB.RefreshUserMappingsProtocolClientSideTranslatorPB:isMethodSupported(java.lang.String)" : [ "isMethodSupported", "getProtocolVersion" ],
  "org.apache.hadoop.security.HttpCrossOriginFilterInitializer:getFilterParameters(org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "getValByRegex" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:zkDoWithRetries(org.apache.hadoop.ha.ActiveStandbyElector$ZKAction,org.apache.zookeeper.KeeperException$Code)" : [ "shouldRetry" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider:needsPassword()" : [ "locatePassword", "get" ],
  "org.apache.hadoop.fs.FSBuilder:must(java.lang.String,float)" : [ "mustLong" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:<init>(java.lang.String)" : [ "<init>", "newArrayList", "initSystemMBean" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:incrAuthenticationFailures()" : [ "incr" ],
  "org.apache.hadoop.util.ExitUtil:terminate(org.apache.hadoop.util.ExitUtil$ExitException)" : [ "getExitCode", "addSuppressed" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkNotNullAndNotEmpty(int[],java.lang.String)" : [ "checkNotNull", "checkNotEmpty" ],
  "org.apache.hadoop.io.erasurecode.CodecUtil:createRawCoderFactory(java.lang.String,java.lang.String)" : [ "getInstance", "getCoderByName" ],
  "org.apache.hadoop.util.PriorityQueue:pop()" : [ "downHeap" ],
  "org.apache.hadoop.fs.audit.CommonAuditContext:reset()" : [ "init" ],
  "org.apache.hadoop.security.token.DtFileOperations:fileToPath(java.io.File)" : [ "<init>" ],
  "org.apache.hadoop.security.ssl.SSLHostnameVerifier$AbstractVerifier:verify(java.lang.String,javax.net.ssl.SSLSession)" : [ "check" ],
  "org.apache.hadoop.security.UserGroupInformation:fixKerberosTicketOrder()" : [ "getSubject" ],
  "org.apache.hadoop.fs.shell.PathData:getDirectoryContents()" : [ "<init>", "checkIfExists", "getStringForChildPath", "getPath" ],
  "org.apache.hadoop.fs.shell.FsUsage$Df:addToUsagesTable(java.net.URI,org.apache.hadoop.fs.FsStatus,java.lang.String)" : [ "getCapacity", "getUsed", "getRemaining", "getUsagesTable", "addRow", "formatPercent" ],
  "org.apache.hadoop.fs.FSBuilder:must(java.lang.String,double)" : [ "mustLong" ],
  "org.apache.hadoop.io.BloomMapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType)" : [ "<init>" ],
  "org.apache.hadoop.io.WritableUtils:writeEnum(java.io.DataOutput,java.lang.Enum)" : [ "writeString" ],
  "org.apache.hadoop.ipc.FairCallQueue:<init>(int,int,java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getDefaultQueueCapacityWeights" ],
  "org.apache.hadoop.ipc.Server:getConnections()" : [ "toArray" ],
  "org.apache.hadoop.security.authorize.AccessControlList:getUsersString()" : [ "getString" ],
  "org.apache.hadoop.metrics2.sink.RollingFileSystemSink:putMetrics(org.apache.hadoop.metrics2.MetricsRecord)" : [ "rollLogDirIfNeeded", "name", "value", "hflush", "throwMetricsException", "checkForErrors" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:stop()" : [ "unregisterSource", "removeInstance", "shutdown" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:getXAttrs(org.apache.hadoop.fs.Path)" : [ "getXAttrs", "fullPath" ],
  "org.apache.hadoop.security.UserGroupInformation$RealUser:equals(java.lang.Object)" : [ "equals" ],
  "org.apache.hadoop.fs.FileContext:unsetStoragePolicy(org.apache.hadoop.fs.Path)" : [ "fixRelativePart" ],
  "org.apache.hadoop.security.Groups:getUserToGroupsMappingService()" : [ "<init>", "getUserToGroupsMappingService" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenManager:cancelToken(org.apache.hadoop.security.token.Token,java.lang.String)" : [ "cancelToken", "verifyToken", "getShortUserName" ],
  "org.apache.hadoop.fs.FileSystem:mkdirs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "mkdirs", "setPermission" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "<init>", "resolve", "getUriPath", "isInternalDir", "getRootFallbackLink", "readOnlyMountTable", "isLastInternalDirLink", "getTargetFileSystem", "verifyRenameStrategy", "getMyFs", "fullPath" ],
  "org.apache.hadoop.util.dynamic.BindingUtils:implemented(org.apache.hadoop.util.dynamic.DynMethods$UnboundMethod[])" : [ "isNoop" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner$Entry:compareTo(org.apache.hadoop.io.file.tfile.RawComparable)" : [ "compareKeys", "getKeyLength" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner:upperBound(byte[])" : [ "upperBound" ],
  "org.apache.hadoop.util.HttpExceptionUtils:throwEx(java.lang.Throwable)" : [ "throwException" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator:cancelDelegationToken(java.net.URL,org.apache.hadoop.security.authentication.client.AuthenticatedURL$Token,org.apache.hadoop.security.token.Token)" : [ "cancelDelegationToken" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.ByteArrayEncodingState:<init>(org.apache.hadoop.io.erasurecode.rawcoder.RawErasureEncoder,byte[][],byte[][])" : [ "findFirstValidInput", "checkBuffers" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.ByteBufferDecodingState:checkOutputBuffers(java.nio.ByteBuffer[])" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider:constructNewPath(org.apache.hadoop.fs.Path)" : [ "<init>", "toString" ],
  "org.apache.hadoop.util.CacheableIPList:<init>(org.apache.hadoop.util.FileBasedIPList,long)" : [ "updateCacheExpiryTime" ],
  "org.apache.hadoop.ipc.Server:addTerseExceptions(java.lang.Class[])" : [ "addTerseLoggingExceptions" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.NativeXORRawErasureCoderFactory:createEncoder(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.fs.FilterFileSystem:createFile(org.apache.hadoop.fs.Path)" : [ "createFile" ],
  "org.apache.hadoop.conf.Configuration:addResource(java.net.URL,boolean)" : [ "<init>", "addResourceObject" ],
  "org.apache.hadoop.metrics2.lib.MutableGaugeInt:snapshot(org.apache.hadoop.metrics2.MetricsRecordBuilder,boolean)" : [ "value" ],
  "org.apache.hadoop.fs.viewfs.ViewFsLocatedFileStatus:<init>(org.apache.hadoop.fs.LocatedFileStatus,org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.security.ssl.SSLFactory:<init>(org.apache.hadoop.security.ssl.SSLFactory$Mode,org.apache.hadoop.conf.Configuration)" : [ "readSSLConfiguration", "getBoolean", "getClass", "newInstance", "getStrings", "getTrimmedStrings", "join" ],
  "org.apache.hadoop.security.KDiag:verify(java.io.File,org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String)" : [ "readTokenStorageFile", "fail", "error" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:isFile(com.jcraft.jsch.ChannelSftp,org.apache.hadoop.fs.Path)" : [ "getFileStatus", "isDirectory" ],
  "org.apache.hadoop.fs.FileSystem$Statistics:getBytesWritten()" : [ "<init>", "visitAll" ],
  "org.apache.hadoop.ipc.ProtobufHelper:tokenFromProto(org.apache.hadoop.security.proto.SecurityProtos$TokenProto)" : [ "tokenFromProto" ],
  "org.apache.hadoop.fs.ClosedIOException:<init>(java.lang.String,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:verifyToken(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier,byte[])" : [ "<init>", "retrievePassword", "formatTokenId" ],
  "org.apache.hadoop.fs.FileContext:rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Options$Rename[])" : [ "rename", "fixRelativePart", "getFSofPath", "getUri", "resolveIntermediate" ],
  "org.apache.hadoop.ipc.FairCallQueue:offer(java.lang.Object)" : [ "offer" ],
  "org.apache.hadoop.fs.viewfs.ConfigUtil:addLinkFallback(org.apache.hadoop.conf.Configuration,java.net.URI)" : [ "addLinkFallback", "getDefaultMountTableName" ],
  "org.apache.hadoop.fs.HarFileSystem:close()" : [ "close" ],
  "org.apache.hadoop.io.compress.lz4.Lz4Compressor:<init>()" : [ "<init>" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator:authenticate(java.net.URL,org.apache.hadoop.security.authentication.client.AuthenticatedURL$Token)" : [ "hasDelegationToken", "getCurrentUser", "checkTGTAndReloginFromKeytab", "wrapException" ],
  "org.apache.hadoop.tools.TableListing$Column:getRow(int)" : [ "wrap" ],
  "org.apache.hadoop.conf.Configuration:getTimeDuration(java.lang.String,java.lang.String,java.util.concurrent.TimeUnit)" : [ "getTimeDuration" ],
  "org.apache.hadoop.util.FileBasedIPList:isIn(java.lang.String)" : [ "includes" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsContextImpl:reset()" : [ "clear" ],
  "org.apache.hadoop.fs.FSDataOutputStream$PositionCache:write(int)" : [ "incrementBytesWritten" ],
  "org.apache.hadoop.crypto.CryptoInputStream:readFully(long,byte[],int,int)" : [ "checkStream", "decrypt" ],
  "org.apache.hadoop.security.token.delegation.SQLDelegationTokenSecretManager:removeExpiredStoredToken(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier)" : [ "getTokenInfoFromSQL", "getRenewDate", "now", "removeStoredToken" ],
  "org.apache.hadoop.util.Lists:addAll(java.util.Collection,java.lang.Iterable)" : [ "addAll", "cast" ],
  "org.apache.hadoop.util.bloom.DynamicBloomFilter:not()" : [ "not" ],
  "org.apache.hadoop.metrics2.impl.MBeanInfoBuilder:counter(org.apache.hadoop.metrics2.MetricsInfo,long)" : [ "newAttrInfo" ],
  "org.apache.hadoop.io.AbstractMapWritable:write(java.io.DataOutput)" : [ "getClass" ],
  "org.apache.hadoop.fs.FilterFs:deleteSnapshot(org.apache.hadoop.fs.Path,java.lang.String)" : [ "deleteSnapshot" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenManager$DelegationTokenSecretManager:createIdentifier()" : [ "<init>" ],
  "org.apache.hadoop.fs.HardLink$HardLinkCGWin:linkCount(java.io.File)" : [ "getWinUtilsFile" ],
  "org.apache.hadoop.util.KMSUtil:toJSON(org.apache.hadoop.crypto.key.KeyProvider$KeyVersion)" : [ "getName", "getVersionName", "getMaterial" ],
  "org.apache.hadoop.security.ProviderUtils:excludeIncompatibleCredentialProviders(org.apache.hadoop.conf.Configuration,java.lang.Class)" : [ "<init>", "get", "unnestUri", "toUri", "getFileSystemClass", "unset", "set" ],
  "org.apache.hadoop.util.bloom.RetouchedBloomFilter:maximumFpRemove(int[])" : [ "getWeight" ],
  "org.apache.hadoop.fs.FSOutputSummer:write1(byte[],int,int)" : [ "writeChecksumChunks", "flushBuffer" ],
  "org.apache.hadoop.ha.SshFenceByTcpPort:checkArgs(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.ha.protocolPB.HAServiceProtocolClientSideTranslatorPB:close()" : [ "stopProxy" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockOperations:close()" : [ "<init>", "add" ],
  "org.apache.hadoop.util.LightWeightResizableGSet:size()" : [ "size" ],
  "org.apache.hadoop.fs.UnionStorageStatistics$LongStatisticIterator:hasNext()" : [ "getIter" ],
  "org.apache.hadoop.conf.Configuration:getTimeDuration(java.lang.String,long,java.util.concurrent.TimeUnit,java.util.concurrent.TimeUnit)" : [ "get", "getTimeDurationHelper" ],
  "org.apache.hadoop.fs.FilterFs:setTimes(org.apache.hadoop.fs.Path,long,long)" : [ "checkPath" ],
  "org.apache.hadoop.util.ReflectionUtils:copy(org.apache.hadoop.conf.Configuration,java.lang.Object,java.lang.Object)" : [ "reset", "getFactory", "getSerializer", "moveData", "getDeserializer" ],
  "org.apache.hadoop.fs.statistics.impl.WrappedIOStatistics:setWrapped(org.apache.hadoop.fs.statistics.IOStatistics)" : [ "checkState" ],
  "org.apache.hadoop.fs.store.ByteBufferInputStream:position()" : [ "checkOpenState" ],
  "org.apache.hadoop.io.SequenceFile$Reader$InputStreamOption:<init>(org.apache.hadoop.fs.FSDataInputStream)" : [ "<init>" ],
  "org.apache.hadoop.fs.FilterFs:setStoragePolicy(org.apache.hadoop.fs.Path,java.lang.String)" : [ "setStoragePolicy" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:addMeanStatisticSample(java.lang.String,long)" : [ "getInnerStatistics" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$WrappingRemoteIterator:next()" : [ "<init>", "stripOutRoot", "getPath" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner:parkCursorAtEnd()" : [ "set", "close" ],
  "org.apache.hadoop.util.SysInfoLinux:getAvailableVirtualMemorySize()" : [ "getAvailablePhysicalMemorySize" ],
  "org.apache.hadoop.security.token.Token:cancel(org.apache.hadoop.conf.Configuration)" : [ "getRenewer" ],
  "org.apache.hadoop.ha.FailoverController:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.ha.HAServiceProtocol$RequestSource)" : [ "<init>", "getGracefulFenceTimeout", "getRpcTimeoutToNewActive", "getInt", "setInt" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:ensureParentZNode()" : [ "checkState", "createConnection", "checkArgument", "createWithRetries", "isNodeExists", "setAclsWithRetries" ],
  "org.apache.hadoop.util.dynamic.DynMethods$UnboundMethod:asStatic()" : [ "checkState", "isStatic" ],
  "org.apache.hadoop.fs.FileSystem:processDeleteOnExit()" : [ "exists" ],
  "org.apache.hadoop.fs.ChecksumFileSystem:rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "<init>", "isDirectory", "getName", "getChecksumFile", "exists" ],
  "org.apache.hadoop.security.ssl.SSLFactory:getHostnameVerifier(org.apache.hadoop.conf.Configuration)" : [ "getHostnameVerifier", "toUpperCase", "get" ],
  "org.apache.hadoop.io.serializer.SerializationFactory:getSerializer(java.lang.Class)" : [ "getSerialization" ],
  "org.apache.hadoop.fs.TrashPolicyDefault:deleteCheckpoint(org.apache.hadoop.fs.Path,boolean)" : [ "now", "getPath", "toUri", "getName", "getTimeFromCheckpoint" ],
  "org.apache.hadoop.ipc.Client$Connection$PingInputStream:read()" : [ "handleTimeout" ],
  "org.apache.hadoop.ipc.Server:getPriorityLevel(org.apache.hadoop.security.UserGroupInformation)" : [ "getPriorityLevel" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkValid(boolean,java.lang.String,java.lang.String)" : [ "checkArgument" ],
  "org.apache.hadoop.security.IngressPortBasedResolver:setConf(org.apache.hadoop.conf.Configuration)" : [ "setConf", "getTrimmedStringCollection" ],
  "org.apache.hadoop.io.retry.RetryPolicies:retryForeverWithFixedSleep(long,java.util.concurrent.TimeUnit)" : [ "<init>" ],
  "org.apache.hadoop.conf.Configuration:getTimeDurationHelper(java.lang.String,java.lang.String,java.util.concurrent.TimeUnit)" : [ "getTimeDurationHelper" ],
  "org.apache.hadoop.net.NodeBase:<init>(java.lang.String,java.lang.String)" : [ "set", "normalize" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:getDoAsUser()" : [ "getCurrentUser", "getAuthenticationMethod", "getShortUserName" ],
  "org.apache.hadoop.fs.ChecksumFileSystem:listStatus(org.apache.hadoop.fs.Path)" : [ "listStatus" ],
  "org.apache.hadoop.conf.Configuration:addResource(java.io.InputStream,java.lang.String,boolean)" : [ "<init>", "addResourceObject" ],
  "org.apache.hadoop.security.token.Token$PrivateToken:isPrivateCloneOf(org.apache.hadoop.io.Text)" : [ "equals" ],
  "org.apache.hadoop.security.authorize.ProxyUsers:refreshSuperUserGroupsConfiguration()" : [ "<init>", "refreshSuperUserGroupsConfiguration" ],
  "org.apache.hadoop.fs.shell.FsUsage$Df:processOptions(java.util.LinkedList)" : [ "<init>", "parse", "setHumanReadable", "getOpt" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:moveFromLocalFile(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "rename" ],
  "org.apache.hadoop.io.SequenceFile$Reader:getCurrentValue(org.apache.hadoop.io.Writable)" : [ "seekToCurrentValue", "getPosition", "getLength", "readVInt" ],
  "org.apache.hadoop.fs.impl.prefetch.FilePosition:setData(org.apache.hadoop.fs.impl.prefetch.BufferData,long,long)" : [ "checkNotNull", "checkNotNegative", "checkWithinRange", "getBuffer", "setAbsolute", "resetReadStats" ],
  "org.apache.hadoop.fs.HarFileSystem:createFile(org.apache.hadoop.fs.Path)" : [ "createFile" ],
  "org.apache.hadoop.security.UserGroupInformation:getCredentialsInternal()" : [ "<init>" ],
  "org.apache.hadoop.security.token.DtFileOperations:aliasTokenFile(java.io.File,java.lang.String,org.apache.hadoop.io.Text,org.apache.hadoop.io.Text,org.apache.hadoop.conf.Configuration)" : [ "<init>", "readTokenStorageFile", "getAllTokens", "addToken", "getService", "equals", "copyToken", "setService", "doFormattedWrite" ],
  "org.apache.hadoop.ipc.metrics.DecayRpcSchedulerDetailedMetrics:addQueueTime(int,long)" : [ "add" ],
  "org.apache.hadoop.fs.shell.PathData:expandAsGlob(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getFileSystem", "globStatus", "toUri", "getPath", "isAbsolute", "removeAuthority", "uriToString", "relativize", "isDirectory" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:setupNoRandPartC()" : [ "updateCRC", "setupNoRandPartA" ],
  "org.apache.hadoop.conf.Configuration:addDefaultResource(java.lang.String)" : [ "reloadConfiguration" ],
  "org.apache.hadoop.util.bloom.CountingBloomFilter:write(java.io.DataOutput)" : [ "write", "buckets2words" ],
  "org.apache.hadoop.io.nativeio.NativeIO$POSIX:getFstat(java.io.FileDescriptor)" : [ "<init>", "getName", "getErrorCode" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:createSnapshot(org.apache.hadoop.fs.Path,java.lang.String)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.fs.viewfs.InodeTree$INodeLink:<init>(java.lang.String,org.apache.hadoop.security.UserGroupInformation,java.util.function.Function,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileContext:getFsStatus(org.apache.hadoop.fs.Path)" : [ "fixRelativePart" ],
  "org.apache.hadoop.fs.FileContext:getAllStoragePolicies()" : [ "getAllStoragePolicies" ],
  "org.apache.hadoop.conf.Configuration:getAllPropertiesByTags(java.util.List)" : [ "getAllPropertiesByTag" ],
  "org.apache.hadoop.http.HttpServer2:setHeaders(org.apache.hadoop.conf.Configuration)" : [ "getValByRegex", "getDefaultHeaders", "toString" ],
  "org.apache.hadoop.security.token.DtUtilShell$Import:execute()" : [ "importTokenFile" ],
  "org.apache.hadoop.ipc.CallerContext$Builder:<init>(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "<init>", "get" ],
  "org.apache.hadoop.log.LogLevel$CLI:process(java.lang.String)" : [ "connect" ],
  "org.apache.hadoop.io.VersionedWritable:readFields(java.io.DataInput)" : [ "<init>" ],
  "org.apache.hadoop.fs.HarFileSystem:getInitialWorkingDirectory()" : [ "getWorkingDirectory" ],
  "org.apache.hadoop.security.SaslInputStream:close()" : [ "disposeSasl" ],
  "org.apache.hadoop.security.authorize.AuthorizationException:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.ipc.RPC$VersionMismatch:<init>(java.lang.String,long,long)" : [ "<init>" ],
  "org.apache.hadoop.security.KDiag:printSysprop(java.lang.String)" : [ "println" ],
  "org.apache.hadoop.net.SocketOutputStream:write(int)" : [ "write" ],
  "org.apache.hadoop.fs.BBUploadHandle:equals(java.lang.Object)" : [ "bytes" ],
  "org.apache.hadoop.io.erasurecode.coder.HHXORErasureDecoder:checkCreateRSRawDecoder()" : [ "createRawDecoder" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:fixFileStatus(org.apache.hadoop.fs.FileStatus,org.apache.hadoop.fs.Path)" : [ "getPath", "toUri", "wrapLocalFileStatus", "setPath" ],
  "org.apache.hadoop.fs.FileSystem$Statistics:toString()" : [ "<init>", "visitAll" ],
  "org.apache.hadoop.io.wrappedio.WrappedIO:fileSystem_getEnclosingRoot(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)" : [ "getEnclosingRoot" ],
  "org.apache.hadoop.util.CrcUtil:getMonomial(long,int)" : [ "galoisFieldMultiply" ],
  "org.apache.hadoop.fs.permission.ChmodParser:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.security.token.DtUtilShell:getCommandUsage()" : [ "getUsage" ],
  "org.apache.hadoop.fs.shell.SetReplication:registerCommands(org.apache.hadoop.fs.shell.CommandFactory)" : [ "addClass" ],
  "org.apache.hadoop.crypto.CryptoOutputStream:freeBuffers()" : [ "freeDB" ],
  "org.apache.hadoop.io.SequenceFile$Sorter:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.io.RawComparator,java.lang.Class,java.lang.Class,org.apache.hadoop.conf.Configuration,org.apache.hadoop.io.SequenceFile$Metadata)" : [ "get", "getInt" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider:locateKeystore()" : [ "locatePassword", "get", "constructOldPath", "constructNewPath", "exists", "tryLoadFromPath", "tryLoadIncompleteFlush" ],
  "org.apache.hadoop.security.ShellBasedIdMapping:loadFullGroupMap()" : [ "updateMapInternal", "monotonicNow" ],
  "org.apache.hadoop.conf.Configuration:getLongBytes(java.lang.String,long)" : [ "getTrimmed", "string2long" ],
  "org.apache.hadoop.net.ScriptBasedMapping:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>", "setConf" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsLogging:logIOStatisticsAtDebug(org.slf4j.Logger,java.lang.String,java.lang.Object)" : [ "ioStatisticsSourceToString" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier:setOwner(org.apache.hadoop.io.Text)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.lib.MutableStat:snapshot(org.apache.hadoop.metrics2.MetricsRecordBuilder,boolean)" : [ "numSamples", "mean", "stddev", "min", "max", "copyTo", "reset", "monotonicNow" ],
  "org.apache.hadoop.security.LdapGroupsMapping:setConf(org.apache.hadoop.conf.Configuration)" : [ "getStrings", "getBoolean", "loadSslConf", "initializeBindUsers", "getTrimmed", "get", "getInt", "getClass" ],
  "org.apache.hadoop.fs.FilterFs:unsetStoragePolicy(org.apache.hadoop.fs.Path)" : [ "unsetStoragePolicy" ],
  "org.apache.hadoop.security.SecurityUtil:doAsLoginUserOrFatal(java.security.PrivilegedAction)" : [ "isSecurityEnabled", "getLoginUser", "doAs" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockData:throwIfInvalidOffset(long)" : [ "checkWithinRange" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:selectDelegationToken(org.apache.hadoop.security.Credentials)" : [ "selectDelegationToken", "getProviders" ],
  "org.apache.hadoop.conf.Configuration$DeprecationDelta:<init>(java.lang.String,java.lang.String,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.find.BaseExpression:prepare()" : [ "getChildren" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:parseIdentityProvider(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "getInstances" ],
  "org.apache.hadoop.fs.statistics.BufferedIOStatisticsInputStream:getIOStatistics()" : [ "retrieveIOStatistics" ],
  "org.apache.hadoop.security.LdapGroupsMapping:getGroups(java.lang.String)" : [ "getGroupsSet" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Writer:prepareDataBlock()" : [ "<init>", "getDefaultCompressionAlgorithm" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:close()" : [ "close", "shutdown" ],
  "org.apache.hadoop.fs.viewfs.InodeTree$INodeDir:<init>(java.lang.String,org.apache.hadoop.security.UserGroupInformation)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.Truncate:registerCommands(org.apache.hadoop.fs.shell.CommandFactory)" : [ "addClass" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockOperations:release(int)" : [ "<init>", "checkNotNegative", "add" ],
  "org.apache.hadoop.security.JniBasedUnixGroupsMapping:getGroups(java.lang.String)" : [ "getGroupsInternal" ],
  "org.apache.hadoop.fs.store.ByteBufferInputStream:reset()" : [ "checkOpenState" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator:getDelegationToken(java.net.URL,org.apache.hadoop.security.authentication.client.AuthenticatedURL$Token,java.lang.String,java.lang.String)" : [ "<init>", "doDelegationTokenOperation", "decodeFromUrlString", "setTokenService" ],
  "org.apache.hadoop.security.ShellBasedUnixGroupsMapping:createGroupExecutor(java.lang.String)" : [ "<init>", "getGroupsForUserCommand" ],
  "org.apache.hadoop.metrics2.impl.MetricsSinkAdapter:consume(org.apache.hadoop.metrics2.impl.MetricsBuffer)" : [ "<init>", "accepts", "name", "records", "context", "timestamp", "now", "notifyAnyWaiters", "iterator" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner$Entry:compareTo(byte[],int,int)" : [ "<init>", "compareTo" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:setPermission(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.security.ShellBasedIdMapping:updateMapIncr(java.lang.String,boolean)" : [ "checkSupportedPlatform", "isInteger", "loadFullGroupMap", "updateStaticMapping", "bashQuote", "updateMapInternal", "getName2IdCmdNIX", "getName2IdCmdMac", "monotonicNow" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreImpl:<init>(java.util.List,java.util.List,java.util.List,java.util.List,java.util.List)" : [ "<init>", "dynamicIOStatistics", "withAtomicLongCounter", "withAtomicLongGauge", "withAtomicLongMaximum", "withAtomicLongMinimum", "withMeanStatisticFunction", "build" ],
  "org.apache.hadoop.util.bloom.RetouchedBloomFilter:removeKey(org.apache.hadoop.util.bloom.Key,java.util.List[])" : [ "hash", "clear" ],
  "org.apache.hadoop.fs.AbstractFileSystem:<init>(java.net.URI,java.lang.String,boolean,int)" : [ "getUri", "getStatistics" ],
  "org.apache.hadoop.fs.impl.prefetch.SingleFilePerBlockCache:<init>(org.apache.hadoop.fs.impl.prefetch.PrefetchingStatistics,int,org.apache.hadoop.fs.statistics.DurationTrackerFactory)" : [ "checkArgument", "stubDurationTrackerFactory" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreImpl:setMaximum(java.lang.String,long)" : [ "setAtomicLong" ],
  "org.apache.hadoop.security.KDiag:dump(java.io.File)" : [ "println" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RawErasureEncoder:getNumAllUnits()" : [ "getNumAllUnits" ],
  "org.apache.hadoop.fs.http.HttpFileSystem:hasPathCapability(org.apache.hadoop.fs.Path,java.lang.String)" : [ "hasPathCapability" ],
  "org.apache.hadoop.io.file.tfile.Utils:writeVInt(java.io.DataOutput,int)" : [ "writeVLong" ],
  "org.apache.hadoop.http.ProfileServlet:<init>()" : [ "getAsyncProfilerHome", "getPid" ],
  "org.apache.hadoop.fs.FilterFileSystem:supportsSymlinks()" : [ "supportsSymlinks" ],
  "org.apache.hadoop.io.IOUtils:copyBytes(java.io.InputStream,java.io.OutputStream,int,boolean)" : [ "copyBytes", "closeStream" ],
  "org.apache.hadoop.fs.FsUrlConnection:<init>(org.apache.hadoop.conf.Configuration,java.net.URL)" : [ "checkArgument" ],
  "org.apache.hadoop.util.curator.ZKCuratorManager:delete(java.lang.String)" : [ "exists" ],
  "org.apache.hadoop.fs.ChecksumFileSystem:open(org.apache.hadoop.fs.Path,int)" : [ "<init>", "getRawFileSystem" ],
  "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback:getGroupsSet(java.lang.String)" : [ "getGroupsSet" ],
  "org.apache.hadoop.fs.impl.AbstractFSBuilderImpl:opt(java.lang.String,int)" : [ "optLong" ],
  "org.apache.hadoop.ipc.ResponseBuffer$FramedBuffer:<init>(int)" : [ "reset" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:convertToExitException(java.lang.Throwable)" : [ "<init>" ],
  "org.apache.hadoop.conf.Configuration:write(java.io.DataOutput)" : [ "getProps", "writeVInt", "writeString", "writeCompressedStringArray" ],
  "org.apache.hadoop.util.DataChecksum:throwChecksumException(org.apache.hadoop.util.DataChecksum$Type,java.util.zip.Checksum,java.lang.String,long,int,int)" : [ "<init>" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:callQueueLength()" : [ "getCallQueueLen" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyStatus:getReplication()" : [ "getReplication" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:getHomeDirectory()" : [ "getHomeDirectory" ],
  "org.apache.hadoop.security.UserGroupInformation:logAllUserInfo(org.apache.hadoop.security.UserGroupInformation)" : [ "logAllUserInfo" ],
  "org.apache.hadoop.net.CachedDNSToSwitchMapping:<init>(org.apache.hadoop.net.DNSToSwitchMapping)" : [ "<init>" ],
  "org.apache.hadoop.util.ApplicationClassLoader:getResource(java.lang.String)" : [ "isSystemClass" ],
  "org.apache.hadoop.fs.FileStatus:<init>(org.apache.hadoop.fs.FileStatus)" : [ "<init>", "getLen", "isDirectory", "getReplication", "getBlockSize", "getModificationTime", "getAccessTime", "getPermission", "getOwner", "getGroup", "isSymlink", "getSymlink", "getPath" ],
  "org.apache.hadoop.fs.BlockLocation:setCachedHosts(java.lang.String[])" : [ "internStringsInArray" ],
  "org.apache.hadoop.fs.shell.TouchCommands$Touchz:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "isDirectory", "toString", "getLen", "touchz" ],
  "org.apache.hadoop.security.token.delegation.web.MultiSchemeDelegationTokenAuthenticationHandler:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:getXAttrs(org.apache.hadoop.fs.Path,java.util.List)" : [ "<init>" ],
  "org.apache.hadoop.net.NetUtils:createSocketAddr(java.lang.String)" : [ "createSocketAddr" ],
  "org.apache.hadoop.io.compress.zstd.ZStandardDecompressor$ZStandardDirectDecompressor:reset()" : [ "reset" ],
  "org.apache.hadoop.conf.Configuration:getStorageSize(java.lang.String,double,org.apache.hadoop.conf.StorageUnit)" : [ "checkNotNull", "checkState", "get", "parse", "convertStorageUnit", "getValue", "getUnit" ],
  "org.apache.hadoop.security.token.DtFileOperations:removeTokenFromFile(boolean,java.io.File,java.lang.String,org.apache.hadoop.io.Text,org.apache.hadoop.conf.Configuration)" : [ "<init>", "readTokenStorageFile", "getAllTokens", "matchAlias", "isManaged", "cancel", "getKind", "getService", "addToken", "doFormattedWrite" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedIO:bulkDelete_available()" : [ "available" ],
  "org.apache.hadoop.util.Lists:newLinkedList(java.lang.Iterable)" : [ "newLinkedList", "addAll" ],
  "org.apache.hadoop.ipc.Server$Listener:run()" : [ "startIdleScan", "getSelector", "doAccept", "closeCurrentConnection", "closeIdle", "stopIdleScan", "closeAll" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Writer:close()" : [ "close", "prepareMetaBlock", "getDefaultCompressionAlgorithm", "write", "getPos" ],
  "org.apache.hadoop.fs.shell.CommandFactory:getInstance(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "newInstance", "setName", "setCommandFactory" ],
  "org.apache.hadoop.http.HttpServer2:getFilterProperties(org.apache.hadoop.conf.Configuration,java.util.List)" : [ "getFilterConfigMap" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:getFirstKey()" : [ "getFirstKey", "checkTFileDataIndex" ],
  "org.apache.hadoop.io.compress.zlib.ZlibCompressor:reset()" : [ "checkStream" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:<init>(java.net.URI,org.apache.hadoop.crypto.key.kms.KMSClientProvider[],long,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getDtService", "getKeyProviderUri", "getCanonicalServiceName", "shuffle", "setClientTokenProvider", "getInt", "checkState", "failoverOnNetworkException" ],
  "org.apache.hadoop.util.functional.CommonCallableSupplier:maybeAwaitCompletion(java.util.concurrent.CompletableFuture)" : [ "waitForCompletion" ],
  "org.apache.hadoop.fs.FilterFileSystem:renameSnapshot(org.apache.hadoop.fs.Path,java.lang.String,java.lang.String)" : [ "renameSnapshot" ],
  "org.apache.hadoop.fs.QuotaUsage:isTypeConsumedAvailable()" : [ "getTypesSupportingQuota" ],
  "org.apache.hadoop.fs.http.HttpsFileSystem:open(org.apache.hadoop.fs.Path,int)" : [ "open" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier:<init>()" : [ "<init>" ],
  "org.apache.hadoop.util.IntrusiveCollection:clear()" : [ "iterator" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:getCanonicalServiceName()" : [ "toString" ],
  "org.apache.hadoop.io.file.tfile.Chunk$ChunkDecoder:isLastChunk()" : [ "checkEOF" ],
  "org.apache.hadoop.security.KDiag:validateKrb5File()" : [ "title", "println", "dump", "endln" ],
  "org.apache.hadoop.io.DataOutputBuffer:writeInt(int,int)" : [ "checkState", "getLength" ],
  "org.apache.hadoop.io.DataInputBuffer:getData()" : [ "getData" ],
  "org.apache.hadoop.util.Timer:monotonicNow()" : [ "monotonicNow" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockOperations:end(org.apache.hadoop.fs.impl.prefetch.BlockOperations$Operation)" : [ "<init>", "add" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.util.GF256:gfInvertMatrix(byte[],byte[],int)" : [ "gfInv", "gfMul" ],
  "org.apache.hadoop.fs.FileContext:removeAclEntries(org.apache.hadoop.fs.Path,java.util.List)" : [ "fixRelativePart" ],
  "org.apache.hadoop.util.functional.TaskPool:foreach(java.lang.Iterable)" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.KeyProviderCryptoExtension$DefaultCryptoExtension:generateEncryptedKey(org.apache.hadoop.crypto.Encryptor,org.apache.hadoop.crypto.key.KeyProvider$KeyVersion,byte[],byte[])" : [ "<init>", "deriveIV", "getMaterial", "getName", "getVersionName" ],
  "org.apache.hadoop.io.retry.RetryInvocationHandler$Call:invoke()" : [ "<init>", "invokeMethod" ],
  "org.apache.hadoop.fs.FileSystem:openFile(org.apache.hadoop.fs.Path)" : [ "createDataInputStreamBuilder" ],
  "org.apache.hadoop.conf.Configuration:getTrimmed(java.lang.String)" : [ "get" ],
  "org.apache.hadoop.security.authorize.ProxyUsers:refreshSuperUserGroupsConfiguration(org.apache.hadoop.conf.Configuration)" : [ "refreshSuperUserGroupsConfiguration" ],
  "org.apache.hadoop.crypto.CryptoInputStream:read(byte[],int,int)" : [ "checkStream", "readFromUnderlyingStream", "decrypt", "afterDecryption" ],
  "org.apache.hadoop.http.lib.StaticUserWebFilter:getUsernameFromConf(org.apache.hadoop.conf.Configuration)" : [ "get" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:register(org.apache.hadoop.metrics2.MetricsSystem$Callback)" : [ "getProxyForCallback" ],
  "org.apache.hadoop.fs.Options$ChecksumOpt:createDisabled()" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.KeyShell$ListCommand:validate()" : [ "getBoolean" ],
  "org.apache.hadoop.fs.FileSystem:append(org.apache.hadoop.fs.Path)" : [ "getInt" ],
  "org.apache.hadoop.ipc.ProcessingDetails:get(org.apache.hadoop.ipc.ProcessingDetails$Timing,java.util.concurrent.TimeUnit)" : [ "get" ],
  "org.apache.hadoop.fs.Trash:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>", "get" ],
  "org.apache.hadoop.security.Credentials:writeTokenStorageToStream(java.io.DataOutputStream)" : [ "writeTokenStorageToStream" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyStatus:setSymlink(org.apache.hadoop.fs.Path)" : [ "setSymlink" ],
  "org.apache.hadoop.fs.viewfs.ViewFsFileStatus:isSymlink()" : [ "isSymlink" ],
  "org.apache.hadoop.security.ShellBasedUnixGroupsMapping:parsePartialGroupNames(java.lang.String,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.snappy.SnappyDecompressor:decompress(byte[],int,int)" : [ "decompressDirectBuf" ],
  "org.apache.hadoop.security.ShellBasedIdMapping:updateMaps()" : [ "checkSupportedPlatform", "loadFullMaps", "updateStaticMapping", "clearNameMaps" ],
  "org.apache.hadoop.metrics2.util.SampleStat:max()" : [ "max" ],
  "org.apache.hadoop.io.EnumSetWritable:<init>(java.util.EnumSet,java.lang.Class)" : [ "set" ],
  "org.apache.hadoop.fs.shell.PathData:stringToUri(java.lang.String)" : [ "normalizeWindowsPath" ],
  "org.apache.hadoop.security.LdapGroupsMapping$LdapSslSocketFactory:createTrustManagers()" : [ "createKeyStore" ],
  "org.apache.hadoop.io.erasurecode.coder.DummyErasureEncoder:prepareEncodingStep(org.apache.hadoop.io.erasurecode.ECBlockGroup)" : [ "<init>" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:delete(org.apache.hadoop.fs.Path,boolean)" : [ "delete", "connect", "disconnect" ],
  "org.apache.hadoop.ipc.UnexpectedServerException:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.Delete$Rmdir:processOptions(java.util.LinkedList)" : [ "<init>", "parse", "getOpt" ],
  "org.apache.hadoop.service.AbstractService:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.util.GcTimeMonitor:getLatestGcData()" : [ "clone" ],
  "org.apache.hadoop.metrics2.lib.MutableInverseQuantiles:setQuantiles(java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.text.DecimalFormat)" : [ "info" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreImpl:incrementCounter(java.lang.String,long)" : [ "incAtomicLong" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:setMinimum(java.lang.String,long)" : [ "getInnerStatistics" ],
  "org.apache.hadoop.fs.store.ByteBufferInputStream:skip(long)" : [ "verifyOpen", "position" ],
  "org.apache.hadoop.ipc.Client$Connection:touch()" : [ "now" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:getInitialWorkingDirectory()" : [ "<init>" ],
  "org.apache.hadoop.fs.FilterFileSystem:resolvePath(org.apache.hadoop.fs.Path)" : [ "resolvePath" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem:rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "rename", "processThrowable", "mayThrowFileNotFound", "createIOException" ],
  "org.apache.hadoop.fs.permission.PermissionStatus$2:<init>(java.lang.String,java.lang.String,org.apache.hadoop.fs.permission.FsPermission)" : [ "<init>" ],
  "org.apache.hadoop.ipc.RPC:getProxy(java.lang.Class,long,java.net.InetSocketAddress,org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory,int)" : [ "getProxy", "getProtocolProxy" ],
  "org.apache.hadoop.io.ObjectWritable:readFields(java.io.DataInput)" : [ "readObject" ],
  "org.apache.hadoop.fs.DFCachingGetSpaceUsed:<init>(org.apache.hadoop.fs.GetSpaceUsed$Builder)" : [ "<init>", "getPath", "getInterval" ],
  "org.apache.hadoop.security.token.Token:decodeIdentifier()" : [ "getClassForIdentifier", "getKind", "newInstance" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:tryDeleteOwnBreadCrumbNode()" : [ "byteToHexString", "deleteWithRetries" ],
  "org.apache.hadoop.fs.impl.FileSystemMultipartUploader:totalPartsLen(java.util.List)" : [ "getLen" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getLinkTarget(org.apache.hadoop.fs.Path)" : [ "<init>", "getLinkTarget", "resolve", "getUriPath" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RSLegacyRawErasureCoderFactory:createDecoder(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.tools.TableListing$Builder:addField(java.lang.String,boolean)" : [ "addField" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:toString()" : [ "ioStatisticsAvailable", "ioStatisticsContextAvailable" ],
  "org.apache.hadoop.util.HttpExceptionUtils:validateResponse(java.net.HttpURLConnection,int)" : [ "mapReader", "checkState", "throwEx" ],
  "org.apache.hadoop.io.compress.BZip2Codec:createOutputStream(java.io.OutputStream,org.apache.hadoop.io.compress.Compressor)" : [ "<init>", "isNativeBzip2Loaded", "getInt" ],
  "org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping:resolve(java.util.List)" : [ "runResolveCommand" ],
  "org.apache.hadoop.fs.Globber$GlobBuilder:<init>(org.apache.hadoop.fs.FileSystem)" : [ "checkNotNull" ],
  "org.apache.hadoop.ipc.metrics.DecayRpcSchedulerDetailedMetrics:create(java.lang.String)" : [ "<init>", "instance" ],
  "org.apache.hadoop.io.erasurecode.coder.HHXORErasureEncoder:<init>(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.security.KDiag:dumpUGI(java.lang.String,org.apache.hadoop.security.UserGroupInformation)" : [ "title", "println", "hasKerberosCredentials", "getAuthenticationMethod", "getRealAuthenticationMethod", "getGroupNames", "getCredentials", "getAllSecretKeys", "dumpTokens" ],
  "org.apache.hadoop.ipc.RpcClientUtil:methodExists(int,long,java.util.Map)" : [ "getMethods" ],
  "org.apache.hadoop.security.UserGroupInformation:setConfiguration(org.apache.hadoop.conf.Configuration)" : [ "initialize" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:getXAttrs(org.apache.hadoop.fs.Path,java.util.List)" : [ "getXAttrs" ],
  "org.apache.hadoop.service.ServiceStateException:<init>(int,java.lang.String,java.lang.Throwable)" : [ "<init>" ],
  "org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue:merge()" : [ "<init>", "getPassFactor", "getSegmentDescriptors", "nextRawKey", "updateProgress", "getPosition", "cleanup", "put", "getApproxChkSumLength", "suffix", "getLocalPathForWrite", "toString", "cloneFileAttributes", "makeQualified", "writeFile", "close", "getLen" ],
  "org.apache.hadoop.fs.shell.AclCommands$SetfaclCommand:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "getOpt", "removeAcl", "removeDefaultAcl", "getAclEntries", "modifyAclEntries", "removeAclEntries", "setAcl" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$MRNflyNode:compareTo(org.apache.hadoop.fs.viewfs.NflyFSystem$MRNflyNode)" : [ "getModificationTime" ],
  "org.apache.hadoop.crypto.OpensslSm4CtrCryptoCodec:setConf(org.apache.hadoop.conf.Configuration)" : [ "setConf", "get" ],
  "org.apache.hadoop.ipc.Server$Connection:setupHttpRequestOnIpcPortResponse()" : [ "setResponse", "sendResponse" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsLogging:logIOStatisticsAtDebug(java.lang.String,java.lang.Object)" : [ "logIOStatisticsAtDebug" ],
  "org.apache.hadoop.fs.FilterFileSystem:concat(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path[])" : [ "concat" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:create(org.apache.hadoop.ipc.Server,org.apache.hadoop.conf.Configuration)" : [ "<init>", "instance" ],
  "org.apache.hadoop.fs.AbstractFileSystem:create(org.apache.hadoop.fs.Path,java.util.EnumSet,org.apache.hadoop.fs.Options$CreateOpts[])" : [ "<init>", "checkPath", "getValue", "getServerDefaults", "getBlockSize", "getBytesPerChecksum", "getChecksumType", "processChecksumOpt", "getFileBufferSize", "getReplication" ],
  "org.apache.hadoop.util.NativeLibraryChecker:main(java.lang.String[])" : [ "<init>", "terminate", "isNativeCodeLoaded", "isNativeBzip2Loaded", "getLibraryName", "isNativeZlibLoaded", "getLoadingFailureReason", "getPmdkSupportStateMessage", "isPmdkAvailable", "getPmdkLibPath", "getWinUtilsFile" ],
  "org.apache.hadoop.util.ApplicationClassLoader:loadClass(java.lang.String,boolean)" : [ "isSystemClass" ],
  "org.apache.hadoop.fs.PathIOException:getMessage()" : [ "formatPath" ],
  "org.apache.hadoop.net.DNS:getHosts(java.lang.String,java.lang.String,boolean)" : [ "getIPsAsInetAddressList", "reverseDns" ],
  "org.apache.hadoop.metrics2.impl.MetricsSinkAdapter:stop()" : [ "cleanupWithLogger" ],
  "org.apache.hadoop.crypto.key.UserProvider:flush()" : [ "addCredentials" ],
  "org.apache.hadoop.fs.shell.MoveCommands$Rename:processPath(org.apache.hadoop.fs.shell.PathData,org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "toString" ],
  "org.apache.hadoop.fs.FsUrlStreamHandler:<init>()" : [ "<init>" ],
  "org.apache.hadoop.util.SemaphoredDelegatingExecutor:submit(java.util.concurrent.Callable)" : [ "trackDuration" ],
  "org.apache.hadoop.fs.ChecksumFs$ChecksumFSInputChecker:getFileLength()" : [ "getLen" ],
  "org.apache.hadoop.http.HttpServer2:constructSecretProvider(org.apache.hadoop.http.HttpServer2$Builder,javax.servlet.ServletContext)" : [ "getFilterProperties" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreImpl:incrementMinimum(java.lang.String,long)" : [ "incAtomicLong" ],
  "org.apache.hadoop.security.ssl.DelegatingSSLSocketFactory:initializeDefaultFactory(org.apache.hadoop.security.ssl.DelegatingSSLSocketFactory$SSLChannelMode)" : [ "<init>" ],
  "org.apache.hadoop.io.retry.RetryPolicies:retryByRemoteException(org.apache.hadoop.io.retry.RetryPolicy,java.util.Map)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.BZip2Codec:createInputStream(java.io.InputStream,org.apache.hadoop.io.compress.Decompressor)" : [ "<init>", "isNativeBzip2Loaded", "getInt" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyNode:<init>(java.lang.String,java.lang.String,org.apache.hadoop.fs.viewfs.ChRootedFileSystem)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.CompressorStream:<init>(java.io.OutputStream,org.apache.hadoop.io.compress.Compressor,int)" : [ "<init>" ],
  "org.apache.hadoop.service.launcher.IrqHandler:handle(sun.misc.Signal)" : [ "<init>" ],
  "org.apache.hadoop.net.SocksSocketFactory:createSocket(java.lang.String,int,java.net.InetAddress,int)" : [ "createSocket" ],
  "org.apache.hadoop.security.token.DtFileOperations:renewTokenFile(java.io.File,java.lang.String,org.apache.hadoop.io.Text,org.apache.hadoop.conf.Configuration)" : [ "readTokenStorageFile", "getAllTokens", "isManaged", "matchAlias", "renew", "getKind", "getService", "formatDate", "doFormattedWrite" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Compressor:getBytesRead()" : [ "checkStream" ],
  "org.apache.hadoop.crypto.OpensslCtrCryptoCodec:close()" : [ "cleanupWithLogger" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$DelegationTokenSecretManagerMetrics:<init>()" : [ "<init>", "iostatisticsStore" ],
  "org.apache.hadoop.security.LdapGroupsMapping$LdapSslSocketFactory:getDefault()" : [ "<init>", "createKeyManagers", "createTrustManagers" ],
  "org.apache.hadoop.fs.FileSystem:deleteOnExit(org.apache.hadoop.fs.Path)" : [ "exists" ],
  "org.apache.hadoop.util.ChunkedArrayList:addChunk(int)" : [ "newArrayListWithCapacity" ],
  "org.apache.hadoop.util.ExitUtil:halt(int,java.lang.Throwable)" : [ "<init>", "halt" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:open(org.apache.hadoop.fs.Path,int)" : [ "open", "fullPath" ],
  "org.apache.hadoop.fs.store.DataBlocks$DiskBlock:hasCapacity(long)" : [ "dataSize" ],
  "org.apache.hadoop.ipc.FairCallQueue$MetricsProxy:getQueueSizes()" : [ "getQueueSizes", "getCallQueue" ],
  "org.apache.hadoop.metrics2.filter.AbstractPatternFilter:accepts(org.apache.hadoop.metrics2.MetricsTag)" : [ "name", "value" ],
  "org.apache.hadoop.fs.FilterFs:getInitialWorkingDirectory()" : [ "getInitialWorkingDirectory" ],
  "org.apache.hadoop.util.Lists:newArrayListWithCapacity(int)" : [ "checkNonnegative" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier:setRenewer(org.apache.hadoop.io.Text)" : [ "<init>", "toString" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState:<init>(org.apache.hadoop.io.file.tfile.Compression$Algorithm,org.apache.hadoop.fs.FSDataOutputStream,org.apache.hadoop.io.BytesWritable,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getPos", "setCapacity", "getFSOutputBufferSize", "getBytes", "getCompressor", "returnCompressor" ],
  "org.apache.hadoop.io.retry.AsyncCallHandler$ConcurrentQueue:offer(java.lang.Object)" : [ "checkState" ],
  "org.apache.hadoop.fs.FileSystem:create(org.apache.hadoop.fs.Path,org.apache.hadoop.util.Progressable)" : [ "create", "getInt", "getDefaultReplication", "getDefaultBlockSize" ],
  "org.apache.hadoop.fs.FilterFileSystem:createPathHandle(org.apache.hadoop.fs.FileStatus,org.apache.hadoop.fs.Options$HandleOpt[])" : [ "getPathHandle" ],
  "org.apache.hadoop.util.bloom.CountingBloomFilter:add(org.apache.hadoop.util.bloom.Key)" : [ "hash", "clear" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getFileChecksum(org.apache.hadoop.fs.Path)" : [ "getFileChecksum", "resolve", "getUriPath" ],
  "org.apache.hadoop.util.SemaphoredDelegatingExecutor:submit(java.lang.Runnable,java.lang.Object)" : [ "trackDuration" ],
  "org.apache.hadoop.fs.FileSystem:createNonRecursive(org.apache.hadoop.fs.Path,boolean,int,short,long,org.apache.hadoop.util.Progressable)" : [ "createNonRecursive", "getFileDefault" ],
  "org.apache.hadoop.tools.TableListing$Column:<init>(java.lang.String,org.apache.hadoop.tools.TableListing$Justification,boolean)" : [ "addRow" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.ByteArrayDecodingState:<init>(org.apache.hadoop.io.erasurecode.rawcoder.RawErasureDecoder,byte[][],int[],byte[][])" : [ "findFirstValidInput", "checkInputBuffers", "checkOutputBuffers" ],
  "org.apache.hadoop.io.compress.zlib.ZlibDecompressor$ZlibDirectDecompressor:<init>(org.apache.hadoop.io.compress.zlib.ZlibDecompressor$CompressionHeader,int)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyStatus:getOwner()" : [ "getOwner" ],
  "org.apache.hadoop.fs.shell.Ls$Lsr:processOptions(java.util.LinkedList)" : [ "processOptions" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:startThreads()" : [ "<init>", "checkState", "updateCurrentKey" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:addRpcQueueTime(long)" : [ "add" ],
  "org.apache.hadoop.ipc.Server:getAuthMethods(org.apache.hadoop.security.token.SecretManager,org.apache.hadoop.conf.Configuration)" : [ "getAuthenticationMethod", "getAuthMethod" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$DelegationTokenInformation:readFields(java.io.DataInput)" : [ "readVLong", "readVInt", "readString" ],
  "org.apache.hadoop.io.compress.zlib.ZlibDecompressor$ZlibDirectDecompressor:finished()" : [ "finished" ],
  "org.apache.hadoop.fs.DFCachingGetSpaceUsed:refresh()" : [ "getUsed" ],
  "org.apache.hadoop.metrics2.impl.MetricsRecordBuilderImpl:addGauge(org.apache.hadoop.metrics2.MetricsInfo,long)" : [ "<init>" ],
  "org.apache.hadoop.util.Shell$ShellCommandExecutor:<init>(java.lang.String[])" : [ "<init>" ],
  "org.apache.hadoop.fs.http.HttpFileSystem:mkdirs(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "mkdirs" ],
  "org.apache.hadoop.security.ShellBasedIdMapping:parseStaticMap(java.io.File)" : [ "<init>", "parseId" ],
  "org.apache.hadoop.fs.QuotaUsage:getQuotaUsage(boolean)" : [ "formatSize" ],
  "org.apache.hadoop.metrics2.impl.SinkQueue:waitForData()" : [ "checkConsumer", "setConsumerLock", "front" ],
  "org.apache.hadoop.metrics2.sink.StatsDSink:init(org.apache.commons.configuration2.SubsetConfiguration)" : [ "<init>", "getHostname" ],
  "org.apache.hadoop.fs.Options$CreateOpts:bytesPerChecksum(short)" : [ "<init>" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RawErasureEncoder:encode(byte[][],byte[][])" : [ "<init>" ],
  "org.apache.hadoop.fs.FileContext$Util:exists(org.apache.hadoop.fs.Path)" : [ "getFileStatus" ],
  "org.apache.hadoop.io.BytesWritable:set(byte[],int,int)" : [ "setSize" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:create(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,boolean,int,short,long,org.apache.hadoop.util.Progressable)" : [ "<init>", "checkNotNull", "equals", "getRootFallbackLink", "getChildren", "getName", "getTargetFileSystem", "getPathWithoutSchemeAndAuthority", "readOnlyMountTable" ],
  "org.apache.hadoop.net.NetworkTopology:<init>()" : [ "newInnerNode" ],
  "org.apache.hadoop.io.retry.RetryPolicies:failoverOnNetworkException(org.apache.hadoop.io.retry.RetryPolicy,int)" : [ "failoverOnNetworkException" ],
  "org.apache.hadoop.security.alias.CredentialProviderFactory:getProviders(org.apache.hadoop.conf.Configuration)" : [ "<init>", "getStringCollection" ],
  "org.apache.hadoop.ipc.metrics.RetryCacheMetrics:getCacheCleared()" : [ "value" ],
  "org.apache.hadoop.crypto.random.OsSecureRandom:fillReservoir(int)" : [ "readFully" ],
  "org.apache.hadoop.fs.shell.TouchCommands$Touch:processOptions(java.util.LinkedList)" : [ "<init>", "popOptionWithArgument", "parse", "getOpt" ],
  "org.apache.hadoop.ipc.Client:setCallIdAndRetryCount(int,int,java.lang.Object)" : [ "checkArgument", "checkState", "setCallIdAndRetryCountUnprotected" ],
  "org.apache.hadoop.io.erasurecode.codec.ErasureCodec:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.io.erasurecode.ErasureCodecOptions)" : [ "<init>", "getSchema", "getNumDataUnits", "getNumParityUnits" ],
  "org.apache.hadoop.fs.permission.FsPermission:toExtendedShort()" : [ "toShort" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreImpl:setMeanStatistic(java.lang.String,org.apache.hadoop.fs.statistics.MeanStatistic)" : [ "set" ],
  "org.apache.hadoop.conf.Configuration:setSocketAddr(java.lang.String,java.net.InetSocketAddress)" : [ "set", "getHostPortString" ],
  "org.apache.hadoop.metrics2.MetricStringBuilder:addGauge(org.apache.hadoop.metrics2.MetricsInfo,float)" : [ "add" ],
  "org.apache.hadoop.ipc.ProtobufHelper:getFixedByteString(java.lang.String)" : [ "getFixedByteString" ],
  "org.apache.hadoop.log.LogLevel$CLI:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:snapshot(org.apache.hadoop.metrics2.MetricsRecordBuilder,boolean)" : [ "tags", "metrics" ],
  "org.apache.hadoop.fs.impl.AbstractFSBuilderImpl:must(java.lang.String,int)" : [ "mustLong" ],
  "org.apache.hadoop.fs.statistics.impl.DynamicIOStatisticsBuilder:withLongFunctionGauge(java.lang.String,java.util.function.ToLongFunction)" : [ "activeInstance", "addGaugeFunction" ],
  "org.apache.hadoop.fs.impl.prefetch.FilePosition:absolute()" : [ "throwIfInvalidBuffer", "relative" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.XORRawDecoder:doDecode(org.apache.hadoop.io.erasurecode.rawcoder.ByteArrayDecodingState)" : [ "resetOutputBuffers" ],
  "org.apache.hadoop.metrics2.lib.MetricsInfoImpl:<init>(java.lang.String,java.lang.String)" : [ "checkNotNull" ],
  "org.apache.hadoop.net.NetworkTopology:sortByDistance(org.apache.hadoop.net.Node,org.apache.hadoop.net.Node[],int)" : [ "sortByDistance" ],
  "org.apache.hadoop.fs.impl.FileSystemMultipartUploader:putPart(org.apache.hadoop.fs.UploadHandle,int,org.apache.hadoop.fs.Path,java.io.InputStream,long)" : [ "eval" ],
  "org.apache.hadoop.fs.FSInputChecker:seek(long)" : [ "resetState", "readFully" ],
  "org.apache.hadoop.ipc.Server$ConnectionManager:close(org.apache.hadoop.ipc.Server$Connection)" : [ "remove", "size", "decrUserConnections", "getShortUserName" ],
  "org.apache.hadoop.fs.shell.FsUsage$Df:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "isViewFileSystem", "isViewFileSystemOverloadScheme", "getStatus", "getTargetFileSystemURIs", "addToUsagesTable", "getMountedOnPath", "toString", "getUsagesTable", "setColumnHide" ],
  "org.apache.hadoop.io.IntWritable$Comparator:<init>()" : [ "<init>" ],
  "org.apache.hadoop.util.bloom.RetouchedBloomFilter:addFalsePositive(org.apache.hadoop.util.bloom.Key[])" : [ "addFalsePositive" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:endCompression()" : [ "bsPutUByte", "bsPutInt", "bsFinishedWithStream" ],
  "org.apache.hadoop.conf.ReconfigurationServlet:applyChanges(java.io.PrintWriter,org.apache.hadoop.conf.Reconfigurable,javax.servlet.http.HttpServletRequest)" : [ "<init>", "getParams", "getRaw" ],
  "org.apache.hadoop.net.unix.DomainSocketWatcher:<init>(int,java.lang.String)" : [ "checkArgument", "socketpair" ],
  "org.apache.hadoop.fs.HarFileSystem$HarFSDataInputStream$HarFsInputStream:readFully(long,byte[],int,int)" : [ "readFully" ],
  "org.apache.hadoop.security.LdapGroupsMapping:loadSslConf(org.apache.hadoop.conf.Configuration)" : [ "get", "getPassword", "extractPassword", "getPasswordFromCredentialProviders" ],
  "org.apache.hadoop.crypto.key.KeyProviderExtension:getKeysMetadata(java.lang.String[])" : [ "getKeysMetadata" ],
  "org.apache.hadoop.util.LightWeightGSet$Values:iterator()" : [ "iterator" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:listLocatedStatus(org.apache.hadoop.fs.Path)" : [ "listLocatedStatus", "isInternalDir" ],
  "org.apache.hadoop.util.bloom.RetouchedBloomFilter:<init>(int,int,int)" : [ "<init>", "createVector" ],
  "org.apache.hadoop.conf.ConfigRedactor:redact(java.lang.String,java.lang.String)" : [ "configIsSensitive" ],
  "org.apache.hadoop.fs.statistics.DurationTrackerFactory:trackDuration(java.lang.String,long)" : [ "stubDurationTracker" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:setXAttr(org.apache.hadoop.fs.Path,java.lang.String,byte[],java.util.EnumSet)" : [ "setXAttr", "fullPath" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator:renewDelegationToken(java.net.URL,org.apache.hadoop.security.authentication.client.AuthenticatedURL$Token,org.apache.hadoop.security.token.Token,java.lang.String)" : [ "doDelegationTokenOperation" ],
  "org.apache.hadoop.ha.protocolPB.ZKFCProtocolServerSideTranslatorPB:getProtocolVersion(java.lang.String,long)" : [ "getProtocolVersion" ],
  "org.apache.hadoop.conf.Configuration:addResource(java.lang.String,boolean)" : [ "<init>", "addResourceObject" ],
  "org.apache.hadoop.security.alias.LocalKeyStoreProvider:flush()" : [ "flush", "valueOf", "setPermission" ],
  "org.apache.hadoop.security.UserGroupInformation$TestingGroups:getGroupsSet(java.lang.String)" : [ "getGroupsSet" ],
  "org.apache.hadoop.fs.shell.Display$Cat:printToStdout(java.io.InputStream)" : [ "copyBytes" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Location:<init>(int,long)" : [ "set" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:<init>(org.apache.hadoop.fs.FileSystem,java.net.URI)" : [ "<init>", "toUri" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:getXAttrs(org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.util.dynamic.BindingUtils:loadInvocation(java.lang.Class,java.lang.Class,java.lang.String,java.lang.Class[])" : [ "<init>", "impl", "orNoop", "build", "isNoop", "noop" ],
  "org.apache.hadoop.fs.FilterFs:getXAttrs(org.apache.hadoop.fs.Path,java.util.List)" : [ "getXAttrs" ],
  "org.apache.hadoop.metrics2.util.SampleStat:min()" : [ "min" ],
  "org.apache.hadoop.crypto.random.OsSecureRandom:finalize()" : [ "close" ],
  "org.apache.hadoop.fs.FSDataOutputStreamBuilder:create()" : [ "getThisBuilder" ],
  "org.apache.hadoop.conf.Configuration:updatePropertiesWithDeprecatedKeys(org.apache.hadoop.conf.Configuration$DeprecationContext,java.lang.String[])" : [ "getReverseDeprecatedKeyMap", "getProps" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Magic:readAndVerify(java.io.DataInput)" : [ "size" ],
  "org.apache.hadoop.ipc.CallQueueManager:put(java.lang.Object)" : [ "put" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:extractCommandOptions(org.apache.hadoop.conf.Configuration,java.util.List)" : [ "parseCommandArgs" ],
  "org.apache.hadoop.fs.FilterFileSystem:getAllStoragePolicies()" : [ "getAllStoragePolicies" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:parseCostProvider(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "getInstances" ],
  "org.apache.hadoop.ipc.RPC:getProxy(java.lang.Class,long,java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration)" : [ "getProxy", "getProtocolProxy" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:setCounter(java.lang.String,long)" : [ "getInnerStatistics" ],
  "org.apache.hadoop.conf.Configuration:onlyKeyExists(java.lang.String)" : [ "handleDeprecation", "getProps" ],
  "org.apache.hadoop.net.NetworkTopology:chooseRandom(org.apache.hadoop.net.InnerNode,org.apache.hadoop.net.Node,java.util.Collection,int,int)" : [ "getRandom" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:setReplication(org.apache.hadoop.fs.Path,short)" : [ "setReplication", "fullPath" ],
  "org.apache.hadoop.log.LogLevel:main(java.lang.String[])" : [ "<init>", "run" ],
  "org.apache.hadoop.metrics2.lib.DefaultMetricsSystem:shutdown()" : [ "shutdownInstance" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:mkOneDir(java.io.File)" : [ "<init>", "mkOneDirWithMode" ],
  "org.apache.hadoop.fs.impl.FlagSet:checkMutable()" : [ "checkState" ],
  "org.apache.hadoop.fs.Globber:createGlobber(org.apache.hadoop.fs.FileSystem)" : [ "<init>" ],
  "org.apache.hadoop.conf.Configured:<init>()" : [ "<init>" ],
  "org.apache.hadoop.io.MapFile$Reader:readIndex()" : [ "<init>", "newKey", "next", "compare", "get", "close" ],
  "org.apache.hadoop.fs.shell.find.Result:toString()" : [ "isPass", "isDescend" ],
  "org.apache.hadoop.crypto.CryptoInputStream:decrypt(org.apache.hadoop.crypto.Decryptor,java.nio.ByteBuffer,java.nio.ByteBuffer,byte)" : [ "checkState" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker:constructRpcRequest(java.lang.reflect.Method,org.apache.hadoop.thirdparty.protobuf.Message)" : [ "<init>", "constructRpcRequestHeader" ],
  "org.apache.hadoop.util.functional.LazyAutoCloseableReference:<init>(org.apache.hadoop.util.functional.CallableRaisingIOE)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.zlib.ZlibCompressor:needsInput()" : [ "setInputFromSavedData" ],
  "org.apache.hadoop.fs.viewfs.InodeTree:buildLinkRegexEntry(org.apache.hadoop.conf.Configuration,org.apache.hadoop.security.UserGroupInformation,java.lang.String,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.FilterFs:getStoragePolicy(org.apache.hadoop.fs.Path)" : [ "getStoragePolicy" ],
  "org.apache.hadoop.io.compress.BlockDecompressorStream:<init>(java.io.InputStream,org.apache.hadoop.io.compress.Decompressor,int)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.find.Find:applyItem(org.apache.hadoop.fs.shell.PathData)" : [ "getOptions", "getMinDepth", "getRootExpression", "equals", "addStop" ],
  "org.apache.hadoop.io.WritableComparator:get(java.lang.Class)" : [ "get" ],
  "org.apache.hadoop.conf.Configuration:setStorageSize(java.lang.String,double,org.apache.hadoop.conf.StorageUnit)" : [ "set" ],
  "org.apache.hadoop.net.StandardSocketFactory:createSocket(java.lang.String,int,java.net.InetAddress,int)" : [ "createSocket" ],
  "org.apache.hadoop.crypto.key.KeyShell:printException(java.lang.Exception)" : [ "prettifyException" ],
  "org.apache.hadoop.ipc.RetryCache:newEntry(java.lang.Object,long,byte[],int)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.impl.MetricsSourceAdapter:stop()" : [ "stopMBeans" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:removeAclEntries(org.apache.hadoop.fs.Path,java.util.List)" : [ "removeAclEntries", "fullPath" ],
  "org.apache.hadoop.util.LightWeightCache:<init>(int,int,long,long)" : [ "<init>" ],
  "org.apache.hadoop.ha.protocolPB.HAServiceProtocolClientSideTranslatorPB:<init>(java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration)" : [ "setProtocolEngine", "getProxy", "getProtocolVersion" ],
  "org.apache.hadoop.crypto.key.KeyProviderCryptoExtension$DefaultCryptoExtension:reencryptEncryptedKeys(java.util.List)" : [ "checkNotNull", "getInstance", "getConf", "getEncryptionKeyName", "getEncryptedKeyVersion", "checkArgument", "getVersionName", "equals", "getCurrentKey", "getName", "getEncryptionKeyVersionName", "decryptEncryptedKey", "generateEncryptedKey", "getMaterial", "getEncryptedKeyIv" ],
  "org.apache.hadoop.security.token.DtUtilShell$Renew:execute()" : [ "renewTokenFile" ],
  "org.apache.hadoop.io.erasurecode.codec.ErasureCodec:getName()" : [ "getCodecName" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:getResolvedQualifiedPath(org.apache.hadoop.fs.Path)" : [ "<init>", "makeQualified", "toUri" ],
  "org.apache.hadoop.fs.http.HttpFileSystem:initialize(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "initialize" ],
  "org.apache.hadoop.util.bloom.DynamicBloomFilter:and(org.apache.hadoop.util.bloom.Filter)" : [ "and" ],
  "org.apache.hadoop.fs.ChecksumFileSystem:listLocatedStatus(org.apache.hadoop.fs.Path)" : [ "listLocatedStatus" ],
  "org.apache.hadoop.io.ObjectWritable:tryInstantiateProtobuf(java.lang.Class,java.io.DataInput)" : [ "getStaticProtobufMethod", "readRawVarint32" ],
  "org.apache.hadoop.fs.FSInputStream:readFully(long,byte[])" : [ "readFully" ],
  "org.apache.hadoop.security.ProviderUtils:noPasswordWarning(java.lang.String,java.lang.String)" : [ "noPasswordInstruction" ],
  "org.apache.hadoop.fs.viewfs.ConfigUtil:addLinkMergeSlash(org.apache.hadoop.conf.Configuration,java.net.URI)" : [ "addLinkMergeSlash", "getDefaultMountTableName" ],
  "org.apache.hadoop.metrics2.lib.MutableRollingAverages:getStats(long)" : [ "monotonicNow", "getSnapshotTimeStamp", "getCount", "getSum" ],
  "org.apache.hadoop.io.Text:skip(java.io.DataInput)" : [ "readVInt", "skipFully" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:selectDelegationToken(org.apache.hadoop.security.Credentials,org.apache.hadoop.io.Text)" : [ "getToken", "equals", "getKind", "getAllTokens" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystemUtil:updateMountPointFsStatus(org.apache.hadoop.fs.viewfs.ViewFileSystem,java.util.Map,org.apache.hadoop.fs.viewfs.ViewFileSystem$MountPoint,org.apache.hadoop.fs.Path)" : [ "getStatus" ],
  "org.apache.hadoop.security.token.Token:decodeFromUrlString(java.lang.String)" : [ "decodeWritable" ],
  "org.apache.hadoop.fs.shell.CommandFactory:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Decompressor:getRemaining()" : [ "checkStream" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:reencryptEncryptedKey(org.apache.hadoop.crypto.key.KeyProviderCryptoExtension$EncryptedKeyVersion)" : [ "doOp", "nextIdx" ],
  "org.apache.hadoop.net.NetworkTopology:sortByDistanceUsingNetworkLocation(org.apache.hadoop.net.Node,org.apache.hadoop.net.Node[],int)" : [ "sortByDistanceUsingNetworkLocation" ],
  "org.apache.hadoop.fs.impl.prefetch.CachingBlockManager:release(org.apache.hadoop.fs.impl.prefetch.BufferData)" : [ "release", "checkNotNull", "getBlockNumber", "end" ],
  "org.apache.hadoop.conf.Configuration:setInt(java.lang.String,int)" : [ "set" ],
  "org.apache.hadoop.io.SequenceFile$Sorter:sortPass(boolean)" : [ "<init>", "setProgressable", "run", "close" ],
  "org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink:xdr_string(java.lang.String)" : [ "xdr_int", "pad" ],
  "org.apache.hadoop.security.SaslRpcClient:isValidAuthType(org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth)" : [ "getMechanismName" ],
  "org.apache.hadoop.io.compress.Lz4Codec:createInputStream(java.io.InputStream,org.apache.hadoop.io.compress.Decompressor)" : [ "<init>", "getInt" ],
  "org.apache.hadoop.io.compress.BlockDecompressorStream:<init>(java.io.InputStream,org.apache.hadoop.io.compress.Decompressor)" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:generateEncryptedKey(java.lang.String)" : [ "doOp", "nextIdx" ],
  "org.apache.hadoop.io.MapFile$Reader:next(org.apache.hadoop.io.WritableComparable,org.apache.hadoop.io.Writable)" : [ "next" ],
  "org.apache.hadoop.io.BytesWritable:setCapacity(int)" : [ "getCapacity" ],
  "org.apache.hadoop.fs.permission.AclUtil:getAclFromPermAndEntries(org.apache.hadoop.fs.permission.FsPermission,java.util.List)" : [ "newArrayListWithCapacity", "setScope", "setType", "setPermission", "getUserAction", "build", "getScope", "getGroupAction", "getOtherAction" ],
  "org.apache.hadoop.ipc.ProxyCombiner$CombinedProxyInvocationHandler:close()" : [ "add", "isEmpty", "build" ],
  "org.apache.hadoop.util.ReadWriteDiskValidatorMetrics:<init>()" : [ "<init>", "newQuantiles" ],
  "org.apache.hadoop.util.SysInfoLinux:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.FileSystem:getDefaultBlockSize()" : [ "getLong" ],
  "org.apache.hadoop.ipc.ResponseBuffer:<init>(int)" : [ "<init>" ],
  "org.apache.hadoop.security.ssl.ReloadingX509KeystoreManager:<init>(java.lang.String,java.lang.String,java.lang.String,java.lang.String)" : [ "loadKeyManager" ],
  "org.apache.hadoop.util.SysInfoLinux:getStorageBytesWritten()" : [ "readProcDisksInfoFile" ],
  "org.apache.hadoop.metrics2.sink.RollingFileSystemSink:throwMetricsException(java.lang.String,java.lang.Throwable)" : [ "<init>" ],
  "org.apache.hadoop.conf.Configuration:setStrings(java.lang.String,java.lang.String[])" : [ "set", "arrayToString" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:getFsStatus(org.apache.hadoop.fs.Path)" : [ "getStatus" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:initialize(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "initialize", "setConfigurationFromURI" ],
  "org.apache.hadoop.service.AbstractService:close()" : [ "stop" ],
  "org.apache.hadoop.conf.Configuration:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.CopyCommandWithMultiThread:isMultiThreadNecessary(java.util.LinkedList)" : [ "hasMoreThanOneSourcePaths" ],
  "org.apache.hadoop.fs.viewfs.ConfigUtil:addLink(org.apache.hadoop.conf.Configuration,java.lang.String,java.net.URI)" : [ "addLink", "getDefaultMountTableName" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator:hasDelegationToken(java.net.URL,org.apache.hadoop.security.authentication.client.AuthenticatedURL$Token)" : [ "getDelegationToken" ],
  "org.apache.hadoop.fs.FilterFileSystem:setOwner(org.apache.hadoop.fs.Path,java.lang.String,java.lang.String)" : [ "setOwner" ],
  "org.apache.hadoop.util.FindClass:run(java.lang.String[])" : [ "usage", "loadClass", "createClassInstance", "loadResource", "dumpResource" ],
  "org.apache.hadoop.security.alias.UserProvider:flush()" : [ "addCredentials" ],
  "org.apache.hadoop.fs.viewfs.ConfigUtil:getDefaultMountTableName(org.apache.hadoop.conf.Configuration)" : [ "get" ],
  "org.apache.hadoop.metrics2.impl.MetricsRecordBuilderImpl:getRecord()" : [ "<init>", "tags", "metrics" ],
  "org.apache.hadoop.util.ShutdownThreadsHelper:shutdownThread(java.lang.Thread)" : [ "shutdownThread" ],
  "org.apache.hadoop.util.ChunkedArrayList:add(java.lang.Object)" : [ "addChunk" ],
  "org.apache.hadoop.tools.TableListing$Builder:addField(java.lang.String)" : [ "addField" ],
  "org.apache.hadoop.fs.shell.CommandWithDestination:processArguments(java.util.LinkedList)" : [ "<init>", "toString", "isDirectory", "parentExists", "toUri" ],
  "org.apache.hadoop.fs.GlobPattern:<init>(java.lang.String)" : [ "set" ],
  "org.apache.hadoop.io.retry.RetryPolicies$FailoverOnNetworkExceptionRetry:shouldRetry(java.lang.Exception,int,int,boolean)" : [ "<init>", "getFailoverOrRetrySleepTime", "getWrappedRetriableException" ],
  "org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream:hflush()" : [ "flush" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:skipToNextBlockMarker()" : [ "skipToNextMarker" ],
  "org.apache.hadoop.fs.FsShellPermissions:registerCommands(org.apache.hadoop.fs.shell.CommandFactory)" : [ "addClass" ],
  "org.apache.hadoop.fs.HarFileSystem$HarFSDataInputStream$HarFsInputStream:available()" : [ "getPos" ],
  "org.apache.hadoop.io.MapFile$Reader:<init>(org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration,org.apache.hadoop.io.SequenceFile$Reader$Option[])" : [ "getValue", "getInt", "open" ],
  "org.apache.hadoop.fs.shell.CommandWithDestination:copyFileToTarget(org.apache.hadoop.fs.shell.PathData,org.apache.hadoop.fs.shell.PathData)" : [ "checkPathsForReservedRaw", "setVerifyChecksum", "awaitFuture", "openFile", "withFileStatus", "build", "copyStreamToTarget", "preserveAttributes", "closeStream" ],
  "org.apache.hadoop.fs.impl.prefetch.BufferPool:acquireHelper(int,boolean)" : [ "<init>", "checkNotNegative", "releaseDoneBlocks", "find", "checkState" ],
  "org.apache.hadoop.fs.FileStatus:<init>(long,boolean,int,long,long,org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:getPermissions(com.jcraft.jsch.ChannelSftp$LsEntry)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.lib.MethodMetric:newCounter(java.lang.Class)" : [ "<init>", "isInt", "isLong" ],
  "org.apache.hadoop.metrics2.lib.MutableGaugeFloat:incr(float)" : [ "compareAndSet" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsSnapshot:<init>()" : [ "createMaps" ],
  "org.apache.hadoop.fs.FileContext:getStoragePolicy(org.apache.hadoop.fs.Path)" : [ "fixRelativePart" ],
  "org.apache.hadoop.util.LightWeightCache:<init>(int,int,long,long,org.apache.hadoop.util.Timer)" : [ "<init>", "updateRecommendedLength" ],
  "org.apache.hadoop.security.UserGroupInformation:spawnAutoRenewalThreadForUserCreds(boolean)" : [ "shouldRelogin", "isFromKeytab", "getTGT", "get", "getRefreshTime", "executeAutoRenewalTask", "getUserName" ],
  "org.apache.hadoop.fs.FileSystem:copyFromLocalFile(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "copyFromLocalFile" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:iostatisticsContext_snapshot()" : [ "checkIoStatisticsContextAvailable", "invoke" ],
  "org.apache.hadoop.ipc.FairCallQueue:offer(org.apache.hadoop.ipc.Schedulable)" : [ "signalNotEmpty" ],
  "org.apache.hadoop.io.MapFile:main(java.lang.String[])" : [ "<init>", "getLocal", "newInstance", "getKeyClass", "getValueClass", "next", "append", "cleanupWithLogger", "close" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyOutputStream:close()" : [ "close", "osException", "cleanupAllTmpFiles", "commit" ],
  "org.apache.hadoop.fs.impl.AbstractMultipartUploader:abortUploadsUnderPath(org.apache.hadoop.fs.Path)" : [ "checkPath" ],
  "org.apache.hadoop.util.WeakReferenceMap:prune()" : [ "noteLost" ],
  "org.apache.hadoop.util.concurrent.HadoopExecutors:newFixedThreadPool(int,java.util.concurrent.ThreadFactory)" : [ "<init>" ],
  "org.apache.hadoop.ha.ZKFailoverController$HealthCallbacks:enteredState(org.apache.hadoop.ha.HealthMonitor$State)" : [ "setLastHealthState" ],
  "org.apache.hadoop.util.curator.ZKCuratorManager:start(java.util.List,boolean)" : [ "<init>", "get", "getInt", "getZKAuths", "getScheme", "getAuth", "validateSslConfiguration" ],
  "org.apache.hadoop.io.nativeio.NativeIO:ensureInitialized()" : [ "<init>", "getLong" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RawErasureDecoder:decode(org.apache.hadoop.io.erasurecode.ECChunk[],int[],org.apache.hadoop.io.erasurecode.ECChunk[])" : [ "decode", "toBuffers" ],
  "org.apache.hadoop.security.SecurityUtil:getTokenServiceAddr(org.apache.hadoop.security.token.Token)" : [ "createSocketAddr", "getService", "toString" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState:finish()" : [ "returnCompressor" ],
  "org.apache.hadoop.service.CompositeService$CompositeServiceShutdownHook:run()" : [ "stopQuietly" ],
  "org.apache.hadoop.metrics2.impl.MetricGaugeInt:<init>(org.apache.hadoop.metrics2.MetricsInfo,int)" : [ "<init>" ],
  "org.apache.hadoop.fs.FsShellPermissions$Chown:processOptions(java.util.LinkedList)" : [ "<init>", "parse", "getOpt", "parseOwnerGroup" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:listStatus(org.apache.hadoop.fs.Path)" : [ "listStatus", "connect", "disconnect" ],
  "org.apache.hadoop.io.SequenceFile$Writer:syncInterval(int)" : [ "<init>" ],
  "org.apache.hadoop.ipc.FairCallQueue:offerQueue(int,org.apache.hadoop.ipc.Schedulable)" : [ "signalNotEmpty" ],
  "org.apache.hadoop.fs.impl.prefetch.FilePosition:<init>(long,int)" : [ "<init>", "checkNotNegative", "checkPositiveInteger", "invalidate" ],
  "org.apache.hadoop.crypto.JceAesCtrCryptoCodec:calculateIV(byte[],long,byte[])" : [ "calculateIV", "getCipherSuite", "getAlgorithmBlockSize" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:mkdirs(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "mkdirs", "connect", "disconnect" ],
  "org.apache.hadoop.fs.ChecksumFs$ChecksumFSInputChecker:seekToNewSource(long)" : [ "seekToNewSource", "getChecksumFilePos", "reportChecksumFailure" ],
  "org.apache.hadoop.ipc.RPC$Server:<init>(java.lang.String,int,java.lang.Class,int,int,int,org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.hadoop.security.token.SecretManager,java.lang.String)" : [ "<init>", "initProtocolMetaInfo" ],
  "org.apache.hadoop.crypto.CryptoInputStream:<init>(java.io.InputStream,org.apache.hadoop.crypto.CryptoCodec,int,byte[],byte[])" : [ "<init>", "getInputStreamOffset" ],
  "org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$WaitableMetricsBuffer:<init>(org.apache.hadoop.metrics2.impl.MetricsBuffer)" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.kms.ValueQueue:writeLock(java.lang.String)" : [ "getLock" ],
  "org.apache.hadoop.ipc.Server:getNumOpenConnectionsPerUser()" : [ "getUserToConnectionsMap" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:getFsStatus()" : [ "getStatus" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:setupNoRandPartB()" : [ "setupNoRandPartA", "setupNoRandPartC" ],
  "org.apache.hadoop.fs.LocalDirAllocator:getLocalPathToRead(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "getLocalPathToRead", "obtainContext" ],
  "org.apache.hadoop.fs.FileContext:getFileContext()" : [ "<init>", "getFileContext" ],
  "org.apache.hadoop.security.token.delegation.SQLDelegationTokenSecretManager:updateDelegationKey(org.apache.hadoop.security.token.delegation.DelegationKey)" : [ "updateDelegationKey", "write", "getKeyId" ],
  "org.apache.hadoop.crypto.key.UserProvider:getKeyVersion(java.lang.String)" : [ "<init>", "getSecretKey" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:register(java.lang.String,java.lang.String,org.apache.hadoop.metrics2.MetricsSink)" : [ "register", "registerSink" ],
  "org.apache.hadoop.metrics2.impl.MetricGaugeDouble:<init>(org.apache.hadoop.metrics2.MetricsInfo,double)" : [ "<init>" ],
  "org.apache.hadoop.security.SaslRpcClient:createSaslClient(org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth)" : [ "<init>", "getClientProperties", "getServerToken", "getRealAuthenticationMethod", "getAuthMethod", "getServerPrincipal", "getMechanismName" ],
  "org.apache.hadoop.fs.FSInputStream:toString()" : [ "ioStatisticsSourceToString" ],
  "org.apache.hadoop.security.KDiag:validateKinitExecutable()" : [ "getTrimmed", "println", "verifyFileIsValid", "printEnv" ],
  "org.apache.hadoop.metrics2.impl.SinkQueue:dequeue()" : [ "checkConsumer", "_dequeue" ],
  "org.apache.hadoop.io.SequenceFile$Reader:getValueClass()" : [ "getClass", "getValueClassName" ],
  "org.apache.hadoop.metrics2.impl.MetricsRecordBuilderImpl:addGauge(org.apache.hadoop.metrics2.MetricsInfo,float)" : [ "<init>" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:iostatisticsContext_setThreadIOStatisticsContext(java.lang.Object)" : [ "checkIoStatisticsContextAvailable", "invoke" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsSnapshot:toString()" : [ "ioStatisticsToString" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkPathExistsAsDir(java.nio.file.Path,java.lang.String)" : [ "checkPathExists", "checkArgument" ],
  "org.apache.hadoop.metrics2.impl.MetricGaugeLong:<init>(org.apache.hadoop.metrics2.MetricsInfo,long)" : [ "<init>" ],
  "org.apache.hadoop.fs.statistics.impl.EvaluatingStatisticsMap:snapshot()" : [ "snapshotMap" ],
  "org.apache.hadoop.fs.impl.AbstractMultipartUploader:checkUploadId(byte[])" : [ "checkArgument" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "rename", "connect", "disconnect" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:forceDecay()" : [ "decayCurrentCosts" ],
  "org.apache.hadoop.service.launcher.InterruptEscalator:<init>(org.apache.hadoop.service.launcher.ServiceLauncher,int)" : [ "checkArgument" ],
  "org.apache.hadoop.fs.FileContext:getFileBlockLocations(org.apache.hadoop.fs.Path,long,long)" : [ "fixRelativePart" ],
  "org.apache.hadoop.fs.statistics.impl.StatisticDurationTracker:<init>(org.apache.hadoop.fs.statistics.impl.IOStatisticsStore,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.impl.MetricsSourceAdapter:updateJmxCache()" : [ "now", "getMetrics", "updateAttrCache", "updateInfoCache" ],
  "org.apache.hadoop.ipc.ProtocolSignature:getFingerprints(java.lang.reflect.Method[])" : [ "getFingerprint" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.util.DumpUtil:dumpChunks(java.lang.String,org.apache.hadoop.io.erasurecode.ECChunk[])" : [ "dumpChunk" ],
  "org.apache.hadoop.metrics2.impl.MetricsConfig:getFilter(java.lang.String)" : [ "subset", "getPlugin" ],
  "org.apache.hadoop.io.file.tfile.Compression$Algorithm$1:createDecompressionStream(java.io.InputStream,org.apache.hadoop.io.compress.Decompressor,int)" : [ "isSupported", "setInt" ],
  "org.apache.hadoop.crypto.key.KeyShell$DeleteCommand:validate()" : [ "confirmPrompt" ],
  "org.apache.hadoop.fs.sftp.SFTPInputStream:seekInternal()" : [ "toUri" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:getKeyVersion(java.lang.String)" : [ "checkNotEmpty", "createURL", "createConnection", "call", "parseJSONKeyVersion" ],
  "org.apache.hadoop.util.bloom.RetouchedBloomFilter:addFalsePositive(org.apache.hadoop.util.bloom.Key)" : [ "hash", "clear" ],
  "org.apache.hadoop.fs.shell.CommandWithDestination:checkPathsForReservedRaw(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "<init>", "getPathWithoutSchemeAndAuthority", "toString" ],
  "org.apache.hadoop.util.functional.RemoteIterators:toArray(org.apache.hadoop.fs.RemoteIterator,java.lang.Object[])" : [ "toList" ],
  "org.apache.hadoop.fs.impl.FileSystemMultipartUploader:complete(org.apache.hadoop.fs.UploadHandle,org.apache.hadoop.fs.Path,java.util.Map)" : [ "eval" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:<init>(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>", "get" ],
  "org.apache.hadoop.ipc.RefreshRegistry:dispatch(java.lang.String,java.lang.String[])" : [ "<init>", "handlerName", "getMessage", "getReturnCode", "setSenderName" ],
  "org.apache.hadoop.fs.shell.PathData:toString()" : [ "uriToString" ],
  "org.apache.hadoop.fs.GetSpaceUsed$Builder:build()" : [ "<init>", "getKlass", "init" ],
  "org.apache.hadoop.fs.PathIOException:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider$KMSTokenRenewer:cancel(org.apache.hadoop.security.token.Token,org.apache.hadoop.conf.Configuration)" : [ "createKeyProvider", "close" ],
  "org.apache.hadoop.security.NetgroupCache:getNetgroupNames()" : [ "getGroups" ],
  "org.apache.hadoop.fs.FileSystem:createSnapshot(org.apache.hadoop.fs.Path)" : [ "createSnapshot" ],
  "org.apache.hadoop.fs.FileSystemStorageStatistics$LongStatisticIterator:next()" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.FutureIOSupport:awaitFuture(java.util.concurrent.Future)" : [ "awaitFuture" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:addMaximumSample(java.lang.String,long)" : [ "getInnerStatistics" ],
  "org.apache.hadoop.security.token.delegation.SQLDelegationTokenSecretManager:getTokenInfoFromSQL(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier)" : [ "getSequenceNumber", "createTokenInfo" ],
  "org.apache.hadoop.conf.Configuration:set(java.lang.String,java.lang.String)" : [ "set" ],
  "org.apache.hadoop.ipc.WritableRpcEngine$Invocation:readFields(java.io.DataInput)" : [ "<init>", "readString", "readObject", "getDeclaredClass" ],
  "org.apache.hadoop.ipc.Client$ConnectionId:hashCode()" : [ "hashCode" ],
  "org.apache.hadoop.io.SequenceFile:createWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType)" : [ "createWriter", "file", "keyClass", "valueClass", "compression" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:getFileBlockLocations(org.apache.hadoop.fs.Path,long,long)" : [ "fullPath" ],
  "org.apache.hadoop.util.bloom.DynamicBloomFilter:xor(org.apache.hadoop.util.bloom.Filter)" : [ "xor" ],
  "org.apache.hadoop.io.compress.SnappyCodec:createInputStream(java.io.InputStream)" : [ "createInputStreamWithCodecPool" ],
  "org.apache.hadoop.fs.sftp.SFTPInputStream:read()" : [ "checkNotClosed", "seekInternal", "incrementBytesRead" ],
  "org.apache.hadoop.io.compress.zlib.ZlibFactory:getZlibCompressorType(org.apache.hadoop.conf.Configuration)" : [ "isNativeZlibLoaded" ],
  "org.apache.hadoop.net.SocketInputStream:<init>(java.nio.channels.ReadableByteChannel,long)" : [ "<init>", "checkChannelValidity" ],
  "org.apache.hadoop.security.ShellBasedIdMapping:getGid(java.lang.String)" : [ "checkAndUpdateMaps", "updateMapIncr" ],
  "org.apache.hadoop.io.file.tfile.Chunk$ChunkEncoder:flush()" : [ "flushBuffer" ],
  "org.apache.hadoop.util.Shell:getSymlinkCommand(java.lang.String,java.lang.String)" : [ "getWinUtilsPath" ],
  "org.apache.hadoop.io.erasurecode.coder.ErasureEncoder:getInputBlocks(org.apache.hadoop.io.erasurecode.ECBlockGroup)" : [ "getDataBlocks" ],
  "org.apache.hadoop.fs.viewfs.InodeTree:addRegexMountEntry(org.apache.hadoop.fs.viewfs.InodeTree$LinkEntry)" : [ "<init>", "getSrc", "getTarget", "getSettings", "initialize" ],
  "org.apache.hadoop.fs.FileSystem:listLocatedStatus(org.apache.hadoop.fs.Path)" : [ "listLocatedStatus" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider$KMSKeyVersion:<init>(java.lang.String,java.lang.String,byte[])" : [ "<init>" ],
  "org.apache.hadoop.io.retry.RetryPolicies$FailoverOnNetworkExceptionRetry:<init>(org.apache.hadoop.io.retry.RetryPolicy,int,long,long)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.lib.MutableQuantiles:snapshot(org.apache.hadoop.metrics2.MetricsRecordBuilder,boolean)" : [ "getQuantiles" ],
  "org.apache.hadoop.metrics2.impl.MetricsConfig:create(java.lang.String)" : [ "loadFirst", "toLowerCase" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:listStatusForFallbackLink()" : [ "<init>", "getRootFallbackLink", "getTargetFileSystem", "getPathWithoutSchemeAndAuthority", "isRoot", "getFileContext", "util", "exists", "getPath", "getName", "setPath" ],
  "org.apache.hadoop.fs.QuotaUsage$Builder:build()" : [ "<init>" ],
  "org.apache.hadoop.io.SequenceFile$Metadata:equals(org.apache.hadoop.io.SequenceFile$Metadata)" : [ "equals" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:decodeTokenIdentifier(org.apache.hadoop.security.token.Token)" : [ "decodeIdentifier" ],
  "org.apache.hadoop.ipc.Client$Call:setRpcResponse(org.apache.hadoop.io.Writable)" : [ "callComplete" ],
  "org.apache.hadoop.metrics2.sink.StatsDSink$StatsD:write(java.lang.String)" : [ "createSocket" ],
  "org.apache.hadoop.fs.impl.prefetch.CachingBlockManager:requestCaching(org.apache.hadoop.fs.impl.prefetch.BufferData)" : [ "<init>", "requestCaching", "setDone", "checkNotNull", "stateEqualsOneOf", "getBlockNumber", "getState", "getActionFuture", "executeFunction", "setCaching", "end" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine$RpcProtobufRequest:toString()" : [ "getRequestHeader" ],
  "org.apache.hadoop.io.SequenceFile$BlockCompressWriter:sync()" : [ "sync", "writeVInt", "writeBuffer", "reset" ],
  "org.apache.hadoop.security.JniBasedUnixGroupsNetgroupMappingWithFallback:getGroupsSet(java.lang.String)" : [ "getGroupsSet" ],
  "org.apache.hadoop.ipc.Client$Connection:receiveRpcResponse()" : [ "<init>", "touch", "readResponse", "wrap", "getValue", "checkResponse", "newInstance", "setRpcResponse", "remaining", "setException", "markClosed" ],
  "org.apache.hadoop.service.AbstractService:registerGlobalListener(org.apache.hadoop.service.ServiceStateChangeListener)" : [ "add" ],
  "org.apache.hadoop.fs.FSDataOutputStreamBuilder:progress(org.apache.hadoop.util.Progressable)" : [ "checkNotNull", "getThisBuilder" ],
  "org.apache.hadoop.io.BinaryComparable:compareTo(byte[],int,int)" : [ "compareBytes" ],
  "org.apache.hadoop.fs.FilterFs:setXAttr(org.apache.hadoop.fs.Path,java.lang.String,byte[])" : [ "setXAttr" ],
  "org.apache.hadoop.security.authorize.ProxyUsers:authorize(org.apache.hadoop.security.UserGroupInformation,java.net.InetAddress)" : [ "getSip" ],
  "org.apache.hadoop.security.Credentials:addAll(org.apache.hadoop.security.Credentials,boolean)" : [ "addToken" ],
  "org.apache.hadoop.fs.impl.StoreImplementationUtils:hasCapability(java.io.OutputStream,java.lang.String)" : [ "objectHasCapability" ],
  "org.apache.hadoop.metrics2.impl.MetricsRecordImpl:context()" : [ "info", "value" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyStatus:getPermission()" : [ "getPermission" ],
  "org.apache.hadoop.fs.BBPartHandle:from(java.nio.ByteBuffer)" : [ "<init>" ],
  "org.apache.hadoop.io.SequenceFile$Writer$AppendIfExistsOption:<init>(boolean)" : [ "<init>" ],
  "org.apache.hadoop.net.unix.DomainSocket$DomainChannel:read(java.nio.ByteBuffer)" : [ "reference" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:addPersistedDelegationToken(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier,long)" : [ "<init>", "getMasterKeyId", "formatTokenId", "getKey", "getSequenceNumber", "getDelegationTokenSeqNum", "setDelegationTokenSeqNum", "getTokenInfo", "getTrackingIdIfEnabled", "addTokenForOwnerStats" ],
  "org.apache.hadoop.io.MapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.io.WritableComparator,java.lang.Class)" : [ "<init>", "comparator", "valueClass" ],
  "org.apache.hadoop.io.BytesWritable:get()" : [ "getBytes" ],
  "org.apache.hadoop.io.retry.AsyncCallHandler$AsyncValue:set(java.lang.Object)" : [ "checkNotNull", "checkState" ],
  "org.apache.hadoop.fs.shell.Head:processOptions(java.util.LinkedList)" : [ "<init>", "parse" ],
  "org.apache.hadoop.fs.XAttrSetFlag:validate(java.lang.String,boolean,java.util.EnumSet)" : [ "<init>" ],
  "org.apache.hadoop.util.CrcComposer:update(int,long)" : [ "composeWithMonomial", "compose", "intToBytes" ],
  "org.apache.hadoop.util.StringUtils:unEscapeString(java.lang.String)" : [ "unEscapeString" ],
  "org.apache.hadoop.ipc.FairCallQueue$MetricsProxy:getMetrics(org.apache.hadoop.metrics2.MetricsCollector,boolean)" : [ "info", "getQueueSizes", "getOverflowedCalls" ],
  "org.apache.hadoop.fs.http.AbstractHttpFileSystem:hasPathCapability(org.apache.hadoop.fs.Path,java.lang.String)" : [ "hasPathCapability", "validatePathCapabilityArgs" ],
  "org.apache.hadoop.io.Text:write(java.io.DataOutput,int)" : [ "writeVInt" ],
  "org.apache.hadoop.io.SequenceFile$Writer$BlockSizeOption:<init>(long)" : [ "<init>" ],
  "org.apache.hadoop.fs.ftp.FtpFs:getServerDefaults(org.apache.hadoop.fs.Path)" : [ "getServerDefaults" ],
  "org.apache.hadoop.fs.FilterFileSystem:getStoragePolicy(org.apache.hadoop.fs.Path)" : [ "getStoragePolicy" ],
  "org.apache.hadoop.util.MergeSort:mergeSort(int[],int[],int,int)" : [ "set", "swap" ],
  "org.apache.hadoop.metrics2.sink.GraphiteSink$Graphite:connect()" : [ "<init>", "isConnected", "tooManyConnectionFailures" ],
  "org.apache.hadoop.io.SequenceFile$Sorter$SortPass:sort(int)" : [ "mergeSort" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:init()" : [ "readAByte", "initBlock", "setupBlock" ],
  "org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream:write(int)" : [ "<init>", "incrementCounter" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:addResponseTime(java.lang.String,org.apache.hadoop.ipc.Schedulable,org.apache.hadoop.ipc.ProcessingDetails)" : [ "addCost", "get", "addQueueTime", "addProcessingTime" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:delete(org.apache.hadoop.fs.Path,boolean)" : [ "delete", "connect", "disconnect" ],
  "org.apache.hadoop.ipc.CallQueueManager:swapQueue(java.lang.Class,java.lang.Class,int,java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "parseNumLevels", "createScheduler", "parseCapacityWeights", "getServerFailOverEnable", "createCallQueueInstance", "queueIsReallyEmpty", "stringRepr" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:changeStateToProcessABlock()" : [ "initBlock", "setupBlock" ],
  "org.apache.hadoop.util.Daemon$DaemonFactory:newThread(java.lang.Runnable)" : [ "<init>" ],
  "org.apache.hadoop.http.ProfileServlet:doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)" : [ "isInstrumentationAccessAllowed", "setResponseHeader", "getInteger", "getOutput", "getEvent", "getLong", "getMinWidth", "getInternalName", "runCmdAsync" ],
  "org.apache.hadoop.net.SocketOutputStream$Writer:<init>(java.nio.channels.WritableByteChannel,long)" : [ "<init>" ],
  "org.apache.hadoop.util.ReflectionUtils:printThreadInfo(java.io.PrintStream,java.lang.String)" : [ "getTaskName" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:getAndMoveToFrontDecode()" : [ "bsR", "recvDecodingTables", "getAndMoveToFrontDecode0", "readAByte" ],
  "org.apache.hadoop.metrics2.lib.DefaultMetricsFactory:getInstance(java.lang.Class)" : [ "<init>" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:mkOneDirWithMode(org.apache.hadoop.fs.Path,java.io.File,org.apache.hadoop.fs.permission.FsPermission)" : [ "getDirDefault", "applyUMask", "getUMask", "isAvailable", "createDirectoryWithMode", "toShort", "setPermission" ],
  "org.apache.hadoop.ha.ZKFCRpcServer:cedeActive(int)" : [ "cedeActive" ],
  "org.apache.hadoop.fs.LocalFileSystem:createSymlink(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,boolean)" : [ "createSymlink" ],
  "org.apache.hadoop.crypto.key.UserProvider:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>", "getCurrentUser", "getCredentials" ],
  "org.apache.hadoop.util.LightWeightGSet$Values:contains(java.lang.Object)" : [ "contains" ],
  "org.apache.hadoop.io.MapFile$Writer:keyClass(java.lang.Class)" : [ "<init>" ],
  "org.apache.hadoop.util.DataChecksum:newDataChecksum(org.apache.hadoop.util.DataChecksum$Type,int)" : [ "<init>", "newCrc32", "newCrc32C" ],
  "org.apache.hadoop.metrics2.impl.MetricsRecordBuilderImpl:addGauge(org.apache.hadoop.metrics2.MetricsInfo,double)" : [ "<init>" ],
  "org.apache.hadoop.io.retry.RetryUtils:getMultipleLinearRandomRetry(org.apache.hadoop.conf.Configuration,java.lang.String,boolean,java.lang.String,java.lang.String)" : [ "getBoolean", "get", "parseCommaSeparatedString" ],
  "org.apache.hadoop.io.SequenceFile:createWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.util.Progressable)" : [ "createWriter", "file", "keyClass", "valueClass", "compression", "progressable" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RSRawErasureCoderFactory:createEncoder(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:publishMetricsNow()" : [ "publishMetrics", "sampleMetrics" ],
  "org.apache.hadoop.io.retry.RetryPolicies:retryUpToMaximumTimeWithFixedSleep(long,long,java.util.concurrent.TimeUnit)" : [ "<init>" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.XORRawEncoder:<init>(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.CoderUtil:resetBuffer(java.nio.ByteBuffer,int)" : [ "getEmptyChunk" ],
  "org.apache.hadoop.io.compress.lz4.Lz4Decompressor:needsInput()" : [ "setInputFromSavedData" ],
  "org.apache.hadoop.security.ssl.SSLHostnameVerifier$AbstractVerifier:check(java.lang.String,javax.net.ssl.SSLSocket)" : [ "check" ],
  "org.apache.hadoop.fs.shell.PathData:openFile(java.lang.String)" : [ "openFile", "awaitFuture", "getLen", "build" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:incrSlowRpc()" : [ "incr" ],
  "org.apache.hadoop.metrics2.impl.MetricsSourceAdapter:updateAttrCache(java.lang.Iterable)" : [ "checkNotNull", "tags", "setAttrCacheTag", "metrics", "setAttrCacheMetric" ],
  "org.apache.hadoop.util.Shell:getQualifiedBinPath(java.lang.String)" : [ "getQualifiedBin" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:setWorkingDirectory(org.apache.hadoop.fs.Path)" : [ "<init>", "isAbsolute" ],
  "org.apache.hadoop.fs.BufferedFSInputStream:readFully(long,byte[],int,int)" : [ "readFully" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:numberOfBytesTillNextMarker(java.io.InputStream)" : [ "<init>", "getProcessedByteCount" ],
  "org.apache.hadoop.fs.FileUtil:checkDest(java.lang.String,org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,boolean)" : [ "<init>", "isDirectory", "toString" ],
  "org.apache.hadoop.util.LightWeightGSet:get(java.lang.Object)" : [ "getIndex", "convert" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:sendMTFValues()" : [ "sendMTFValues0", "sendMTFValues1", "sendMTFValues2", "sendMTFValues3", "sendMTFValues4", "sendMTFValues5", "sendMTFValues6", "sendMTFValues7" ],
  "org.apache.hadoop.metrics2.sink.RollingFileSystemSink:getRollInterval()" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:satisfyStoragePolicy(org.apache.hadoop.fs.Path)" : [ "satisfyStoragePolicy", "fullPath" ],
  "org.apache.hadoop.fs.Options$HandleOpt:content()" : [ "changed", "moved" ],
  "org.apache.hadoop.ha.HealthMonitor:tryConnect()" : [ "checkState", "createProxy", "enterState" ],
  "org.apache.hadoop.fs.ChecksumFileSystem:copyToLocalFile(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,boolean)" : [ "<init>", "copyToLocalFile", "isDirectory", "getName", "getChecksumFile", "exists", "listStatus", "getPath" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:getFileStatus(org.apache.hadoop.fs.Path)" : [ "fullPath" ],
  "org.apache.hadoop.metrics2.impl.MetricsBufferBuilder:get()" : [ "<init>" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Reader$BlockReader:getCompressionName()" : [ "getCompressionName" ],
  "org.apache.hadoop.security.SaslInputStream:read(java.nio.ByteBuffer)" : [ "read" ],
  "org.apache.hadoop.fs.QuotaUsage:toString(boolean)" : [ "toString" ],
  "org.apache.hadoop.crypto.key.KeyProvider:createKey(java.lang.String,org.apache.hadoop.crypto.key.KeyProvider$Options)" : [ "generateKey", "getBitLength", "getCipher" ],
  "org.apache.hadoop.fs.shell.PathData:lookupStat(org.apache.hadoop.fs.FileSystem,java.lang.String,boolean)" : [ "<init>" ],
  "org.apache.hadoop.security.UserGroupInformation:getGroupNames()" : [ "getGroupsSet" ],
  "org.apache.hadoop.ha.HealthMonitor:loopUntilConnected()" : [ "tryConnect" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:open(org.apache.hadoop.fs.Path,int)" : [ "<init>", "connect", "makeAbsolute", "getFileStatus", "isDirectory", "disconnect", "toUri" ],
  "org.apache.hadoop.io.wrappedio.WrappedIO:fileSystem_openFile(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,java.lang.String,org.apache.hadoop.fs.FileStatus,java.lang.Long,java.util.Map)" : [ "uncheckIOExceptions", "withFileStatus" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:exists(org.apache.hadoop.fs.Path)" : [ "pathToFile" ],
  "org.apache.hadoop.io.SequenceFile$Reader:initialize(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.FSDataInputStream,long,long,org.apache.hadoop.conf.Configuration,boolean)" : [ "toString", "seek", "getPos", "init", "cleanupWithLogger" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator:renewDelegationToken(java.net.URL,org.apache.hadoop.security.authentication.client.AuthenticatedURL$Token,org.apache.hadoop.security.token.Token)" : [ "renewDelegationToken" ],
  "org.apache.hadoop.fs.BlockLocation:setTopologyPaths(java.lang.String[])" : [ "internStringsInArray" ],
  "org.apache.hadoop.security.token.TokenIdentifier:getTrackingId()" : [ "getBytes" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:<init>()" : [ "<init>" ],
  "org.apache.hadoop.util.FindClass:<init>()" : [ "<init>" ],
  "org.apache.hadoop.security.token.DtUtilShell:init(java.lang.String[])" : [ "<init>", "maybeDoLoginFromKeytabAndPrincipal" ],
  "org.apache.hadoop.crypto.key.KeyProvider$Options:<init>(org.apache.hadoop.conf.Configuration)" : [ "get", "getInt" ],
  "org.apache.hadoop.ipc.RetryCache:waitForCompletion(org.apache.hadoop.ipc.RetryCache,java.lang.Object,byte[],int)" : [ "waitForCompletion", "skipRetryCache", "newEntry" ],
  "org.apache.hadoop.security.UserGroupInformation:doSubjectLogin(javax.security.auth.Subject,org.apache.hadoop.security.UserGroupInformation$LoginParams)" : [ "<init>", "ensureInitialized", "getDefaults", "newLoginContext", "getLoginAppName", "login", "put", "getUserName", "setLogin", "setLastLogin", "now", "setPrincipal", "setKeytabFile", "setTicketCacheFile" ],
  "org.apache.hadoop.http.HttpServer2:getConnectorAddress(int)" : [ "checkArgument" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:merge(org.apache.hadoop.fs.FileStatus[],org.apache.hadoop.fs.FileStatus[])" : [ "getPath", "getName" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:close()" : [ "finish", "closeStream" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RSRawEncoder:doEncode(org.apache.hadoop.io.erasurecode.rawcoder.ByteArrayEncodingState)" : [ "resetOutputBuffers", "encodeData" ],
  "org.apache.hadoop.util.DataChecksum:writeValue(java.io.DataOutputStream,boolean)" : [ "reset" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreImpl:getCounterReference(java.lang.String)" : [ "lookup" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:getKeyVersions(java.lang.String)" : [ "doOp", "nextIdx" ],
  "org.apache.hadoop.fs.FileSystem:getUsed()" : [ "<init>", "getUsed" ],
  "org.apache.hadoop.fs.QuotaUsage:toString()" : [ "toString" ],
  "org.apache.hadoop.io.SequenceFile$Reader$OnlyHeaderOption:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.HarFileSystem:makeRelative(java.lang.String,org.apache.hadoop.fs.Path)" : [ "<init>", "compareTo", "getName", "getParent", "depth", "toString" ],
  "org.apache.hadoop.net.NetUtils:getInputStream(java.net.Socket,long)" : [ "<init>", "setTimeout" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsSnapshot:snapshot(org.apache.hadoop.fs.statistics.IOStatistics)" : [ "checkNotNull", "snapshotMap", "copy" ],
  "org.apache.hadoop.io.compress.ZStandardCodec:createInputStream(java.io.InputStream)" : [ "createInputStreamWithCodecPool" ],
  "org.apache.hadoop.ipc.Client$Connection:sendPing()" : [ "now", "sendRequest", "flush" ],
  "org.apache.hadoop.io.retry.RetryInvocationHandler:log(java.lang.reflect.Method,boolean,int,int,long,java.lang.Exception)" : [ "getProxyInfo", "toString", "hasSuccessfulCall", "getString" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:exitWithUsageMessage()" : [ "exitWithMessage" ],
  "org.apache.hadoop.ipc.UserIdentityProvider:makeIdentity(org.apache.hadoop.ipc.Schedulable)" : [ "getShortUserName" ],
  "org.apache.hadoop.http.HttpServer2$QuotingInputFilter$RequestQuoter:getParameterValues(java.lang.String)" : [ "unquoteHtmlChars", "quoteHtmlChars" ],
  "org.apache.hadoop.util.UTF8ByteArrayUtils:findNthByte(byte[],int,int,byte,int)" : [ "findByte" ],
  "org.apache.hadoop.io.BloomMapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.io.WritableComparator,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.util.Progressable)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.impl.MBeanInfoBuilder:gauge(org.apache.hadoop.metrics2.MetricsInfo,double)" : [ "newAttrInfo" ],
  "org.apache.hadoop.fs.FileUtil:unTar(java.io.InputStream,java.io.File,boolean)" : [ "unTarUsingJava", "unTarUsingTar" ],
  "org.apache.hadoop.fs.store.ByteBufferInputStream:checkOpenState()" : [ "checkState", "isOpen" ],
  "org.apache.hadoop.io.compress.DefaultCodec:createCompressor()" : [ "getZlibCompressor" ],
  "org.apache.hadoop.fs.viewfs.ConfigUtil:addLinkNfly(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String,java.lang.String,java.lang.String)" : [ "set", "getConfigViewFsPrefix" ],
  "org.apache.hadoop.util.HostsFileReader:refresh(java.lang.String,java.lang.String)" : [ "refreshInternal" ],
  "org.apache.hadoop.security.alias.LocalKeyStoreProvider:createPermissions(java.lang.String)" : [ "modeToPosixFilePermission" ],
  "org.apache.hadoop.security.UserGroupInformation:getRealAuthenticationMethod()" : [ "getRealUser", "getAuthenticationMethod" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.XORRawEncoder:doEncode(org.apache.hadoop.io.erasurecode.rawcoder.ByteBufferEncodingState)" : [ "resetOutputBuffers" ],
  "org.apache.hadoop.io.SequenceFile:createWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.util.Progressable)" : [ "createWriter", "file", "keyClass", "valueClass", "compression", "progressable" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:setAcl(org.apache.hadoop.fs.Path,java.util.List)" : [ "setAcl" ],
  "org.apache.hadoop.fs.http.HttpsFileSystem:create(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,boolean,int,short,long,org.apache.hadoop.util.Progressable)" : [ "create" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.DecodingValidator:validate(java.nio.ByteBuffer[],int[],java.nio.ByteBuffer[])" : [ "<init>", "markBuffers", "findFirstValidInput", "allocateBuffer", "getValidIndexes", "decode", "toLimits", "resetBuffers" ],
  "org.apache.hadoop.fs.statistics.impl.DynamicIOStatisticsBuilder:withLongFunctionMinimum(java.lang.String,java.util.function.ToLongFunction)" : [ "activeInstance", "addMinimumFunction" ],
  "org.apache.hadoop.crypto.CryptoInputStream:getPadding(long)" : [ "getAlgorithmBlockSize" ],
  "org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink:init(org.apache.commons.configuration2.SubsetConfiguration)" : [ "getDefaultHost", "parse", "loadGangliaConf" ],
  "org.apache.hadoop.fs.FilterFs:checkPath(org.apache.hadoop.fs.Path)" : [ "checkPath" ],
  "org.apache.hadoop.fs.shell.AclCommands$SetfaclCommand:processOptions(java.util.LinkedList)" : [ "<init>", "parse", "getOpt", "parseAclSpec", "newArrayList", "getScope" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:register(java.lang.String,org.apache.hadoop.metrics2.MetricsSystem$Callback)" : [ "getProxyForCallback" ],
  "org.apache.hadoop.conf.Configuration:getConfResourceAsReader(java.lang.String)" : [ "getResource" ],
  "org.apache.hadoop.ipc.Server:<init>(java.lang.String,int,java.lang.Class,int,int,int,org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.hadoop.security.token.SecretManager)" : [ "<init>" ],
  "org.apache.hadoop.io.WritableUtils:readCompressedString(java.io.DataInput)" : [ "readCompressedByteArray" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedIO:bulkDelete_delete(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,java.util.Collection)" : [ "checkAvailable", "extractIOEs" ],
  "org.apache.hadoop.fs.viewfs.ConfigUtil:isNestedMountPointSupported(org.apache.hadoop.conf.Configuration)" : [ "getBoolean" ],
  "org.apache.hadoop.fs.store.DataBlocks$ByteBufferBlockFactory:<init>(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.snappy.SnappyCompressor:compress(byte[],int,int)" : [ "setInputFromSavedData", "compressDirectBuf" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:getDtService(java.net.URI)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:getServerDefaults(org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.conf.ReconfigurableBase:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.FileContext:getFileContext(java.net.URI)" : [ "<init>", "getFileContext" ],
  "org.apache.hadoop.io.SequenceFile$BlockCompressWriter:writeBuffer(org.apache.hadoop.io.DataOutputBuffer)" : [ "reset", "getData", "getLength", "writeVInt" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:currentConfig()" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:getKeyVersions(java.lang.String)" : [ "checkNotEmpty", "createURL", "createConnection", "call", "parseJSONKeyVersion" ],
  "org.apache.hadoop.fs.ContentSummary:equals(java.lang.Object)" : [ "equals", "getLength", "getFileCount", "getDirectoryCount", "getSnapshotLength", "getSnapshotFileCount", "getSnapshotDirectoryCount", "getSnapshotSpaceConsumed", "getErasureCodingPolicy" ],
  "org.apache.hadoop.http.HttpServer2$QuotingInputFilter$RequestQuoter:getParameterMap()" : [ "quoteHtmlChars" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:getStatus(org.apache.hadoop.fs.Path)" : [ "<init>", "pathToFile" ],
  "org.apache.hadoop.fs.FileSystem$Cache:getUnique(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getInternal" ],
  "org.apache.hadoop.ipc.RPC$Server:addProtocol(org.apache.hadoop.ipc.RPC$RpcKind,java.lang.Class,java.lang.Object)" : [ "registerProtocolAndImpl" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:iostatistics_means(java.io.Serializable)" : [ "invoke" ],
  "org.apache.hadoop.fs.FileContext:renameSnapshot(org.apache.hadoop.fs.Path,java.lang.String,java.lang.String)" : [ "fixRelativePart" ],
  "org.apache.hadoop.ipc.RemoteException:valueOf(org.xml.sax.Attributes)" : [ "<init>" ],
  "org.apache.hadoop.io.erasurecode.CodecUtil:getRawCoderNames(org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "getStrings", "getInstance", "getCoderNames" ],
  "org.apache.hadoop.ipc.ResponseBuffer:setCapacity(int)" : [ "setCapacity" ],
  "org.apache.hadoop.fs.FileUtil:unpackEntries(org.apache.commons.compress.archivers.tar.TarArchiveInputStream,org.apache.commons.compress.archivers.tar.TarArchiveEntry,java.io.File)" : [ "getCanonicalPath" ],
  "org.apache.hadoop.net.NodeBase:<init>(java.lang.String)" : [ "normalize", "set" ],
  "org.apache.hadoop.fs.ContentSummary:toString()" : [ "toString" ],
  "org.apache.hadoop.io.MapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.util.Progressable)" : [ "<init>", "keyClass", "valueClass", "compression", "progressable" ],
  "org.apache.hadoop.security.UserGroupInformation:getShortUserName()" : [ "getShortName" ],
  "org.apache.hadoop.util.LightWeightGSet:remove(java.lang.Object)" : [ "remove", "getIndex" ],
  "org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:removeStoredMasterKey(org.apache.hadoop.security.token.delegation.DelegationKey)" : [ "getNodePath", "getKeyId" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.NativeXORRawEncoder:<init>(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>", "getNumDataUnits", "getNumParityUnits" ],
  "org.apache.hadoop.fs.FilterFileSystem:listXAttrs(org.apache.hadoop.fs.Path)" : [ "listXAttrs" ],
  "org.apache.hadoop.metrics2.impl.MetricsConfig:getInstanceConfigs(java.lang.String)" : [ "subset", "keys" ],
  "org.apache.hadoop.io.BytesWritable:hashCode()" : [ "hashCode" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:registerSource(java.lang.String,java.lang.String,org.apache.hadoop.metrics2.MetricsSource)" : [ "<init>", "checkNotNull", "subset", "start" ],
  "org.apache.hadoop.fs.shell.SetReplication:processArguments(java.util.LinkedList)" : [ "waitForReplication" ],
  "org.apache.hadoop.util.curator.ZKCuratorManager:safeCreate(java.lang.String,byte[],java.util.List,org.apache.zookeeper.CreateMode,java.util.List,java.lang.String)" : [ "exists", "createTransaction", "create", "commit" ],
  "org.apache.hadoop.fs.AbstractFileSystem:renameInternal(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,boolean)" : [ "<init>", "getFileLinkStatus", "equals", "isSymlink", "getSymlink", "isDirectory", "listStatusIterator", "getParent", "isFile" ],
  "org.apache.hadoop.fs.FileSystem:moveFromLocalFile(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "copyFromLocalFile" ],
  "org.apache.hadoop.metrics2.impl.MetricsConfig:subset(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.impl.MetricsSourceAdapter:<init>(java.lang.String,java.lang.String,java.lang.String,org.apache.hadoop.metrics2.MetricsSource,java.lang.Iterable,long,org.apache.hadoop.metrics2.impl.MetricsConfig)" : [ "<init>", "getFilter" ],
  "org.apache.hadoop.io.compress.BZip2Codec:createDecompressor()" : [ "getBzip2Decompressor" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:renameSnapshot(org.apache.hadoop.fs.Path,java.lang.String,java.lang.String)" : [ "renameSnapshot", "fullPath" ],
  "org.apache.hadoop.security.SaslPlainServer:wrap(byte[],int,int)" : [ "throwIfNotComplete" ],
  "org.apache.hadoop.crypto.OpensslCtrCryptoCodec$OpensslCtrCipher:<init>(int,org.apache.hadoop.crypto.CipherSuite,java.lang.String)" : [ "getInstance", "getName" ],
  "org.apache.hadoop.crypto.key.UserProvider:getKeys()" : [ "getAllSecretKeys", "find", "toString" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:getCanonicalServiceName()" : [ "getCanonicalServiceName" ],
  "org.apache.hadoop.fs.FileUtil:createJarWithClassPath(java.lang.String,org.apache.hadoop.fs.Path,java.util.Map)" : [ "createJarWithClassPath" ],
  "org.apache.hadoop.ipc.Server:channelRead(java.nio.channels.ReadableByteChannel,java.nio.ByteBuffer)" : [ "channelIO", "incrReceivedBytes" ],
  "org.apache.hadoop.fs.Options$HandleOpt:changed(boolean)" : [ "<init>" ],
  "org.apache.hadoop.conf.Configuration:getSocketAddr(java.lang.String,java.lang.String,int)" : [ "getTrimmed", "createSocketAddr" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:numOpenConnections()" : [ "getNumOpenConnections" ],
  "org.apache.hadoop.fs.shell.Concat:registerCommands(org.apache.hadoop.fs.shell.CommandFactory)" : [ "addClass" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:monitorActiveStatus()" : [ "monitorLockNodeAsync" ],
  "org.apache.hadoop.security.alias.CredentialShell$CheckCommand:validate()" : [ "needsPassword", "noPasswordError", "noPasswordWarning" ],
  "org.apache.hadoop.service.ServiceStateModel:toString()" : [ "toString" ],
  "org.apache.hadoop.security.Groups:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.PathData:getStringForChildPath(org.apache.hadoop.fs.Path)" : [ "getName", "toString", "uriToString" ],
  "org.apache.hadoop.io.erasurecode.coder.ErasureDecoder:getInputBlocks(org.apache.hadoop.io.erasurecode.ECBlockGroup)" : [ "getNumDataUnits", "getNumParityUnits", "getDataBlocks", "getParityBlocks" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:incrClientBackoffDisconnected()" : [ "incr" ],
  "org.apache.hadoop.ha.SshFenceByTcpPort:getKeyFiles()" : [ "getTrimmedStringCollection" ],
  "org.apache.hadoop.io.compress.CompressionCodecFactory:getCodecClassByName(java.lang.String)" : [ "getCodecByName" ],
  "org.apache.hadoop.fs.impl.prefetch.BufferPool:<init>(int,int,org.apache.hadoop.fs.impl.prefetch.PrefetchingStatistics)" : [ "checkPositiveInteger" ],
  "org.apache.hadoop.fs.PathExistsException:<init>(java.lang.String,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.WeakReferenceThreadMap:getForCurrentThread()" : [ "currentThreadId" ],
  "org.apache.hadoop.util.functional.LazyAutoCloseableReference:lazyAutoCloseablefromSupplier(java.util.function.Supplier)" : [ "<init>" ],
  "org.apache.hadoop.fs.GlobFilter:<init>(java.lang.String,org.apache.hadoop.fs.PathFilter)" : [ "init" ],
  "org.apache.hadoop.util.JvmPauseMonitor:serviceInit(org.apache.hadoop.conf.Configuration)" : [ "serviceInit", "getLong" ],
  "org.apache.hadoop.ha.ZKFailoverController:initZK()" : [ "<init>", "get", "getInt", "resolveConfIndirection", "parseACLs", "excludeIncompatibleCredentialProviders", "getFileSystemClass", "getZKAuthInfos", "checkArgument", "getParentZnode" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider:backupToOld(org.apache.hadoop.fs.Path)" : [ "renameOrFail" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:getCurrentKey(java.lang.String)" : [ "checkNotEmpty", "createURL", "createConnection", "call", "parseJSONKeyVersion" ],
  "org.apache.hadoop.ipc.Server:<init>(java.lang.String,int,java.lang.Class,int,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.fs.statistics.MeanStatistic:add(org.apache.hadoop.fs.statistics.MeanStatistic)" : [ "isEmpty" ],
  "org.apache.hadoop.util.Progress:addPhase(java.lang.String)" : [ "addPhase", "setStatus" ],
  "org.apache.hadoop.fs.statistics.MeanStatistic:clear()" : [ "setSamplesAndSum" ],
  "org.apache.hadoop.security.LdapGroupsMapping:initializeBindUsers()" : [ "getStrings", "get", "getPasswordForBindUser" ],
  "org.apache.hadoop.crypto.CryptoOutputStream:hflush()" : [ "flush" ],
  "org.apache.hadoop.fs.ChecksumFileSystem:mkdirs(org.apache.hadoop.fs.Path)" : [ "mkdirs" ],
  "org.apache.hadoop.fs.LocalDirAllocator:getLocalPathForWrite(java.lang.String,long,org.apache.hadoop.conf.Configuration,boolean)" : [ "getLocalPathForWrite", "obtainContext" ],
  "org.apache.hadoop.security.ShellBasedIdMapping:getUidAllowingUnknown(java.lang.String)" : [ "checkAndUpdateMaps", "getUid" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:stop()" : [ "<init>", "inMiniClusterMode", "stopTimer", "stopSources", "stopSinks", "clearConfigs" ],
  "org.apache.hadoop.io.compress.CompressionCodecFactory:getCodec(org.apache.hadoop.fs.Path)" : [ "getName", "toLowerCase" ],
  "org.apache.hadoop.util.HostsFileReader:setExcludesFile(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.http.HttpServer2:addNoCacheFilter(org.eclipse.jetty.servlet.ServletContextHandler)" : [ "defineFilter" ],
  "org.apache.hadoop.io.Text:validateUTF8(byte[])" : [ "validateUTF8" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsLogging$StatisticsToString:toString()" : [ "ioStatisticsToString" ],
  "org.apache.hadoop.fs.http.HttpsFileSystem:initialize(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "initialize" ],
  "org.apache.hadoop.security.SecurityUtil:setConfigurationInternal(org.apache.hadoop.conf.Configuration)" : [ "getBoolean", "setTokenServiceUseIp", "getInt", "newInstance" ],
  "org.apache.hadoop.fs.impl.FlagSet:createFlagSet(java.lang.Class,java.lang.String,java.util.EnumSet)" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.KeyShell$Command:getKeyProvider()" : [ "getProviders", "isTransient" ],
  "org.apache.hadoop.security.authorize.ProxyServers:refresh()" : [ "<init>", "refresh" ],
  "org.apache.hadoop.io.retry.RetryInvocationHandler:invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[])" : [ "isRpcInvocation", "getProxy", "nextCallId", "newCall", "invokeOnce", "getState", "getReturnValue" ],
  "org.apache.hadoop.fs.shell.find.BaseExpression:toString()" : [ "getArguments", "getChildren" ],
  "org.apache.hadoop.util.ApplicationClassLoader:<init>(java.lang.String,java.lang.ClassLoader,java.util.List)" : [ "<init>", "constructUrlsFromClasspath" ],
  "org.apache.hadoop.crypto.CipherOption:<init>(org.apache.hadoop.crypto.CipherSuite)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.Display:registerCommands(org.apache.hadoop.fs.shell.CommandFactory)" : [ "addClass" ],
  "org.apache.hadoop.fs.statistics.impl.DynamicIOStatistics:addGaugeFunction(java.lang.String,java.util.function.Function)" : [ "addFunction" ],
  "org.apache.hadoop.metrics2.lib.MutableGaugeLong:incr()" : [ "incr" ],
  "org.apache.hadoop.conf.Configuration:getFloat(java.lang.String,float)" : [ "getTrimmed" ],
  "org.apache.hadoop.ipc.ProtocolMetaInfoServerSideTranslatorPB:getProtocolVersionForRpcKind(org.apache.hadoop.ipc.RPC$RpcKind,java.lang.String)" : [ "getProtocolName", "getSupportedProtocolVersions" ],
  "org.apache.hadoop.security.alias.CredentialShell:init(java.lang.String[])" : [ "printGenericCommandUsage", "set" ],
  "org.apache.hadoop.util.bloom.CountingBloomFilter:approximateCount(org.apache.hadoop.util.bloom.Key)" : [ "hash", "clear" ],
  "org.apache.hadoop.io.wrappedio.WrappedIO:byteBufferPositionedReadable_readFully(java.io.InputStream,long,java.nio.ByteBuffer)" : [ "uncheckIOExceptions" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsSnapshot:setMeanStatistic(java.lang.String,org.apache.hadoop.fs.statistics.MeanStatistic)" : [ "meanStatistics" ],
  "org.apache.hadoop.log.LogLevel:printUsage()" : [ "printGenericCommandUsage" ],
  "org.apache.hadoop.fs.viewfs.ViewFsFileStatus:equals(java.lang.Object)" : [ "equals" ],
  "org.apache.hadoop.metrics2.lib.DefaultMetricsSystem:newObjectName(java.lang.String)" : [ "<init>", "uniqueName" ],
  "org.apache.hadoop.fs.FileSystem$Cache$Key:toString()" : [ "toString" ],
  "org.apache.hadoop.ipc.Server$Responder:doAsyncWrite(java.nio.channels.SelectionKey)" : [ "processResponse" ],
  "org.apache.hadoop.security.ShellBasedIdMapping:getUid(java.lang.String)" : [ "checkAndUpdateMaps", "updateMapIncr" ],
  "org.apache.hadoop.io.file.tfile.TFile$TFileIndex:getRecordNumByLocation(org.apache.hadoop.io.file.tfile.TFile$Reader$Location)" : [ "getBlockIndex", "getRecordIndex" ],
  "org.apache.hadoop.fs.shell.CommandWithDestination:copyStreamToTarget(java.io.InputStream,org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "isDirectory", "toString", "suffix", "writeStreamToFile", "rename", "close" ],
  "org.apache.hadoop.jmx.JMXJsonServlet:writeObject(com.fasterxml.jackson.core.JsonGenerator,java.lang.Object,java.lang.String)" : [ "extraCheck", "extraWrite", "writeAttribute" ],
  "org.apache.hadoop.net.DomainNameResolverFactory:newInstance(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String)" : [ "newInstance" ],
  "org.apache.hadoop.net.InnerNodeImpl:isLeafParent()" : [ "isRack" ],
  "org.apache.hadoop.util.bloom.DynamicBloomFilter:readFields(java.io.DataInput)" : [ "<init>", "readFields" ],
  "org.apache.hadoop.ipc.Client$Connection:handleSaslConnectionFailure(int,int,java.io.IOException,java.util.Random,org.apache.hadoop.security.UserGroupInformation)" : [ "doAs" ],
  "org.apache.hadoop.fs.PathPermissionException:<init>(java.lang.String,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.io.SetFile$Reader:<init>(org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.ha.protocolPB.HAServiceProtocolServerSideTranslatorPB:getProtocolVersion(java.lang.String,long)" : [ "getProtocolVersion" ],
  "org.apache.hadoop.ha.ZKFailoverController:createReqInfo()" : [ "<init>" ],
  "org.apache.hadoop.security.Credentials:addAll(org.apache.hadoop.security.Credentials)" : [ "addAll" ],
  "org.apache.hadoop.fs.FSBuilder:opt(java.lang.String,double)" : [ "optLong" ],
  "org.apache.hadoop.util.FindClass:main(java.lang.String[])" : [ "<init>", "run", "printStack" ],
  "org.apache.hadoop.io.erasurecode.coder.HHXORErasureDecoder:prepareDecodingStep(org.apache.hadoop.io.erasurecode.ECBlockGroup)" : [ "<init>", "checkCreateRSRawDecoder", "checkCreateXorRawEncoder" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:moveToFrontCodeAndSend()" : [ "bsW", "generateMTFValues", "sendMTFValues" ],
  "org.apache.hadoop.io.SecureIOUtils:checkStat(java.io.File,java.lang.String,java.lang.String,java.lang.String,java.lang.String)" : [ "createRemoteUser", "getGroupsSet" ],
  "org.apache.hadoop.security.SecurityUtil:replacePattern(java.lang.String[],java.lang.String)" : [ "getLocalHostName", "toLowerCase" ],
  "org.apache.hadoop.fs.shell.CommandWithDestination:preserveAttributes(org.apache.hadoop.fs.shell.PathData,org.apache.hadoop.fs.shell.PathData,boolean)" : [ "shouldPreserve", "setTimes", "getModificationTime", "getAccessTime", "setOwner", "getOwner", "getGroup", "setPermission", "getPermission", "hasAcl", "getAclStatus", "getEntries", "getAclFromPermAndEntries", "setAcl", "getXAttrs", "setXAttr" ],
  "org.apache.hadoop.fs.FSDataOutputStreamBuilder:<init>(org.apache.hadoop.fs.FileContext,org.apache.hadoop.fs.Path)" : [ "<init>", "checkNotNull", "getFSofPath", "getServerDefaults", "getFileBufferSize", "getReplication", "getBlockSize" ],
  "org.apache.hadoop.io.retry.RetryInvocationHandler:<init>(org.apache.hadoop.io.retry.FailoverProxyProvider,org.apache.hadoop.io.retry.RetryPolicy,java.util.Map)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:createSnapshot(org.apache.hadoop.fs.Path,java.lang.String)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.metrics2.impl.MetricsSourceAdapter:setAttrCacheMetric(org.apache.hadoop.metrics2.AbstractMetric,int)" : [ "metricName", "name" ],
  "org.apache.hadoop.io.ArrayPrimitiveWritable:set(java.lang.Object)" : [ "checkArray", "checkPrimitive", "checkDeclaredComponentType" ],
  "org.apache.hadoop.fs.BulkDeleteUtils:validatePathIsUnderParent(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "equals", "getParent" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RSLegacyRawEncoder:<init>(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>", "getFieldSize", "getPrimitivePower", "multiply" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:getDefaultBlockSize()" : [ "getDefaultBlockSize", "fullPath" ],
  "org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation$ThreadSafeSampleStat:add(double)" : [ "add" ],
  "org.apache.hadoop.crypto.OpensslCipher:update(java.nio.ByteBuffer,java.nio.ByteBuffer)" : [ "checkState", "checkArgument" ],
  "org.apache.hadoop.fs.FilterFileSystem:getTrashRoot(org.apache.hadoop.fs.Path)" : [ "getTrashRoot" ],
  "org.apache.hadoop.fs.HarFileSystem:msync()" : [ "msync" ],
  "org.apache.hadoop.fs.HarFileSystem:getFileStatus(org.apache.hadoop.fs.Path)" : [ "getFileHarStatus", "toFileStatus" ],
  "org.apache.hadoop.util.Sets:addAll(java.util.TreeSet,java.lang.Iterable)" : [ "addAll", "cast" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:<init>(org.apache.hadoop.ipc.Server,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getListenerAddress", "tag", "getServerName", "getInts", "getBoolean", "getMetricsTimeUnit", "newQuantiles" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL:openConnection(java.net.URL,org.apache.hadoop.security.authentication.client.AuthenticatedURL$Token)" : [ "openConnection" ],
  "org.apache.hadoop.fs.store.DataBlocks$DataBlock:flush()" : [ "verifyState" ],
  "org.apache.hadoop.fs.FileContext:getLinkTarget(org.apache.hadoop.fs.Path)" : [ "fixRelativePart" ],
  "org.apache.hadoop.fs.Path:<init>(org.apache.hadoop.fs.Path,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.source.JvmMetrics:create(java.lang.String,java.lang.String,org.apache.hadoop.metrics2.MetricsSystem)" : [ "<init>", "getBoolean", "description" ],
  "org.apache.hadoop.ipc.Server:getProtocol()" : [ "getProtocol" ],
  "org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:incrementCurrentKeyId()" : [ "incrSharedCount" ],
  "org.apache.hadoop.fs.shell.find.Find:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "getOptions", "isDepthFirst", "applyItem" ],
  "org.apache.hadoop.metrics2.lib.MutableRates:add(java.lang.String,long)" : [ "add" ],
  "org.apache.hadoop.io.WritableComparator:hashBytes(byte[],int)" : [ "hashBytes" ],
  "org.apache.hadoop.util.bloom.BloomFilter:add(org.apache.hadoop.util.bloom.Key)" : [ "hash", "clear" ],
  "org.apache.hadoop.ipc.RetryCache:<init>(java.lang.String,double,long)" : [ "<init>", "computeCapacity", "create" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine$RpcProtobufRequest:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreImpl:incrementMaximum(java.lang.String,long)" : [ "incAtomicLong" ],
  "org.apache.hadoop.fs.permission.PermissionParser:combineModes(int,boolean)" : [ "combineModeSegments" ],
  "org.apache.hadoop.ipc.CallQueueManager:parseCapacityWeights(int,java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "getInts", "getDefaultQueueCapacityWeights" ],
  "org.apache.hadoop.fs.FileContext:getUMask()" : [ "getUMask" ],
  "org.apache.hadoop.fs.statistics.MeanStatistic:equals(java.lang.Object)" : [ "isEmpty", "getSum", "getSamples" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:makeAbsolute(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "<init>", "isAbsolute" ],
  "org.apache.hadoop.fs.TrashPolicyDefault:initialize(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem)" : [ "getFloat", "getBoolean" ],
  "org.apache.hadoop.fs.shell.CommandFormat$TooManyArgumentsException:<init>(int,int)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileUtil:stat2Paths(org.apache.hadoop.fs.FileStatus[],org.apache.hadoop.fs.Path)" : [ "stat2Paths" ],
  "org.apache.hadoop.util.VersionInfo:getCompilePlatform()" : [ "_getCompilePlatform" ],
  "org.apache.hadoop.ipc.RPC:waitForProxy(java.lang.Class,long,java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration,long)" : [ "waitForProtocolProxy", "getProxy" ],
  "org.apache.hadoop.io.file.tfile.Utils$Version:equals(java.lang.Object)" : [ "compareTo" ],
  "org.apache.hadoop.fs.audit.CommonAuditContext:createInstance()" : [ "<init>", "init" ],
  "org.apache.hadoop.ipc.RPC:getProtocolProxy(java.lang.Class,long,java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration)" : [ "getProtocolProxy", "getDefaultSocketFactory" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getDefaultReplication(org.apache.hadoop.fs.Path)" : [ "<init>", "getDefaultReplication", "resolve", "getUriPath" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:newSink(java.lang.String,java.lang.String,org.apache.hadoop.metrics2.MetricsSink,org.apache.hadoop.metrics2.impl.MetricsConfig)" : [ "<init>", "getFilter" ],
  "org.apache.hadoop.io.compress.lz4.Lz4Compressor:reinit(org.apache.hadoop.conf.Configuration)" : [ "reset" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:launchService(org.apache.hadoop.conf.Configuration,org.apache.hadoop.service.Service,java.util.List,boolean,boolean)" : [ "<init>", "coreServiceLaunch", "getServiceName", "convertToExitException", "noteException" ],
  "org.apache.hadoop.ipc.Client$Connection:setupConnection(org.apache.hadoop.security.UserGroupInformation)" : [ "updateAddress", "wrapException", "getHostname", "connect", "hasKerberosCredentials", "getProtocol", "getUserName", "getHostFromPrincipal", "getLocalInetAddress", "bindToLocalAddress", "handleConnectionTimeout", "handleConnectionFailure" ],
  "org.apache.hadoop.metrics2.lib.MutableMetricsFactory:getInfo(org.apache.hadoop.metrics2.annotation.Metric,java.lang.reflect.Method)" : [ "getInfo", "getName" ],
  "org.apache.hadoop.fs.DU:<init>(org.apache.hadoop.fs.GetSpaceUsed$Builder)" : [ "<init>", "getPath", "getInterval", "getJitter", "getInitialUsed" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RSLegacyRawDecoder:doDecode(org.apache.hadoop.io.erasurecode.rawcoder.ByteBufferDecodingState)" : [ "<init>", "resetOutputBuffers", "getNullIndexes", "resetBuffer", "checkGetDirectBuffer", "doDecodeImpl" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyNode:<init>(java.lang.String,java.lang.String,java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedIO:byteBufferPositionedReadable_readFullyAvailable(java.io.InputStream)" : [ "available", "extractIOEs" ],
  "org.apache.hadoop.http.HttpServer2$QuotingInputFilter:init(javax.servlet.FilterConfig)" : [ "initHttpHeaderMap" ],
  "org.apache.hadoop.util.Lists:partition(java.util.List,int)" : [ "checkArgument" ],
  "org.apache.hadoop.fs.viewfs.InodeTree:tryResolveInRegexMountpoint(java.lang.String,boolean)" : [ "resolve" ],
  "org.apache.hadoop.util.SysInfoWindows:getNumProcessors()" : [ "refreshIfNeeded" ],
  "org.apache.hadoop.ha.HAAdmin:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileUtil:chmod(java.lang.String,java.lang.String,boolean)" : [ "<init>", "getSetPermissionCommand", "execute", "stringifyException" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:newRate(java.lang.String,java.lang.String)" : [ "newRate" ],
  "org.apache.hadoop.log.LogThrottlingHelper:<init>(long)" : [ "<init>" ],
  "org.apache.hadoop.io.UTF8:getBytes(java.lang.String)" : [ "utf8Length", "reset", "writeChars", "getData", "getLength" ],
  "org.apache.hadoop.security.KDiag:fail(java.lang.String,java.lang.String,java.lang.Object[])" : [ "<init>", "error" ],
  "org.apache.hadoop.fs.shell.TouchCommands$Touchz:processOptions(java.util.LinkedList)" : [ "<init>", "parse" ],
  "org.apache.hadoop.util.RunJar:main(java.lang.String[])" : [ "run" ],
  "org.apache.hadoop.io.SequenceFile$Reader:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration)" : [ "<init>", "file", "makeQualified" ],
  "org.apache.hadoop.service.launcher.ServiceShutdownHook:run()" : [ "shutdown" ],
  "org.apache.hadoop.util.curator.ZKCuratorManager$HadoopZookeeperFactory:setJaasConfiguration(org.apache.zookeeper.client.ZKClientConfig)" : [ "getServerPrincipal" ],
  "org.apache.hadoop.fs.Path:checkNotRelative()" : [ "<init>", "isAbsolute", "toUri" ],
  "org.apache.hadoop.net.NetworkTopology:add(org.apache.hadoop.net.Node)" : [ "<init>", "locationToDepth", "getPath", "getNodeForNetworkLocation", "incrementRacks", "interAddNodeWithEmptyRack" ],
  "org.apache.hadoop.crypto.CryptoOutputStream:hsync()" : [ "flush" ],
  "org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping:runResolveCommand(java.util.List,java.lang.String)" : [ "<init>", "execute", "getOutput" ],
  "org.apache.hadoop.util.dynamic.BindingUtils:available(org.apache.hadoop.util.dynamic.DynMethods$UnboundMethod)" : [ "isNoop" ],
  "org.apache.hadoop.io.SequenceFile$Reader:readBuffer(org.apache.hadoop.io.DataInputBuffer,org.apache.hadoop.io.compress.CompressionInputStream)" : [ "<init>", "readVInt", "write", "reset", "getData", "getLength" ],
  "org.apache.hadoop.util.LightWeightCache:put(java.lang.Object)" : [ "<init>", "put", "evictExpiredEntries", "setExpirationTime", "evictEntries" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkIntegerMultiple(long,java.lang.String,long,java.lang.String)" : [ "checkArgument" ],
  "org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:addOrUpdateDelegationKey(org.apache.hadoop.security.token.delegation.DelegationKey,boolean)" : [ "getNodePath", "getKeyId", "write" ],
  "org.apache.hadoop.net.SocketOutputStream:<init>(java.net.Socket,long)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileContext:getFileContext(org.apache.hadoop.conf.Configuration)" : [ "<init>", "getFileContext", "getTrimmed" ],
  "org.apache.hadoop.io.compress.CompressionInputStream:getIOStatistics()" : [ "retrieveIOStatistics" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:setXAttr(org.apache.hadoop.fs.Path,java.lang.String,byte[],java.util.EnumSet)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.fs.shell.CommandFactory:registerCommands(java.lang.Class)" : [ "stringifyException" ],
  "org.apache.hadoop.fs.shell.Display$Cat:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "isDirectory", "toString", "setVerifyChecksum", "printToStdout", "getInputStream" ],
  "org.apache.hadoop.fs.FSDataInputStream:getIOStatistics()" : [ "retrieveIOStatistics" ],
  "org.apache.hadoop.fs.FileUtil:list(java.io.File)" : [ "canRead" ],
  "org.apache.hadoop.ipc.WritableRpcEngine:getProxy(java.lang.Class,long,org.apache.hadoop.ipc.Client$ConnectionId,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory,org.apache.hadoop.ipc.AlignmentContext)" : [ "getProxy", "getAddress", "getTicket", "getRpcTimeout", "getRetryPolicy" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:delete(org.apache.hadoop.fs.Path)" : [ "delete" ],
  "org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:incrementDelegationTokenSeqNum()" : [ "incrSharedCount" ],
  "org.apache.hadoop.fs.store.ByteBufferInputStream:read(byte[],int,int)" : [ "checkArgument", "verifyOpen", "hasRemaining", "available" ],
  "org.apache.hadoop.io.file.tfile.Chunk$ChunkDecoder:getRemain()" : [ "checkEOF" ],
  "org.apache.hadoop.security.alias.LocalKeyStoreProvider:<init>(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:storeDelegationKey(org.apache.hadoop.security.token.delegation.DelegationKey)" : [ "getKeyId", "storeNewMasterKey" ],
  "org.apache.hadoop.util.StringUtils:escapeString(java.lang.String,char,char[])" : [ "hasChar" ],
  "org.apache.hadoop.metrics2.source.JvmMetrics:getMetrics(org.apache.hadoop.metrics2.MetricsCollector,boolean)" : [ "getMemoryUsage", "getGcUsage", "getThreadUsage", "getThreadUsageFromGroup" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RSRawDecoder:<init>(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>", "getFieldSize", "genCauchyMatrix", "dumpMatrix" ],
  "org.apache.hadoop.http.HttpServer2:hasAdministratorAccess(javax.servlet.ServletContext,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)" : [ "getBoolean", "userHasAdministratorAccess" ],
  "org.apache.hadoop.metrics2.lib.MutableRollingAverages:rollOverAvgs()" : [ "<init>", "total", "numSamples" ],
  "org.apache.hadoop.ha.HAAdmin:help(java.lang.String[])" : [ "help" ],
  "org.apache.hadoop.util.SysInfoLinux:getNumCores()" : [ "readProcCpuInfoFile" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:getXAttrs(org.apache.hadoop.fs.Path)" : [ "getXAttrs", "fullPath" ],
  "org.apache.hadoop.ha.HAAdmin:checkParameterValidity(java.lang.String[],java.util.Map)" : [ "printUsage" ],
  "org.apache.hadoop.net.unix.DomainSocket$DomainInputStream:close()" : [ "close" ],
  "org.apache.hadoop.security.UserGroupInformation$LoginParams:getDefaults()" : [ "<init>", "put" ],
  "org.apache.hadoop.conf.StorageUnit$1:getDefault(double)" : [ "toEBs" ],
  "org.apache.hadoop.fs.shell.CopyCommands$AppendToFile:processOptions(java.util.LinkedList)" : [ "<init>", "parse", "getOpt" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InnerCache:get(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getNewInstance" ],
  "org.apache.hadoop.security.SaslOutputStream:write(int)" : [ "write" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:reEstablishSession()" : [ "createConnection", "sleepFor" ],
  "org.apache.hadoop.util.PriorityQueue:insert(java.lang.Object)" : [ "put", "top", "adjustTop" ],
  "org.apache.hadoop.conf.Configuration:getDouble(java.lang.String,double)" : [ "getTrimmed" ],
  "org.apache.hadoop.crypto.CryptoInputStream:updateDecryptor(org.apache.hadoop.crypto.Decryptor,long,byte[])" : [ "getCounter" ],
  "org.apache.hadoop.util.Shell$ShellCommandExecutor:<init>(java.lang.String[],java.io.File,java.util.Map,long,boolean)" : [ "<init>" ],
  "org.apache.hadoop.security.CompositeGroupsMapping:setConf(org.apache.hadoop.conf.Configuration)" : [ "getBoolean", "loadMappingProviders" ],
  "org.apache.hadoop.fs.shell.Tail:dumpFromOffset(org.apache.hadoop.fs.shell.PathData,long)" : [ "refreshStatus", "getLen", "openFile", "seek", "copyBytes", "getPos" ],
  "org.apache.hadoop.util.JvmPauseMonitor:formatMessage(long,java.util.Map,java.util.Map)" : [ "intersection", "newArrayList", "toString" ],
  "org.apache.hadoop.security.token.delegation.web.MultiSchemeDelegationTokenAuthenticationHandler:init(java.util.Properties)" : [ "init", "checkNotNull", "checkArgument" ],
  "org.apache.hadoop.io.MapWritable:<init>(org.apache.hadoop.io.MapWritable)" : [ "<init>" ],
  "org.apache.hadoop.io.erasurecode.codec.XORErasureCodec:createEncoder()" : [ "<init>" ],
  "org.apache.hadoop.io.compress.BlockCompressorStream:write(byte[],int,int)" : [ "finish", "rawWriteInt", "compress" ],
  "org.apache.hadoop.fs.ContentSummary:toString(boolean,boolean,boolean,java.util.List)" : [ "toString" ],
  "org.apache.hadoop.fs.FSInputStream:validatePositionedReadArgs(long,byte[],int,int)" : [ "checkArgument" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner:seekTo(org.apache.hadoop.io.file.tfile.TFile$Reader$Location)" : [ "compareTo", "parkCursorAtEnd", "getBlockIndex", "initBlock", "inBlockAdvance", "getRecordIndex" ],
  "org.apache.hadoop.fs.shell.AclCommands$SetfaclCommand:getAclEntries(org.apache.hadoop.fs.shell.PathData)" : [ "isDirectory" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:warmUpEncryptedKeys(java.lang.String[])" : [ "initializeQueuesForKeys" ],
  "org.apache.hadoop.net.SocketOutputStream:write(byte[],int,int)" : [ "write" ],
  "org.apache.hadoop.util.CrcComposer:update(java.io.DataInputStream,long,long)" : [ "update" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:getFileBlockLocations(org.apache.hadoop.fs.FileStatus,long,long)" : [ "<init>", "getFileBlockLocations", "fullPath", "getPath" ],
  "org.apache.hadoop.util.bloom.RetouchedBloomFilter:getWeight(java.util.List)" : [ "getWeight" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:incrClientBackoff()" : [ "incr" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockOperations$End:getDebugInfo()" : [ "getDebugInfo" ],
  "org.apache.hadoop.io.UTF8:readString(java.io.DataInput)" : [ "readChars" ],
  "org.apache.hadoop.io.SequenceFile$RecordCompressWriter:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.io.SequenceFile$Writer$Option[])" : [ "<init>" ],
  "org.apache.hadoop.security.UserGroupInformation$HadoopConfiguration:getAppConfigurationEntry(java.lang.String)" : [ "getKerberosEntry" ],
  "org.apache.hadoop.conf.ReconfigurationServlet:printConf(java.io.PrintWriter,org.apache.hadoop.conf.Reconfigurable)" : [ "<init>", "getChangedProperties" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyStatus:getLen()" : [ "getLen" ],
  "org.apache.hadoop.io.Text:<init>(byte[])" : [ "set" ],
  "org.apache.hadoop.security.UserGroupInformation:setLastLogin(long)" : [ "setLastLogin" ],
  "org.apache.hadoop.metrics2.lib.MutableInverseQuantiles$InversePercentile:<init>(double)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.Command:run(java.lang.String[])" : [ "isDeprecated", "displayWarning", "getReplacementCommand", "processOptions", "processRawArguments", "displayError", "exitCodeForError" ],
  "org.apache.hadoop.fs.FilterFs:getStatistics()" : [ "getStatistics" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsSupport:snapshotIOStatistics(org.apache.hadoop.fs.statistics.IOStatistics)" : [ "<init>" ],
  "org.apache.hadoop.fs.FilterFs:listXAttrs(org.apache.hadoop.fs.Path)" : [ "listXAttrs" ],
  "org.apache.hadoop.http.HtmlQuoting:needsQuoting(java.lang.String)" : [ "needsQuoting" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine$Server:<init>(java.lang.Class,java.lang.Object,org.apache.hadoop.conf.Configuration,java.lang.String,int,int,int,int,boolean,org.apache.hadoop.security.token.SecretManager,java.lang.String,org.apache.hadoop.ipc.AlignmentContext)" : [ "<init>" ],
  "org.apache.hadoop.fs.HarFileSystem:getUsed(org.apache.hadoop.fs.Path)" : [ "getUsed" ],
  "org.apache.hadoop.fs.shell.Command:processArgument(org.apache.hadoop.fs.shell.PathData)" : [ "processPathArgument", "processNonexistentPath" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:disconnect(org.apache.commons.net.ftp.FTPClient)" : [ "<init>" ],
  "org.apache.hadoop.io.InputBuffer:reset(byte[],int)" : [ "reset" ],
  "org.apache.hadoop.util.SysInfoWindows:getCpuFrequency()" : [ "refreshIfNeeded" ],
  "org.apache.hadoop.fs.FSInputStream:readFully(long,byte[],int,int)" : [ "validatePositionedReadArgs", "read" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:getAllStoragePolicies()" : [ "getAllStoragePolicies" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker:<init>(java.lang.Class,java.net.InetSocketAddress,org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory,int,org.apache.hadoop.io.retry.RetryPolicy,java.util.concurrent.atomic.AtomicBoolean,org.apache.hadoop.ipc.AlignmentContext)" : [ "<init>", "getConnectionId" ],
  "org.apache.hadoop.fs.FileSystem:newInstance(org.apache.hadoop.conf.Configuration)" : [ "getDefaultUri" ],
  "org.apache.hadoop.io.file.tfile.Chunk$ChunkEncoder:flushBuffer()" : [ "writeChunk" ],
  "org.apache.hadoop.io.file.tfile.TFile$TFileMeta:makeComparator(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.io.DefaultStringifier:toString(java.lang.Object)" : [ "reset", "getLength", "getData" ],
  "org.apache.hadoop.fs.RawLocalFileSystem$DeprecatedRawLocalFileStatus:<init>(java.io.File,long,org.apache.hadoop.fs.FileSystem)" : [ "<init>", "getLastAccessTime", "makeQualified" ],
  "org.apache.hadoop.util.StringUtils:byteToHexString(byte[])" : [ "byteToHexString" ],
  "org.apache.hadoop.fs.Path:isRoot()" : [ "getParent" ],
  "org.apache.hadoop.metrics2.lib.MutableCounterLong:snapshot(org.apache.hadoop.metrics2.MetricsRecordBuilder,boolean)" : [ "value" ],
  "org.apache.hadoop.crypto.JceCtrCryptoCodec$JceCtrCipher:<init>(int,java.lang.String,org.apache.hadoop.crypto.CipherSuite,java.lang.String)" : [ "getName" ],
  "org.apache.hadoop.fs.Trash:moveToAppropriateTrash(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration)" : [ "<init>", "resolvePath", "get", "toUri", "getServerDefaults", "getTrashInterval", "setLong", "getBoolean", "moveToTrash" ],
  "org.apache.hadoop.fs.impl.MultipartUploaderBuilderImpl:checksumOpt(org.apache.hadoop.fs.Options$ChecksumOpt)" : [ "checkNotNull" ],
  "org.apache.hadoop.security.authorize.AccessControlList:write(java.io.DataOutput)" : [ "getAclString", "writeString" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider$KMSEncryptedKeyVersion:<init>(java.lang.String,java.lang.String,byte[],java.lang.String,byte[])" : [ "<init>" ],
  "org.apache.hadoop.conf.Configuration:getPasswordFromCredentialProviders(java.lang.String)" : [ "getProviders", "getCredentialEntry", "getCredential" ],
  "org.apache.hadoop.ipc.Server:refreshCallQueue(org.apache.hadoop.conf.Configuration)" : [ "getQueueClassPrefix", "getInt", "swapQueue", "getSchedulerClass", "getQueueClass", "setClientBackoffEnabled", "getClientBackoffEnable" ],
  "org.apache.hadoop.ipc.CallQueueManager:getServerFailOverEnable(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "get", "getBoolean" ],
  "org.apache.hadoop.ipc.protocolPB.GenericRefreshProtocolServerSideTranslatorPB:refresh(org.apache.hadoop.thirdparty.protobuf.RpcController,org.apache.hadoop.ipc.proto.GenericRefreshProtocolProtos$GenericRefreshRequestProto)" : [ "pack" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.DummyRawErasureCoderFactory:createEncoder(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:blockSort()" : [ "mainSort", "randomiseBlock" ],
  "org.apache.hadoop.fs.impl.prefetch.BufferPool:release(org.apache.hadoop.fs.impl.prefetch.BufferData)" : [ "checkNotNull", "checkArgument", "canRelease" ],
  "org.apache.hadoop.ipc.RetryCache$CacheEntryWithPayload:<init>(byte[],int,java.lang.Object,long)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:<init>(org.apache.hadoop.fs.AbstractFileSystem,org.apache.hadoop.fs.Path)" : [ "<init>", "getUri", "checkPath", "getUriPath", "toUri" ],
  "org.apache.hadoop.fs.FileSystem$Statistics:<init>(org.apache.hadoop.fs.FileSystem$Statistics)" : [ "<init>", "visitAll" ],
  "org.apache.hadoop.conf.Configuration:set(java.lang.String,java.lang.String,java.lang.String)" : [ "checkArgument", "getDeprecatedKeyMap", "getProps", "getOverlay", "isDeprecated", "putIntoUpdatingResource", "getAlternativeNames", "handleDeprecation" ],
  "org.apache.hadoop.io.erasurecode.coder.HHXORErasureEncoder:release()" : [ "release" ],
  "org.apache.hadoop.fs.FilterFileSystem:resolveLink(org.apache.hadoop.fs.Path)" : [ "resolveLink" ],
  "org.apache.hadoop.fs.http.HttpsFileSystem:getFileStatus(org.apache.hadoop.fs.Path)" : [ "getFileStatus" ],
  "org.apache.hadoop.net.NetworkTopology:chooseRandom(java.lang.String,java.lang.String,java.util.Collection)" : [ "chooseRandom", "isChildScope", "getNode", "countNumOfAvailableNodes" ],
  "org.apache.hadoop.fs.FilterFileSystem:deleteSnapshot(org.apache.hadoop.fs.Path,java.lang.String)" : [ "deleteSnapshot" ],
  "org.apache.hadoop.ipc.Server$Connection:sendResponse(org.apache.hadoop.ipc.Server$RpcCall)" : [ "doRespond" ],
  "org.apache.hadoop.crypto.CryptoOutputStream:<init>(java.io.OutputStream,org.apache.hadoop.crypto.CryptoCodec,int,byte[],byte[],long,boolean)" : [ "checkCodec", "checkBufferSize", "updateEncryptor" ],
  "org.apache.hadoop.ipc.internal.ShadedProtobufHelper:tokenFromProto(org.apache.hadoop.security.proto.SecurityProtos$TokenProto)" : [ "<init>" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:iostatisticsContext_getCurrent()" : [ "checkIoStatisticsContextAvailable", "invoke" ],
  "org.apache.hadoop.util.FindClass:loadedClass(java.lang.String,java.lang.Class)" : [ "out" ],
  "org.apache.hadoop.security.authorize.AccessControlList:removeUser(java.lang.String)" : [ "isWildCardACLValue", "isAllAllowed" ],
  "org.apache.hadoop.fs.FileSystem$Cache:closeAll(org.apache.hadoop.security.UserGroupInformation)" : [ "close", "equals", "createIOException" ],
  "org.apache.hadoop.ipc.FairCallQueue:offer(org.apache.hadoop.ipc.Schedulable,long,java.util.concurrent.TimeUnit)" : [ "signalNotEmpty" ],
  "org.apache.hadoop.fs.shell.FsUsage$Du:setUsagesTable(org.apache.hadoop.fs.shell.FsUsage$TableBuilder)" : [ "setUsagesTable" ],
  "org.apache.hadoop.util.JvmPauseMonitor:serviceStop()" : [ "serviceStop" ],
  "org.apache.hadoop.fs.FilterFileSystem:createSymlink(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,boolean)" : [ "createSymlink" ],
  "org.apache.hadoop.io.SequenceFile$Writer:append(java.lang.Object,java.lang.Object)" : [ "reset", "getLength", "checkAndWriteSync", "getData" ],
  "org.apache.hadoop.io.BloomMapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.hadoop.io.SequenceFile$Writer$Option[])" : [ "<init>", "getFileSystem", "initBloomFilter" ],
  "org.apache.hadoop.io.compress.BZip2Codec:createOutputStream(java.io.OutputStream)" : [ "createOutputStreamWithCodecPool" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem:getFileStatus(org.apache.hadoop.fs.Path)" : [ "workSet", "getModificationTime", "processThrowable", "mayThrowFileNotFound", "createIOException" ],
  "org.apache.hadoop.util.FindClass:explainResult(int,java.lang.String)" : [ "err" ],
  "org.apache.hadoop.fs.FSDataInputStream:minSeekForVectorReads()" : [ "minSeekForVectorReads" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:openFile(org.apache.hadoop.fs.Path)" : [ "openFile", "fullPath" ],
  "org.apache.hadoop.io.compress.DefaultCodec:createOutputStream(java.io.OutputStream,org.apache.hadoop.io.compress.Compressor)" : [ "<init>", "getInt" ],
  "org.apache.hadoop.ipc.ExternalCall:<init>(java.security.PrivilegedExceptionAction)" : [ "<init>" ],
  "org.apache.hadoop.util.InstrumentedLock:logWaitWarning(long,org.apache.hadoop.util.InstrumentedLock$SuppressedSnapshot)" : [ "getSuppressedCount", "getMaxSuppressedWait", "getStackTrace" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:deleteSnapshot(org.apache.hadoop.fs.Path,java.lang.String)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.conf.ConfigurationWithLogging:set(java.lang.String,java.lang.String,java.lang.String)" : [ "set", "redact" ],
  "org.apache.hadoop.util.IntrusiveCollection:removeAll(java.util.Collection)" : [ "remove" ],
  "org.apache.hadoop.fs.PathPermissionException:<init>(java.lang.String,java.lang.String,java.lang.Throwable)" : [ "<init>" ],
  "org.apache.hadoop.io.file.tfile.Compression$Algorithm:getDecompressor()" : [ "getDecompressor" ],
  "org.apache.hadoop.ipc.Server$Connection:processRpcOutOfBandRequest(org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcRequestHeaderProto,org.apache.hadoop.ipc.RpcWritable$Buffer)" : [ "<init>", "processConnectionContext", "saslReadAndProcess" ],
  "org.apache.hadoop.security.User:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.io.file.tfile.Chunk$ChunkEncoder:writeBufData(byte[],int,int)" : [ "writeVInt" ],
  "org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext:createTmpFileForWrite(java.lang.String,long,org.apache.hadoop.conf.Configuration)" : [ "getLocalPathForWrite", "getParent", "toUri", "getName" ],
  "org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider:needsPassword()" : [ "locatePassword", "get" ],
  "org.apache.hadoop.security.ProviderUtils:noPasswordError(java.lang.String,java.lang.String)" : [ "noPasswordInstruction" ],
  "org.apache.hadoop.crypto.OpensslCipher:finalize()" : [ "clean" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:getClientBackoffDisconnected()" : [ "value" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:mkdirs(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "mkdirs", "fullPath" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:wrapLocalFileStatus(org.apache.hadoop.fs.FileStatus,org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider$TokenSelector:<init>()" : [ "<init>" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:launchServiceAndExit(java.util.List)" : [ "startupShutdownMessage", "registerFailureHandling", "loadConfigurationClasses", "createConfiguration", "addResource", "bindCommandOptions", "extractCommandOptions", "launchService", "noteException", "getExitCode", "getUsageMessage", "exit" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:unsetStoragePolicy(org.apache.hadoop.fs.Path)" : [ "unsetStoragePolicy", "resolve", "getUriPath" ],
  "org.apache.hadoop.util.InstrumentedLock:logWarning(long,org.apache.hadoop.util.InstrumentedLock$SuppressedSnapshot)" : [ "getSuppressedCount", "getMaxSuppressedWait", "getStackTrace" ],
  "org.apache.hadoop.security.ssl.SSLFactory:createSSLEngine()" : [ "disableExcludedCiphers" ],
  "org.apache.hadoop.io.MapWritable:equals(java.lang.Object)" : [ "size", "entrySet" ],
  "org.apache.hadoop.io.nativeio.NativeIO$POSIX:setPmdkSupportState(int)" : [ "getStateCode" ],
  "org.apache.hadoop.fs.shell.SetReplication:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "isSymlink", "toString", "isFile", "isErasureCoded", "setReplication" ],
  "org.apache.hadoop.io.SequenceFile$Writer$ProgressableOption:<init>(org.apache.hadoop.util.Progressable)" : [ "<init>" ],
  "org.apache.hadoop.conf.Configuration:addResource(java.io.InputStream)" : [ "<init>", "addResourceObject" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:getFileChecksum(org.apache.hadoop.fs.Path,long)" : [ "getFileChecksum", "fullPath" ],
  "org.apache.hadoop.fs.store.DataBlocks$ByteBufferBlockFactory$ByteBufferBlock:startUpload()" : [ "<init>", "startUpload", "bufferCapacityUsed" ],
  "org.apache.hadoop.fs.FileSystem:fixRelativePart(org.apache.hadoop.fs.Path)" : [ "<init>", "isUriPathAbsolute" ],
  "org.apache.hadoop.fs.shell.FsUsage:registerCommands(org.apache.hadoop.fs.shell.CommandFactory)" : [ "addClass" ],
  "org.apache.hadoop.fs.FSOutputSummer:writeChecksumChunks(byte[],int,int)" : [ "calculateChunkedSums", "createWriteTraceScope", "getBytesPerChecksum", "getChecksumSize", "close" ],
  "org.apache.hadoop.tracing.NullTraceScope:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.ftp.FTPInputStream:read()" : [ "incrementBytesRead" ],
  "org.apache.hadoop.http.HttpServer2:stop()" : [ "addMultiException", "remove" ],
  "org.apache.hadoop.crypto.CryptoInputStream:getPos()" : [ "checkStream" ],
  "org.apache.hadoop.util.Shell:getRunScriptCommand(java.io.File)" : [ "bashQuote" ],
  "org.apache.hadoop.conf.Configuration:setFloat(java.lang.String,float)" : [ "set" ],
  "org.apache.hadoop.fs.viewfs.FsGetter:getNewInstance(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "newInstance" ],
  "org.apache.hadoop.metrics2.impl.MetricsSinkAdapter:putMetricsImmediate(org.apache.hadoop.metrics2.impl.MetricsBuffer)" : [ "<init>", "enqueue", "refreshQueueSizeGauge", "incr", "waitTillNotified" ],
  "org.apache.hadoop.fs.statistics.impl.StatisticDurationTracker:<init>(org.apache.hadoop.fs.statistics.impl.IOStatisticsStore,java.lang.String,long)" : [ "<init>" ],
  "org.apache.hadoop.ipc.Server:getQueueClass(java.lang.String,int,org.apache.hadoop.conf.Configuration)" : [ "getClass", "convertQueueClass" ],
  "org.apache.hadoop.security.UserGroupInformation:loginUserFromKeytabAndReturnUGI(java.lang.String,java.lang.String)" : [ "<init>", "isSecurityEnabled", "getCurrentUser", "put", "doSubjectLogin" ],
  "org.apache.hadoop.io.compress.CompressionOutputStream:getIOStatistics()" : [ "retrieveIOStatistics" ],
  "org.apache.hadoop.net.TableMapping$RawTableMapping:resolve(java.util.List)" : [ "load" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:incrSentBytes(int)" : [ "incr" ],
  "org.apache.hadoop.fs.shell.Command:isDeprecated()" : [ "getReplacementCommand" ],
  "org.apache.hadoop.util.GenericOptionsParser:parseGeneralOptions(org.apache.commons.cli.Options,java.lang.String[])" : [ "buildGeneralOptions", "preProcessForWindows", "processGeneralOptions" ],
  "org.apache.hadoop.fs.FilterFs:setXAttr(org.apache.hadoop.fs.Path,java.lang.String,byte[],java.util.EnumSet)" : [ "setXAttr" ],
  "org.apache.hadoop.io.MapFile$Reader:binarySearch(org.apache.hadoop.io.WritableComparable)" : [ "compare" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:newQuantiles(java.lang.String,java.lang.String,java.lang.String,java.lang.String,int)" : [ "<init>", "checkMetricName" ],
  "org.apache.hadoop.io.DefaultStringifier:load(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.Class)" : [ "<init>", "get", "fromString", "close" ],
  "org.apache.hadoop.fs.FSOutputSummer:flushBuffer(boolean,boolean)" : [ "getBytesPerChecksum", "writeChecksumChunks" ],
  "org.apache.hadoop.ha.HAAdmin:setConf(org.apache.hadoop.conf.Configuration)" : [ "setConf", "getInt" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:getQuotaUsage(org.apache.hadoop.fs.Path)" : [ "getQuotaUsage", "fullPath" ],
  "org.apache.hadoop.fs.BBUploadHandle:from(java.nio.ByteBuffer)" : [ "<init>" ],
  "org.apache.hadoop.util.curator.ZKCuratorManager$HadoopZookeeperFactory:newZooKeeper(java.lang.String,int,org.apache.zookeeper.Watcher,boolean)" : [ "newZooKeeper" ],
  "org.apache.hadoop.fs.shell.FsCommand:processRawArguments(java.util.LinkedList)" : [ "getBoolean", "getTrimmed", "getCommandName" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkNotNullAndNumberOfElements(java.util.Collection,int,java.lang.String)" : [ "checkNotNull", "checkArgument" ],
  "org.apache.hadoop.io.erasurecode.ECChunk:toBuffers(org.apache.hadoop.io.erasurecode.ECChunk[])" : [ "getBuffer" ],
  "org.apache.hadoop.fs.FilterFileSystem:rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Options$Rename[])" : [ "rename" ],
  "org.apache.hadoop.fs.HardLink$HardLinkCGUnix:linkCount(java.io.File)" : [ "makeShellPath" ],
  "org.apache.hadoop.security.SecurityUtil:getLocalHostName(org.apache.hadoop.conf.Configuration)" : [ "get", "getDefaultHost" ],
  "org.apache.hadoop.ipc.RpcScheduler:addResponseTime(java.lang.String,org.apache.hadoop.ipc.Schedulable,org.apache.hadoop.ipc.ProcessingDetails)" : [ "addResponseTime", "get" ],
  "org.apache.hadoop.io.retry.RetryPolicies:failoverOnNetworkException(org.apache.hadoop.io.retry.RetryPolicy,int,long,long)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.zlib.ZlibCompressor:<init>(org.apache.hadoop.io.compress.zlib.ZlibCompressor$CompressionLevel,org.apache.hadoop.io.compress.zlib.ZlibCompressor$CompressionStrategy,org.apache.hadoop.io.compress.zlib.ZlibCompressor$CompressionHeader,int)" : [ "compressionLevel", "compressionStrategy", "windowBits" ],
  "org.apache.hadoop.net.InnerNodeImpl:add(org.apache.hadoop.net.Node)" : [ "isAncestor", "isParent", "getNextAncestorName", "createParentNode" ],
  "org.apache.hadoop.util.NativeCrc32:isAvailable()" : [ "isNativeCodeLoaded" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.ByteArrayDecodingState:checkOutputBuffers(byte[][])" : [ "<init>" ],
  "org.apache.hadoop.crypto.OpensslCtrCryptoCodec$OpensslCtrCipher:encrypt(java.nio.ByteBuffer,java.nio.ByteBuffer)" : [ "process" ],
  "org.apache.hadoop.metrics2.lib.MethodMetric:newGauge(java.lang.Class)" : [ "<init>", "isInt", "isLong", "isFloat", "isDouble" ],
  "org.apache.hadoop.io.file.tfile.TFile$Writer:prepareAppendKey(int)" : [ "initDataBlock" ],
  "org.apache.hadoop.fs.shell.PathData:getDirectoryContentsIterator()" : [ "checkIfExists", "listStatusIterator", "mappingRemoteIterator" ],
  "org.apache.hadoop.io.retry.RetryInvocationHandler:<init>(org.apache.hadoop.io.retry.FailoverProxyProvider,org.apache.hadoop.io.retry.RetryPolicy)" : [ "<init>" ],
  "org.apache.hadoop.fs.FilterFs:modifyAclEntries(org.apache.hadoop.fs.Path,java.util.List)" : [ "modifyAclEntries" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:create(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,boolean,int,short,long,org.apache.hadoop.util.Progressable)" : [ "<init>", "connect", "makeAbsolute", "exists", "delete", "disconnect", "getParent", "mkdirs", "getDefault", "toUri", "getName" ],
  "org.apache.hadoop.fs.FileSystem:getFileBlockLocations(org.apache.hadoop.fs.FileStatus,long,long)" : [ "<init>", "getLen" ],
  "org.apache.hadoop.util.VersionInfo:getSrcChecksum()" : [ "_getSrcChecksum" ],
  "org.apache.hadoop.io.OutputBuffer:getData()" : [ "getData" ],
  "org.apache.hadoop.ha.ActiveStandbyElector$WatcherWithClientRef:process(org.apache.zookeeper.WatchedEvent)" : [ "processWatchEvent", "stringifyException" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider:innerSetKeyVersion(java.lang.String,java.lang.String,byte[],java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.io.SequenceFile$Reader:<init>(org.apache.hadoop.fs.FSDataInputStream,int,long,long,org.apache.hadoop.conf.Configuration)" : [ "<init>", "stream", "start", "length" ],
  "org.apache.hadoop.fs.shell.FsUsage$Du:getUsagesTable()" : [ "getUsagesTable" ],
  "org.apache.hadoop.ipc.metrics.RpcDetailedMetrics:addOverallProcessingTime(java.lang.String,long)" : [ "add" ],
  "org.apache.hadoop.util.curator.ZKCuratorManager$HadoopZookeeperFactory:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileStatus:compareTo(org.apache.hadoop.fs.FileStatus)" : [ "compareTo", "getPath" ],
  "org.apache.hadoop.security.alias.KeyStoreProvider:createPermissions(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.util.HostsFileReader:refresh(java.io.InputStream,java.io.InputStream)" : [ "<init>", "readFileToSetWithFileInputStream", "readFileToMapWithFileInputStream" ],
  "org.apache.hadoop.util.RateLimitingFactory:create(int)" : [ "unlimitedRate" ],
  "org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.PathHandle)" : [ "<init>" ],
  "org.apache.hadoop.http.HttpServer2$Builder:makeConfigurationChangeMonitor(long,org.eclipse.jetty.util.ssl.SslContextFactory$Server)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:createSnapshot(org.apache.hadoop.fs.Path,java.lang.String)" : [ "createSnapshot", "resolve", "getUriPath" ],
  "org.apache.hadoop.security.UserGroupInformation$UgiMetrics:create()" : [ "instance", "register" ],
  "org.apache.hadoop.io.WritableUtils:writeVInt(java.io.DataOutput,int)" : [ "writeVLong" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:initMode()" : [ "toUpperCase" ],
  "org.apache.hadoop.util.StringUtils:byteDesc(long)" : [ "long2String" ],
  "org.apache.hadoop.net.unix.DomainSocketWatcher:add(org.apache.hadoop.net.unix.DomainSocket,org.apache.hadoop.net.unix.DomainSocketWatcher$Handler)" : [ "<init>", "cleanupWithLogger", "reference", "kick" ],
  "org.apache.hadoop.util.Sets:newHashSetWithExpectedSize(int)" : [ "capacity" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.CoderUtil:toBuffers(org.apache.hadoop.io.erasurecode.ECChunk[])" : [ "getBuffer", "isAllZero", "resetBuffer" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyStatus:isDirectory()" : [ "isDirectory" ],
  "org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext:createPath(org.apache.hadoop.fs.Path,java.lang.String,boolean)" : [ "<init>", "getParent", "toUri" ],
  "org.apache.hadoop.util.PureJavaCrc32:<init>()" : [ "reset" ],
  "org.apache.hadoop.util.LightWeightGSet$SetIterator:next()" : [ "ensureNext", "convert" ],
  "org.apache.hadoop.io.InputBuffer:getLength()" : [ "getLength" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner:advance()" : [ "atEnd", "getBlockIndex", "getRecordIndex", "getBlockEntryCount", "compareTo", "parkCursorAtEnd", "initBlock", "inBlockAdvance" ],
  "org.apache.hadoop.io.retry.FailoverProxyProvider$ProxyInfo:getString(java.lang.String)" : [ "proxyName" ],
  "org.apache.hadoop.io.DataInputBuffer:reset(byte[],int)" : [ "reset" ],
  "org.apache.hadoop.io.BloomMapFile$Reader:probablyHasKey(org.apache.hadoop.io.WritableComparable)" : [ "reset", "set", "membershipTest" ],
  "org.apache.hadoop.fs.HarFileSystem:getServerDefaults()" : [ "getServerDefaults" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:getServerDefaults(org.apache.hadoop.fs.Path)" : [ "getServerDefaults" ],
  "org.apache.hadoop.ipc.Server$Call:<init>(int,int,org.apache.hadoop.ipc.RPC$RpcKind,byte[],org.apache.hadoop.tracing.Span,org.apache.hadoop.ipc.CallerContext)" : [ "<init>", "monotonicNowNanos" ],
  "org.apache.hadoop.fs.GlobFilter:accept(org.apache.hadoop.fs.Path)" : [ "matches", "getName" ],
  "org.apache.hadoop.util.functional.RemoteIterators$HaltableRemoteIterator:<init>(org.apache.hadoop.fs.RemoteIterator,org.apache.hadoop.util.functional.CallableRaisingIOE)" : [ "<init>" ],
  "org.apache.hadoop.io.SequenceFile$Writer:stream(org.apache.hadoop.fs.FSDataOutputStream)" : [ "<init>" ],
  "org.apache.hadoop.crypto.CryptoInputStream:readFromUnderlyingStream(java.nio.ByteBuffer)" : [ "getTmpBuf" ],
  "org.apache.hadoop.net.TableMapping:getConf()" : [ "getRawMapping" ],
  "org.apache.hadoop.io.SequenceFile$Sorter$SortPass:run(boolean)" : [ "<init>", "getCompressionType", "getCompressionCodec", "reset", "getLength", "createValueBytes", "nextRaw", "close", "grow", "getData", "sort", "flush" ],
  "org.apache.hadoop.io.MapFile$Reader:reset()" : [ "seek" ],
  "org.apache.hadoop.fs.BufferedFSInputStream:readFully(long,byte[])" : [ "readFully" ],
  "org.apache.hadoop.ipc.FairCallQueue:putQueue(int,org.apache.hadoop.ipc.Schedulable)" : [ "signalNotEmpty" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:renameSnapshot(org.apache.hadoop.fs.Path,java.lang.String,java.lang.String)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext$Context:getAndIncrDirNumLastAccessed()" : [ "getAndIncrDirNumLastAccessed" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:listStatus(com.jcraft.jsch.ChannelSftp,org.apache.hadoop.fs.Path)" : [ "<init>", "makeAbsolute", "getFileStatus", "isDirectory", "toUri" ],
  "org.apache.hadoop.io.SequenceFile$Reader:seek(long)" : [ "seek" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:addMinimumSample(java.lang.String,long)" : [ "getInnerStatistics" ],
  "org.apache.hadoop.fs.impl.AbstractFSBuilderImpl:<init>(org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:containsKmsDt(org.apache.hadoop.security.UserGroupInformation)" : [ "getCredentials", "getAllTokens", "selectDelegationToken" ],
  "org.apache.hadoop.io.SequenceFile$Writer$KeyClassOption:<init>(java.lang.Class)" : [ "<init>" ],
  "org.apache.hadoop.ipc.RPC$Server:getHighestSupportedProtocol(org.apache.hadoop.ipc.RPC$RpcKind,java.lang.String)" : [ "<init>", "getProtocolImplMap" ],
  "org.apache.hadoop.util.ComparableVersion$StringItem:compareTo(org.apache.hadoop.util.ComparableVersion$Item)" : [ "comparableQualifier" ],
  "org.apache.hadoop.ipc.WritableRpcEngine$Server:<init>(java.lang.Class,java.lang.Object,org.apache.hadoop.conf.Configuration,java.lang.String,int)" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:rollNewVersion(java.lang.String)" : [ "doOp", "nextIdx", "invalidateCache" ],
  "org.apache.hadoop.http.HtmlQuoting:quoteHtmlChars(java.lang.String)" : [ "quoteHtmlChars", "needsQuoting" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.NativeRSRawDecoder:<init>(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>", "getNumDataUnits", "getNumParityUnits" ],
  "org.apache.hadoop.security.Credentials:addToken(org.apache.hadoop.io.Text,org.apache.hadoop.security.token.Token)" : [ "isPrivateCloneOf", "privateClone", "getService" ],
  "org.apache.hadoop.util.LightWeightCache:remove(java.lang.Object)" : [ "remove", "evictExpiredEntries", "checkState" ],
  "org.apache.hadoop.util.dynamic.BindingUtils:checkAvailable(org.apache.hadoop.util.dynamic.DynMethods$UnboundMethod)" : [ "available" ],
  "org.apache.hadoop.fs.FileContext:msync()" : [ "msync" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:iostatisticsSnapshot_fromJsonString(java.lang.String)" : [ "checkIoStatisticsAvailable", "invoke" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem:delete(org.apache.hadoop.fs.Path,boolean)" : [ "delete", "processThrowable", "mayThrowFileNotFound", "createIOException" ],
  "org.apache.hadoop.fs.FileSystem:primitiveMkdir(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,boolean)" : [ "<init>", "getParent", "isDirectory" ],
  "org.apache.hadoop.util.StringUtils:createStartupShutdownMessage(java.lang.String,java.lang.String,java.lang.String[])" : [ "toStartupShutdownString", "getVersion", "getUrl", "getRevision", "getUser", "getDate" ],
  "org.apache.hadoop.io.nativeio.NativeIO$Windows:access(java.lang.String,org.apache.hadoop.io.nativeio.NativeIO$Windows$AccessRight)" : [ "accessRight" ],
  "org.apache.hadoop.ipc.Client:call(org.apache.hadoop.ipc.RPC$RpcKind,org.apache.hadoop.io.Writable,org.apache.hadoop.ipc.Client$ConnectionId,java.util.concurrent.atomic.AtomicBoolean,org.apache.hadoop.ipc.AlignmentContext)" : [ "call" ],
  "org.apache.hadoop.io.BloomMapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.util.Progressable)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getEnclosingRoot(org.apache.hadoop.fs.Path)" : [ "<init>", "getEnclosingRoot", "resolve", "getUriPath", "depth" ],
  "org.apache.hadoop.http.HttpServer2:bindForSinglePort(org.eclipse.jetty.server.ServerConnector,int)" : [ "bindListener", "constructBindException" ],
  "org.apache.hadoop.fs.statistics.impl.WrappedIOStatistics:minimums()" : [ "getWrapped" ],
  "org.apache.hadoop.ipc.WritableRpcEngine$Invoker:<init>(java.lang.Class,java.net.InetSocketAddress,org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory,int,java.util.concurrent.atomic.AtomicBoolean,org.apache.hadoop.ipc.AlignmentContext)" : [ "getConnectionId", "getClient" ],
  "org.apache.hadoop.fs.shell.find.BaseExpression:isAction()" : [ "getChildren" ],
  "org.apache.hadoop.io.SortedMapWritable:<init>(org.apache.hadoop.io.SortedMapWritable)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.Mkdir:registerCommands(org.apache.hadoop.fs.shell.CommandFactory)" : [ "addClass" ],
  "org.apache.hadoop.io.TwoDArrayWritable:<init>(java.lang.Class,org.apache.hadoop.io.Writable[][])" : [ "<init>" ],
  "org.apache.hadoop.ipc.Server:getRemoteUser()" : [ "getRemoteUser" ],
  "org.apache.hadoop.fs.impl.prefetch.BoundedResourcePool:tryAcquire()" : [ "acquireHelper" ],
  "org.apache.hadoop.io.FloatWritable:<init>(float)" : [ "set" ],
  "org.apache.hadoop.conf.Configuration$Parser:handleEndElement()" : [ "weakIntern", "handleEndProperty" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:renameInternal(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RSLegacyRawDecoder:doDecodeImpl(java.nio.ByteBuffer[],int[],java.nio.ByteBuffer[])" : [ "findFirstValidInput", "substitute", "solveVandermondeSystem" ],
  "org.apache.hadoop.ipc.WritableRpcEngine$Server:<init>(java.lang.Class,java.lang.Object,org.apache.hadoop.conf.Configuration,java.lang.String,int,int,int,int,boolean,org.apache.hadoop.security.token.SecretManager,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ConfigUtil:getConfigViewFsPrefix()" : [ "getConfigViewFsPrefix" ],
  "org.apache.hadoop.fs.permission.FsPermission:read(java.io.DataInput)" : [ "<init>", "fromShort" ],
  "org.apache.hadoop.service.launcher.ServiceShutdownHook:register(int)" : [ "unregister", "get", "addShutdownHook" ],
  "org.apache.hadoop.fs.shell.FsUsage$Dus:processOptions(java.util.LinkedList)" : [ "processOptions" ],
  "org.apache.hadoop.fs.FileSystem:makeQualified(org.apache.hadoop.fs.Path)" : [ "makeQualified", "checkPath" ],
  "org.apache.hadoop.security.authorize.AccessControlList:buildACL(java.lang.String[])" : [ "isWildCardACLValue", "getTrimmedStringCollection", "cacheGroupsAdd" ],
  "org.apache.hadoop.crypto.key.KeyShell$CreateCommand:validate()" : [ "needsPassword", "noPasswordError", "noPasswordWarning" ],
  "org.apache.hadoop.fs.shell.FsCommand:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.find.Find:isAncestor(org.apache.hadoop.fs.shell.PathData,org.apache.hadoop.fs.shell.PathData)" : [ "isRoot", "getParent", "equals" ],
  "org.apache.hadoop.fs.shell.PathData:relativize(java.net.URI,java.net.URI,boolean)" : [ "findLongestDirPrefix" ],
  "org.apache.hadoop.util.dynamic.DynConstructors$Ctor:newInstanceChecked(java.lang.Object[])" : [ "throwIfInstance" ],
  "org.apache.hadoop.fs.FsShell:init()" : [ "<init>", "setQuietMode", "setConfiguration", "addObject", "registerCommands" ],
  "org.apache.hadoop.util.VersionInfo:main(java.lang.String[])" : [ "getVersion", "getUrl", "getRevision", "getUser", "getDate", "getCompilePlatform", "getProtocVersion", "getSrcChecksum", "findContainingJar" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:addKey(org.apache.hadoop.security.token.delegation.DelegationKey)" : [ "getKeyId", "getCurrentKeyId", "setCurrentKeyId" ],
  "org.apache.hadoop.util.bloom.BloomFilter:<init>(int,int,int)" : [ "<init>" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Location:set(org.apache.hadoop.io.file.tfile.TFile$Reader$Location)" : [ "set" ],
  "org.apache.hadoop.fs.protocolPB.PBHelper:convert(org.apache.hadoop.fs.FSProtos$FsPermissionProto)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:removeDefaultAcl(org.apache.hadoop.fs.Path)" : [ "removeDefaultAcl", "resolve", "getUriPath" ],
  "org.apache.hadoop.io.LongWritable$DecreasingComparator:compare(byte[],int,int,byte[],int,int)" : [ "compare" ],
  "org.apache.hadoop.ipc.RpcWritable$ProtobufWrapper:writeTo(org.apache.hadoop.ipc.ResponseBuffer)" : [ "ensureCapacity" ],
  "org.apache.hadoop.fs.impl.FutureIOSupport:raiseInnerCause(java.util.concurrent.ExecutionException)" : [ "raiseInnerCause" ],
  "org.apache.hadoop.fs.store.DataBlocks$BlockUploadData:<init>(java.io.File)" : [ "checkArgument" ],
  "org.apache.hadoop.fs.impl.prefetch.BufferData:setDone()" : [ "getChecksum" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsContext:getCurrentIOStatisticsContext()" : [ "getCurrentIOStatisticsContext" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:setReplication(org.apache.hadoop.fs.Path,short)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.crypto.JceSm4CtrCryptoCodec:createDecryptor()" : [ "<init>", "getCipherSuite" ],
  "org.apache.hadoop.fs.FilterFs:msync()" : [ "msync" ],
  "org.apache.hadoop.conf.Configuration:addResource(java.io.InputStream,boolean)" : [ "<init>", "addResourceObject" ],
  "org.apache.hadoop.fs.FSDataOutputStreamBuilder:getFS()" : [ "checkNotNull" ],
  "org.apache.hadoop.ipc.Server$RpcCall:setDeferredResponse(org.apache.hadoop.io.Writable)" : [ "getServer", "sendDeferedResponse" ],
  "org.apache.hadoop.fs.shell.MoveCommands:registerCommands(org.apache.hadoop.fs.shell.CommandFactory)" : [ "addClass" ],
  "org.apache.hadoop.fs.AbstractFileSystem:get(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "createFileSystem" ],
  "org.apache.hadoop.util.Lists:newArrayList(java.lang.Object[])" : [ "computeArrayListCapacity" ],
  "org.apache.hadoop.metrics2.impl.MBeanInfoBuilder:counter(org.apache.hadoop.metrics2.MetricsInfo,int)" : [ "newAttrInfo" ],
  "org.apache.hadoop.conf.Configuration:getStringCollection(java.lang.String)" : [ "getStringCollection", "get" ],
  "org.apache.hadoop.util.SysInfoWindows:getStorageBytesRead()" : [ "refreshIfNeeded" ],
  "org.apache.hadoop.security.UserGroupInformation:isLoginSuccess()" : [ "isLoginSuccess", "getLogin" ],
  "org.apache.hadoop.ha.ZKFailoverController:formatZK(boolean,boolean)" : [ "parentZNodeExists", "confirmFormat", "clearParentZNode", "ensureParentZNode" ],
  "org.apache.hadoop.io.compress.zlib.BuiltInZlibDeflater:reinit(org.apache.hadoop.conf.Configuration)" : [ "getCompressionLevel", "compressionLevel", "getCompressionStrategy", "compressionStrategy" ],
  "org.apache.hadoop.util.StringUtils:getTrimmedStringCollectionSplitByEquals(java.lang.String)" : [ "getTrimmedStrings", "getTrimmedStringsSplitByEquals", "checkArgument" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:getMetricsTimeUnit(org.apache.hadoop.conf.Configuration)" : [ "get" ],
  "org.apache.hadoop.util.ExitUtil:terminate(int,java.lang.Throwable)" : [ "<init>", "terminate" ],
  "org.apache.hadoop.security.UserGroupInformation:checkTGTAndReloginFromKeytab()" : [ "reloginFromKeytab" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:close()" : [ "close" ],
  "org.apache.hadoop.io.SequenceFile$Writer$ValueClassOption:<init>(java.lang.Class)" : [ "<init>" ],
  "org.apache.hadoop.io.retry.AsyncCallHandler$AsyncCall:invoke()" : [ "<init>", "isAsynchronousMode", "setAsynchronousMode", "checkState", "isZeros" ],
  "org.apache.hadoop.fs.FileUtil:isRegularFile(java.io.File)" : [ "isRegularFile" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme:<init>()" : [ "<init>" ],
  "org.apache.hadoop.ipc.Server$Connection:buildSaslNegotiateResponse()" : [ "createSaslServer" ],
  "org.apache.hadoop.io.SetFile$Reader:get(org.apache.hadoop.io.WritableComparable)" : [ "seek", "next" ],
  "org.apache.hadoop.fs.FileContext:setPermission(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "fixRelativePart" ],
  "org.apache.hadoop.fs.shell.CopyCommands$Merge:processOptions(java.util.LinkedList)" : [ "<init>", "parse", "getOpt", "isDirectory", "toString" ],
  "org.apache.hadoop.net.unix.DomainSocket$DomainChannel:isOpen()" : [ "isOpen" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:modifyAclEntries(org.apache.hadoop.fs.Path,java.util.List)" : [ "modifyAclEntries" ],
  "org.apache.hadoop.security.SaslPlainServer:unwrap(byte[],int,int)" : [ "throwIfNotComplete" ],
  "org.apache.hadoop.metrics2.sink.StatsDSink:writeMetric(java.lang.String)" : [ "<init>", "write" ],
  "org.apache.hadoop.fs.FSOutputSummer:write(int)" : [ "flushBuffer" ],
  "org.apache.hadoop.fs.shell.Head:dumpToOffset(org.apache.hadoop.fs.shell.PathData)" : [ "openFile", "copyBytes" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:read()" : [ "read" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem$1:close()" : [ "<init>", "close" ],
  "org.apache.hadoop.conf.Configuration:writeXml(java.lang.String,java.io.Writer)" : [ "writeXml" ],
  "org.apache.hadoop.io.file.tfile.TFileDumper:dumpInfo(java.lang.String,java.io.PrintStream,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getFileSystem", "getLen", "open", "getBlockCount", "size", "toString", "getDefaultCompressionName", "getEntryCount", "isSorted", "getComparatorName", "getBlockRegionList", "getCompressedSize", "getRawSize", "format", "getRegion", "getCompressionAlgorithm", "checkTFileDataIndex", "calculateWidth", "getEntry", "getOffset", "getMetaName", "getName", "cleanupWithLogger" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.NativeXORRawDecoder:<init>(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>", "getNumDataUnits", "getNumParityUnits" ],
  "org.apache.hadoop.io.erasurecode.coder.HHXORErasureDecodingStep:doDecodeMultiAndParity(java.nio.ByteBuffer[][],java.nio.ByteBuffer[][],int[],int)" : [ "getNumDataUnits", "getNumParityUnits", "decode", "getPiggyBacksFromInput" ],
  "org.apache.hadoop.util.DiskChecker:checkDir(org.apache.hadoop.fs.LocalFileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "checkDirInternal" ],
  "org.apache.hadoop.fs.GlobPattern:compile(java.lang.String)" : [ "<init>", "compiled" ],
  "org.apache.hadoop.fs.impl.AbstractFSBuilderImpl:<init>(org.apache.hadoop.fs.PathHandle)" : [ "<init>" ],
  "org.apache.hadoop.ipc.UnexpectedServerException:<init>(java.lang.String,java.lang.Throwable)" : [ "<init>" ],
  "org.apache.hadoop.fs.FSDataOutputStreamBuilder:replication(short)" : [ "getThisBuilder" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Compressor:reinit(org.apache.hadoop.conf.Configuration)" : [ "reset", "getBlockSize", "getWorkFactor" ],
  "org.apache.hadoop.io.file.tfile.BoundedRangeFileInputStream:read(byte[],int,int)" : [ "seek" ],
  "org.apache.hadoop.metrics2.source.JvmMetrics:shutdownSingleton()" : [ "shutdown" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:pathToFile(org.apache.hadoop.fs.Path)" : [ "<init>", "isAbsolute", "getWorkingDirectory", "toUri" ],
  "org.apache.hadoop.metrics2.lib.MetricsSourceBuilder:<init>(java.lang.Object,org.apache.hadoop.metrics2.lib.MutableMetricsFactory)" : [ "checkNotNull", "initRegistry", "getDeclaredFieldsIncludingInherited", "add", "getDeclaredMethodsIncludingInherited" ],
  "org.apache.hadoop.net.NetUtils:getLocalInetAddress(java.lang.String)" : [ "getByName" ],
  "org.apache.hadoop.security.KDiag:loginFromKeytab()" : [ "println", "failif", "loginUserFromKeytabAndReturnUGI", "dumpUGI", "validateUGI", "title", "setShouldRenewImmediatelyForTests", "reloginFromKeytab", "warn" ],
  "org.apache.hadoop.io.BloomMapFile$Writer:append(org.apache.hadoop.io.WritableComparable,org.apache.hadoop.io.Writable)" : [ "append", "reset", "set", "add" ],
  "org.apache.hadoop.fs.HarFileSystem:appendFile(org.apache.hadoop.fs.Path)" : [ "appendFile" ],
  "org.apache.hadoop.fs.InvalidPathException:<init>(java.lang.String,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.io.ObjectWritable:loadClass(org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "getClassByName" ],
  "org.apache.hadoop.util.Shell:execCommand(java.util.Map,java.lang.String[])" : [ "execCommand" ],
  "org.apache.hadoop.io.file.tfile.Chunk$ChunkDecoder:read(byte[])" : [ "read" ],
  "org.apache.hadoop.util.dynamic.DynMethods$Builder:impl(java.lang.Class,java.lang.String,java.lang.Class[])" : [ "<init>" ],
  "org.apache.hadoop.security.Credentials:writeTokenStorageToStream(java.io.DataOutputStream,org.apache.hadoop.security.Credentials$SerializedFormat)" : [ "writeWritableOutputStream", "writeProtobufOutputStream" ],
  "org.apache.hadoop.io.UTF8$Comparator:<init>()" : [ "<init>" ],
  "org.apache.hadoop.io.compress.CodecPool:updateLeaseCount(org.apache.hadoop.thirdparty.com.google.common.cache.LoadingCache,java.lang.Object,int)" : [ "getClass" ],
  "org.apache.hadoop.io.retry.RetryPolicies$ExponentialBackoffRetry:<init>(int,long,java.util.concurrent.TimeUnit)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:getFileBlockLocations(org.apache.hadoop.fs.FileStatus,long,long)" : [ "<init>", "getFileBlockLocations", "equals", "getPath", "getRootFallbackLink", "getTargetFileSystem", "getPathWithoutSchemeAndAuthority", "getName", "checkPathIsSlash" ],
  "org.apache.hadoop.fs.FileSystem:getEnclosingRoot(org.apache.hadoop.fs.Path)" : [ "<init>", "makeQualified" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:setOwner(org.apache.hadoop.fs.Path,java.lang.String,java.lang.String)" : [ "setOwner", "resolve", "getUriPath" ],
  "org.apache.hadoop.security.alias.UserProvider:getCredentialEntry(java.lang.String)" : [ "<init>", "getSecretKey" ],
  "org.apache.hadoop.io.nativeio.NativeIO$POSIX:isPmdkAvailable()" : [ "getMessage" ],
  "org.apache.hadoop.ipc.Client$Connection:handleConnectionTimeout(int,int,java.io.IOException)" : [ "closeConnection" ],
  "org.apache.hadoop.net.NodeBase:hashCode()" : [ "getPath" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:createScanner()" : [ "<init>" ],
  "org.apache.hadoop.ha.SshFenceByTcpPort:getSshConnectTimeout()" : [ "getInt" ],
  "org.apache.hadoop.util.dynamic.BindingUtils:noop(java.lang.String)" : [ "<init>", "orNoop", "build" ],
  "org.apache.hadoop.fs.FsShellPermissions$Chmod:processOptions(java.util.LinkedList)" : [ "<init>", "parse", "getOpt" ],
  "org.apache.hadoop.util.StringUtils:escapeString(java.lang.String,char,char)" : [ "escapeString" ],
  "org.apache.hadoop.io.compress.ZStandardCodec:isNativeCodeLoaded()" : [ "isNativeCodeLoaded" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:getServerDefaults()" : [ "getServerDefaults" ],
  "org.apache.hadoop.util.DiskChecker:diskIoCheckWithoutNativeIo(java.io.File)" : [ "cleanupWithLogger" ],
  "org.apache.hadoop.util.IntrusiveCollection:containsAll(java.util.Collection)" : [ "contains" ],
  "org.apache.hadoop.net.TableMapping:<init>()" : [ "<init>" ],
  "org.apache.hadoop.ipc.FairCallQueue:put(org.apache.hadoop.ipc.Schedulable)" : [ "offerQueues", "putQueue" ],
  "org.apache.hadoop.ipc.Server:getClientBackoffEnable(java.lang.String,int,org.apache.hadoop.conf.Configuration)" : [ "getBoolean" ],
  "org.apache.hadoop.ipc.Server$Connection:setupBadVersionResponse(int)" : [ "sendResponse", "writeString", "setResponse" ],
  "org.apache.hadoop.security.ShellBasedUnixGroupsNetgroupMapping:cacheGroupsAdd(java.util.List)" : [ "isCached", "add", "getUsersForNetgroup" ],
  "org.apache.hadoop.ipc.Client$Connection:waitForWork()" : [ "now", "markClosed" ],
  "org.apache.hadoop.io.compress.BZip2Codec:getDecompressorType()" : [ "getBzip2DecompressorType" ],
  "org.apache.hadoop.crypto.key.kms.ValueQueue:getSize(java.lang.String)" : [ "readLock", "readUnlock" ],
  "org.apache.hadoop.fs.FileUtil:setOwner(java.io.File,java.lang.String,java.lang.String)" : [ "getSetOwnerCommand", "execCommand" ],
  "org.apache.hadoop.fs.FileContext:resolveAbstractFileSystems(org.apache.hadoop.fs.Path)" : [ "fixRelativePart" ],
  "org.apache.hadoop.fs.permission.FsCreateModes:create(org.apache.hadoop.fs.permission.FsPermission,org.apache.hadoop.fs.permission.FsPermission)" : [ "<init>", "getUnmasked" ],
  "org.apache.hadoop.util.functional.RemoteIterators$SingletonIterator:getIOStatistics()" : [ "retrieveIOStatistics" ],
  "org.apache.hadoop.util.FileBasedIPList:<init>(java.lang.String)" : [ "<init>", "readLines" ],
  "org.apache.hadoop.ipc.ProtocolSignature:getProtocolSignature(java.lang.String,long)" : [ "getSigFingerprint" ],
  "org.apache.hadoop.fs.LocalFileSystem:getLinkTarget(org.apache.hadoop.fs.Path)" : [ "getLinkTarget" ],
  "org.apache.hadoop.fs.impl.WeakReferenceThreadMap:removeForCurrentThread()" : [ "currentThreadId" ],
  "org.apache.hadoop.fs.impl.prefetch.BufferPool:distance(org.apache.hadoop.fs.impl.prefetch.BufferData,int)" : [ "getBlockNumber" ],
  "org.apache.hadoop.fs.FileUtil:write(org.apache.hadoop.fs.FileContext,org.apache.hadoop.fs.Path,java.lang.CharSequence)" : [ "write" ],
  "org.apache.hadoop.fs.impl.FutureIOSupport:awaitFuture(java.util.concurrent.Future,long,java.util.concurrent.TimeUnit)" : [ "awaitFuture" ],
  "org.apache.hadoop.fs.RawPathHandle:equals(java.lang.Object)" : [ "bytes" ],
  "org.apache.hadoop.fs.FileContext:hasPathCapability(org.apache.hadoop.fs.Path,java.lang.String)" : [ "validatePathCapabilityArgs", "resolve", "fixRelativePart" ],
  "org.apache.hadoop.io.SetFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.io.WritableComparator,org.apache.hadoop.io.SequenceFile$CompressionType)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileSystem$FileSystemDataOutputStreamBuilder:build()" : [ "<init>", "create", "createNonRecursive", "toString" ],
  "org.apache.hadoop.net.NetUtils:normalizeIP2HostName(java.lang.String)" : [ "createSocketAddr", "getHostPortString" ],
  "org.apache.hadoop.io.erasurecode.codec.ErasureCodec:setCodecOptions(org.apache.hadoop.io.erasurecode.ErasureCodecOptions)" : [ "getSchema" ],
  "org.apache.hadoop.fs.FileContext$Util:listStatus(org.apache.hadoop.fs.Path)" : [ "fixRelativePart" ],
  "org.apache.hadoop.conf.Configuration$DeprecationDelta:<init>(java.lang.String,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.conf.Configuration$DeprecationDelta:<init>(java.lang.String,java.lang.String[],java.lang.String)" : [ "checkNotNull", "checkArgument" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:newInverseQuantiles(java.lang.String,java.lang.String,java.lang.String,java.lang.String,int)" : [ "<init>", "checkMetricName" ],
  "org.apache.hadoop.ipc.protocolPB.RefreshCallQueueProtocolClientSideTranslatorPB:isMethodSupported(java.lang.String)" : [ "isMethodSupported", "getProtocolVersion" ],
  "org.apache.hadoop.io.WritableFactories:newInstance(java.lang.Class,org.apache.hadoop.conf.Configuration)" : [ "newInstance", "getFactory" ],
  "org.apache.hadoop.io.OutputBuffer$Buffer:write(java.io.InputStream,int)" : [ "readFully" ],
  "org.apache.hadoop.util.JvmPauseMonitor$GcTimes:subtract(org.apache.hadoop.util.JvmPauseMonitor$GcTimes)" : [ "<init>" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2:getServer(java.lang.Class,java.lang.Object,java.lang.String,int,int,int,int,boolean,org.apache.hadoop.conf.Configuration,org.apache.hadoop.security.token.SecretManager,java.lang.String,org.apache.hadoop.ipc.AlignmentContext)" : [ "<init>" ],
  "org.apache.hadoop.service.AbstractService:enterState(org.apache.hadoop.service.Service$STATE)" : [ "enterState", "getName", "getServiceState", "recordLifecycleEvent" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyNode:equals(java.lang.Object)" : [ "equals" ],
  "org.apache.hadoop.net.SocketInputStream:read()" : [ "read" ],
  "org.apache.hadoop.util.LightWeightCache:get(java.lang.Object)" : [ "get", "checkState", "setExpirationTime" ],
  "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter:init(javax.servlet.FilterConfig)" : [ "getProxyuserConfiguration", "refreshSuperUserGroupsConfiguration" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Writer:getDefaultCompressionAlgorithm()" : [ "getDefaultCompressionAlgorithm" ],
  "org.apache.hadoop.util.CrcUtil:composeWithMonomial(int,int,int,int)" : [ "galoisFieldMultiply" ],
  "org.apache.hadoop.io.compress.zlib.BuiltInGzipCompressor:reinit(org.apache.hadoop.conf.Configuration)" : [ "init" ],
  "org.apache.hadoop.fs.ChecksumFs:renameInternal(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "isDirectory", "rename", "getChecksumFile", "exists" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:logExpireTokens(java.util.Collection)" : [ "logExpireToken", "formatTokenId", "removeExpiredStoredToken" ],
  "org.apache.hadoop.ipc.RetryCache$CacheEntry:<init>(byte[],int,long,boolean)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileContext:processDeleteOnExit()" : [ "delete" ],
  "org.apache.hadoop.fs.shell.find.Find:isExpression(java.lang.String)" : [ "isExpression", "getExpressionFactory" ],
  "org.apache.hadoop.fs.LocalDirAllocator:ifExists(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "ifExists", "obtainContext" ],
  "org.apache.hadoop.io.WritableComparator:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.FileContext:removeAcl(org.apache.hadoop.fs.Path)" : [ "fixRelativePart" ],
  "org.apache.hadoop.util.FindClass:getClass(java.lang.String)" : [ "getClassByName" ],
  "org.apache.hadoop.conf.Configuration:addResource(org.apache.hadoop.conf.Configuration)" : [ "<init>", "addResourceObject", "getProps" ],
  "org.apache.hadoop.util.bloom.RetouchedBloomFilter:add(org.apache.hadoop.util.bloom.Key)" : [ "hash", "clear" ],
  "org.apache.hadoop.fs.FileSystem:addFileSystemForTesting(java.net.URI,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem)" : [ "<init>" ],
  "org.apache.hadoop.io.BoundedByteArrayOutputStream:<init>(byte[],int,int)" : [ "resetBuffer" ],
  "org.apache.hadoop.fs.shell.CommandWithDestination:setPreserve(boolean)" : [ "preserve" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:noteException(org.apache.hadoop.util.ExitUtil$ExitException)" : [ "getExitCode" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:delete(org.apache.hadoop.fs.Path,boolean)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.util.VersionInfo:getBranch()" : [ "_getBranch" ],
  "org.apache.hadoop.crypto.OpensslCtrCryptoCodec$OpensslCtrCipher:process(java.nio.ByteBuffer,java.nio.ByteBuffer)" : [ "update", "doFinal" ],
  "org.apache.hadoop.io.nativeio.NativeIO:isAvailable()" : [ "isNativeCodeLoaded" ],
  "org.apache.hadoop.util.ApplicationClassLoader:constructUrlsFromClasspath(java.lang.String)" : [ "getJarsInDirectory", "toUri" ],
  "org.apache.hadoop.ipc.Server$Connection:initializeAuthContext(int)" : [ "<init>", "valueOf", "doSaslReply" ],
  "org.apache.hadoop.util.StringUtils:formatTimeDiff(long,long)" : [ "formatTime" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:mkdir(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,boolean)" : [ "<init>", "isRoot", "getRootFallbackLink", "getTargetFileSystem", "getPathWithoutSchemeAndAuthority", "equals", "toString", "getName", "getUri", "readOnlyMountTable" ],
  "org.apache.hadoop.ipc.RpcNoSuchProtocolException:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:clearParentZNode()" : [ "checkState", "zkDoWithRetries" ],
  "org.apache.hadoop.fs.HarFileSystem$HarFSDataInputStream$HarFsInputStream:seek(long)" : [ "seek", "validatePosition" ],
  "org.apache.hadoop.metrics2.lib.UniqueNames:uniqueName(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.security.UserGroupInformation:main(java.lang.String[])" : [ "getCurrentUser", "print", "getAuthenticationMethod", "isFromKeytab", "loginUserFromKeytab", "getLoginUser" ],
  "org.apache.hadoop.fs.HarFileSystem:canonicalizeUri(java.net.URI)" : [ "canonicalizeUri" ],
  "org.apache.hadoop.fs.FileContext$FileContextFinalizer:run()" : [ "processDeleteOnExit" ],
  "org.apache.hadoop.fs.FileStatus:<init>(long,boolean,int,long,long,long,org.apache.hadoop.fs.permission.FsPermission,java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileStatus:<init>(long,boolean,int,long,long,long,org.apache.hadoop.fs.permission.FsPermission,java.lang.String,java.lang.String,org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.fs.Options$ChecksumOpt:processChecksumOpt(org.apache.hadoop.fs.Options$ChecksumOpt,org.apache.hadoop.fs.Options$ChecksumOpt,int)" : [ "<init>", "getChecksumType", "getBytesPerChecksum" ],
  "org.apache.hadoop.fs.HarFileSystem:copyToLocalFile(boolean,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "copy", "getConf" ],
  "org.apache.hadoop.util.StringUtils:unEscapeString(java.lang.String,char,char)" : [ "unEscapeString" ],
  "org.apache.hadoop.io.compress.BlockDecompressorStream:decompress(byte[],int,int)" : [ "rawReadInt", "getCompressedData" ],
  "org.apache.hadoop.fs.viewfs.InodeTree:buildResolveResultForRegexMountPoint(org.apache.hadoop.fs.viewfs.InodeTree$ResultKind,java.lang.String,java.lang.String,org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.ipc.Server$Connection:getAuthorizedUgi(java.lang.String)" : [ "<init>", "getIdentifier", "addTokenIdentifier", "createRemoteUser" ],
  "org.apache.hadoop.metrics2.MetricsTag:toString()" : [ "value" ],
  "org.apache.hadoop.net.NetUtils:getFreeSocketPorts(int)" : [ "checkArgument", "getFreeSocketPort" ],
  "org.apache.hadoop.ha.ZKFailoverController:getParentZnode()" : [ "get" ],
  "org.apache.hadoop.http.HttpServer2:addContext(org.eclipse.jetty.servlet.ServletContextHandler,boolean)" : [ "addNoCacheFilter" ],
  "org.apache.hadoop.security.token.delegation.web.KerberosDelegationTokenAuthenticationHandler:<init>()" : [ "<init>" ],
  "org.apache.hadoop.io.SequenceFile$Reader:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.io.SequenceFile$Reader$Option[])" : [ "<init>", "getFileSystem", "getLen", "openFile", "initialize" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsLogging:ioStatisticsToString(org.apache.hadoop.fs.statistics.IOStatistics)" : [ "mapToString" ],
  "org.apache.hadoop.crypto.CipherSuite:getConfigSuffix()" : [ "toLowerCase" ],
  "org.apache.hadoop.io.SequenceFile$Sorter:writeFile(org.apache.hadoop.io.SequenceFile$Sorter$RawKeyValueIterator,org.apache.hadoop.io.SequenceFile$Writer)" : [ "appendRaw", "getData", "getLength", "sync" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:getDefaultBlockSize(org.apache.hadoop.fs.Path)" : [ "getDefaultBlockSize", "fullPath" ],
  "org.apache.hadoop.security.http.CrossOriginFilter:init(javax.servlet.FilterConfig)" : [ "initializeAllowedMethods", "initializeAllowedHeaders", "initializeAllowedOrigins", "initializeMaxAge" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:main(java.lang.String[])" : [ "serviceMain" ],
  "org.apache.hadoop.util.MachineList:<init>(java.util.Collection)" : [ "<init>" ],
  "org.apache.hadoop.util.ShutdownHookManager:hasShutdownHook(java.lang.Runnable)" : [ "<init>" ],
  "org.apache.hadoop.fs.FsShell:printUsage(java.io.PrintStream)" : [ "printInfo" ],
  "org.apache.hadoop.metrics2.sink.RollingFileSystemSink:getNextIdToTry(org.apache.hadoop.fs.Path,int)" : [ "listFiles", "toString", "getName", "extractId" ],
  "org.apache.hadoop.io.UTF8:fromBytes(byte[])" : [ "<init>", "reset", "readChars" ],
  "org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue:lessThan(java.lang.Object,java.lang.Object)" : [ "getKey", "getData", "getLength" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getUsed()" : [ "<init>", "getUsed", "resolve", "getUriPath", "isInternalDir" ],
  "org.apache.hadoop.conf.Configuration:getFile(java.lang.String,java.lang.String)" : [ "getTrimmedStrings" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:createSymlink(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,boolean)" : [ "readOnlyMountTable" ],
  "org.apache.hadoop.security.UserGroupInformation:getUGIFromSubject(javax.security.auth.Subject)" : [ "<init>", "doSubjectLogin" ],
  "org.apache.hadoop.jmx.JMXJsonServlet:listBeans(com.fasterxml.jackson.core.JsonGenerator,javax.management.ObjectName,java.lang.String,javax.servlet.http.HttpServletResponse)" : [ "writeAttribute" ],
  "org.apache.hadoop.fs.store.DataBlocks$ByteArrayBlock:<init>(long,int,org.apache.hadoop.fs.store.BlockUploadStatistics)" : [ "<init>" ],
  "org.apache.hadoop.fs.statistics.impl.DynamicIOStatisticsBuilder:activeInstance()" : [ "checkState" ],
  "org.apache.hadoop.security.alias.BouncyCastleFipsKeyStoreProvider:<init>(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.ipc.Server$Call:<init>(int,int,java.lang.Void,java.lang.Void,org.apache.hadoop.ipc.RPC$RpcKind,byte[])" : [ "<init>" ],
  "org.apache.hadoop.io.SortedMapWritable:write(java.io.DataOutput)" : [ "write" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner:lowerBound(byte[])" : [ "lowerBound" ],
  "org.apache.hadoop.metrics2.lib.MetricsSourceBuilder:initRegistry(java.lang.Object)" : [ "<init>", "getDeclaredFieldsIncludingInherited", "getInfo", "setContext" ],
  "org.apache.hadoop.fs.shell.find.Name:prepare()" : [ "<init>", "toLowerCase" ],
  "org.apache.hadoop.fs.FileSystem:checkAccessPermissions(org.apache.hadoop.fs.FileStatus,org.apache.hadoop.fs.permission.FsAction)" : [ "<init>", "getPermission", "getCurrentUser", "getShortUserName", "getOwner", "getUserAction", "implies", "getGroupsSet", "getGroup", "getGroupAction", "getOtherAction", "getPath", "isDirectory" ],
  "org.apache.hadoop.metrics2.sink.RollingFileSystemSink:checkForErrors(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.ChecksumFileSystem:copyFromLocalFile(boolean,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "copy" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider:noPasswordError()" : [ "noPasswordError" ],
  "org.apache.hadoop.fs.FilterFileSystem:getDefaultBlockSize()" : [ "getDefaultBlockSize" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:getXAttr(org.apache.hadoop.fs.Path,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.Command:displayError(java.lang.Exception)" : [ "displayError", "getName", "stringifyException" ],
  "org.apache.hadoop.io.ArrayPrimitiveWritable:readFields(java.io.DataInput)" : [ "readString", "getPrimitiveClass", "checkDeclaredComponentType", "readBooleanArray", "readCharArray", "readByteArray", "readShortArray", "readIntArray", "readLongArray", "readFloatArray", "readDoubleArray" ],
  "org.apache.hadoop.fs.FileSystem:create(org.apache.hadoop.fs.Path)" : [ "create" ],
  "org.apache.hadoop.fs.viewfs.RegexMountPointResolvedDstPathReplaceInterceptor:deserializeFromString(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.util.ProgramDriver:run(java.lang.String[])" : [ "printUsage", "invoke" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:getWorkingDirectory()" : [ "getHomeDirectory" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:addRawCallVolume(org.apache.hadoop.metrics2.MetricsRecordBuilder)" : [ "info", "getTotalRawCallVolume" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.util.GaloisField:power(int,int)" : [ "getFieldSize" ],
  "org.apache.hadoop.util.DurationInfo:<init>(org.slf4j.Logger,java.lang.String,java.lang.Object[])" : [ "<init>" ],
  "org.apache.hadoop.crypto.random.OsSecureRandom:next(int)" : [ "fillReservoir" ],
  "org.apache.hadoop.fs.permission.AclUtil:getMinimalAcl(org.apache.hadoop.fs.permission.FsPermission)" : [ "newArrayList", "setScope", "setType", "setPermission", "getUserAction", "build", "getGroupAction", "getOtherAction" ],
  "org.apache.hadoop.util.StringUtils:getStrings(java.lang.String)" : [ "getStrings" ],
  "org.apache.hadoop.util.functional.RemoteIterators$TypeCastingRemoteIterator:<init>(org.apache.hadoop.fs.RemoteIterator)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:skipToNextMarker(long,int)" : [ "bsR" ],
  "org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:getTokenInfoFromZK(java.lang.String,boolean)" : [ "<init>", "readFields" ],
  "org.apache.hadoop.security.KDiag:printEnv(java.lang.String)" : [ "println" ],
  "org.apache.hadoop.fs.FileUtil:write(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,java.lang.CharSequence,java.nio.charset.Charset)" : [ "createFile", "overwrite", "close" ],
  "org.apache.hadoop.fs.ChecksumFs:getChecksumFileLength(org.apache.hadoop.fs.Path,long)" : [ "getChecksumLength", "getBytesPerSum" ],
  "org.apache.hadoop.util.dynamic.DynMethods$Builder:build(java.lang.Object)" : [ "build", "bind" ],
  "org.apache.hadoop.io.wrappedio.WrappedStatistics:iostatisticsContext_snapshot()" : [ "getCurrentIOStatisticsContext" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme:initialize(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "initialize", "get", "setBoolean", "getBoolean", "getMountTableConfigLoader" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:initBlock()" : [ "initialiseCRC", "getAllowableBlockSize" ],
  "org.apache.hadoop.fs.store.DataBlocks$DiskBlock:toString()" : [ "dataSize" ],
  "org.apache.hadoop.fs.shell.CommandFormat:parse(java.util.List)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:createSnapshot(org.apache.hadoop.fs.Path,java.lang.String)" : [ "createSnapshot", "fullPath" ],
  "org.apache.hadoop.fs.shell.TouchCommands:registerCommands(org.apache.hadoop.fs.shell.CommandFactory)" : [ "addClass" ],
  "org.apache.hadoop.util.LightWeightGSet:<init>(int)" : [ "actualArrayLength" ],
  "org.apache.hadoop.fs.FileUtil:copy(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.FileStatus,org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,boolean,boolean,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getPath", "checkDest", "getName", "isDirectory", "checkDependencies", "mkdirs", "listStatusIterator", "awaitFuture", "openFile", "getLen", "build", "create", "copyBytes", "cleanupWithLogger" ],
  "org.apache.hadoop.fs.FSDataOutputStream:<init>(java.io.OutputStream,org.apache.hadoop.fs.FileSystem$Statistics,long)" : [ "<init>" ],
  "org.apache.hadoop.io.retry.RetryPolicies:shouldFailoverOnException(java.lang.Exception)" : [ "unwrapRemoteException" ],
  "org.apache.hadoop.ipc.CallQueueManager:put(org.apache.hadoop.ipc.Schedulable)" : [ "isClientBackoffEnabled", "shouldBackOff", "throwBackoff", "addInternal" ],
  "org.apache.hadoop.util.CrcComposer:digest()" : [ "intToBytes" ],
  "org.apache.hadoop.fs.FileSystem:getDefaultUri(org.apache.hadoop.conf.Configuration)" : [ "fixName", "getTrimmed" ],
  "org.apache.hadoop.security.token.delegation.DelegationKey:getKey()" : [ "createSecretKey" ],
  "org.apache.hadoop.fs.FilterFileSystem:listLocatedStatus(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.PathFilter)" : [ "listLocatedStatus" ],
  "org.apache.hadoop.fs.FileSystem:getNamed(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "get", "fixName" ],
  "org.apache.hadoop.fs.shell.PathData:<init>(org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.fs.FileStatus)" : [ "<init>", "stringToUri", "makeQualified", "setStat", "checkIfSchemeInferredFromPath" ],
  "org.apache.hadoop.fs.impl.prefetch.BufferData:setReady(org.apache.hadoop.fs.impl.prefetch.BufferData$State[])" : [ "getChecksum", "updateState" ],
  "org.apache.hadoop.util.InstrumentedLock:<init>(java.lang.String,org.slf4j.Logger,long,long)" : [ "<init>" ],
  "org.apache.hadoop.util.ComparableVersion$StringItem:isNull()" : [ "comparableQualifier" ],
  "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker:read(long,byte[],int,int)" : [ "<init>", "close" ],
  "org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation:init(java.lang.Class)" : [ "addMetricIfNotExists" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "rename", "fullPath" ],
  "org.apache.hadoop.conf.ReconfigurableBase:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileUtil:execCommand(java.io.File,java.lang.String[])" : [ "execCommand" ],
  "org.apache.hadoop.io.compress.BlockCompressorStream:compress()" : [ "rawWriteInt" ],
  "org.apache.hadoop.ipc.CallQueueManager:offer(java.lang.Object)" : [ "offer" ],
  "org.apache.hadoop.ipc.Server$Connection:processRpcRequest(org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcRequestHeaderProto,org.apache.hadoop.ipc.RpcWritable$Buffer)" : [ "<init>", "getRpcRequestWrapper", "getHostAddress", "newInstance", "setTracer", "curThreadTracer", "byteStringToSpanContext", "newSpan", "toTraceName", "setSignature", "build", "convert", "getPriorityLevel", "getRequestHeader", "getMaxIdleTime", "incRpcCount" ],
  "org.apache.hadoop.fs.shell.FsUsage$Df:getUsagesTable()" : [ "getUsagesTable" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:setXAttr(org.apache.hadoop.fs.Path,java.lang.String,byte[],java.util.EnumSet)" : [ "setXAttr" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:decryptEncryptedKey(org.apache.hadoop.crypto.key.KeyProviderCryptoExtension$EncryptedKeyVersion)" : [ "doOp", "nextIdx" ],
  "org.apache.hadoop.io.Text:readString(java.io.DataInput)" : [ "readString" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2$RpcProtobufRequest:toString()" : [ "getRequestHeader" ],
  "org.apache.hadoop.util.ReflectionUtils:setJobConf(java.lang.Object,org.apache.hadoop.conf.Configuration)" : [ "getClassByNameOrNull" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RSRawEncoder:doEncode(org.apache.hadoop.io.erasurecode.rawcoder.ByteBufferEncodingState)" : [ "resetOutputBuffers", "encodeData" ],
  "org.apache.hadoop.fs.FileSystem:getHomeDirectory()" : [ "<init>", "getCurrentUser", "getShortUserName", "makeQualified" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:getServerDefaults()" : [ "getServerDefaults" ],
  "org.apache.hadoop.ipc.Server:setupResponseForWritable(org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto,org.apache.hadoop.io.Writable)" : [ "reset", "wrap", "toByteArray", "capacity", "setCapacity" ],
  "org.apache.hadoop.log.LogThrottlingHelper:<init>(long,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.ha.HAAdmin:help(java.lang.String[],java.util.Map)" : [ "printUsage" ],
  "org.apache.hadoop.fs.MD5MD5CRC32FileChecksum:getChecksumOpt()" : [ "<init>", "getCrcType" ],
  "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback:<init>()" : [ "isNativeCodeLoaded" ],
  "org.apache.hadoop.fs.FilterFs:getServerDefaults(org.apache.hadoop.fs.Path)" : [ "getServerDefaults" ],
  "org.apache.hadoop.ha.HAServiceTarget:getProxyForAddress(org.apache.hadoop.conf.Configuration,int,int,java.net.InetSocketAddress)" : [ "<init>", "setInt", "getDefaultSocketFactory" ],
  "org.apache.hadoop.http.HttpServer2:<init>(org.apache.hadoop.http.HttpServer2$Builder)" : [ "getWebAppsPath", "createWebAppContext", "constructSecretProvider", "initializeWebServer", "newArrayList" ],
  "org.apache.hadoop.fs.HarFileSystem:<init>()" : [ "<init>" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:updateReportedByteCount(int)" : [ "updateProcessedByteCount" ],
  "org.apache.hadoop.util.IntrusiveCollection:toArray()" : [ "iterator" ],
  "org.apache.hadoop.io.MapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType)" : [ "<init>", "keyClass", "valueClass", "compression" ],
  "org.apache.hadoop.security.SaslPropertiesResolver:getInstance(org.apache.hadoop.conf.Configuration)" : [ "getClass", "newInstance" ],
  "org.apache.hadoop.fs.shell.Delete$Rm:processOptions(java.util.LinkedList)" : [ "<init>", "parse", "getOpt" ],
  "org.apache.hadoop.fs.StorageType:getMovableTypes()" : [ "getNonTransientTypes" ],
  "org.apache.hadoop.util.QuickSort:sort(org.apache.hadoop.util.IndexedSortable,int,int,org.apache.hadoop.util.Progressable)" : [ "sortInternal", "getMaxDepth" ],
  "org.apache.hadoop.util.ToolRunner:run(org.apache.hadoop.util.Tool,java.lang.String[])" : [ "run" ],
  "org.apache.hadoop.net.NetworkTopology:getInstance(org.apache.hadoop.conf.Configuration)" : [ "getInstance" ],
  "org.apache.hadoop.fs.shell.Display$AvroFileInputStream:<init>(org.apache.hadoop.fs.FileStatus)" : [ "<init>", "getFileContext", "getPath" ],
  "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker:readChunk(long,byte[],int,int,byte[])" : [ "<init>", "getChecksumFilePos", "getPos", "seek" ],
  "org.apache.hadoop.ipc.RpcWritable$Buffer:wrap(java.nio.ByteBuffer)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:getStoragePolicy(org.apache.hadoop.fs.Path)" : [ "getStoragePolicy", "fullPath" ],
  "org.apache.hadoop.crypto.CryptoInputStream:read(long,java.nio.ByteBuffer)" : [ "checkStream", "decrypt" ],
  "org.apache.hadoop.fs.shell.find.Find:createOptions()" : [ "setOut", "setErr", "setIn", "setCommandFactory", "setConfiguration" ],
  "org.apache.hadoop.ipc.Server:getServerRpcInvoker(org.apache.hadoop.ipc.RPC$RpcKind)" : [ "getRpcInvoker" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:deleteSnapshot(org.apache.hadoop.fs.Path,java.lang.String)" : [ "deleteSnapshot", "fullPath" ],
  "org.apache.hadoop.fs.impl.AbstractFSBuilderImpl:must(java.lang.String,long)" : [ "mustLong" ],
  "org.apache.hadoop.fs.FileUtil:write(org.apache.hadoop.fs.FileContext,org.apache.hadoop.fs.Path,java.lang.Iterable,java.nio.charset.Charset)" : [ "create", "overwrite", "close" ],
  "org.apache.hadoop.conf.ReconfigurableBase:reconfigureProperty(java.lang.String,java.lang.String)" : [ "<init>", "isPropertyReconfigurable", "get", "set", "unset" ],
  "org.apache.hadoop.fs.FileContext:removeXAttr(org.apache.hadoop.fs.Path,java.lang.String)" : [ "fixRelativePart" ],
  "org.apache.hadoop.util.ZKUtil:getPermFromString(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Reader:getDataBlock(int)" : [ "getBlockCount", "getBlockRegionList", "createReader", "getDefaultCompressionAlgorithm" ],
  "org.apache.hadoop.fs.MD5MD5CRC32FileChecksum:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.FileSystem:getQuotaUsage(org.apache.hadoop.fs.Path)" : [ "getContentSummary" ],
  "org.apache.hadoop.fs.permission.AclEntry:parseAclSpec(java.lang.String,boolean)" : [ "getStringCollection", "parseAclEntry" ],
  "org.apache.hadoop.fs.shell.Delete$Expunge:processArguments(java.util.LinkedList)" : [ "<init>", "set", "get", "getChildFileSystems", "expungeImmediately", "expunge", "checkpoint" ],
  "org.apache.hadoop.net.SocketOutputStream:transferToFully(java.nio.channels.FileChannel,long,int)" : [ "transferToFully" ],
  "org.apache.hadoop.io.file.tfile.BCFile$DataIndex:write(java.io.DataOutput)" : [ "write", "writeString", "getName", "writeVInt" ],
  "org.apache.hadoop.fs.shell.Command:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.io.MD5Hash:read(java.io.DataInput)" : [ "<init>", "readFields" ],
  "org.apache.hadoop.fs.FSOutputSummer:<init>(org.apache.hadoop.util.DataChecksum)" : [ "getBytesPerChecksum", "getChecksumSize" ],
  "org.apache.hadoop.ipc.Client$Connection:writeConnectionContext(org.apache.hadoop.ipc.Client$ConnectionId,org.apache.hadoop.security.SaslRpcServer$AuthMethod)" : [ "<init>", "makeIpcConnectionContext", "getProtocolName", "getProtocol", "getTicket", "makeRpcRequestHeader", "sendRequest", "toByteArray" ],
  "org.apache.hadoop.fs.FileSystem:completeLocalOutput(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "moveFromLocalFile" ],
  "org.apache.hadoop.metrics2.MetricStringBuilder:setContext(java.lang.String)" : [ "tuple" ],
  "org.apache.hadoop.fs.FileSystem:moveToLocalFile(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "copyToLocalFile" ],
  "org.apache.hadoop.util.MachineList:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.security.AuthenticationFilterInitializer:getFilterConfigMap(org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "getPropsWithPrefix", "get", "getServerPrincipal" ],
  "org.apache.hadoop.util.functional.RemoteIterators$MappingRemoteIterator:<init>(org.apache.hadoop.fs.RemoteIterator,org.apache.hadoop.util.functional.FunctionRaisingIOE)" : [ "<init>" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreBuilderImpl:withSampleTracking(java.lang.String[])" : [ "withCounters", "withMinimums", "withMaximums", "withMeanStatistics" ],
  "org.apache.hadoop.io.file.tfile.TFile$TFileMeta:<init>(java.lang.String)" : [ "makeComparator" ],
  "org.apache.hadoop.util.LightWeightGSet$Values:clear()" : [ "clear" ],
  "org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread:run()" : [ "running" ],
  "org.apache.hadoop.conf.Configuration:getInts(java.lang.String)" : [ "getTrimmedStrings" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:compareKeys(org.apache.hadoop.io.file.tfile.RawComparable,org.apache.hadoop.io.file.tfile.RawComparable)" : [ "isSorted", "compare" ],
  "org.apache.hadoop.fs.viewfs.FsGetter:get(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "get" ],
  "org.apache.hadoop.util.HostsFileReader:updateFileNames(java.lang.String,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.io.SequenceFile$Sorter:merge(java.util.List,org.apache.hadoop.fs.Path)" : [ "merge" ],
  "org.apache.hadoop.security.authorize.ProxyUsers:getInstance(org.apache.hadoop.conf.Configuration)" : [ "getClass", "newInstance" ],
  "org.apache.hadoop.ha.PowerShellFencer:tryFence(org.apache.hadoop.ha.HAServiceTarget,java.lang.String)" : [ "<init>", "buildPSScript", "start", "join" ],
  "org.apache.hadoop.ipc.RpcNoSuchMethodException:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:getServerDefaults(org.apache.hadoop.fs.Path)" : [ "getServerDefaults", "fullPath" ],
  "org.apache.hadoop.conf.Configuration:getClass(java.lang.String,java.lang.Class)" : [ "getTrimmed", "getClassByName" ],
  "org.apache.hadoop.util.DurationInfo:toString()" : [ "toString", "getFormattedText" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:listStatus(org.apache.hadoop.fs.Path)" : [ "<init>", "isInternalDir", "stripOutRoot", "getPath" ],
  "org.apache.hadoop.io.file.tfile.TFile:getSupportedCompressionAlgorithms()" : [ "getSupportedAlgorithms" ],
  "org.apache.hadoop.fs.impl.MultipartUploaderBuilderImpl:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)" : [ "<init>", "makeQualified", "checkNotNull", "getInt", "getDefaultReplication", "getDefaultBlockSize" ],
  "org.apache.hadoop.fs.FileContext:getAbstractFileSystem(org.apache.hadoop.security.UserGroupInformation,java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "doAs" ],
  "org.apache.hadoop.metrics2.sink.GraphiteSink$Graphite:write(java.lang.String)" : [ "isConnected", "connect" ],
  "org.apache.hadoop.metrics2.sink.FileSink:putMetrics(org.apache.hadoop.metrics2.MetricsRecord)" : [ "name", "value" ],
  "org.apache.hadoop.ipc.Server:registerProtocolEngine(org.apache.hadoop.ipc.RPC$RpcKind,java.lang.Class,org.apache.hadoop.ipc.RPC$RpcInvoker)" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:cancelDelegationToken(org.apache.hadoop.security.token.Token)" : [ "getDoAsUser", "generateDelegationToken", "getActualUgi", "doAs" ],
  "org.apache.hadoop.net.NetworkTopology:toString()" : [ "getNumOfLeaves", "getPath" ],
  "org.apache.hadoop.security.SecurityUtil:getZKAuthInfos(org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "getPassword", "resolveConfIndirection", "parseAuth" ],
  "org.apache.hadoop.conf.Configuration:getInt(java.lang.String,int)" : [ "getTrimmed", "getHexDigits" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:renameSnapshot(org.apache.hadoop.fs.Path,java.lang.String,java.lang.String)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.io.NullWritable$Comparator:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getChrootedPath(org.apache.hadoop.fs.viewfs.InodeTree$ResolveResult,org.apache.hadoop.fs.FileStatus,org.apache.hadoop.fs.Path)" : [ "<init>", "stripOutRoot", "getPath", "stripRoot" ],
  "org.apache.hadoop.fs.ContentSummary:<init>(long,long,long,long,long,long)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileUtil:stat2Paths(org.apache.hadoop.fs.FileStatus[])" : [ "getPath" ],
  "org.apache.hadoop.util.dynamic.DynMethods$BoundMethod:invoke(java.lang.Object[])" : [ "invoke" ],
  "org.apache.hadoop.ipc.Client:getRpcResponse(org.apache.hadoop.ipc.Client$Call,org.apache.hadoop.ipc.Client$Connection,long,java.util.concurrent.TimeUnit)" : [ "getRpcResponse", "wait", "getRemoteAddress", "wrapException", "getHostname" ],
  "org.apache.hadoop.ipc.Server$Connection:checkDataLength(int)" : [ "getHostAddress" ],
  "org.apache.hadoop.net.NetworkTopologyWithNodeGroup:getRack(java.lang.String)" : [ "normalize", "isRack", "isNodeGroup" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:getActiveData()" : [ "createConnection", "getDataWithRetries", "isNodeDoesNotExist" ],
  "org.apache.hadoop.http.HttpServer2$QuotingInputFilter$RequestQuoter:getParameter(java.lang.String)" : [ "quoteHtmlChars", "unquoteHtmlChars" ],
  "org.apache.hadoop.http.ProfileOutputServlet:doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)" : [ "isInstrumentationAccessAllowed", "setResponseHeader", "sanitize" ],
  "org.apache.hadoop.io.IOUtils:copyBytes(java.io.InputStream,java.io.OutputStream,org.apache.hadoop.conf.Configuration,boolean)" : [ "copyBytes", "getInt" ],
  "org.apache.hadoop.util.curator.ZKCuratorManager:safeDelete(java.lang.String,java.util.List,java.lang.String)" : [ "exists", "createTransaction", "delete", "commit" ],
  "org.apache.hadoop.io.compress.zlib.BuiltInGzipCompressor:compress(byte[],int,int)" : [ "<init>", "finished", "writeHeader", "fillTrailer", "writeTrailer" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:createZooKeeper()" : [ "setSslConfiguration", "initiateZookeeper" ],
  "org.apache.hadoop.io.retry.CallReturn:getReturnValue()" : [ "checkState" ],
  "org.apache.hadoop.fs.FileContext:listStatus(org.apache.hadoop.fs.Path)" : [ "fixRelativePart" ],
  "org.apache.hadoop.fs.shell.Stat:processOptions(java.util.LinkedList)" : [ "<init>", "parse", "getOpt" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier:getUser()" : [ "toString", "equals", "createRemoteUser", "createProxyUser", "setAuthenticationMethod" ],
  "org.apache.hadoop.ipc.WritableRpcEngine$Invoker:close()" : [ "stopClient" ],
  "org.apache.hadoop.io.erasurecode.coder.XORErasureEncoder:prepareEncodingStep(org.apache.hadoop.io.erasurecode.ECBlockGroup)" : [ "<init>", "createRawEncoder" ],
  "org.apache.hadoop.fs.permission.FsPermission:<init>(org.apache.hadoop.fs.permission.FsAction,org.apache.hadoop.fs.permission.FsAction,org.apache.hadoop.fs.permission.FsAction,boolean)" : [ "set" ],
  "org.apache.hadoop.conf.Configuration$Parser:handleEndProperty()" : [ "<init>", "getDeprecatedKeyMap", "clearAccessed" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:getLinkTarget(org.apache.hadoop.fs.Path)" : [ "getFileLinkStatus", "getSymlink" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:getFileStatus(org.apache.commons.net.ftp.FTPFile,org.apache.hadoop.fs.Path)" : [ "<init>", "getPermissions" ],
  "org.apache.hadoop.io.retry.RetryInvocationHandler:handleException(java.lang.reflect.Method,int,org.apache.hadoop.io.retry.RetryPolicy,org.apache.hadoop.io.retry.RetryInvocationHandler$Counters,long,java.lang.Exception)" : [ "newRetryInfo", "idempotentOrAtMostOnce", "isFail", "getProxyInfo", "getString", "getFailException", "log", "isFailover" ],
  "org.apache.hadoop.crypto.key.UserProvider:getMetadata(java.lang.String)" : [ "<init>", "getSecretKey" ],
  "org.apache.hadoop.io.compress.zstd.ZStandardDecompressor$ZStandardDirectDecompressor:<init>(int)" : [ "<init>" ],
  "org.apache.hadoop.util.StringUtils:getTrimmedStringCollection(java.lang.String)" : [ "getTrimmedStrings" ],
  "org.apache.hadoop.fs.FileSystem:getStorageStatistics()" : [ "<init>" ],
  "org.apache.hadoop.fs.FileSystem$Statistics:incrementBytesWritten(long)" : [ "getThreadStatistics" ],
  "org.apache.hadoop.ipc.CallerContext$Builder:appendIfAbsent(java.lang.String,java.lang.String)" : [ "isValid" ],
  "org.apache.hadoop.util.Shell$ShellCommandExecutor:<init>(java.lang.String[],java.io.File,java.util.Map,long)" : [ "<init>" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker:call(org.apache.hadoop.ipc.RPC$Server,java.lang.String,org.apache.hadoop.ipc.RpcWritable$Buffer,long,java.lang.String,java.lang.String,long)" : [ "call", "getProtocolImpl", "isShadedPBImpl", "processCall" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2:getProxy(java.lang.Class,long,java.net.InetSocketAddress,org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory,int,org.apache.hadoop.io.retry.RetryPolicy)" : [ "getProxy" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:getAclStatus(org.apache.hadoop.fs.Path)" : [ "checkPathIsSlash", "owner", "getShortUserName", "group", "getPrimaryGroupName", "addEntries", "getMinimalAcl", "stickyBit", "build" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:reset()" : [ "terminateConnection" ],
  "org.apache.hadoop.metrics2.impl.MetricsRecordImpl:<init>(org.apache.hadoop.metrics2.MetricsInfo,long,java.util.List,java.lang.Iterable)" : [ "checkArg", "checkNotNull" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:removeAcl(org.apache.hadoop.fs.Path)" : [ "removeAcl", "fullPath" ],
  "org.apache.hadoop.net.DNS:getDefaultIP(java.lang.String)" : [ "getIPs" ],
  "org.apache.hadoop.fs.viewfs.ViewFsFileStatus:getLen()" : [ "getLen" ],
  "org.apache.hadoop.util.AsyncDiskService:awaitTermination(long)" : [ "now" ],
  "org.apache.hadoop.metrics2.util.SampleStat$MinMax:reset(org.apache.hadoop.metrics2.util.SampleStat$MinMax)" : [ "min", "max" ],
  "org.apache.hadoop.io.Text:decode(byte[],int,int)" : [ "decode" ],
  "org.apache.hadoop.crypto.CryptoInputStream:decrypt(long,byte[],int,int)" : [ "decrypt", "getBuffer", "getDecryptor", "updateDecryptor", "getPadding", "afterDecryption", "returnBuffer", "returnDecryptor" ],
  "org.apache.hadoop.fs.FSInputChecker:fill()" : [ "readChecksumChunk" ],
  "org.apache.hadoop.ipc.Server$Connection:saslReadAndProcess(org.apache.hadoop.ipc.RpcWritable$Buffer)" : [ "<init>", "getMessage", "saslProcess" ],
  "org.apache.hadoop.security.http.XFrameOptionsFilter:getFilterParams(org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "getPropsWithPrefix" ],
  "org.apache.hadoop.security.SecurityUtil:getByName(java.lang.String)" : [ "<init>", "start", "stop", "now" ],
  "org.apache.hadoop.fs.store.audit.HttpReferrerAuditHeader:<init>(org.apache.hadoop.fs.store.audit.HttpReferrerAuditHeader$Builder)" : [ "addAttribute", "buildHttpReferrer" ],
  "org.apache.hadoop.util.Shell:getSetPermissionCommand(java.lang.String,boolean)" : [ "getWinUtilsPath" ],
  "org.apache.hadoop.fs.AbstractFileSystem:makeQualified(org.apache.hadoop.fs.Path)" : [ "makeQualified", "checkPath", "getUri" ],
  "org.apache.hadoop.fs.shell.FsUsage$Df:setHumanReadable(boolean)" : [ "setHumanReadable" ],
  "org.apache.hadoop.io.retry.AsyncCallHandler$AsyncCall:processWaitTimeAndRetryInfo()" : [ "monotonicNow" ],
  "org.apache.hadoop.fs.viewfs.ConfigUtil:addLinkMerge(org.apache.hadoop.conf.Configuration,java.lang.String,java.net.URI[])" : [ "set", "getConfigViewFsPrefix" ],
  "org.apache.hadoop.fs.permission.FsPermission:fromShort(short)" : [ "set" ],
  "org.apache.hadoop.security.token.Token:isManaged()" : [ "getRenewer" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:parseBackOffByResponseTimeEnabled(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "getBoolean" ],
  "org.apache.hadoop.net.ScriptBasedMappingWithDependency:setConf(org.apache.hadoop.conf.Configuration)" : [ "setConf", "getRawMapping" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.AbstractNativeRawDecoder:doDecode(org.apache.hadoop.io.erasurecode.rawcoder.ByteArrayDecodingState)" : [ "doDecode", "convertToByteBufferState" ],
  "org.apache.hadoop.security.token.DtUtilShell$Append:execute()" : [ "appendTokenFiles" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:satisfyStoragePolicy(org.apache.hadoop.fs.Path)" : [ "satisfyStoragePolicy", "resolve", "getUriPath" ],
  "org.apache.hadoop.fs.FileSystem:get(org.apache.hadoop.conf.Configuration)" : [ "getDefaultUri" ],
  "org.apache.hadoop.ipc.RPC:getProtocolEngine(java.lang.Class,org.apache.hadoop.conf.Configuration)" : [ "getClass", "newInstance" ],
  "org.apache.hadoop.fs.shell.Ls:formatSize(long)" : [ "long2String" ],
  "org.apache.hadoop.util.RunJar:unJar(java.io.InputStream,java.io.File,java.util.regex.Pattern)" : [ "ensureDirectory", "copyBytes" ],
  "org.apache.hadoop.io.erasurecode.coder.XORErasureDecoder:getOutputBlocks(org.apache.hadoop.io.erasurecode.ECBlockGroup)" : [ "getParityBlocks", "isErased", "getDataBlocks" ],
  "org.apache.hadoop.conf.ConfServlet:writeResponse(org.apache.hadoop.conf.Configuration,java.io.Writer,java.lang.String,java.lang.String)" : [ "<init>", "dumpConfiguration", "writeXml" ],
  "org.apache.hadoop.fs.statistics.impl.WrappedIOStatistics:gauges()" : [ "getWrapped" ],
  "org.apache.hadoop.io.erasurecode.CodecRegistry:<init>()" : [ "updateCoders" ],
  "org.apache.hadoop.fs.permission.AclStatus:getEffectivePermission(org.apache.hadoop.fs.permission.AclEntry)" : [ "getEffectivePermission" ],
  "org.apache.hadoop.fs.permission.FsPermission:getDefault()" : [ "<init>" ],
  "org.apache.hadoop.net.NetUtils:getIPs(java.lang.String,boolean)" : [ "addMatchingAddrs" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$DelegationTokenInformation:write(java.io.DataOutput)" : [ "writeVLong", "writeVInt", "writeString" ],
  "org.apache.hadoop.fs.impl.prefetch.CachingBlockManager:requestPrefetch(int)" : [ "<init>", "requestPrefetch", "checkNotNegative", "tryAcquire", "stateEqualsOneOf", "executeFunction", "setPrefetch", "end" ],
  "org.apache.hadoop.io.erasurecode.ECSchema:<init>(java.lang.String,int,int)" : [ "<init>" ],
  "org.apache.hadoop.fs.UnionStorageStatistics$LongStatisticIterator:next()" : [ "getIter" ],
  "org.apache.hadoop.util.InstrumentedLock:lockInterruptibly()" : [ "monotonicNow", "check", "startLockTiming" ],
  "org.apache.hadoop.ipc.Server:addSuppressedLoggingExceptions(java.lang.Class[])" : [ "addSuppressedLoggingExceptions" ],
  "org.apache.hadoop.fs.local.RawLocalFs:getServerDefaults()" : [ "getServerDefaults" ],
  "org.apache.hadoop.fs.DelegationTokenRenewer$RenewAction:toString()" : [ "getDelay" ],
  "org.apache.hadoop.ipc.protocolPB.RefreshCallQueueProtocolClientSideTranslatorPB:refreshCallQueue()" : [ "ipc" ],
  "org.apache.hadoop.util.dynamic.DynConstructors$Builder:hiddenImpl(java.lang.String,java.lang.Class[])" : [ "hiddenImpl" ],
  "org.apache.hadoop.io.compress.PassthroughCodec$PassthroughDecompressorStream:<init>(java.io.InputStream)" : [ "<init>" ],
  "org.apache.hadoop.ipc.Client$Connection:handleConnectionFailure(int,java.io.IOException)" : [ "closeConnection" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:createSnapshot(org.apache.hadoop.fs.Path,java.lang.String)" : [ "createSnapshot", "fullPath" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Writer:prepareMetaBlock(java.lang.String,java.lang.String)" : [ "prepareMetaBlock", "getCompressionAlgorithmByName" ],
  "org.apache.hadoop.io.BooleanWritable$Comparator:<init>()" : [ "<init>" ],
  "org.apache.hadoop.security.UserGroupInformation:addToken(org.apache.hadoop.security.token.Token)" : [ "addToken", "getService" ],
  "org.apache.hadoop.util.SysInfoWindows:getVirtualMemorySize()" : [ "refreshIfNeeded" ],
  "org.apache.hadoop.log.LogLevel$CLI:run(java.lang.String[])" : [ "parseArguments", "sendLogLevelRequest" ],
  "org.apache.hadoop.io.serializer.DeserializerComparator:<init>(org.apache.hadoop.io.serializer.Deserializer)" : [ "<init>" ],
  "org.apache.hadoop.io.SequenceFile$Writer:file(org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.fs.PathOperationException:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.io.MapWritable:write(java.io.DataOutput)" : [ "write" ],
  "org.apache.hadoop.util.LightWeightResizableGSet:<init>(int)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.lib.MutableMetricsFactory:newForField(java.lang.reflect.Field,org.apache.hadoop.metrics2.annotation.Metric,org.apache.hadoop.metrics2.lib.MetricsRegistry)" : [ "<init>", "newForField", "getInfo", "add", "newCounter", "newGauge", "newRate", "newRatesWithAggregation", "newStat", "newMutableRollingAverages", "newQuantiles" ],
  "org.apache.hadoop.ipc.Server:getAuxiliaryListenerAddresses()" : [ "getAddress" ],
  "org.apache.hadoop.io.compress.Lz4Codec:createCompressor()" : [ "<init>", "getInt", "getBoolean" ],
  "org.apache.hadoop.fs.PathNotFoundException:<init>(java.lang.String,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.statistics.DurationStatisticSummary:fetchDurationSummary(org.apache.hadoop.fs.statistics.IOStatistics,java.lang.String,boolean)" : [ "<init>" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:getTotalRequests()" : [ "getTotalRequests" ],
  "org.apache.hadoop.util.GcTimeMonitor$Builder:build()" : [ "<init>" ],
  "org.apache.hadoop.http.HttpServer2:initializeWebServer(java.lang.String,java.lang.String,org.apache.hadoop.conf.Configuration,java.lang.String[])" : [ "<init>", "checkNotNull", "getInt", "getRequestLog", "getWebAppsPath", "addDefaultApps", "getBoolean", "setHeaders", "addGlobalFilter", "getFilterInitializers", "set", "addDefaultServlets", "addPrometheusServlet", "addAsyncProfilerServlet" ],
  "org.apache.hadoop.fs.shell.Delete$Rm:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "isDirectory", "toString", "moveToTrash", "canBeSafelyDeleted" ],
  "org.apache.hadoop.io.retry.LossyRetryInvocationHandler:invokeMethod(java.lang.reflect.Method,java.lang.Object[])" : [ "<init>", "invokeMethod" ],
  "org.apache.hadoop.security.authorize.ProxyUsers:authorize(org.apache.hadoop.security.UserGroupInformation,java.lang.String)" : [ "authorize", "getSip" ],
  "org.apache.hadoop.crypto.key.KeyShell$RollCommand:execute()" : [ "rollNewVersion" ],
  "org.apache.hadoop.io.nativeio.NativeIO$POSIX:getPmdkSupportStateMessage()" : [ "getMessage" ],
  "org.apache.hadoop.security.UserGroupInformation:getPrimaryGroupName()" : [ "getGroupsSet" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.NativeRSRawEncoder:<init>(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>", "getNumDataUnits", "getNumParityUnits" ],
  "org.apache.hadoop.io.ArrayPrimitiveWritable$Internal:<init>()" : [ "<init>" ],
  "org.apache.hadoop.ipc.RPC:getProtocolInterfaces(java.lang.Class)" : [ "getSuperInterfaces" ],
  "org.apache.hadoop.util.IdentityHashStore:put(java.lang.Object,java.lang.Object)" : [ "checkNotNull", "realloc", "putInternal" ],
  "org.apache.hadoop.security.SaslPropertiesResolver:getServerProperties(java.net.InetAddress,int)" : [ "getServerProperties" ],
  "org.apache.hadoop.net.unix.DomainSocket$DomainOutputStream:write(int)" : [ "reference" ],
  "org.apache.hadoop.security.UserGroupInformation$TestingGroups:getGroups(java.lang.String)" : [ "getGroupsSet" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreImpl:getMaximumReference(java.lang.String)" : [ "lookup" ],
  "org.apache.hadoop.fs.impl.PathCapabilitiesSupport:validatePathCapabilityArgs(org.apache.hadoop.fs.Path,java.lang.String)" : [ "checkArgument" ],
  "org.apache.hadoop.conf.Configuration:loadResources(java.util.Properties,java.util.ArrayList,int,boolean,boolean)" : [ "<init>", "loadResource", "addTags" ],
  "org.apache.hadoop.fs.Path:isAbsolute()" : [ "isUriPathAbsolute" ],
  "org.apache.hadoop.io.file.tfile.TFile$TFileMeta:write(java.io.DataOutput)" : [ "write", "writeVLong", "writeString" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:renewDelegationToken(org.apache.hadoop.security.token.Token)" : [ "getDoAsUser", "generateDelegationToken", "createURL", "createAuthenticatedURL", "getActualUgi", "doAs" ],
  "org.apache.hadoop.io.retry.AsyncCallHandler$ConcurrentQueue:isEmpty(long)" : [ "monotonicNow" ],
  "org.apache.hadoop.http.HttpServer2:addInternalServlet(java.lang.String,java.lang.String,java.lang.Class)" : [ "addInternalServlet" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtobufRpcEngineCallbackImpl:setResponse(org.apache.hadoop.thirdparty.protobuf.Message)" : [ "now", "setDeferredResponse", "wrap" ],
  "org.apache.hadoop.fs.TrashPolicyDefault:deleteCheckpoint(boolean)" : [ "deleteCheckpoint", "getTrashRoots", "getPath" ],
  "org.apache.hadoop.io.erasurecode.coder.ErasureDecoder:getOutputBlocks(org.apache.hadoop.io.erasurecode.ECBlockGroup)" : [ "getNumErasedBlocks", "getNumDataUnits", "getDataBlocks", "isErased", "getNumParityUnits", "getParityBlocks" ],
  "org.apache.hadoop.fs.viewfs.ViewFsFileStatus:getBlockSize()" : [ "getBlockSize" ],
  "org.apache.hadoop.service.launcher.HadoopUncaughtExceptionHandler:uncaughtException(java.lang.Thread,java.lang.Throwable)" : [ "get", "isShutdownInProgress", "haltOnOutOfMemory", "convertToExitException", "terminate" ],
  "org.apache.hadoop.fs.FileSystem:listStatus(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.PathFilter)" : [ "listStatus" ],
  "org.apache.hadoop.security.token.delegation.web.PseudoDelegationTokenAuthenticationHandler:<init>()" : [ "<init>" ],
  "org.apache.hadoop.net.NetworkTopologyWithNodeGroup:getWeight(org.apache.hadoop.net.Node,org.apache.hadoop.net.Node)" : [ "isOnSameNodeGroup", "isOnSameRack" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:connect()" : [ "get", "getInt", "wrapException", "getTransferMode", "setTimeout", "setDataConnectionMode" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreImpl:getMinimumReference(java.lang.String)" : [ "lookup" ],
  "org.apache.hadoop.ipc.metrics.RpcDetailedMetrics:addProcessingTime(java.lang.String,long)" : [ "add" ],
  "org.apache.hadoop.fs.impl.prefetch.CachingBlockManager:prefetch(org.apache.hadoop.fs.impl.prefetch.BufferData,java.time.Instant)" : [ "readBlock" ],
  "org.apache.hadoop.util.GenericOptionsParser:<init>(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.Options,java.lang.String[])" : [ "parseGeneralOptions" ],
  "org.apache.hadoop.metrics2.impl.MetricsConfig:create(java.lang.String,java.lang.String[])" : [ "loadFirst" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:truncate(org.apache.hadoop.fs.Path,long)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:close()" : [ "close" ],
  "org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool:trimIdleSelectors(long)" : [ "close" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState:getCompressedSize()" : [ "getCurrentPos" ],
  "org.apache.hadoop.io.SequenceFile:createWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec)" : [ "createWriter", "file", "keyClass", "valueClass", "compression" ],
  "org.apache.hadoop.fs.shell.find.ExpressionFactory:registerExpression(java.lang.Class)" : [ "stringifyException" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:updateCurrentKey()" : [ "<init>", "incrementCurrentKeyId", "logUpdateMasterKey", "storeDelegationKey" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:<init>(java.io.OutputStream)" : [ "<init>" ],
  "org.apache.hadoop.ipc.ProtocolSignature:getFingerprint(java.lang.reflect.Method[])" : [ "getFingerprint", "getFingerprints" ],
  "org.apache.hadoop.util.Progress:addNewPhase()" : [ "<init>", "setParent" ],
  "org.apache.hadoop.ha.HealthMonitor:doHealthChecks()" : [ "isHealthCheckFailedException", "enterState", "stopProxy", "setLastServiceStatus" ],
  "org.apache.hadoop.fs.Stat:<init>(org.apache.hadoop.fs.Path,long,boolean,org.apache.hadoop.fs.FileSystem)" : [ "<init>", "toUri", "makeQualified" ],
  "org.apache.hadoop.metrics2.lib.MutableGaugeInt:decr()" : [ "decr" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsSnapshot:setMinimum(java.lang.String,long)" : [ "minimums" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:setOwner(org.apache.hadoop.fs.Path,java.lang.String,java.lang.String)" : [ "setOwner" ],
  "org.apache.hadoop.io.compress.zlib.ZlibFactory:getZlibCompressor(org.apache.hadoop.conf.Configuration)" : [ "<init>", "isNativeZlibLoaded", "getCompressionLevel", "compressionLevel" ],
  "org.apache.hadoop.io.ArrayFile$Reader:seek(long)" : [ "set" ],
  "org.apache.hadoop.io.DataInputByteBuffer:getData()" : [ "getData" ],
  "org.apache.hadoop.metrics2.MetricStringBuilder:tag(org.apache.hadoop.metrics2.MetricsInfo,java.lang.String)" : [ "add" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:getRpcRequeueCalls()" : [ "value" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:writeBreadCrumbNode(org.apache.zookeeper.data.Stat)" : [ "checkState", "createWithRetries", "setDataWithRetries" ],
  "org.apache.hadoop.conf.Configuration:dumpConfiguration(org.apache.hadoop.conf.Configuration,java.io.Writer)" : [ "<init>", "getProps", "appendJSONProperty" ],
  "org.apache.hadoop.io.SequenceFile$Reader:nextRawKey(org.apache.hadoop.io.DataOutputBuffer)" : [ "readRecordLength", "write", "getPos", "readBlock", "readVInt" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Reader$BlockReader:close()" : [ "finish" ],
  "org.apache.hadoop.security.token.DtFileOperations:matchAlias(org.apache.hadoop.security.token.Token,org.apache.hadoop.io.Text)" : [ "getService", "equals" ],
  "org.apache.hadoop.fs.impl.prefetch.CachingBlockManager:getInternal(org.apache.hadoop.fs.impl.prefetch.BufferData)" : [ "checkNotNull", "stateEqualsOneOf", "getBlockNumber", "getState", "getPrefetched", "end", "throwIfStateIncorrect", "read" ],
  "org.apache.hadoop.http.HttpServer2:addAsyncProfilerServlet(org.eclipse.jetty.server.handler.ContextHandlerCollection,org.apache.hadoop.conf.Configuration)" : [ "getAsyncProfilerHome", "addServlet", "setContextAttributes" ],
  "org.apache.hadoop.fs.viewfs.ConfigUtil:addLink(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String,java.net.URI)" : [ "set", "getConfigViewFsPrefix" ],
  "org.apache.hadoop.io.file.tfile.Compression$Algorithm$1:createCompressionStream(java.io.OutputStream,org.apache.hadoop.io.compress.Compressor,int)" : [ "<init>", "isSupported", "setInt" ],
  "org.apache.hadoop.util.functional.FutureIO:awaitAllFutures(java.util.Collection,java.time.Duration)" : [ "awaitFuture" ],
  "org.apache.hadoop.util.AutoCloseableLock:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.FileSystem:openFileWithOptions(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.impl.OpenFileParameters)" : [ "rejectUnknownMandatoryKeys", "getMandatoryKeys", "eval" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$DelegationTokenSecretManagerMetrics:trackRemoveToken(org.apache.hadoop.util.functional.InvocationRaisingIOE)" : [ "trackInvocation" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:setPermission(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.ByteArrayEncodingState:checkBuffers(byte[][])" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.InodeTree$INodeLink:<init>(java.lang.String,org.apache.hadoop.security.UserGroupInformation,java.lang.Object,java.lang.String[])" : [ "<init>" ],
  "org.apache.hadoop.net.SocksSocketFactory:createSocket(java.lang.String,int)" : [ "createSocket" ],
  "org.apache.hadoop.io.SequenceFile$Writer:keyClass(java.lang.Class)" : [ "<init>" ],
  "org.apache.hadoop.security.token.delegation.DelegationKey:readFields(java.io.DataInput)" : [ "readVInt", "readVLong", "readVIntInRange" ],
  "org.apache.hadoop.io.SequenceFile:setDefaultCompressionType(org.apache.hadoop.conf.Configuration,org.apache.hadoop.io.SequenceFile$CompressionType)" : [ "set" ],
  "org.apache.hadoop.fs.FilterFs:listStatus(org.apache.hadoop.fs.Path)" : [ "checkPath" ],
  "org.apache.hadoop.security.KDiag:verifyFileIsValid(java.io.File,java.lang.String,java.lang.String)" : [ "verify" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:createInternal(org.apache.hadoop.fs.Path,java.util.EnumSet,org.apache.hadoop.fs.permission.FsPermission,int,short,long,org.apache.hadoop.util.Progressable,org.apache.hadoop.fs.Options$ChecksumOpt,boolean)" : [ "<init>", "getOptionalParentPath", "getFileStatus", "isDirectory", "primitiveCreate" ],
  "org.apache.hadoop.io.Text:readFields(java.io.DataInput,int)" : [ "readVInt", "readWithKnownLength" ],
  "org.apache.hadoop.security.UserGroupInformation:reattachMetrics()" : [ "reattach" ],
  "org.apache.hadoop.security.Credentials:mergeAll(org.apache.hadoop.security.Credentials)" : [ "addAll" ],
  "org.apache.hadoop.crypto.key.KeyShell$CreateCommand:execute()" : [ "createKey", "toString" ],
  "org.apache.hadoop.security.Groups:getGroupInternal(java.lang.String)" : [ "isNegativeCacheEnabled", "noGroupsForUser" ],
  "org.apache.hadoop.util.bloom.RetouchedBloomFilter:addFalsePositive(java.util.List)" : [ "addFalsePositive" ],
  "org.apache.hadoop.net.NetUtils:getConnectAddress(org.apache.hadoop.ipc.Server)" : [ "getConnectAddress", "getListenerAddress" ],
  "org.apache.hadoop.fs.FileContext:getFileContext(org.apache.hadoop.fs.AbstractFileSystem,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding:emptyStatistics()" : [ "getInstance" ],
  "org.apache.hadoop.crypto.key.KeyShell$ListCommand:execute()" : [ "getKeysMetadata" ],
  "org.apache.hadoop.security.alias.CredentialShell$CreateCommand:validate()" : [ "needsPassword", "noPasswordError", "noPasswordWarning" ],
  "org.apache.hadoop.util.JsonSerialization:fromInstance(java.lang.Object)" : [ "fromJson", "toJson" ],
  "org.apache.hadoop.fs.PathAccessDeniedException:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.HarFileSystem$HarFSDataInputStream$HarFsInputStream:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,long,long,int)" : [ "seek" ],
  "org.apache.hadoop.fs.impl.prefetch.SingleFilePerBlockCache:get(int,java.nio.ByteBuffer)" : [ "checkNotNull", "getEntry", "readFile", "validateEntry" ],
  "org.apache.hadoop.util.SysInfoWindows:refreshIfNeeded()" : [ "now", "reset", "getSystemInfoInfoFromShell" ],
  "org.apache.hadoop.io.compress.zstd.ZStandardCompressor:getBytesWritten()" : [ "checkStream" ],
  "org.apache.hadoop.fs.permission.ScopedAclEntries:calculatePivotOnDefaultEntries(java.util.List)" : [ "getScope" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner:seekTo(byte[],int,int)" : [ "<init>", "seekTo" ],
  "org.apache.hadoop.io.erasurecode.coder.RSErasureEncoder:checkCreateRSRawEncoder()" : [ "createRawEncoder" ],
  "org.apache.hadoop.security.UserGroupInformation:createLoginUser(javax.security.auth.Subject)" : [ "<init>", "doSubjectLogin", "createProxyUser", "getTrimmedStringCollection", "get", "readTokenStorageFile", "numberOfTokens", "addCredentials", "decodeFromUrlString", "addToken", "getService" ],
  "org.apache.hadoop.fs.FileContext:resolvePath(org.apache.hadoop.fs.Path)" : [ "resolve" ],
  "org.apache.hadoop.ipc.FairCallQueue:add(org.apache.hadoop.ipc.Schedulable)" : [ "offerQueues" ],
  "org.apache.hadoop.io.file.tfile.TFile$TFileIndex:addEntry(org.apache.hadoop.io.file.tfile.TFile$TFileIndexEntry)" : [ "entries" ],
  "org.apache.hadoop.security.UserGroupInformation:shouldRelogin()" : [ "hasKerberosCredentials", "isHadoopLogin" ],
  "org.apache.hadoop.ipc.WritableRpcEngine$Server:<init>(java.lang.Object,org.apache.hadoop.conf.Configuration,java.lang.String,int,int,int,int,boolean,org.apache.hadoop.security.token.SecretManager)" : [ "<init>" ],
  "org.apache.hadoop.io.Text:encode(java.lang.String)" : [ "encode" ],
  "org.apache.hadoop.fs.Options$CreateOpts:donotCreateParent()" : [ "<init>" ],
  "org.apache.hadoop.io.DataOutputBuffer:write(java.io.DataInput,int)" : [ "write" ],
  "org.apache.hadoop.fs.statistics.impl.DynamicIOStatisticsBuilder:withAtomicLongCounter(java.lang.String,java.util.concurrent.atomic.AtomicLong)" : [ "withLongFunctionCounter" ],
  "org.apache.hadoop.security.KDiag:close()" : [ "flush" ],
  "org.apache.hadoop.fs.shell.CommandWithDestination:recursePath(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "getTargetPath", "checkPathsForReservedRaw", "isDirectory", "toString", "mkdirs", "setOperation", "refreshStatus", "preserveAttributes" ],
  "org.apache.hadoop.fs.impl.prefetch.SingleFilePerBlockCache:validateEntry(org.apache.hadoop.fs.impl.prefetch.SingleFilePerBlockCache$Entry,java.nio.ByteBuffer)" : [ "getChecksum" ],
  "org.apache.hadoop.util.InstrumentedLock:unlock()" : [ "monotonicNow", "check" ],
  "org.apache.hadoop.io.erasurecode.coder.RSErasureDecoder:checkCreateRSRawDecoder()" : [ "createRawDecoder" ],
  "org.apache.hadoop.fs.FileSystem$Cache:closeAll()" : [ "closeAll" ],
  "org.apache.hadoop.fs.ContentSummary:<init>(long,long,long)" : [ "<init>" ],
  "org.apache.hadoop.net.NetworkTopologyWithNodeGroup$InnerNodeWithNodeGroup:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.util.KMSUtil:getKeyProviderUri(org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "getTrimmed" ],
  "org.apache.hadoop.fs.HarFileSystem:getDefaultReplication(org.apache.hadoop.fs.Path)" : [ "getDefaultReplication" ],
  "org.apache.hadoop.conf.Configuration:getRaw(java.lang.String)" : [ "handleDeprecation", "getProps" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:endBlock()" : [ "getFinalCRC", "blockSort", "bsPutUByte", "bsPutInt", "bsW", "moveToFrontCodeAndSend" ],
  "org.apache.hadoop.ipc.internal.ShadedProtobufHelper:ipc(org.apache.hadoop.ipc.internal.ShadedProtobufHelper$IpcCall)" : [ "getRemoteException" ],
  "org.apache.hadoop.util.functional.TaskPool$Builder:setStatisticsContext()" : [ "setThreadIOStatisticsContext" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.XORRawErasureCoderFactory:createDecoder(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.fs.FsShell:displayError(java.lang.String,java.lang.String)" : [ "getInstance" ],
  "org.apache.hadoop.security.authorize.AccessControlList:<init>(java.lang.String)" : [ "<init>", "buildACL", "getUserToGroupsMappingService" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockData:getSize(int)" : [ "isLastBlock" ],
  "org.apache.hadoop.ha.ZKFailoverController:checkEligibleForFailover()" : [ "<init>", "getLastHealthState" ],
  "org.apache.hadoop.security.UserGroupInformation:isKerberosKeyTabLoginRenewalEnabled()" : [ "ensureInitialized" ],
  "org.apache.hadoop.util.BlockingThreadPoolExecutorService:toString()" : [ "toString", "getActiveCount" ],
  "org.apache.hadoop.conf.Configuration:getTimeDurations(java.lang.String,java.util.concurrent.TimeUnit)" : [ "getTrimmedStrings", "getTimeDurationHelper" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystemUtil:getStatus(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)" : [ "<init>", "isViewFileSystem", "isViewFileSystemOverloadScheme", "getUriPath", "getMountPoints", "breakIntoPathComponents", "getMountedOnPath", "toString", "updateMountPointFsStatus" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:createKey(java.lang.String,byte[],org.apache.hadoop.crypto.key.KeyProvider$Options)" : [ "checkNotNull", "createKeyInternal" ],
  "org.apache.hadoop.conf.Configuration:getDeprecatedKey(java.lang.String)" : [ "getReverseDeprecatedKeyMap" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkNotEmpty(int,java.lang.String)" : [ "checkArgument" ],
  "org.apache.hadoop.metrics2.sink.RollingFileSystemSink:throwMetricsException(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.AbstractMultipartUploader:checkPutArguments(org.apache.hadoop.fs.Path,java.io.InputStream,int,org.apache.hadoop.fs.UploadHandle,long)" : [ "checkPath", "checkArgument" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RSLegacyRawEncoder:doEncode(org.apache.hadoop.io.erasurecode.rawcoder.ByteBufferEncodingState)" : [ "resetOutputBuffers", "remainder" ],
  "org.apache.hadoop.io.erasurecode.coder.HHXORErasureEncodingStep:doEncode(java.nio.ByteBuffer[][],java.nio.ByteBuffer[][])" : [ "getNumParityUnits", "getPiggyBacksFromInput", "encode", "encodeWithPiggyBacks" ],
  "org.apache.hadoop.fs.MD5MD5CRC32FileChecksum:getBytes()" : [ "toByteArray" ],
  "org.apache.hadoop.ipc.FairCallQueue:take()" : [ "removeNextElement" ],
  "org.apache.hadoop.fs.impl.prefetch.BufferPool:tryAcquire(int)" : [ "acquireHelper" ],
  "org.apache.hadoop.security.UserGroupInformation:reloginFromKeytab()" : [ "reloginFromKeytab" ],
  "org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool:release(org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool$SelectorInfo)" : [ "now", "trimIdleSelectors" ],
  "org.apache.hadoop.fs.FileSystemStorageStatistics:getScheme()" : [ "getScheme" ],
  "org.apache.hadoop.fs.sftp.SFTPInputStream:available()" : [ "checkNotClosed" ],
  "org.apache.hadoop.crypto.CryptoInputStream:<init>(java.io.InputStream,org.apache.hadoop.crypto.CryptoCodec,int,byte[],byte[],long)" : [ "checkCodec", "checkBufferSize", "getDecryptor", "resetStreamOffset" ],
  "org.apache.hadoop.fs.impl.prefetch.BufferPool:toString()" : [ "toString", "getAll" ],
  "org.apache.hadoop.fs.shell.Ls:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "toString", "getContentSummary", "isDirectory", "getPermission", "hasAcl", "isFile", "getReplication", "getOwner", "getGroup", "getErasureCodingPolicy", "formatSize", "getLen", "isUseAtime", "getAccessTime", "getModificationTime", "isHideNonPrintable" ],
  "org.apache.hadoop.conf.Configuration$Parser:handleStartProperty()" : [ "weakIntern" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:getBlockEntryCount(int)" : [ "getEntry", "entries" ],
  "org.apache.hadoop.security.SecurityUtil:getClientPrincipal(java.lang.Class,org.apache.hadoop.conf.Configuration)" : [ "getKerberosInfo", "get" ],
  "org.apache.hadoop.io.ObjectWritable:write(java.io.DataOutput)" : [ "writeObject" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsSnapshot:aggregate(org.apache.hadoop.fs.statistics.IOStatistics)" : [ "aggregateMaps", "aggregateGauges", "passthroughFn", "aggregateCounters", "aggregateMeanStatistics", "aggregateMaximums", "copy", "aggregateMinimums" ],
  "org.apache.hadoop.fs.Options$ChecksumOpt:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.DelegationTokenRenewer$RenewAction:renew()" : [ "renew", "updateRenewalTime", "now" ],
  "org.apache.hadoop.http.HttpServer2Metrics:create(org.eclipse.jetty.server.handler.StatisticsHandler,int)" : [ "<init>", "instance", "remove" ],
  "org.apache.hadoop.fs.FilterFileSystem:listLocatedStatus(org.apache.hadoop.fs.Path)" : [ "listLocatedStatus" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$MRNflyNode:updateFileStatus(org.apache.hadoop.fs.Path)" : [ "getFileStatus" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler$MetricsProxy:<init>(java.lang.String,int,org.apache.hadoop.ipc.DecayRpcScheduler)" : [ "setDelegate", "register", "registerMetrics2Source" ],
  "org.apache.hadoop.ipc.ProtobufHelper:protoFromToken(org.apache.hadoop.security.token.Token)" : [ "protoFromToken" ],
  "org.apache.hadoop.util.FileBasedIPList:reload()" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider:loadFromPath(org.apache.hadoop.fs.Path,char[])" : [ "open", "getPermission" ],
  "org.apache.hadoop.fs.shell.PathData:toFile()" : [ "pathToFile" ],
  "org.apache.hadoop.metrics2.lib.MutableGaugeFloat:decr()" : [ "incr" ],
  "org.apache.hadoop.io.SetFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType)" : [ "<init>", "get" ],
  "org.apache.hadoop.fs.PartialListing:<init>(org.apache.hadoop.fs.Path,org.apache.hadoop.ipc.RemoteException)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileContext$Util:globStatus(org.apache.hadoop.fs.Path)" : [ "<init>", "glob" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsLogging:mapToString(java.lang.StringBuilder,java.lang.String,java.util.Map,java.lang.String)" : [ "entryToString" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:removeExpiredStoredToken(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier)" : [ "removeStoredToken" ],
  "org.apache.hadoop.fs.Trash:getCurrentTrashDir(org.apache.hadoop.fs.Path)" : [ "getCurrentTrashDir" ],
  "org.apache.hadoop.net.NodeBase:<init>(java.lang.String,java.lang.String,org.apache.hadoop.net.Node,int)" : [ "set", "normalize" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:iostatisticsSnapshot_save(java.io.Serializable,org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,boolean)" : [ "checkIoStatisticsAvailable", "invoke" ],
  "org.apache.hadoop.fs.shell.SetReplication:processOptions(java.util.LinkedList)" : [ "<init>", "parse", "getOpt" ],
  "org.apache.hadoop.fs.FileContext:setTimes(org.apache.hadoop.fs.Path,long,long)" : [ "fixRelativePart" ],
  "org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:removeStoredToken(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier,boolean)" : [ "getNodePath", "getSequenceNumber", "getTokenInfoFromZK", "getRenewDate", "now" ],
  "org.apache.hadoop.io.MapFile$Reader:getValueClass()" : [ "getValueClass" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:isStaleClient(java.lang.Object)" : [ "checkNotNull" ],
  "org.apache.hadoop.io.wrappedio.WrappedStatistics:iostatisticsContext_getCurrent()" : [ "getCurrentIOStatisticsContext" ],
  "org.apache.hadoop.log.LogThrottlingHelper:record(java.lang.String,long,double[])" : [ "<init>", "shouldLog" ],
  "org.apache.hadoop.fs.DUHelper:getFolderUsage(java.lang.String)" : [ "<init>", "calculateFolderSize" ],
  "org.apache.hadoop.fs.protocolPB.PBHelper:convert(org.apache.hadoop.fs.permission.FsPermission)" : [ "toShort" ],
  "org.apache.hadoop.crypto.CryptoInputStream:close()" : [ "freeBuffers" ],
  "org.apache.hadoop.io.compress.CompressorStream:write(int)" : [ "write" ],
  "org.apache.hadoop.conf.Configuration:getAlternativeNames(java.lang.String)" : [ "getReverseDeprecatedKeyMap", "getDeprecatedKeyMap", "getProps" ],
  "org.apache.hadoop.fs.FsShell:getCurrentTrashDir(org.apache.hadoop.fs.Path)" : [ "getCurrentTrashDir", "getTrash" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:removeAcl(org.apache.hadoop.fs.Path)" : [ "removeAcl", "resolve", "getUriPath" ],
  "org.apache.hadoop.fs.shell.Command:expandArguments(java.util.LinkedList)" : [ "expandArgument", "displayError" ],
  "org.apache.hadoop.fs.shell.Tail:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "isDirectory", "toString", "dumpFromOffset" ],
  "org.apache.hadoop.ipc.Server$Call:getUserGroupInformation()" : [ "getRemoteUser" ],
  "org.apache.hadoop.security.protocolPB.RefreshAuthorizationPolicyProtocolClientSideTranslatorPB:isMethodSupported(java.lang.String)" : [ "isMethodSupported", "getProtocolVersion" ],
  "org.apache.hadoop.util.ProtoUtil:makeRpcRequestHeader(org.apache.hadoop.ipc.RPC$RpcKind,org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcRequestHeaderProto$OperationProto,int,int,byte[],org.apache.hadoop.ipc.AlignmentContext)" : [ "convert", "getCurrentSpan", "spanContextToByteString", "getContext", "getCurrent", "isContextValid", "getSignature" ],
  "org.apache.hadoop.security.UserGroupInformation:isAuthenticationMethodEnabled(org.apache.hadoop.security.UserGroupInformation$AuthenticationMethod)" : [ "ensureInitialized" ],
  "org.apache.hadoop.conf.Configuration$Resource:<init>(java.lang.Object,java.lang.String)" : [ "<init>", "getRestrictParserDefault" ],
  "org.apache.hadoop.fs.FileUtil:makeSecureShellPath(java.io.File)" : [ "makeShellPath" ],
  "org.apache.hadoop.http.HttpServer2:addGlobalFilter(java.lang.String,java.lang.String,java.util.Map)" : [ "getFilterHolder", "getFilterMapping", "defineFilter" ],
  "org.apache.hadoop.fs.FileStatus:<init>(long,boolean,int,long,long,long,org.apache.hadoop.fs.permission.FsPermission,java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,boolean,boolean,boolean)" : [ "<init>", "attributes" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server:registerForDeferredResponse2()" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:truncate(org.apache.hadoop.fs.Path,long)" : [ "readOnlyMountTable" ],
  "org.apache.hadoop.metrics2.MetricsJsonBuilder:setContext(java.lang.String)" : [ "tuple" ],
  "org.apache.hadoop.util.ExitUtil:terminate(int,java.lang.String)" : [ "<init>", "terminate" ],
  "org.apache.hadoop.fs.FilterFileSystem:openFileWithOptions(org.apache.hadoop.fs.PathHandle,org.apache.hadoop.fs.impl.OpenFileParameters)" : [ "openFileWithOptions" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:getStoragePolicy(org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:registerFailureHandling()" : [ "<init>", "register" ],
  "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer:<init>(org.apache.hadoop.fs.ChecksumFileSystem,org.apache.hadoop.fs.Path,boolean,int,short,long,org.apache.hadoop.util.Progressable,org.apache.hadoop.fs.permission.FsPermission)" : [ "<init>", "newDataChecksum", "getBytesPerSum", "getRawFileSystem", "getChecksumFile" ],
  "org.apache.hadoop.security.SaslRpcClient:getOutputStream(java.io.OutputStream)" : [ "useWrap" ],
  "org.apache.hadoop.fs.viewfs.ViewFsLocatedFileStatus:compareTo(org.apache.hadoop.fs.FileStatus)" : [ "compareTo" ],
  "org.apache.hadoop.fs.shell.Count:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "getQuotaUsage", "toString", "isHumanReadable", "getContentSummary", "toErasureCodingPolicy", "toSnapshot" ],
  "org.apache.hadoop.net.unix.DomainSocketWatcher:remove(org.apache.hadoop.net.unix.DomainSocket)" : [ "kick" ],
  "org.apache.hadoop.io.SetFile$Writer:<init>(org.apache.hadoop.fs.FileSystem,java.lang.String,java.lang.Class)" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.KeyShell:main(java.lang.String[])" : [ "<init>", "run" ],
  "org.apache.hadoop.ipc.protocolPB.GenericRefreshProtocolClientSideTranslatorPB:unpack(org.apache.hadoop.ipc.proto.GenericRefreshProtocolProtos$GenericRefreshResponseCollectionProto)" : [ "unpack" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Compressor:setInput(byte[],int,int)" : [ "setInputFromSavedData" ],
  "org.apache.hadoop.fs.FilterFs:isValidName(java.lang.String)" : [ "isValidName" ],
  "org.apache.hadoop.fs.permission.FsPermission:<init>(java.lang.String)" : [ "<init>", "getPermission" ],
  "org.apache.hadoop.fs.store.DataBlocks$DataBlock:close()" : [ "enterClosedState", "innerClose" ],
  "org.apache.hadoop.fs.Options$HandleOpt$Data:<init>(boolean)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand:printXAttr(java.lang.String,byte[])" : [ "encodeValue" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:getFileLinkStatus(org.apache.hadoop.fs.Path)" : [ "getFileLinkStatusInternal", "isSymlink", "qualifySymlinkTarget", "getUri", "getPath", "getSymlink", "setSymlink" ],
  "org.apache.hadoop.util.KMSUtil:createKeyProviderFromUri(org.apache.hadoop.conf.Configuration,java.net.URI)" : [ "get", "isTransient" ],
  "org.apache.hadoop.io.WritableUtils:readEnum(java.io.DataInput,java.lang.Class)" : [ "readString" ],
  "org.apache.hadoop.metrics2.sink.GraphiteSink$Graphite:flush()" : [ "isConnected" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtobufRpcEngineCallbackImpl:error(java.lang.Throwable)" : [ "now", "setDeferredError" ],
  "org.apache.hadoop.fs.FileSystem$Cache$Key:hashCode()" : [ "hashCode" ],
  "org.apache.hadoop.fs.Path:toString()" : [ "hasWindowsDrive" ],
  "org.apache.hadoop.security.KDiag:<init>(org.apache.hadoop.conf.Configuration,java.io.PrintWriter,java.io.File,java.lang.String,long,boolean)" : [ "<init>" ],
  "org.apache.hadoop.ha.FailoverController:preFailoverChecks(org.apache.hadoop.ha.HAServiceTarget,org.apache.hadoop.ha.HAServiceTarget,boolean)" : [ "<init>", "getProxy", "getState", "isReadyToBecomeActive", "getNotReadyReason", "monitorHealth", "createReqInfo" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:checkToken(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier)" : [ "<init>", "getTokenInfo", "getRealUser", "formatTokenId", "now", "getRenewDate", "formatTime" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:getRpcSlowCalls()" : [ "value" ],
  "org.apache.hadoop.crypto.key.kms.ValueQueue:readLock(java.lang.String)" : [ "getLock" ],
  "org.apache.hadoop.io.Text:append(byte[],int,int)" : [ "ensureCapacity" ],
  "org.apache.hadoop.io.erasurecode.coder.ErasureEncoder:<init>(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>", "getNumDataUnits", "getNumParityUnits" ],
  "org.apache.hadoop.fs.impl.WeakReferenceThreadMap:setForCurrentThread(java.lang.Object)" : [ "currentThreadId" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:newRate(java.lang.String)" : [ "newRate" ],
  "org.apache.hadoop.crypto.OpensslCtrCryptoCodec:calculateIV(byte[],long,byte[],int)" : [ "checkArgument" ],
  "org.apache.hadoop.ipc.Server:getPriorityLevel(org.apache.hadoop.ipc.Schedulable)" : [ "getPriorityLevel" ],
  "org.apache.hadoop.fs.FileContext$Util:globStatus(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.PathFilter)" : [ "<init>", "glob" ],
  "org.apache.hadoop.metrics2.impl.MetricsRecordImpl:toString()" : [ "toString" ],
  "org.apache.hadoop.io.MapFile$Reader:comparator(org.apache.hadoop.io.WritableComparator)" : [ "<init>" ],
  "org.apache.hadoop.fs.MD5MD5CRC32CastagnoliFileChecksum:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.FilterFs:setReplication(org.apache.hadoop.fs.Path,short)" : [ "checkPath" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.util.GaloisField:gaussianElimination(int[][])" : [ "divide", "add", "multiply" ],
  "org.apache.hadoop.fs.FileStatus:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:setTimes(org.apache.hadoop.fs.Path,long,long)" : [ "setTimes", "fullPath" ],
  "org.apache.hadoop.security.token.Token$TrivialRenewer:handleKind(org.apache.hadoop.io.Text)" : [ "equals", "getKind" ],
  "org.apache.hadoop.net.DNS:getDefaultHost(java.lang.String,java.lang.String)" : [ "getDefaultHost" ],
  "org.apache.hadoop.fs.FilterFileSystem:getFileChecksum(org.apache.hadoop.fs.Path,long)" : [ "getFileChecksum" ],
  "org.apache.hadoop.io.SequenceFile$Writer:compression(org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec)" : [ "<init>" ],
  "org.apache.hadoop.fs.FilterFileSystem:getFileLinkStatus(org.apache.hadoop.fs.Path)" : [ "getFileLinkStatus" ],
  "org.apache.hadoop.io.file.tfile.TFile$TFileIndex:<init>(int,java.io.DataInput,org.apache.hadoop.io.file.tfile.CompareUtils$BytesComparator)" : [ "<init>", "readVInt", "buffer", "entries" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:listXAttrs(org.apache.hadoop.fs.Path)" : [ "listXAttrs", "resolve", "getUriPath" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:setAcl(org.apache.hadoop.fs.Path,java.util.List)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.util.ReflectionUtils:cloneWritableInto(org.apache.hadoop.io.Writable,org.apache.hadoop.io.Writable)" : [ "reset", "moveData" ],
  "org.apache.hadoop.fs.FileSystem:copyToLocalFile(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "copyToLocalFile" ],
  "org.apache.hadoop.util.LightWeightGSet:put(java.lang.Object)" : [ "<init>", "getIndex", "remove" ],
  "org.apache.hadoop.io.compress.zlib.ZlibCompressor:setInput(byte[],int,int)" : [ "setInputFromSavedData" ],
  "org.apache.hadoop.metrics2.lib.MutableStat:toString()" : [ "toString", "lastStat" ],
  "org.apache.hadoop.ipc.ProtocolSignature:getSigFingerprint(java.lang.Class,long)" : [ "<init>", "getProtocolName", "getFingerprints", "getFingerprint" ],
  "org.apache.hadoop.security.KDiag:endln()" : [ "println" ],
  "org.apache.hadoop.fs.ChecksumFs$ChecksumFSOutputSummer:<init>(org.apache.hadoop.fs.ChecksumFs,org.apache.hadoop.fs.Path,java.util.EnumSet,org.apache.hadoop.fs.permission.FsPermission,int,short,long,org.apache.hadoop.util.Progressable,org.apache.hadoop.fs.Options$ChecksumOpt,boolean)" : [ "<init>", "newDataChecksum", "getBytesPerSum", "getRawFs", "getChecksumFile" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider$EncryptedQueueRefiller:fillQueueForKey(java.lang.String,java.util.Queue,int)" : [ "checkNotNull", "parseJSONEncKeyVersions" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:readOnlyMountTable(java.lang.String,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.security.authorize.AccessControlList:getAclString()" : [ "getUsersString", "getGroupsString" ],
  "org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator:verifyCanMlock()" : [ "isAvailable" ],
  "org.apache.hadoop.fs.shell.CommandFormat$NotEnoughArgumentsException:<init>(int,int)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ConfigUtil:getHomeDirValue(org.apache.hadoop.conf.Configuration)" : [ "getHomeDirValue", "getDefaultMountTableName" ],
  "org.apache.hadoop.io.MD5Hash:<init>(java.lang.String)" : [ "setDigest" ],
  "org.apache.hadoop.util.ChunkedArrayList:<init>(int,int)" : [ "checkArgument", "newArrayList" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedIO:bulkDelete_pageSize(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)" : [ "checkAvailable", "extractIOEs" ],
  "org.apache.hadoop.io.erasurecode.coder.RSErasureEncoder:release()" : [ "release" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:readOnlyMountTable(java.lang.String,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.permission.FsCreateModes:<init>(org.apache.hadoop.fs.permission.FsPermission,org.apache.hadoop.fs.permission.FsPermission)" : [ "<init>", "getUnmasked" ],
  "org.apache.hadoop.io.file.tfile.TFile$TFileMeta:<init>(java.io.DataInput)" : [ "<init>", "compatibleWith", "readVLong", "readString", "makeComparator" ],
  "org.apache.hadoop.util.CloseableReferenceCount:unreference()" : [ "checkState" ],
  "org.apache.hadoop.ipc.CallQueueManager:<init>(java.lang.Class,java.lang.Class,boolean,int,java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "parseNumLevels", "createScheduler", "parseCapacityWeights", "getServerFailOverEnable", "createCallQueueInstance" ],
  "org.apache.hadoop.security.token.Token:<init>(byte[],byte[],org.apache.hadoop.io.Text,org.apache.hadoop.io.Text)" : [ "<init>" ],
  "org.apache.hadoop.ha.ActiveStandbyElector$WatcherWithClientRef:setZooKeeperRef(org.apache.zookeeper.ZooKeeper)" : [ "checkState" ],
  "org.apache.hadoop.ipc.Server:setupResponseOldVersionFatal(java.io.ByteArrayOutputStream,org.apache.hadoop.ipc.Server$RpcCall,org.apache.hadoop.io.Writable,java.lang.String,java.lang.String)" : [ "writeString", "setResponse" ],
  "org.apache.hadoop.fs.shell.XAttrCommands:registerCommands(org.apache.hadoop.fs.shell.CommandFactory)" : [ "addClass" ],
  "org.apache.hadoop.fs.shell.find.Find:recursePath(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "isStop", "getOptions", "getMaxDepth", "isSymlink", "isFollowLink", "getSymlink", "toString", "isAncestor", "getErr", "isDirectory" ],
  "org.apache.hadoop.io.MapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,java.lang.Class,java.lang.Class)" : [ "<init>", "keyClass", "valueClass" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:shutdown()" : [ "instance" ],
  "org.apache.hadoop.io.MapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.hadoop.io.SequenceFile$Writer$Option[])" : [ "<init>", "getInt", "getValue", "getKeyClass", "get", "newKey", "getFileSystem", "mkdirs", "prependOptions", "file", "keyClass", "createWriter", "valueClass", "compression" ],
  "org.apache.hadoop.ha.FailoverController:getRpcTimeoutToNewActive(org.apache.hadoop.conf.Configuration)" : [ "getInt" ],
  "org.apache.hadoop.conf.ConfigurationWithLogging:get(java.lang.String,java.lang.String)" : [ "get", "redact" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:renameInternal(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "fullPath" ],
  "org.apache.hadoop.fs.Path:initialize(java.lang.String,java.lang.String,java.lang.String,java.lang.String)" : [ "normalizePath" ],
  "org.apache.hadoop.fs.FsServerDefaults:<init>(long,int,int,short,int,boolean,long,org.apache.hadoop.util.DataChecksum$Type,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.ipc.metrics.DecayRpcSchedulerDetailedMetrics:addProcessingTime(int,long)" : [ "add" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.DummyRawErasureCoderFactory:createDecoder(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.util.PureJavaCrc32C:<init>()" : [ "reset" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyOutputStream:flush()" : [ "osException", "mayThrow" ],
  "org.apache.hadoop.conf.ReconfigurableBase:startReconfigurationTask()" : [ "<init>", "now" ],
  "org.apache.hadoop.security.token.delegation.DelegationTokenLoadingCache:isEmpty()" : [ "size" ],
  "org.apache.hadoop.http.HttpServer2:bindForPortRange(org.eclipse.jetty.server.ServerConnector,int)" : [ "bindListener", "constructBindException", "iterator" ],
  "org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream:hasCapability(java.lang.String)" : [ "isProbeForSyncable" ],
  "org.apache.hadoop.util.SysInfoLinux:readProcDisksInfoFile()" : [ "readDiskBlockInformation" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:createScannerByKey(org.apache.hadoop.io.file.tfile.RawComparable,org.apache.hadoop.io.file.tfile.RawComparable)" : [ "<init>", "compareKeys" ],
  "org.apache.hadoop.util.ConfigurationHelper:parseEnumSet(java.lang.String,java.lang.String,java.lang.Class,boolean)" : [ "mapEnumNamesToValues", "getTrimmedStringCollection", "checkArgument" ],
  "org.apache.hadoop.io.file.tfile.BCFile$DataIndex:<init>(java.io.DataInput)" : [ "<init>", "getCompressionAlgorithmByName", "readString", "readVInt" ],
  "org.apache.hadoop.security.alias.KeyStoreProvider:getOutputStreamForKeystore()" : [ "create" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:configureConnection(java.net.HttpURLConnection)" : [ "createSSLSocketFactory", "getHostnameVerifier" ],
  "org.apache.hadoop.io.compress.GzipCodec:createOutputStream(java.io.OutputStream)" : [ "createOutputStreamWithCodecPool" ],
  "org.apache.hadoop.metrics2.lib.MutableQuantiles:<init>(java.lang.String,java.lang.String,java.lang.String,java.lang.String,int)" : [ "<init>", "setInterval", "setNumInfo", "info", "getQuantiles", "setQuantileInfos", "setQuantiles", "setEstimator" ],
  "org.apache.hadoop.fs.permission.FsPermission:<init>(org.apache.hadoop.fs.permission.FsAction,org.apache.hadoop.fs.permission.FsAction,org.apache.hadoop.fs.permission.FsAction)" : [ "<init>" ],
  "org.apache.hadoop.net.NetworkTopology:sortByDistanceUsingNetworkLocation(org.apache.hadoop.net.Node,org.apache.hadoop.net.Node[],int,java.util.function.Consumer)" : [ "sortByDistance" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine:getClient(org.apache.hadoop.conf.Configuration)" : [ "getClient" ],
  "org.apache.hadoop.http.HttpServer2:defineFilter(org.eclipse.jetty.servlet.ServletContextHandler,java.lang.String,java.lang.String,java.util.Map,java.lang.String[])" : [ "defineFilter", "getFilterHolder", "getFilterMapping" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.find.Print:registerExpression(org.apache.hadoop.fs.shell.find.ExpressionFactory)" : [ "addClass" ],
  "org.apache.hadoop.fs.FilterFileSystem:getInitialWorkingDirectory()" : [ "getInitialWorkingDirectory" ],
  "org.apache.hadoop.util.QuickSort:sort(org.apache.hadoop.util.IndexedSortable,int,int)" : [ "sort" ],
  "org.apache.hadoop.security.ShellBasedUnixGroupsMapping:setConf(org.apache.hadoop.conf.Configuration)" : [ "setConf", "getTimeDuration" ],
  "org.apache.hadoop.fs.ChecksumFileSystem:hasPathCapability(org.apache.hadoop.fs.Path,java.lang.String)" : [ "hasPathCapability", "validatePathCapabilityArgs" ],
  "org.apache.hadoop.fs.FileSystem:getLength(org.apache.hadoop.fs.Path)" : [ "getLen" ],
  "org.apache.hadoop.io.erasurecode.coder.HHXORErasureDecodingStep:performCoding(java.nio.ByteBuffer[],java.nio.ByteBuffer[])" : [ "getNumDataUnits", "getNumParityUnits", "findFirstValidInput", "doDecodeSingle", "doDecodeMultiAndParity" ],
  "org.apache.hadoop.security.Credentials:writeTokenStorageFile(org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration,org.apache.hadoop.security.Credentials$SerializedFormat)" : [ "getFileSystem", "create", "writeTokenStorageToStream", "close" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.util.RSUtil:genCauchyMatrix(byte[],int,int)" : [ "gfInv" ],
  "org.apache.hadoop.io.MapFile:delete(org.apache.hadoop.fs.FileSystem,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.util.functional.RemoteIterators$WrappingRemoteIterator:close()" : [ "close" ],
  "org.apache.hadoop.ha.HAAdmin:runCmd(java.lang.String[])" : [ "checkParameterValidity", "addTransitionToActiveCliOpts", "parseOpts", "confirmForceManual", "transitionToActive", "transitionToStandby", "getServiceState", "getAllServiceState", "checkHealth", "help" ],
  "org.apache.hadoop.io.SequenceFile$Metadata:readFields(java.io.DataInput)" : [ "<init>", "readFields" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:isIOStatisticsSnapshot(java.io.Serializable)" : [ "ioStatisticsAvailable", "invoke" ],
  "org.apache.hadoop.fs.AbstractFileSystem:getCanonicalServiceName()" : [ "buildDTServiceName", "getUri" ],
  "org.apache.hadoop.metrics2.source.JvmMetrics:registerIfNeeded()" : [ "instance", "description" ],
  "org.apache.hadoop.ipc.FairCallQueue:<init>(int,int,java.lang.String,boolean,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getDefaultQueueCapacityWeights" ],
  "org.apache.hadoop.fs.FilterFs:removeAclEntries(org.apache.hadoop.fs.Path,java.util.List)" : [ "removeAclEntries" ],
  "org.apache.hadoop.fs.impl.prefetch.EmptyPrefetchingStatistics:prefetchOperationStarted()" : [ "stubDurationTracker" ],
  "org.apache.hadoop.security.SaslOutputStream:close()" : [ "disposeSasl" ],
  "org.apache.hadoop.ipc.Server:channelWrite(java.nio.channels.WritableByteChannel,java.nio.ByteBuffer)" : [ "channelIO", "incrSentBytes" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getDefaultReplication()" : [ "<init>" ],
  "org.apache.hadoop.ipc.RetryCache:newEntry(long,byte[],int)" : [ "<init>" ],
  "org.apache.hadoop.fs.http.AbstractHttpFileSystem:initialize(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "initialize" ],
  "org.apache.hadoop.fs.statistics.MeanStatistic:copy()" : [ "<init>" ],
  "org.apache.hadoop.util.concurrent.AsyncGetFuture:get()" : [ "callAsyncGet" ],
  "org.apache.hadoop.io.compress.DecompressorStream:skip(long)" : [ "checkStream", "read" ],
  "org.apache.hadoop.ipc.Client$Connection:sendRpcRequest(org.apache.hadoop.ipc.Client$Call)" : [ "<init>", "makeRpcRequestHeader", "wrap" ],
  "org.apache.hadoop.security.token.TokenIdentifier:getBytes()" : [ "<init>", "getData", "getLength" ],
  "org.apache.hadoop.ipc.RemoteException:unwrapRemoteException()" : [ "getClassName", "instantiateException" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider:<init>(org.apache.hadoop.crypto.key.JavaKeyStoreProvider)" : [ "<init>" ],
  "org.apache.hadoop.fs.HarFileSystem$HarMetaData:parseMetaData()" : [ "<init>", "open", "getModificationTime", "getConf", "readLine", "toString", "getLen", "clear", "cleanupWithLogger", "addPartFileStatuses", "getParent", "seek" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedIO:byteBufferPositionedReadable_available()" : [ "available" ],
  "org.apache.hadoop.crypto.CryptoInputStream:read(java.nio.ByteBuffer)" : [ "read", "checkStream", "decrypt" ],
  "org.apache.hadoop.util.LightWeightGSet:contains(java.lang.Object)" : [ "get" ],
  "org.apache.hadoop.io.compress.Lz4Codec:createOutputStream(java.io.OutputStream,org.apache.hadoop.io.compress.Compressor)" : [ "<init>", "getInt" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:selectDelegationToken(org.apache.hadoop.security.Credentials)" : [ "selectDelegationToken" ],
  "org.apache.hadoop.fs.DU:<init>(java.io.File,long,long,long)" : [ "<init>" ],
  "org.apache.hadoop.security.authorize.AccessControlList:<init>(java.lang.String,java.lang.String)" : [ "<init>", "buildACL", "getUserToGroupsMappingService" ],
  "org.apache.hadoop.fs.LocalFileSystemPathHandle:verify(org.apache.hadoop.fs.FileStatus)" : [ "<init>", "getModificationTime" ],
  "org.apache.hadoop.http.HttpServer2:isInstrumentationAccessAllowed(javax.servlet.ServletContext,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)" : [ "getBoolean", "hasAdministratorAccess" ],
  "org.apache.hadoop.crypto.key.kms.ValueQueue:getAtMost(java.lang.String,int)" : [ "readLock", "readUnlock", "submitRefillTask" ],
  "org.apache.hadoop.security.authorize.AccessControlList:readFields(java.io.DataInput)" : [ "readString", "buildACL" ],
  "org.apache.hadoop.io.WritableComparator:newKey()" : [ "newInstance" ],
  "org.apache.hadoop.conf.Configuration:getPassword(java.lang.String)" : [ "getPasswordFromCredentialProviders", "getPasswordFromConfig" ],
  "org.apache.hadoop.util.Shell:getSetOwnerCommand(java.lang.String)" : [ "getWinUtilsPath" ],
  "org.apache.hadoop.security.UserGroupInformation:getNextTgtRenewalTime(long,long,org.apache.hadoop.io.retry.RetryPolicy)" : [ "value" ],
  "org.apache.hadoop.conf.Configuration:getValByRegex(java.lang.String)" : [ "getProps" ],
  "org.apache.hadoop.conf.ReconfigurationServlet:doPost(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)" : [ "getReconfigurable", "printHeader", "applyChanges", "stringifyException", "printFooter" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyStatus:equals(java.lang.Object)" : [ "equals" ],
  "org.apache.hadoop.util.HostsFileReader:lazyRefresh(java.lang.String,java.lang.String)" : [ "refreshInternal" ],
  "org.apache.hadoop.metrics2.impl.MetricsSourceAdapter:getAttributes(java.lang.String[])" : [ "updateJmxCache" ],
  "org.apache.hadoop.io.IOUtils:wrapException(java.lang.String,java.lang.String,java.io.IOException)" : [ "<init>", "wrapWithMessage" ],
  "org.apache.hadoop.ipc.RPC:getProxy(java.lang.Class,long,java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory)" : [ "getProxy", "getProtocolProxy" ],
  "org.apache.hadoop.security.UserGroupInformation:setLogin(javax.security.auth.login.LoginContext)" : [ "setLogin" ],
  "org.apache.hadoop.util.HostsFileReader:<init>(java.lang.String,java.lang.String)" : [ "<init>", "refresh" ],
  "org.apache.hadoop.metrics2.source.JvmMetrics:reattach(org.apache.hadoop.metrics2.MetricsSystem,org.apache.hadoop.metrics2.source.JvmMetrics)" : [ "description" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:checkMetricName(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:listLocatedStatus(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.PathFilter)" : [ "listLocatedStatus", "resolve", "getUriPath", "isInternalDir" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:setVerifyChecksum(boolean)" : [ "readOnlyMountTable" ],
  "org.apache.hadoop.io.retry.RetryPolicies:getWrappedRetriableException(java.lang.Exception)" : [ "unwrapRemoteException" ],
  "org.apache.hadoop.security.WhitelistBasedResolver:setConf(org.apache.hadoop.conf.Configuration)" : [ "<init>", "setConf", "get", "getBoolean", "getLong", "getSaslProperties" ],
  "org.apache.hadoop.io.compress.zstd.ZStandardCompressor:setInput(byte[],int,int)" : [ "setInputFromSavedData" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:getComparatorName()" : [ "getComparatorString" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:open(org.apache.hadoop.fs.PathHandle,int)" : [ "<init>", "verify", "getFileStatus", "getPath" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Factory:getBzip2Decompressor(org.apache.hadoop.conf.Configuration)" : [ "<init>", "isNativeBzip2Loaded" ],
  "org.apache.hadoop.util.BlockingThreadPoolExecutorService:<init>(int,java.util.concurrent.ThreadPoolExecutor)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:publishMetrics(org.apache.hadoop.metrics2.impl.MetricsBuffer,boolean)" : [ "monotonicNow", "putMetricsImmediate", "putMetrics", "add", "incr" ],
  "org.apache.hadoop.net.NetworkTopology:isOnSameRack(org.apache.hadoop.net.Node,org.apache.hadoop.net.Node)" : [ "isSameParents" ],
  "org.apache.hadoop.fs.Stat:parseExecResult(java.io.BufferedReader)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileStatus:equals(java.lang.Object)" : [ "equals", "getPath" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockOperations:getDurationInfo(java.lang.StringBuilder)" : [ "duration", "append" ],
  "org.apache.hadoop.conf.Configuration:getLong(java.lang.String,long)" : [ "getTrimmed", "getHexDigits" ],
  "org.apache.hadoop.fs.shell.AclCommands$GetfaclCommand:processOptions(java.util.LinkedList)" : [ "<init>", "parse", "getOpt" ],
  "org.apache.hadoop.io.SequenceFile$Sorter$SegmentDescriptor:cleanup()" : [ "close" ],
  "org.apache.hadoop.io.erasurecode.codec.HHXORErasureCodec:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.io.erasurecode.ErasureCodecOptions)" : [ "<init>" ],
  "org.apache.hadoop.io.SetFile$Reader:seek(org.apache.hadoop.io.WritableComparable)" : [ "seek" ],
  "org.apache.hadoop.fs.impl.FlagSet:pathCapabilities()" : [ "hasCapability" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyStatus:isFile()" : [ "isFile" ],
  "org.apache.hadoop.util.Shell:<init>(long)" : [ "<init>" ],
  "org.apache.hadoop.io.SequenceFile$Sorter$SortPass:grow()" : [ "grow" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:getEnclosingRoot(org.apache.hadoop.fs.Path)" : [ "<init>", "getEnclosingRoot", "resolve", "toString", "depth" ],
  "org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream:read(long,byte[],int,int)" : [ "<init>", "incrementBytesRead", "incrementCounter" ],
  "org.apache.hadoop.fs.ChecksumFs:listStatus(org.apache.hadoop.fs.Path)" : [ "isChecksumFile", "getPath" ],
  "org.apache.hadoop.ipc.Server$Call:getHostAddress()" : [ "getHostInetAddress" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:truncate(org.apache.hadoop.fs.Path,long)" : [ "truncate", "fullPath" ],
  "org.apache.hadoop.fs.HarFileSystem:listStatus(org.apache.hadoop.fs.Path)" : [ "makeQualified", "getPathInHar", "isDir", "fileStatusesInIndex", "toFileStatus" ],
  "org.apache.hadoop.util.bloom.BloomFilter:readFields(java.io.DataInput)" : [ "readFields", "getNBytes" ],
  "org.apache.hadoop.util.CacheableIPList:reset()" : [ "reload", "updateCacheExpiryTime" ],
  "org.apache.hadoop.net.SocketInputStream:read(byte[],int,int)" : [ "read" ],
  "org.apache.hadoop.fs.FSDataInputStream:read(org.apache.hadoop.io.ByteBufferPool,int)" : [ "read" ],
  "org.apache.hadoop.fs.FSDataOutputStreamBuilder:append()" : [ "getThisBuilder" ],
  "org.apache.hadoop.util.functional.FutureIO:awaitFuture(java.util.concurrent.Future)" : [ "raiseInnerCause" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenManager:init()" : [ "startThreads" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:newRate(java.lang.String,java.lang.String,boolean)" : [ "newRate" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:removeDefaultAcl(org.apache.hadoop.fs.Path)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink:loadGangliaConf(org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink$GangliaConfType)" : [ "setUnits", "setDmax", "setTmax", "setSlope" ],
  "org.apache.hadoop.crypto.OpensslSm4CtrCryptoCodec:<init>()" : [ "getLoadingFailureReason", "isSupported" ],
  "org.apache.hadoop.util.bloom.HashFunction:<init>(int,int,int)" : [ "getInstance" ],
  "org.apache.hadoop.fs.shell.CopyCommands:registerCommands(org.apache.hadoop.fs.shell.CommandFactory)" : [ "addClass" ],
  "org.apache.hadoop.metrics2.impl.MetricsRecordBuilderImpl:<init>(org.apache.hadoop.metrics2.MetricsCollector,org.apache.hadoop.metrics2.MetricsInfo,org.apache.hadoop.metrics2.MetricsFilter,org.apache.hadoop.metrics2.MetricsFilter,boolean)" : [ "now", "newArrayList" ],
  "org.apache.hadoop.io.AbstractMapWritable:addToMap(java.lang.Class)" : [ "addToMap" ],
  "org.apache.hadoop.io.compress.CompressorStream:<init>(java.io.OutputStream)" : [ "<init>" ],
  "org.apache.hadoop.crypto.OpensslCtrCryptoCodec$OpensslCtrCipher:init(byte[],byte[])" : [ "init", "checkNotNull" ],
  "org.apache.hadoop.fs.shell.MoveCommands$Rename:processOptions(java.util.LinkedList)" : [ "<init>", "parse" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL:cancelDelegationToken(java.net.URL,org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL$Token,java.lang.String)" : [ "checkNotNull" ],
  "org.apache.hadoop.fs.shell.FsCommand:registerCommands(org.apache.hadoop.fs.shell.CommandFactory)" : [ "registerCommands" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockData:getBlockNumber(long)" : [ "throwIfInvalidOffset" ],
  "org.apache.hadoop.fs.FsServerDefaults:write(java.io.DataOutput)" : [ "writeEnum" ],
  "org.apache.hadoop.fs.FilterFileSystem:create(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,java.util.EnumSet,int,short,long,org.apache.hadoop.util.Progressable,org.apache.hadoop.fs.Options$ChecksumOpt)" : [ "create" ],
  "org.apache.hadoop.io.SequenceFile$Reader$BufferSizeOption:<init>(int)" : [ "<init>" ],
  "org.apache.hadoop.security.token.Token$PrivateToken:equals(java.lang.Object)" : [ "equals" ],
  "org.apache.hadoop.fs.permission.FsPermission:applyUMask(org.apache.hadoop.fs.permission.FsPermission)" : [ "<init>", "and", "not" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.CoderUtil:resetOutputBuffers(java.nio.ByteBuffer[],int)" : [ "resetBuffer" ],
  "org.apache.hadoop.ha.HAAdmin:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:setReplication(org.apache.hadoop.fs.Path,short)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.util.StringUtils:split(java.lang.String,char,char)" : [ "findNext" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:counters()" : [ "getInnerStatistics" ],
  "org.apache.hadoop.security.UserGroupInformation:createUserForTesting(java.lang.String,java.lang.String[])" : [ "ensureInitialized", "createRemoteUser", "getShortUserName" ],
  "org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "getXAttrs", "printXAttr", "getXAttr" ],
  "org.apache.hadoop.io.compress.ZStandardCodec:getDecompressorType()" : [ "checkNativeCodeLoaded" ],
  "org.apache.hadoop.fs.CompositeCrcFileChecksum:getChecksumOpt()" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.FileRangeImpl:toString()" : [ "getOffset", "getLength", "getReference" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RSRawDecoder:doDecode(org.apache.hadoop.io.erasurecode.rawcoder.ByteArrayDecodingState)" : [ "resetOutputBuffers", "prepareDecoding", "encodeData" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.AbstractNativeRawEncoder:doEncode(org.apache.hadoop.io.erasurecode.rawcoder.ByteArrayEncodingState)" : [ "doEncode", "convertToByteBufferState" ],
  "org.apache.hadoop.crypto.CryptoOutputStream:<init>(java.io.OutputStream,org.apache.hadoop.crypto.CryptoCodec,byte[],byte[],long,boolean)" : [ "<init>", "getBufferSize" ],
  "org.apache.hadoop.security.alias.CredentialShell$Command:warnIfTransientProvider()" : [ "isTransient" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:<init>(java.net.URI,org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,java.lang.String,boolean)" : [ "<init>", "getDefaultPortIfDefined", "initialize" ],
  "org.apache.hadoop.io.wrappedio.WrappedStatistics:iostatisticsSnapshot_save(java.io.Serializable,org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,boolean)" : [ "applyToIOStatisticsSnapshot" ],
  "org.apache.hadoop.util.LineReader:readCustomLine(org.apache.hadoop.io.Text,int,int)" : [ "clear", "fillBuffer", "append", "unsetNeedAdditionalRecordAfterSplit" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:addRpcProcessingTime(long)" : [ "add" ],
  "org.apache.hadoop.metrics2.impl.MetricsConfigException:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.Lz4Codec:createDecompressor()" : [ "<init>", "getInt" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:configureSources()" : [ "getFilter", "getInstanceConfigs", "registerSystemSource" ],
  "org.apache.hadoop.fs.AbstractFileSystem:getHomeDirectory()" : [ "<init>", "getCurrentUser", "getShortUserName", "makeQualified", "getUri" ],
  "org.apache.hadoop.io.ElasticByteBufferPool:getBuffer(boolean,int)" : [ "<init>", "getBufferTree" ],
  "org.apache.hadoop.log.LogLevel$CLI:connect(java.net.URL)" : [ "<init>", "init", "createSSLSocketFactory" ],
  "org.apache.hadoop.ipc.RPC:getProtocolProxy(java.lang.Class,long,org.apache.hadoop.ipc.Client$ConnectionId,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory,org.apache.hadoop.ipc.AlignmentContext)" : [ "isSecurityEnabled", "init", "getProtocolEngine" ],
  "org.apache.hadoop.metrics2.sink.PrometheusMetricsSink:putMetrics(org.apache.hadoop.metrics2.MetricsRecord)" : [ "prometheusName", "name" ],
  "org.apache.hadoop.security.authorize.ProxyServers:isProxyServer(java.lang.String)" : [ "refresh" ],
  "org.apache.hadoop.security.http.CrossOriginFilter:initializeAllowedHeaders(javax.servlet.FilterConfig)" : [ "getAllowedHeadersHeader" ],
  "org.apache.hadoop.util.StringInterner:internStringsInArray(java.lang.String[])" : [ "weakIntern" ],
  "org.apache.hadoop.io.serializer.WritableSerialization:getDeserializer(java.lang.Class)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.security.alias.UserProvider:deleteCredentialEntry(java.lang.String)" : [ "<init>", "getSecretKey", "removeSecretKey" ],
  "org.apache.hadoop.metrics2.lib.Interns:tag(java.lang.String,java.lang.String,java.lang.String)" : [ "add", "info" ],
  "org.apache.hadoop.security.token.Token:encodeWritable(org.apache.hadoop.io.Writable)" : [ "<init>", "getLength", "getData" ],
  "org.apache.hadoop.fs.CachingGetSpaceUsed:init()" : [ "initRefreshThread" ],
  "org.apache.hadoop.crypto.JceCtrCryptoCodec$JceCtrCipher:encrypt(java.nio.ByteBuffer,java.nio.ByteBuffer)" : [ "process" ],
  "org.apache.hadoop.fs.statistics.DurationStatisticSummary:fetchSuccessSummary(org.apache.hadoop.fs.statistics.IOStatistics,java.lang.String)" : [ "fetchDurationSummary" ],
  "org.apache.hadoop.security.UserGroupInformation:newLoginContext(java.lang.String,javax.security.auth.Subject,org.apache.hadoop.security.UserGroupInformation$HadoopConfiguration)" : [ "<init>" ],
  "org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext$PathIterator:advance()" : [ "<init>", "exists" ],
  "org.apache.hadoop.conf.Configuration:setBoolean(java.lang.String,boolean)" : [ "set" ],
  "org.apache.hadoop.io.compress.BZip2Codec$BZip2CompressionOutputStream:<init>(java.io.OutputStream)" : [ "<init>" ],
  "org.apache.hadoop.fs.http.AbstractHttpFileSystem:open(org.apache.hadoop.fs.Path,int)" : [ "<init>", "toUri" ],
  "org.apache.hadoop.util.HostsFileReader:<init>(java.lang.String,java.io.InputStream,java.lang.String,java.io.InputStream)" : [ "<init>", "refresh" ],
  "org.apache.hadoop.util.functional.LazyAtomicReference:get()" : [ "uncheckIOExceptions", "eval" ],
  "org.apache.hadoop.io.erasurecode.coder.util.HHUtil:findFirstValidInput(java.lang.Object[])" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:getFileBlockLocations(org.apache.hadoop.fs.Path,long,long)" : [ "<init>", "equals", "getRootFallbackLink", "getTargetFileSystem", "getPathWithoutSchemeAndAuthority", "getName", "checkPathIsSlash" ],
  "org.apache.hadoop.fs.shell.Command:processRawArguments(java.util.LinkedList)" : [ "processArguments", "expandArguments" ],
  "org.apache.hadoop.security.authorize.AuthorizationException:printStackTrace()" : [ "printStackTrace" ],
  "org.apache.hadoop.metrics2.impl.SinkQueue:consumeAll(org.apache.hadoop.metrics2.impl.SinkQueue$Consumer)" : [ "waitForData", "size", "front", "_dequeue", "clearConsumerLock" ],
  "org.apache.hadoop.http.HttpServer2$Builder:loadSSLConfiguration()" : [ "getBoolean", "getTrimmed", "getPasswordString", "get" ],
  "org.apache.hadoop.io.retry.RetryInvocationHandler:invokeMethod(java.lang.reflect.Method,java.lang.Object[])" : [ "getProxy" ],
  "org.apache.hadoop.fs.shell.Tail:processOptions(java.util.LinkedList)" : [ "<init>", "addOptionWithValue", "parse", "getOpt", "getOptValue" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:syncTokenOwnerStats()" : [ "addTokenForOwnerStats" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:createScannerByKey(byte[],byte[])" : [ "<init>", "createScannerByKey" ],
  "org.apache.hadoop.fs.FileUtil:permissionsFromMode(int)" : [ "addPermissions" ],
  "org.apache.hadoop.io.file.tfile.Chunk$ChunkDecoder:skip(long)" : [ "checkEOF" ],
  "org.apache.hadoop.fs.shell.CommandWithDestination:getTargetPath(org.apache.hadoop.fs.shell.PathData)" : [ "isDirectory", "getPathDataForChild", "representsDirectory" ],
  "org.apache.hadoop.fs.FilterFs:open(org.apache.hadoop.fs.Path,int)" : [ "checkPath" ],
  "org.apache.hadoop.fs.shell.SnapshotCommands$DeleteSnapshot:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "isDirectory", "toString" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:open(org.apache.hadoop.fs.Path,int)" : [ "checkPathIsSlash" ],
  "org.apache.hadoop.fs.impl.AbstractFSBuilderImpl:optDouble(java.lang.String,double)" : [ "opt" ],
  "org.apache.hadoop.security.authorize.ProxyUsers:getSip()" : [ "refreshSuperUserGroupsConfiguration" ],
  "org.apache.hadoop.metrics2.lib.DefaultMetricsSystem:newSourceName(java.lang.String,boolean)" : [ "<init>", "uniqueName" ],
  "org.apache.hadoop.fs.DelegationTokenRenewer$RenewAction:hashCode()" : [ "hashCode" ],
  "org.apache.hadoop.ha.ZKFailoverController:badArg(java.lang.String)" : [ "<init>", "printUsage" ],
  "org.apache.hadoop.fs.GlobalStorageStatistics$StorageIterator:next()" : [ "getName" ],
  "org.apache.hadoop.io.MapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.io.WritableComparator,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType)" : [ "<init>", "comparator", "valueClass", "compression" ],
  "org.apache.hadoop.ha.protocolPB.HAServiceProtocolClientSideTranslatorPB:transitionToObserver(org.apache.hadoop.ha.HAServiceProtocol$StateChangeRequestInfo)" : [ "convert", "ipc" ],
  "org.apache.hadoop.io.retry.RetryPolicies:exponentialBackoffRetry(int,long,java.util.concurrent.TimeUnit)" : [ "<init>" ],
  "org.apache.hadoop.io.SequenceFile$Reader:next(org.apache.hadoop.io.Writable,org.apache.hadoop.io.Writable)" : [ "next", "getValueClass", "getCurrentValue" ],
  "org.apache.hadoop.conf.ReconfigurationUtil:parseChangedProperties(org.apache.hadoop.conf.Configuration,org.apache.hadoop.conf.Configuration)" : [ "getChangedProperties" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:addUniqueIdentityCount(org.apache.hadoop.metrics2.MetricsRecordBuilder)" : [ "info", "getUniqueIdentityCount" ],
  "org.apache.hadoop.crypto.OpensslCipher:tokenizeTransformation(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.TrashPolicyDefault:deleteCheckpoint()" : [ "deleteCheckpoint" ],
  "org.apache.hadoop.ha.protocolPB.HAServiceProtocolClientSideTranslatorPB:transitionToActive(org.apache.hadoop.ha.HAServiceProtocol$StateChangeRequestInfo)" : [ "convert", "ipc" ],
  "org.apache.hadoop.net.NetworkTopologyWithNodeGroup:getNodeForNetworkLocation(org.apache.hadoop.net.Node)" : [ "<init>" ],
  "org.apache.hadoop.io.SecureIOUtils:insecureCreateForWrite(java.io.File,int)" : [ "<init>", "setPermission" ],
  "org.apache.hadoop.io.SequenceFile$Reader:nextRawValue(org.apache.hadoop.io.SequenceFile$ValueBytes)" : [ "seekToCurrentValue", "readVInt" ],
  "org.apache.hadoop.security.token.DelegationTokenIssuer:collectDelegationTokens(org.apache.hadoop.security.token.DelegationTokenIssuer,java.lang.String,org.apache.hadoop.security.Credentials,java.util.List)" : [ "<init>", "getToken", "addToken", "getAdditionalTokenIssuers" ],
  "org.apache.hadoop.fs.store.DataBlocks$ByteArrayBlock:remainingCapacity()" : [ "dataSize" ],
  "org.apache.hadoop.io.file.tfile.Chunk$ChunkDecoder:checkEOF()" : [ "isClosed", "readLength" ],
  "org.apache.hadoop.io.ArrayPrimitiveWritable:checkPrimitive(java.lang.Class)" : [ "<init>" ],
  "org.apache.hadoop.util.Shell$ShellCommandExecutor:<init>(java.lang.String[],java.io.File,java.util.Map)" : [ "<init>" ],
  "org.apache.hadoop.util.curator.ZKCuratorManager:createRootDirRecursively(java.lang.String)" : [ "createRootDirRecursively" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkValuesEqual(long,java.lang.String,long,java.lang.String)" : [ "checkArgument" ],
  "org.apache.hadoop.fs.FilterFileSystem:primitiveMkdir(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "primitiveMkdir" ],
  "org.apache.hadoop.metrics2.lib.MutableRollingAverages$RatesRoller:<init>(org.apache.hadoop.metrics2.lib.MutableRollingAverages)" : [ "run" ],
  "org.apache.hadoop.io.compress.DefaultCodec:getCompressorType()" : [ "getZlibCompressorType" ],
  "org.apache.hadoop.util.StringUtils:getStrings(java.lang.String,java.lang.String)" : [ "getStringCollection" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:deleteSnapshot(org.apache.hadoop.fs.Path,java.lang.String)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.io.compress.snappy.SnappyDecompressor:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.FileSystem:getStatus(org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:isParentOf(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "toUri" ],
  "org.apache.hadoop.net.NetUtils:createSocketAddr(java.lang.String,int)" : [ "createSocketAddr" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:addTopNCallerSummary(org.apache.hadoop.metrics2.MetricsRecordBuilder)" : [ "getTopCallers", "getName", "info", "getValue" ],
  "org.apache.hadoop.fs.FSOutputSummer:getChecksumSize()" : [ "getChecksumSize" ],
  "org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:cancelToken(org.apache.hadoop.security.token.Token,java.lang.String)" : [ "cancelToken", "getIdentifier", "readFields", "syncLocalCacheWithZk" ],
  "org.apache.hadoop.fs.sftp.SFTPInputStream:seek(long)" : [ "checkNotClosed" ],
  "org.apache.hadoop.ipc.ExternalCall:get()" : [ "waitForCompletion" ],
  "org.apache.hadoop.io.file.tfile.TFile$TFileIndex:getLastKey()" : [ "<init>", "buffer" ],
  "org.apache.hadoop.io.retry.RetryInvocationHandler$RetryInfo:newRetryInfo(org.apache.hadoop.io.retry.RetryPolicy,java.lang.Exception,org.apache.hadoop.io.retry.RetryInvocationHandler$Counters,boolean,long)" : [ "<init>", "getExceptions" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider$KeyMetadata:readObject(java.io.ObjectInputStream)" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.KeyProviderExtension:isTransient()" : [ "isTransient" ],
  "org.apache.hadoop.fs.http.HttpFileSystem:create(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,boolean,int,short,long,org.apache.hadoop.util.Progressable)" : [ "create" ],
  "org.apache.hadoop.fs.MD5MD5CRC32FileChecksum:write(java.io.DataOutput)" : [ "write" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:listXAttrs(org.apache.hadoop.fs.Path)" : [ "listXAttrs", "fullPath" ],
  "org.apache.hadoop.log.LogThrottlingHelper:getCurrentStats(java.lang.String,int)" : [ "getStats" ],
  "org.apache.hadoop.fs.ChecksumFileSystem:getChecksumFile(org.apache.hadoop.fs.Path)" : [ "<init>", "getParent", "getName" ],
  "org.apache.hadoop.io.wrappedio.WrappedStatistics:iostatisticsContext_setThreadIOStatisticsContext(java.lang.Object)" : [ "setThreadIOStatisticsContext" ],
  "org.apache.hadoop.util.CombinedIPWhiteList:<init>(java.lang.String,java.lang.String,long)" : [ "<init>" ],
  "org.apache.hadoop.util.bloom.RetouchedBloomFilter:write(java.io.DataOutput)" : [ "write" ],
  "org.apache.hadoop.io.IOUtils:closeStream(java.io.Closeable)" : [ "cleanupWithLogger" ],
  "org.apache.hadoop.metrics2.lib.MutableStat:<init>(java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean)" : [ "<init>", "info" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:initBlock()" : [ "<init>", "bsGetInt", "bsR", "getAndMoveToFrontDecode", "initialiseCRC", "bsGetUByte", "complete" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:setWorkingDirectory(org.apache.hadoop.fs.Path)" : [ "makeAbsolute" ],
  "org.apache.hadoop.io.ElasticByteBufferPool:size(boolean)" : [ "getBufferTree" ],
  "org.apache.hadoop.util.RunJar:createClassLoader(java.io.File,java.io.File)" : [ "<init>", "useClientClassLoader", "getHadoopClasspath", "getSystemClasses", "getTrimmedStrings" ],
  "org.apache.hadoop.io.erasurecode.ECSchema:<init>(java.util.Map)" : [ "extractIntOption" ],
  "org.apache.hadoop.util.Progress:addPhase(java.lang.String,float)" : [ "addPhase", "setStatus" ],
  "org.apache.hadoop.io.AbstractMapWritable:copy(org.apache.hadoop.io.Writable)" : [ "<init>", "reset", "getData", "getLength", "readFields" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:listXAttrs(org.apache.hadoop.fs.Path)" : [ "listXAttrs" ],
  "org.apache.hadoop.fs.FileUtil:setExecutable(java.io.File,boolean)" : [ "chmod" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockData:<init>(long,int)" : [ "checkNotNegative", "checkPositiveInteger", "setState" ],
  "org.apache.hadoop.io.ArrayFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.util.Progressable)" : [ "<init>" ],
  "org.apache.hadoop.io.WritableComparator:readVInt(byte[],int)" : [ "readVLong" ],
  "org.apache.hadoop.fs.PartialListing:get()" : [ "unwrapRemoteException" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:registerSystemSource()" : [ "<init>", "makeSource", "subset", "start" ],
  "org.apache.hadoop.ipc.RetryCache$CacheEntry:<init>(byte[],int,long)" : [ "checkArgument", "getMsb", "getLsb" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Reader:getDefaultCompressionName()" : [ "getDefaultCompressionAlgorithm", "getName" ],
  "org.apache.hadoop.fs.PathIOException:getTargetPath()" : [ "<init>" ],
  "org.apache.hadoop.crypto.CryptoInputStream:decrypt(java.nio.ByteBuffer,int,int)" : [ "decrypt", "afterDecryption" ],
  "org.apache.hadoop.ipc.Client$Connection:setFallBackToSimpleAuth(java.util.concurrent.atomic.AtomicBoolean)" : [ "<init>", "isSecurityEnabled" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:becomeActive()" : [ "fenceOldActive", "writeBreadCrumbNode" ],
  "org.apache.hadoop.io.BooleanWritable:toString()" : [ "get" ],
  "org.apache.hadoop.io.UTF8:compareTo(org.apache.hadoop.io.UTF8)" : [ "compareBytes" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.ByteBufferEncodingState:<init>(org.apache.hadoop.io.erasurecode.rawcoder.RawErasureEncoder,java.nio.ByteBuffer[],java.nio.ByteBuffer[])" : [ "findFirstValidInput", "checkBuffers" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockManager:get(int)" : [ "<init>", "checkNotNegative", "getSize", "getStartOffset" ],
  "org.apache.hadoop.fs.shell.Ls:isSorted()" : [ "isOrderTime", "isOrderSize", "isOrderReverse" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:call(java.net.HttpURLConnection,java.lang.Object,int,java.lang.Class,int)" : [ "writeJson", "closeStream", "createConnection", "validateResponse" ],
  "org.apache.hadoop.util.ReadWriteDiskValidator:checkStatus(java.io.File)" : [ "<init>", "getMetric", "diskCheckFailed", "checkDir", "addWriteFileLatency", "addReadFileLatency" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:delete(org.apache.hadoop.fs.Path,boolean)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.io.SequenceFile$Metadata:<init>()" : [ "<init>" ],
  "org.apache.hadoop.security.ShellBasedIdMapping$PassThroughMap:<init>()" : [ "<init>" ],
  "org.apache.hadoop.security.token.delegation.SQLDelegationTokenSecretManager:createTokenInfo(byte[])" : [ "<init>", "readFields" ],
  "org.apache.hadoop.ha.HAAdmin:printUsage(java.io.PrintStream,java.lang.String,java.util.Map)" : [ "getUsageString" ],
  "org.apache.hadoop.util.LightWeightCache:setExpirationTime(org.apache.hadoop.util.LightWeightCache$Entry,long)" : [ "monotonicNowNanos" ],
  "org.apache.hadoop.crypto.random.OsSecureRandom:close()" : [ "cleanupWithLogger" ],
  "org.apache.hadoop.io.ObjectWritable:writeObject(java.io.DataOutput,java.lang.Object,java.lang.Class,org.apache.hadoop.conf.Configuration,boolean)" : [ "<init>", "writeString", "constructOutputStream" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getHomeDirectory()" : [ "<init>", "getHomeDirPrefixValue", "getShortUserName" ],
  "org.apache.hadoop.security.UserGroupInformation$UgiMetrics:addGetGroups(long)" : [ "add" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "pathToFile", "handleEmptyDstDirectoryOnWindows", "copy" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:serviceMain(java.lang.String[])" : [ "serviceMain" ],
  "org.apache.hadoop.fs.impl.FileSystemMultipartUploaderBuilder:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.fs.http.HttpsFileSystem:getWorkingDirectory()" : [ "getWorkingDirectory" ],
  "org.apache.hadoop.fs.shell.Head:expandArgument(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.Command:processPathArgument(org.apache.hadoop.fs.shell.PathData)" : [ "processPaths" ],
  "org.apache.hadoop.fs.viewfs.InodeTree$INodeLink:getTargetLink()" : [ "<init>" ],
  "org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:getTokenInfoFromZK(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier)" : [ "getTokenInfoFromZK" ],
  "org.apache.hadoop.fs.FsShell:printInstanceUsage(java.io.PrintStream,org.apache.hadoop.fs.shell.Command)" : [ "getUsagePrefix", "getUsage" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkWithinRange(long,java.lang.String,long,long)" : [ "checkArgument" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner:seekToEnd()" : [ "parkCursorAtEnd" ],
  "org.apache.hadoop.fs.FileSystem:getUsed(org.apache.hadoop.fs.Path)" : [ "getContentSummary", "getLength" ],
  "org.apache.hadoop.util.functional.RemoteIterators$FilteringRemoteIterator:next()" : [ "hasNext" ],
  "org.apache.hadoop.fs.FileUtil:unZip(java.io.InputStream,java.io.File)" : [ "copyBytes", "permissionsFromMode" ],
  "org.apache.hadoop.fs.ChecksumFs$ChecksumFSInputChecker:available()" : [ "available" ],
  "org.apache.hadoop.security.alias.KeyStoreProvider:getInputStreamForFile()" : [ "open" ],
  "org.apache.hadoop.fs.AbstractFileSystem:getUriPath(org.apache.hadoop.fs.Path)" : [ "<init>", "checkPath", "toUri", "isValidName" ],
  "org.apache.hadoop.fs.FilterFs:renameInternal(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,boolean)" : [ "renameInternal" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:getMetadata(java.lang.String)" : [ "doOp", "nextIdx" ],
  "org.apache.hadoop.io.Text:find(java.lang.String,int)" : [ "encode" ],
  "org.apache.hadoop.fs.shell.find.Find:getExpression(java.lang.String)" : [ "getExpression", "getExpressionFactory" ],
  "org.apache.hadoop.fs.ContentSummary$Builder:spaceConsumed(long)" : [ "spaceConsumed" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$MRNflyNode:hashCode()" : [ "hashCode" ],
  "org.apache.hadoop.util.Shell:appendScriptExtension(java.io.File,java.lang.String)" : [ "appendScriptExtension" ],
  "org.apache.hadoop.ipc.RpcWritable$Buffer:writeTo(org.apache.hadoop.ipc.ResponseBuffer)" : [ "ensureCapacity" ],
  "org.apache.hadoop.security.authorize.ServiceAuthorizationManager:refresh(org.apache.hadoop.conf.Configuration,org.apache.hadoop.security.authorize.PolicyProvider)" : [ "<init>", "addResource", "refreshWithLoadedConfiguration" ],
  "org.apache.hadoop.util.CleanerUtil:unmapHackImpl()" : [ "newBufferCleaner" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider:revertFromOld(org.apache.hadoop.fs.Path,boolean)" : [ "renameOrFail" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:getLocationByRecordNum(long)" : [ "getLocationByRecordNum", "checkTFileDataIndex" ],
  "org.apache.hadoop.fs.FilterFileSystem:setXAttr(org.apache.hadoop.fs.Path,java.lang.String,byte[],java.util.EnumSet)" : [ "setXAttr" ],
  "org.apache.hadoop.util.functional.TaskPool$Builder:suppressExceptions()" : [ "suppressExceptions" ],
  "org.apache.hadoop.fs.shell.find.Result:negate()" : [ "<init>", "isPass", "isDescend" ],
  "org.apache.hadoop.crypto.CryptoOutputStream:write(int)" : [ "write" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockManager:<init>(org.apache.hadoop.fs.impl.prefetch.BlockData)" : [ "checkNotNull" ],
  "org.apache.hadoop.fs.ChecksumFs:getSumBufferSize(int,int,org.apache.hadoop.fs.Path)" : [ "getServerDefaults", "getFileBufferSize" ],
  "org.apache.hadoop.io.SequenceFile$Sorter:merge(org.apache.hadoop.fs.Path[],boolean,org.apache.hadoop.fs.Path)" : [ "merge" ],
  "org.apache.hadoop.ipc.CallerContext$Builder:<init>(java.lang.String,java.lang.String)" : [ "isValid", "checkFieldSeparator" ],
  "org.apache.hadoop.metrics2.lib.MutableGaugeLong:<init>(org.apache.hadoop.metrics2.MetricsInfo,long)" : [ "<init>" ],
  "org.apache.hadoop.io.SequenceFile$Sorter$LinkedSegmentsDescriptor:cleanup()" : [ "cleanup", "shouldPreserveInput" ],
  "org.apache.hadoop.ipc.WritableRpcEngine$Server:<init>(java.lang.Object,org.apache.hadoop.conf.Configuration,java.lang.String,int)" : [ "<init>" ],
  "org.apache.hadoop.crypto.CryptoOutputStream:getIOStatistics()" : [ "retrieveIOStatistics" ],
  "org.apache.hadoop.fs.FileSystem:create(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "create", "setPermission" ],
  "org.apache.hadoop.ipc.ProtobufHelper:getFixedByteString(org.apache.hadoop.io.Text)" : [ "getFixedByteString" ],
  "org.apache.hadoop.io.compress.CodecPool:returnDecompressor(org.apache.hadoop.io.compress.Decompressor)" : [ "payback", "updateLeaseCount" ],
  "org.apache.hadoop.fs.viewfs.ViewFsLocatedFileStatus:hashCode()" : [ "hashCode" ],
  "org.apache.hadoop.fs.GlobExpander:expand(java.lang.String)" : [ "<init>", "expandLeftmost" ],
  "org.apache.hadoop.metrics2.lib.MutableGaugeFloat:snapshot(org.apache.hadoop.metrics2.MetricsRecordBuilder,boolean)" : [ "value" ],
  "org.apache.hadoop.security.token.delegation.SQLDelegationTokenSecretManager:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>", "getLong", "getInt", "getTimeDuration", "getTokenInfoFromSQL" ],
  "org.apache.hadoop.io.ArrayFile:<init>()" : [ "<init>" ],
  "org.apache.hadoop.crypto.CryptoStreamUtils:getBufferSize(org.apache.hadoop.conf.Configuration)" : [ "getInt" ],
  "org.apache.hadoop.fs.ContentSummary$Builder:typeConsumed(org.apache.hadoop.fs.StorageType,long)" : [ "typeConsumed" ],
  "org.apache.hadoop.io.file.tfile.Chunk$ChunkEncoder:close()" : [ "writeChunk" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:rollMasterKey()" : [ "removeExpiredKeys", "setExpiryDate", "now", "updateDelegationKey", "updateCurrentKey" ],
  "org.apache.hadoop.ipc.Server:bind(java.net.ServerSocket,java.net.InetSocketAddress,int,org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "getRange", "isEmpty", "wrapException", "iterator" ],
  "org.apache.hadoop.util.StringUtils:escapeString(java.lang.String)" : [ "escapeString" ],
  "org.apache.hadoop.fs.FilterFs:getXAttrs(org.apache.hadoop.fs.Path)" : [ "getXAttrs" ],
  "org.apache.hadoop.fs.FileUtil:write(org.apache.hadoop.fs.FileContext,org.apache.hadoop.fs.Path,java.lang.CharSequence,java.nio.charset.Charset)" : [ "create", "overwrite", "close" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:setTimes(org.apache.hadoop.fs.Path,long,long)" : [ "setTimes" ],
  "org.apache.hadoop.net.NetUtils:getOutputStream(java.net.Socket,long)" : [ "<init>" ],
  "org.apache.hadoop.io.SequenceFile:getDefaultCompressionType(org.apache.hadoop.conf.Configuration)" : [ "get" ],
  "org.apache.hadoop.fs.BlockLocation:<init>(java.lang.String[],java.lang.String[],java.lang.String[],java.lang.String[],java.lang.String[],org.apache.hadoop.fs.StorageType[],long,long,boolean)" : [ "internStringsInArray" ],
  "org.apache.hadoop.fs.WindowsGetSpaceUsed:refresh()" : [ "getFolderUsage" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL:renewDelegationToken(java.net.URL,org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL$Token)" : [ "renewDelegationToken" ],
  "org.apache.hadoop.fs.FileContext$Util:listStatus(org.apache.hadoop.fs.Path[],org.apache.hadoop.fs.PathFilter)" : [ "listStatus" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:createOutputStream(org.apache.hadoop.fs.Path,boolean)" : [ "createOutputStreamWithMode" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:tag(java.lang.String,java.lang.String,java.lang.String,boolean)" : [ "tag", "info" ],
  "org.apache.hadoop.fs.RawPathHandle:toString()" : [ "bytes" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:getCounterReference(java.lang.String)" : [ "getInnerStatistics" ],
  "org.apache.hadoop.util.BlockingThreadPoolExecutorService:newDaemonThreadFactory(java.lang.String)" : [ "getNamedThreadFactory" ],
  "org.apache.hadoop.crypto.OpensslCipher:checkState()" : [ "checkState" ],
  "org.apache.hadoop.fs.FileSystemStorageStatistics:reset()" : [ "reset" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationHandler:initTokenManager(java.util.Properties)" : [ "<init>", "set", "get", "init" ],
  "org.apache.hadoop.io.SequenceFile$Writer:compression(org.apache.hadoop.io.SequenceFile$CompressionType)" : [ "<init>" ],
  "org.apache.hadoop.fs.ContentSummary$Builder:typeQuota(org.apache.hadoop.fs.StorageType,long)" : [ "typeQuota" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner:rewind()" : [ "seekTo" ],
  "org.apache.hadoop.fs.FilterFs:mkdir(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,boolean)" : [ "checkPath" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:closeChildFileSystems(org.apache.hadoop.fs.FileSystem)" : [ "getChildFileSystems", "getBoolean", "close" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:incrementGauge(java.lang.String,long)" : [ "getInnerStatistics" ],
  "org.apache.hadoop.util.hash.MurmurHash:hash(byte[],int,int)" : [ "hash" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem$2:close()" : [ "close" ],
  "org.apache.hadoop.ipc.CallerContext$Builder:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.crypto.OpensslCipher:getInstance(java.lang.String,java.lang.String)" : [ "<init>", "tokenizeTransformation", "get" ],
  "org.apache.hadoop.util.VersionInfo:getUrl()" : [ "_getUrl" ],
  "org.apache.hadoop.security.SecurityUtil:login(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String,java.lang.String)" : [ "isSecurityEnabled", "get", "getServerPrincipal", "loginUserFromKeytab" ],
  "org.apache.hadoop.security.http.RestCsrfPreventionFilter:getFilterParams(org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "getPropsWithPrefix" ],
  "org.apache.hadoop.fs.LocalFileSystem:copyFromLocalFile(boolean,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "copy" ],
  "org.apache.hadoop.util.Progress:addPhase()" : [ "addNewPhase" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker:close()" : [ "stopClient" ],
  "org.apache.hadoop.fs.impl.prefetch.FilePosition:setAbsolute(long)" : [ "isValid", "isWithinCurrentBuffer" ],
  "org.apache.hadoop.metrics2.MetricsTag:<init>(org.apache.hadoop.metrics2.MetricsInfo,java.lang.String)" : [ "checkNotNull" ],
  "org.apache.hadoop.io.Text:<init>(org.apache.hadoop.io.Text)" : [ "set" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:incrRpcCallSuccesses()" : [ "incr" ],
  "org.apache.hadoop.util.hash.JenkinsHash:main(java.lang.String[])" : [ "hash" ],
  "org.apache.hadoop.fs.FileContext:setReplication(org.apache.hadoop.fs.Path,short)" : [ "fixRelativePart" ],
  "org.apache.hadoop.fs.shell.FsUsage$TableBuilder:<init>(java.lang.Object[])" : [ "<init>", "addRow" ],
  "org.apache.hadoop.conf.Configuration:dumpConfiguration(org.apache.hadoop.conf.Configuration,java.lang.String,java.io.Writer)" : [ "<init>", "dumpConfiguration", "get", "appendJSONProperty" ],
  "org.apache.hadoop.net.DNSDomainNameResolver:getHostnameByIP(java.net.InetAddress)" : [ "reverseDns" ],
  "org.apache.hadoop.util.WeakReferenceMap:<init>(java.util.function.Function,java.util.function.Consumer)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:getAndMoveToFrontDecode0(int)" : [ "bsR", "readAByte" ],
  "org.apache.hadoop.util.functional.FutureIO:awaitAllFutures(java.util.Collection)" : [ "awaitFuture" ],
  "org.apache.hadoop.metrics2.lib.MutableRollingAverages:add(java.lang.String,long)" : [ "add" ],
  "org.apache.hadoop.metrics2.lib.MutableStat:resetMinMax()" : [ "reset" ],
  "org.apache.hadoop.fs.ChecksumFileSystem$FSDataBoundedInputStream:skip(long)" : [ "getFileLength" ],
  "org.apache.hadoop.util.ZKUtil:parseAuth(java.lang.String)" : [ "<init>", "newArrayList" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter:getConfiguration(java.lang.String,javax.servlet.FilterConfig)" : [ "setAuthHandlerClass" ],
  "org.apache.hadoop.fs.FileUtil:copy(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,boolean,org.apache.hadoop.conf.Configuration)" : [ "copy" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenManager:createToken(org.apache.hadoop.security.UserGroupInformation,java.lang.String,java.lang.String)" : [ "<init>", "getShortUserName", "getUserName", "getRealUser", "setOwner", "setRenewer", "setRealUser", "setService" ],
  "org.apache.hadoop.fs.FSInputChecker:read(byte[],int,int)" : [ "read1" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockOperations:getSummary(boolean)" : [ "getSummary", "getDebugInfo", "getDurationInfo" ],
  "org.apache.hadoop.net.unix.DomainSocket:setAttribute(int,int)" : [ "reference", "unreference" ],
  "org.apache.hadoop.ipc.Server$Call:<init>(int,int,org.apache.hadoop.ipc.RPC$RpcKind,byte[])" : [ "<init>" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Reader$BlockReader:getCompressedSize()" : [ "getCompressedSize", "getBlockRegion" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Factory:getBzip2Compressor(org.apache.hadoop.conf.Configuration)" : [ "<init>", "isNativeBzip2Loaded" ],
  "org.apache.hadoop.util.InstrumentedLock:lock()" : [ "monotonicNow", "check", "startLockTiming" ],
  "org.apache.hadoop.io.wrappedio.WrappedStatistics:iostatisticsSnapshot_create(java.lang.Object)" : [ "<init>" ],
  "org.apache.hadoop.fs.AbstractFileSystem:createFileSystem(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getClass", "newInstance" ],
  "org.apache.hadoop.ha.ZKFailoverController:becomeStandby()" : [ "getGracefulFenceTimeout", "getProxy", "createReqInfo" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:setAcl(org.apache.hadoop.fs.Path,java.util.List)" : [ "setAcl", "resolve", "getUriPath" ],
  "org.apache.hadoop.fs.FilterFileSystem:removeDefaultAcl(org.apache.hadoop.fs.Path)" : [ "removeDefaultAcl" ],
  "org.apache.hadoop.security.SaslRpcClient:<init>(org.apache.hadoop.security.UserGroupInformation,java.lang.Class,java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration)" : [ "getInstance" ],
  "org.apache.hadoop.util.DiskChecker:checkAccessByFileMethods(java.io.File)" : [ "<init>", "canRead", "canWrite", "canExecute" ],
  "org.apache.hadoop.util.SysInfoLinux:readProcMemInfoFile()" : [ "readProcMemInfoFile" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:reset()" : [ "setCurrentKeyId", "setDelegationTokenSeqNum" ],
  "org.apache.hadoop.util.dynamic.DynMethods$Builder:ctorImpl(java.lang.Class,java.lang.Class[])" : [ "<init>", "impl", "buildChecked" ],
  "org.apache.hadoop.net.unix.DomainSocket$DomainInputStream:available()" : [ "reference" ],
  "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer:getIOStatistics()" : [ "retrieveIOStatistics" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:startMetricsMBeans()" : [ "startMBeans" ],
  "org.apache.hadoop.io.compress.zstd.ZStandardDecompressor:finalize()" : [ "reset" ],
  "org.apache.hadoop.fs.ContentSummary$Builder:typeQuota(long[])" : [ "typeQuota" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:setStoragePolicy(org.apache.hadoop.fs.Path,java.lang.String)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.io.retry.RetryPolicies$MultipleLinearRandomRetry:equals(java.lang.Object)" : [ "toString" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:getHomeDirectory()" : [ "<init>", "connect", "disconnect" ],
  "org.apache.hadoop.tracing.Tracer:newSpan(java.lang.String,org.apache.hadoop.tracing.SpanContext)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:getDefaultReplication()" : [ "getDefaultReplication", "fullPath" ],
  "org.apache.hadoop.fs.VectoredReadUtils:mergeSortedRanges(java.util.List,int,int,int)" : [ "<init>", "roundDown", "roundUp", "merge" ],
  "org.apache.hadoop.util.SysInfoWindows:getStorageBytesWritten()" : [ "refreshIfNeeded" ],
  "org.apache.hadoop.fs.BulkDeleteUtils:validateBulkDeletePaths(java.util.Collection,int,org.apache.hadoop.fs.Path)" : [ "checkArgument" ],
  "org.apache.hadoop.io.compress.CompressionCodecFactory:setCodecClasses(org.apache.hadoop.conf.Configuration,java.util.List)" : [ "set" ],
  "org.apache.hadoop.security.ShellBasedIdMapping:loadFullMaps()" : [ "loadFullUserMap", "loadFullGroupMap" ],
  "org.apache.hadoop.fs.store.DataBlocks$BlockUploadData:close()" : [ "cleanupWithLogger" ],
  "org.apache.hadoop.fs.FsShell:printInfo(java.io.PrintStream,java.lang.String,boolean)" : [ "<init>", "getInstance", "printInstanceHelp", "printInstanceUsage", "getUsagePrefix", "getNames", "isDeprecated", "getUsage", "printGenericCommandUsage" ],
  "org.apache.hadoop.net.InnerNodeImpl:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.io.retry.RetryPolicies:retryOtherThanRemoteAndSaslException(org.apache.hadoop.io.retry.RetryPolicy,java.util.Map)" : [ "<init>" ],
  "org.apache.hadoop.ha.HAAdmin:createReqInfo()" : [ "<init>" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding:trackDuration(org.apache.hadoop.fs.statistics.DurationTrackerFactory,java.lang.String,org.apache.hadoop.util.functional.CallableRaisingIOE)" : [ "trackDurationOfOperation" ],
  "org.apache.hadoop.io.MultipleIOException$Builder:build()" : [ "createIOException" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:create(org.apache.hadoop.fs.Path,boolean,boolean,int,short,long,org.apache.hadoop.util.Progressable,org.apache.hadoop.fs.permission.FsPermission)" : [ "<init>", "exists", "getParent", "mkdirs", "toString", "createOutputStreamWithMode" ],
  "org.apache.hadoop.ipc.WeightedRoundRobinMultiplexer:advanceIndex()" : [ "moveToNextQueue" ],
  "org.apache.hadoop.io.SequenceFile$BlockCompressWriter:append(java.lang.Object,java.lang.Object)" : [ "getLength", "writeVInt", "sync" ],
  "org.apache.hadoop.io.ArrayPrimitiveWritable$Internal:<init>(java.lang.Object)" : [ "<init>" ],
  "org.apache.hadoop.fs.TrashPolicyDefault:moveToTrash(org.apache.hadoop.fs.Path)" : [ "<init>", "isEnabled", "isAbsolute", "makeQualified", "toString", "getTrashRoot", "getParent", "makeTrashRelativePath", "rename", "exists", "now", "getName" ],
  "org.apache.hadoop.io.DataInputBuffer:getPosition()" : [ "getPosition" ],
  "org.apache.hadoop.fs.FileSystem:globStatus(org.apache.hadoop.fs.Path)" : [ "createGlobber", "withPathPattern", "withPathFiltern", "withResolveSymlinks", "build", "glob" ],
  "org.apache.hadoop.fs.MD5MD5CRC32FileChecksum:getAlgorithmName()" : [ "getCrcType" ],
  "org.apache.hadoop.util.functional.FutureIO:raiseInnerCause(java.util.concurrent.CompletionException)" : [ "unwrapInnerException" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider$KMSTokenRenewer:handleKind(org.apache.hadoop.io.Text)" : [ "equals" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:renewToken(org.apache.hadoop.security.token.Token,java.lang.String)" : [ "<init>", "getIdentifier", "readFields", "formatTokenId", "now", "getMaxDate", "formatTime", "getRenewer", "toString", "getDelegationKey", "getMasterKeyId", "getSequenceNumber", "getKey", "getPassword", "getTrackingIdIfEnabled", "getTokenInfo", "trackUpdateToken" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:unsetStoragePolicy(org.apache.hadoop.fs.Path)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.fs.FSDataOutputStreamBuilder:getThisBuilder()" : [ "getThisBuilder" ],
  "org.apache.hadoop.conf.ConfigurationWithLogging:getFloat(java.lang.String,float)" : [ "getFloat" ],
  "org.apache.hadoop.util.Shell:isSetsidSupported()" : [ "<init>", "execute" ],
  "org.apache.hadoop.fs.FileContext:getServerDefaults(org.apache.hadoop.fs.Path)" : [ "resolve", "fixRelativePart" ],
  "org.apache.hadoop.io.compress.DefaultCodec:createInputStream(java.io.InputStream,org.apache.hadoop.io.compress.Decompressor)" : [ "<init>", "getInt" ],
  "org.apache.hadoop.fs.FilterFileSystem:open(org.apache.hadoop.fs.PathHandle,int)" : [ "open" ],
  "org.apache.hadoop.fs.FileSystem:setQuota(org.apache.hadoop.fs.Path,long,long)" : [ "methodNotSupported" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:mkdirs(org.apache.hadoop.fs.Path)" : [ "mkdirs", "fullPath" ],
  "org.apache.hadoop.fs.impl.AbstractFSBuilderImpl:must(java.lang.String,java.lang.String[])" : [ "setStrings", "getThisBuilder" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RSRawDecoder:doDecode(org.apache.hadoop.io.erasurecode.rawcoder.ByteBufferDecodingState)" : [ "resetOutputBuffers", "prepareDecoding", "encodeData" ],
  "org.apache.hadoop.fs.store.DataBlocks$DiskBlockFactory:<init>(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "<init>", "get" ],
  "org.apache.hadoop.security.UserGroupInformation:toString()" : [ "getUserName", "getAuthenticationMethod", "getRealUser" ],
  "org.apache.hadoop.security.ssl.DelegatingSSLSocketFactory:<init>(org.apache.hadoop.security.ssl.DelegatingSSLSocketFactory$SSLChannelMode)" : [ "initializeSSLContext", "alterCipherList" ],
  "org.apache.hadoop.util.curator.ZKCuratorManager:start(java.util.List)" : [ "start" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:readAByte(java.io.InputStream)" : [ "updateProcessedByteCount" ],
  "org.apache.hadoop.fs.Trash:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getInstance" ],
  "org.apache.hadoop.util.StringUtils:limitDecimalTo2(double)" : [ "format" ],
  "org.apache.hadoop.io.ArrayFile$Reader:key()" : [ "get" ],
  "org.apache.hadoop.security.ssl.FileMonitoringTimerTask:<init>(java.nio.file.Path,java.util.function.Consumer,java.util.function.Consumer)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:checkTagName(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.io.retry.RetryPolicies$MultipleLinearRandomRetry:shouldRetry(java.lang.Exception,int,int,boolean)" : [ "<init>", "searchPair" ],
  "org.apache.hadoop.fs.FileSystem$Statistics:incrementBytesRead(long)" : [ "getThreadStatistics" ],
  "org.apache.hadoop.tools.protocolPB.GetUserMappingsProtocolClientSideTranslatorPB:isMethodSupported(java.lang.String)" : [ "isMethodSupported", "getProtocolVersion" ],
  "org.apache.hadoop.net.NetUtils:wrapException(java.lang.String,int,java.lang.String,int,java.io.IOException)" : [ "wrapWithMessage", "see", "getHostDetailsAsString" ],
  "org.apache.hadoop.fs.FSDataOutputStreamBuilder:blockSize(long)" : [ "getThisBuilder" ],
  "org.apache.hadoop.io.wrappedio.WrappedStatistics:applyToIOStatisticsSnapshot(java.io.Serializable,org.apache.hadoop.util.functional.FunctionRaisingIOE)" : [ "unchecked", "requireIOStatisticsSnapshot" ],
  "org.apache.hadoop.fs.ContentSummary$Builder:<init>()" : [ "<init>" ],
  "org.apache.hadoop.security.token.DtUtilShell$Remove:execute()" : [ "removeTokenFromFile" ],
  "org.apache.hadoop.security.ssl.DelegatingSSLSocketFactory:createSocket(java.net.InetAddress,int)" : [ "configureSocket" ],
  "org.apache.hadoop.io.compress.CompressionCodecFactory:getCodecClasses(org.apache.hadoop.conf.Configuration)" : [ "get", "getClassByName" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:bsGetBit()" : [ "readAByte" ],
  "org.apache.hadoop.metrics2.AbstractMetric:equals(java.lang.Object)" : [ "info" ],
  "org.apache.hadoop.conf.ReconfigurationServlet:doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)" : [ "getReconfigurable", "printHeader", "printConf", "printFooter" ],
  "org.apache.hadoop.security.KDiag:validateJAAS(boolean)" : [ "verify", "title", "println", "verifyFileIsValid", "dump", "endln" ],
  "org.apache.hadoop.service.AbstractService:serviceInit(org.apache.hadoop.conf.Configuration)" : [ "setConfig" ],
  "org.apache.hadoop.fs.http.HttpFileSystem:rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "rename" ],
  "org.apache.hadoop.fs.PathIsNotDirectoryException:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.util.concurrent.HadoopScheduledThreadPoolExecutor:afterExecute(java.lang.Runnable,java.lang.Throwable)" : [ "logThrowableFromAfterExecute" ],
  "org.apache.hadoop.ipc.RetryCache:addCacheEntryWithPayload(byte[],int,java.lang.Object)" : [ "<init>", "put", "incrCacheUpdated" ],
  "org.apache.hadoop.fs.shell.CopyCommandWithMultiThread:processArguments(java.util.LinkedList)" : [ "processArguments", "isMultiThreadNecessary", "initThreadPoolExecutor", "waitForCompletion" ],
  "org.apache.hadoop.service.AbstractService:unregisterServiceListener(org.apache.hadoop.service.ServiceStateChangeListener)" : [ "remove" ],
  "org.apache.hadoop.fs.permission.FsPermission:valueOf(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation:snapshot(org.apache.hadoop.metrics2.MetricsRecordBuilder,boolean)" : [ "aggregateLocalStatesToGlobalMetrics" ],
  "org.apache.hadoop.metrics2.source.JvmMetrics:getGcUsage(org.apache.hadoop.metrics2.MetricsRecordBuilder)" : [ "getGcInfo", "getNumGcWarnThresholdExceeded", "getNumGcInfoThresholdExceeded", "getTotalGcExtraSleepTime", "getLatestGcData", "getGcTimePercentage" ],
  "org.apache.hadoop.ipc.Server:stop()" : [ "doStop", "shutdownMetricsUpdaterExecutor", "shutdown" ],
  "org.apache.hadoop.util.PriorityQueue:put(java.lang.Object)" : [ "upHeap" ],
  "org.apache.hadoop.fs.PathPermissionException:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.ha.HAServiceTarget:getHealthMonitorProxy(org.apache.hadoop.conf.Configuration,int,int)" : [ "getHealthMonitorAddress", "getProxyForAddress" ],
  "org.apache.hadoop.io.compress.DefaultCodec:createOutputStream(java.io.OutputStream)" : [ "createOutputStreamWithCodecPool" ],
  "org.apache.hadoop.fs.CachingGetSpaceUsed:initRefreshThread(boolean)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileSystem:create(org.apache.hadoop.fs.Path,boolean,int,short,long)" : [ "create" ],
  "org.apache.hadoop.ipc.protocolPB.GenericRefreshProtocolServerSideTranslatorPB:pack(java.util.Collection)" : [ "getReturnCode", "getMessage", "getSenderName" ],
  "org.apache.hadoop.io.SequenceFile:createWriter(org.apache.hadoop.fs.FileContext,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.io.SequenceFile$Metadata,java.util.EnumSet,org.apache.hadoop.fs.Options$CreateOpts[])" : [ "createWriter", "create", "ownStream" ],
  "org.apache.hadoop.io.SequenceFile$Sorter:<init>(org.apache.hadoop.fs.FileSystem,java.lang.Class,java.lang.Class,org.apache.hadoop.conf.Configuration)" : [ "<init>", "get" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding:emptyStatisticsStore()" : [ "getInstance" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:getLinkTarget(org.apache.hadoop.fs.Path)" : [ "getLinkTarget", "fullPath" ],
  "org.apache.hadoop.crypto.CryptoOutputStream:encrypt()" : [ "checkState", "getTmpBuf", "updateEncryptor" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme:getMountPathInfo(org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration)" : [ "<init>", "resolve", "isInternalDir", "getRootFallbackLink", "getTargetFileSystem", "fsGetter", "get", "toUri", "fullPath", "getMyFs" ],
  "org.apache.hadoop.fs.HarFs:<init>(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.fs.statistics.impl.StorageStatisticsFromIOStatistics:toLongStatistic(java.util.Map$Entry)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.ZStandardCodec:getCompressionBufferSize(org.apache.hadoop.conf.Configuration)" : [ "getBufferSize", "getRecommendedBufferSize" ],
  "org.apache.hadoop.fs.shell.Command:recursePath(org.apache.hadoop.fs.shell.PathData)" : [ "isSorted", "processPaths", "getDirectoryContents", "getDirectoryContentsIterator", "maybeIgnoreMissingDirectory" ],
  "org.apache.hadoop.security.Groups:getGroupsSet(java.lang.String)" : [ "getGroupInternal" ],
  "org.apache.hadoop.ipc.Server:getRemotePort()" : [ "getRemotePort" ],
  "org.apache.hadoop.io.compress.zstd.ZStandardDecompressor:getRemaining()" : [ "checkStream" ],
  "org.apache.hadoop.fs.shell.Count:<init>(java.lang.String[],int,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.FileSystemMultipartUploader:innerComplete(org.apache.hadoop.fs.UploadHandle,org.apache.hadoop.fs.Path,java.util.Map)" : [ "<init>", "toByteArray", "checkArgument", "totalPartsLen", "create", "close", "mergePaths", "getName", "concat", "rename", "getPathHandle" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding:aggregateMeanStatistics(org.apache.hadoop.fs.statistics.MeanStatistic,org.apache.hadoop.fs.statistics.MeanStatistic)" : [ "copy", "add" ],
  "org.apache.hadoop.io.MD5Hash$Comparator:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.FilterFileSystem:removeXAttr(org.apache.hadoop.fs.Path,java.lang.String)" : [ "removeXAttr" ],
  "org.apache.hadoop.fs.shell.find.Find:processArguments(java.util.LinkedList)" : [ "getRootExpression", "getOptions" ],
  "org.apache.hadoop.fs.permission.ChmodParser:applyNewPermission(org.apache.hadoop.fs.FileStatus)" : [ "getPermission", "toShort", "isDirectory" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:sampleMetrics()" : [ "clear", "snapshotMetrics", "get" ],
  "org.apache.hadoop.fs.FileContext:satisfyStoragePolicy(org.apache.hadoop.fs.Path)" : [ "fixRelativePart" ],
  "org.apache.hadoop.fs.FileSystem:setDefaultUri(org.apache.hadoop.conf.Configuration,java.net.URI)" : [ "set" ],
  "org.apache.hadoop.crypto.CryptoOutputStream:close()" : [ "flush", "freeBuffers" ],
  "org.apache.hadoop.net.TableMapping:reloadCachedMappings()" : [ "reloadCachedMappings", "getRawMapping" ],
  "org.apache.hadoop.fs.FileSystem:createDataInputStreamBuilder(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.security.SaslPropertiesResolver:getSaslProperties(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.hadoop.security.SaslRpcServer$QualityOfProtection)" : [ "getStrings", "toUpperCase", "getSaslQop", "join" ],
  "org.apache.hadoop.fs.impl.AbstractFSBuilderImpl:must(java.lang.String,boolean)" : [ "must" ],
  "org.apache.hadoop.io.retry.RetryInvocationHandler:getConnectionId()" : [ "getConnectionIdForProxy", "getProxy" ],
  "org.apache.hadoop.security.ShellBasedIdMapping$StaticMapping:<init>(java.util.Map,java.util.Map)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.impl.MetricsRecordBuilderImpl:tag(org.apache.hadoop.metrics2.MetricsInfo,java.lang.String)" : [ "tag" ],
  "org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:syncLocalCacheWithZk(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier)" : [ "getTokenInfoFromZK", "getSequenceNumber" ],
  "org.apache.hadoop.fs.Path:getParentUtil()" : [ "<init>", "startPositionWithoutWindowsDrive" ],
  "org.apache.hadoop.fs.sftp.SFTPConnectionPool:connect(java.lang.String,int,java.lang.String,java.lang.String,java.lang.String)" : [ "<init>", "getFromPool", "stringifyException" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getAllStoragePolicies()" : [ "getAllStoragePolicies", "getChildFileSystems" ],
  "org.apache.hadoop.security.alias.CredentialShell:main(java.lang.String[])" : [ "<init>", "run" ],
  "org.apache.hadoop.fs.shell.Display$TextRecordInputStream:read()" : [ "next", "getCurrentValue", "reset", "getData", "getLength" ],
  "org.apache.hadoop.fs.FSDataInputStream:read(org.apache.hadoop.io.ByteBufferPool,int,java.util.EnumSet)" : [ "fallbackRead", "put" ],
  "org.apache.hadoop.fs.FileSystem$FileSystemDataOutputStreamBuilder:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.ipc.RPC:getRpcTimeout(org.apache.hadoop.conf.Configuration)" : [ "getInt" ],
  "org.apache.hadoop.fs.FileSystem:appendFile(org.apache.hadoop.fs.Path)" : [ "createDataOutputStreamBuilder", "append" ],
  "org.apache.hadoop.fs.PathNotFoundException:<init>(java.lang.String,java.lang.String,java.lang.Throwable)" : [ "<init>" ],
  "org.apache.hadoop.io.IOUtils:fsync(java.io.File)" : [ "fsync" ],
  "org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation$ThreadSafeSampleStat:snapshotInto(org.apache.hadoop.metrics2.lib.MutableRate)" : [ "numSamples", "total", "reset" ],
  "org.apache.hadoop.io.WritableUtils:cloneInto(org.apache.hadoop.io.Writable,org.apache.hadoop.io.Writable)" : [ "cloneWritableInto" ],
  "org.apache.hadoop.ipc.RpcServerException:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RSLegacyRawDecoder:decode(byte[][],int[],byte[][])" : [ "decode", "adjustOrder" ],
  "org.apache.hadoop.net.NetUtils:createSocketAddr(java.lang.String,int,java.lang.String,boolean)" : [ "createSocketAddr" ],
  "org.apache.hadoop.fs.shell.TouchCommands$Touch:processNonexistentPath(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "parentExists", "toString", "toUri", "touch" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:read(byte[],int,int)" : [ "init", "changeStateToProcessABlock", "read0", "skipToNextBlockMarker" ],
  "org.apache.hadoop.util.CrcUtil:compose(int,int,long,int)" : [ "getMonomial", "composeWithMonomial" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:<init>(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>", "now", "getCurrentUser", "getBoolean", "getType", "get" ],
  "org.apache.hadoop.fs.FsUrlStreamHandler:openConnection(java.net.URL)" : [ "<init>" ],
  "org.apache.hadoop.fs.HarFileSystem$HarFSDataInputStream$HarFsInputStream:setDropBehind(java.lang.Boolean)" : [ "setDropBehind" ],
  "org.apache.hadoop.io.erasurecode.codec.RSErasureCodec:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.io.erasurecode.ErasureCodecOptions)" : [ "<init>" ],
  "org.apache.hadoop.io.SequenceFile$Writer:hasCapability(java.lang.String)" : [ "hasCapability" ],
  "org.apache.hadoop.fs.FilterFileSystem:getDefaultBlockSize(org.apache.hadoop.fs.Path)" : [ "getDefaultBlockSize" ],
  "org.apache.hadoop.ipc.RPC:waitForProxy(java.lang.Class,long,java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration)" : [ "waitForProtocolProxy", "getProxy" ],
  "org.apache.hadoop.util.JsonSerialization:load(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)" : [ "load" ],
  "org.apache.hadoop.fs.DF:<init>(java.io.File,long)" : [ "<init>" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:iostatisticsContext_aggregate(java.lang.Object)" : [ "checkIoStatisticsContextAvailable", "invoke" ],
  "org.apache.hadoop.io.SequenceFile$Sorter:cloneFileAttributes(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.util.Progressable)" : [ "<init>", "file", "getCompressionType", "getCompressionCodec", "close", "createWriter", "keyClass", "valueClass", "compression", "progressable" ],
  "org.apache.hadoop.net.NodeBase:toString()" : [ "getPath" ],
  "org.apache.hadoop.fs.FSLinkResolver:qualifySymlinkTarget(java.net.URI,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "toUri", "makeQualified", "getParent" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RawErasureEncoder:encode(org.apache.hadoop.io.erasurecode.ECChunk[],org.apache.hadoop.io.erasurecode.ECChunk[])" : [ "encode", "toBuffers" ],
  "org.apache.hadoop.crypto.CryptoInputStream:read()" : [ "read" ],
  "org.apache.hadoop.io.erasurecode.coder.HHXORErasureDecoder:<init>(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.fs.FilterFileSystem:getXAttr(org.apache.hadoop.fs.Path,java.lang.String)" : [ "getXAttr" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsSnapshot:setCounter(java.lang.String,long)" : [ "counters" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider$KeyMetadata:getAlgorithm()" : [ "getCipher" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker:call(org.apache.hadoop.ipc.RPC$Server,java.lang.String,org.apache.hadoop.ipc.RpcWritable$Buffer,java.lang.String,org.apache.hadoop.ipc.RPC$Server$ProtoClassProtoImpl)" : [ "<init>", "getValue", "init", "setDetailedMetricsName", "deferResponse", "wrap" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.CoderUtil:resetOutputBuffers(byte[][],int[],int)" : [ "resetBuffer" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsLogging$SourceToString:toString()" : [ "ioStatisticsSourceToString" ],
  "org.apache.hadoop.crypto.CryptoOutputStream:write(byte[],int,int)" : [ "checkStream", "encrypt" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:deprecatedGetFileStatus(org.apache.hadoop.fs.Path)" : [ "<init>", "pathToFile" ],
  "org.apache.hadoop.security.SecurityUtil:buildTokenService(java.net.InetSocketAddress)" : [ "<init>", "toLowerCase" ],
  "org.apache.hadoop.net.DNS:getDefaultHost(java.lang.String)" : [ "getDefaultHost" ],
  "org.apache.hadoop.ha.protocolPB.HAServiceProtocolClientSideTranslatorPB:transitionToStandby(org.apache.hadoop.ha.HAServiceProtocol$StateChangeRequestInfo)" : [ "convert", "ipc" ],
  "org.apache.hadoop.fs.permission.FsPermission:<init>(short)" : [ "fromShort" ],
  "org.apache.hadoop.io.SequenceFile:createWriter(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FSDataOutputStream,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.io.SequenceFile$Metadata)" : [ "createWriter", "stream", "keyClass", "valueClass", "compression", "metadata" ],
  "org.apache.hadoop.io.compress.BZip2Codec:createInputStream(java.io.InputStream)" : [ "createInputStreamWithCodecPool" ],
  "org.apache.hadoop.ipc.ResponseBuffer:ensureCapacity(int)" : [ "capacity", "setCapacity" ],
  "org.apache.hadoop.net.NetworkTopology:interAddNodeWithEmptyRack(org.apache.hadoop.net.Node)" : [ "countEmptyRacks" ],
  "org.apache.hadoop.fs.ContentSummary:toSnapshot(boolean)" : [ "formatSize" ],
  "org.apache.hadoop.io.retry.AsyncCallHandler:initAsyncCall(org.apache.hadoop.io.retry.AsyncCallHandler$AsyncCall,org.apache.hadoop.io.retry.AsyncCallHandler$AsyncValue)" : [ "addCall" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:loadConfigurationClasses()" : [ "<init>", "getConfigurationsToCreate", "getClassLoader" ],
  "org.apache.hadoop.security.authorize.AuthorizationException:<init>()" : [ "<init>" ],
  "org.apache.hadoop.security.http.CrossOriginFilter:doFilter(javax.servlet.ServletRequest,javax.servlet.ServletResponse,javax.servlet.FilterChain)" : [ "doCrossFilter" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:truncate(org.apache.hadoop.fs.Path,long)" : [ "truncate" ],
  "org.apache.hadoop.fs.local.RawLocalFs:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.util.GenericOptionsParser:validateFiles(java.lang.String,boolean)" : [ "<init>", "matchesCurrentDirectory", "getLocal", "expandWildcard", "makeQualified", "toString", "getFileSystem", "join" ],
  "org.apache.hadoop.fs.FileSystem$Cache:getInternal(java.net.URI,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem$Cache$Key)" : [ "<init>", "get", "getTimeDuration", "isShutdownInProgress", "addShutdownHook", "getBoolean", "cleanupWithLogger", "close" ],
  "org.apache.hadoop.fs.viewfs.InodeTree$INodeDirLink:<init>(java.lang.String,org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.fs.viewfs.InodeTree$INodeLink)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:renameInternal(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,boolean)" : [ "renameInternal", "fullPath" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:reencryptEncryptedKeys(java.util.List)" : [ "checkNotNull", "getEncryptionKeyName", "getEncryptionKeyVersionName", "getEncryptedKeyIv", "getEncryptedKeyVersion", "checkArgument", "getVersionName", "toJSON", "createURL", "createConnection", "call", "parseJSONEncKeyVersion" ],
  "org.apache.hadoop.security.UserGroupInformation:isLoginKeytabBased()" : [ "getLoginUser", "isFromKeytab" ],
  "org.apache.hadoop.fs.ChecksumFileSystem:create(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,java.util.EnumSet,int,short,long,org.apache.hadoop.util.Progressable,org.apache.hadoop.fs.Options$ChecksumOpt)" : [ "create" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:removeXAttr(org.apache.hadoop.fs.Path,java.lang.String)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine:getProxy(java.lang.Class,long,java.net.InetSocketAddress,org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory,int,org.apache.hadoop.io.retry.RetryPolicy,java.util.concurrent.atomic.AtomicBoolean,org.apache.hadoop.ipc.AlignmentContext)" : [ "<init>" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner:seekTo(byte[])" : [ "seekTo" ],
  "org.apache.hadoop.fs.shell.Mkdir:processNonexistentPath(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "getParent", "toString", "exists", "mkdirs" ],
  "org.apache.hadoop.io.compress.BZip2Codec$BZip2CompressionInputStream:<init>(java.io.InputStream,long,long,org.apache.hadoop.io.compress.SplittableCompressionCodec$READ_MODE)" : [ "<init>", "readStreamHeader", "updateReportedByteCount", "updatePos" ],
  "org.apache.hadoop.fs.Path:<init>(java.lang.String,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.util.ShutdownHookManager:executeShutdown()" : [ "getShutdownHooksInOrder", "getHook", "getTimeout", "getTimeUnit" ],
  "org.apache.hadoop.io.file.tfile.Chunk$SingleChunkEncoder:<init>(java.io.DataOutputStream,int)" : [ "writeVInt" ],
  "org.apache.hadoop.net.ScriptBasedMappingWithDependency:<init>()" : [ "<init>" ],
  "org.apache.hadoop.metrics2.lib.MetricsAnnotations:makeSource(java.lang.Object)" : [ "<init>", "getAnnotatedMetricsFactory", "build" ],
  "org.apache.hadoop.security.UserGroupInformation$HadoopLoginContext:logout()" : [ "getSubjectLock" ],
  "org.apache.hadoop.io.WritableUtils:readVLong(java.io.DataInput)" : [ "decodeVIntSize", "isNegativeVInt" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:configure(java.lang.String)" : [ "create", "configureSinks", "configureSources", "configureSystem" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine:getProxy(java.lang.Class,long,org.apache.hadoop.ipc.Client$ConnectionId,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory,org.apache.hadoop.ipc.AlignmentContext)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme:getFallbackFileSystem()" : [ "getRootFallbackLink", "getTargetFileSystem", "getMyFs" ],
  "org.apache.hadoop.fs.DF:toString()" : [ "getCapacity", "getUsed", "getAvailable", "getPercentUsed" ],
  "org.apache.hadoop.io.nativeio.NativeIO$POSIX$Pmem:memSync(org.apache.hadoop.io.nativeio.NativeIO$POSIX$PmemMappedRegion)" : [ "isPmem", "getAddress", "getLength" ],
  "org.apache.hadoop.fs.LocatedFileStatus:compareTo(org.apache.hadoop.fs.FileStatus)" : [ "compareTo" ],
  "org.apache.hadoop.ipc.WritableRpcEngine:getServer(java.lang.Class,java.lang.Object,java.lang.String,int,int,int,int,boolean,org.apache.hadoop.conf.Configuration,org.apache.hadoop.security.token.SecretManager,java.lang.String,org.apache.hadoop.ipc.AlignmentContext)" : [ "<init>" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker:<init>(java.lang.Class,java.net.InetSocketAddress,org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory,int,org.apache.hadoop.io.retry.RetryPolicy,java.util.concurrent.atomic.AtomicBoolean,org.apache.hadoop.ipc.AlignmentContext)" : [ "<init>", "getConnectionId" ],
  "org.apache.hadoop.util.JsonSerialization:fromBytes(byte[])" : [ "fromJson" ],
  "org.apache.hadoop.fs.FileContext$FCDataOutputStreamBuilder:<init>(org.apache.hadoop.fs.FileContext,org.apache.hadoop.fs.Path)" : [ "<init>", "checkNotNull" ],
  "org.apache.hadoop.io.MapFile$Reader:createDataFileReader(org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration,org.apache.hadoop.io.SequenceFile$Reader$Option[])" : [ "<init>", "prependOptions", "file" ],
  "org.apache.hadoop.ha.ZKFailoverController:gracefulFailoverToYou()" : [ "getLoginUser", "doAs" ],
  "org.apache.hadoop.security.LdapGroupsMapping:switchBindUser(javax.naming.AuthenticationException)" : [ "equals" ],
  "org.apache.hadoop.fs.FileSystem:append(org.apache.hadoop.fs.Path,boolean)" : [ "append", "getInt" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyStatus:getBlockSize()" : [ "getBlockSize" ],
  "org.apache.hadoop.net.ScriptBasedMapping:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.FileContext:createSnapshot(org.apache.hadoop.fs.Path)" : [ "createSnapshot" ],
  "org.apache.hadoop.crypto.JceAesCtrCryptoCodec:createDecryptor()" : [ "<init>", "getCipherSuite" ],
  "org.apache.hadoop.ipc.Server$Connection:switchToSimple()" : [ "disposeSasl" ],
  "org.apache.hadoop.ipc.Server$FatalRpcServerException:<init>(org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$RpcErrorCodeProto,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:iostatisticsSnapshot_create()" : [ "checkIoStatisticsAvailable", "invoke" ],
  "org.apache.hadoop.io.compress.zstd.ZStandardCompressor:reset()" : [ "checkStream" ],
  "org.apache.hadoop.fs.HarFileSystem:getDefaultBlockSize()" : [ "getDefaultBlockSize" ],
  "org.apache.hadoop.security.ShellBasedIdMapping:<init>(org.apache.hadoop.conf.Configuration,boolean)" : [ "getLong", "get", "updateStaticMapping", "updateMaps" ],
  "org.apache.hadoop.fs.store.DataBlocks$DataBlock:startUpload()" : [ "enterState" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsContextIntegration:getCurrentIOStatisticsContext()" : [ "getForCurrentThread", "getInstance" ],
  "org.apache.hadoop.fs.FSDataOutputStream:getPos()" : [ "getPos" ],
  "org.apache.hadoop.io.retry.RetryPolicies$RetryUpToMaximumCountWithFixedSleep:<init>(int,long,java.util.concurrent.TimeUnit)" : [ "<init>" ],
  "org.apache.hadoop.security.ssl.SSLFactory:readSSLConfiguration(org.apache.hadoop.conf.Configuration,org.apache.hadoop.security.ssl.SSLFactory$Mode)" : [ "<init>", "setBoolean", "getBoolean", "get", "addResource", "getResource" ],
  "org.apache.hadoop.fs.FileContext:setOwner(org.apache.hadoop.fs.Path,java.lang.String,java.lang.String)" : [ "<init>", "fixRelativePart" ],
  "org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator:posixFadviseIfPossible(java.lang.String,java.io.FileDescriptor,long,long,int)" : [ "posixFadviseIfPossible" ],
  "org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec:createDecryptor()" : [ "<init>", "getCipherSuite" ],
  "org.apache.hadoop.net.NetworkTopology:remove(org.apache.hadoop.net.Node)" : [ "getPath", "getNode", "interRemoveNodeWithEmptyRack" ],
  "org.apache.hadoop.ipc.FairCallQueue$MetricsProxy:<init>(java.lang.String)" : [ "register", "instance" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:setAclsWithRetries(java.lang.String)" : [ "zkDoWithRetries" ],
  "org.apache.hadoop.metrics2.sink.RollingFileSystemSink:flush()" : [ "hflush", "throwMetricsException" ],
  "org.apache.hadoop.util.bloom.RetouchedBloomFilter:selectiveClearing(org.apache.hadoop.util.bloom.Key,short)" : [ "hash", "randomRemove", "minimumFnRemove", "maximumFpRemove", "ratioRemove", "clearBit" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:getHomeDirectory()" : [ "getHomeDirectory" ],
  "org.apache.hadoop.fs.impl.prefetch.Retryer:<init>(int,int,int)" : [ "checkPositiveInteger", "checkGreater" ],
  "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix:long2String(long,java.lang.String,int)" : [ "format" ],
  "org.apache.hadoop.fs.shell.Concat:processArguments(java.util.LinkedList)" : [ "<init>", "isFile", "concat" ],
  "org.apache.hadoop.io.compress.BZip2Codec$BZip2CompressionOutputStream:write(int)" : [ "write", "internalReset" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:getHomeDirectory()" : [ "<init>", "getShortUserName" ],
  "org.apache.hadoop.io.compress.zstd.ZStandardCompressor:reinit(org.apache.hadoop.conf.Configuration)" : [ "getCompressionLevel", "reset" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsSupport:snapshotIOStatistics()" : [ "<init>" ],
  "org.apache.hadoop.util.HostsFileReader:getHosts()" : [ "getIncludedHosts" ],
  "org.apache.hadoop.security.JniBasedUnixGroupsMapping:getGroupsSet(java.lang.String)" : [ "getGroupsInternal" ],
  "org.apache.hadoop.io.SequenceFile$Writer:valueClass(java.lang.Class)" : [ "<init>" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:processWatchEvent(org.apache.zookeeper.ZooKeeper,org.apache.zookeeper.WatchedEvent)" : [ "isStaleClient", "monitorActiveStatus", "enterNeutralMode", "reJoinElection", "fatalError", "joinElectionInternal" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:generateDelegationToken(org.apache.hadoop.security.token.Token)" : [ "<init>", "getIdentifier", "getPassword", "getKind", "getService", "setDelegationToken" ],
  "org.apache.hadoop.util.Shell:getSignalKillCommand(int,java.lang.String)" : [ "getWinUtilsPath", "bashQuote" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.util.DumpUtil:dumpChunk(org.apache.hadoop.io.erasurecode.ECChunk)" : [ "toBytesArray", "bytesToHex" ],
  "org.apache.hadoop.fs.AbstractFileSystem:rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Options$Rename[])" : [ "renameInternal" ],
  "org.apache.hadoop.fs.Globber:<init>(org.apache.hadoop.fs.FileContext,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.PathFilter)" : [ "getTracer" ],
  "org.apache.hadoop.security.token.Token$PrivateToken:hashCode()" : [ "hashCode" ],
  "org.apache.hadoop.fs.viewfs.ViewFsLocatedFileStatus:getBlockLocations()" : [ "getBlockLocations" ],
  "org.apache.hadoop.security.authorize.ProxyUsers:getDefaultImpersonationProvider()" : [ "getSip" ],
  "org.apache.hadoop.util.functional.RemoteIterators$WrappingRemoteIterator:getIOStatistics()" : [ "retrieveIOStatistics" ],
  "org.apache.hadoop.io.SequenceFile$Writer:close()" : [ "close", "returnCompressor" ],
  "org.apache.hadoop.io.SequenceFile$RecordCompressWriter:append(java.lang.Object,java.lang.Object)" : [ "reset", "getLength", "getData" ],
  "org.apache.hadoop.fs.FileContext:listXAttrs(org.apache.hadoop.fs.Path)" : [ "fixRelativePart" ],
  "org.apache.hadoop.fs.impl.MultipartUploaderBuilderImpl:permission(org.apache.hadoop.fs.permission.FsPermission)" : [ "checkNotNull" ],
  "org.apache.hadoop.net.InnerNodeImpl:createParentNode(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.util.DataChecksum:getChecksumSize(int)" : [ "getChecksumSize", "getBytesPerChecksum" ],
  "org.apache.hadoop.ipc.FairCallQueue:poll(long,java.util.concurrent.TimeUnit)" : [ "removeNextElement" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:getServerDefaults()" : [ "getServerDefaults" ],
  "org.apache.hadoop.net.NetworkTopology:isNodeInScope(org.apache.hadoop.net.Node,java.lang.String)" : [ "getPath" ],
  "org.apache.hadoop.fs.viewfs.ViewFsFileStatus:getReplication()" : [ "getReplication" ],
  "org.apache.hadoop.fs.FileContext:setXAttr(org.apache.hadoop.fs.Path,java.lang.String,byte[],java.util.EnumSet)" : [ "fixRelativePart" ],
  "org.apache.hadoop.io.erasurecode.coder.HHXORErasureDecodingStep:doDecodeSingle(java.nio.ByteBuffer[][],java.nio.ByteBuffer[][],int,int,boolean)" : [ "getNumDataUnits", "getNumParityUnits", "allocateByteBuffer", "decode", "getPiggyBackForDecode", "doDecodeByPiggyBack" ],
  "org.apache.hadoop.io.WritableUtils:writeCompressedByteArray(java.io.DataOutput,byte[])" : [ "closeStream" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:updateDelegationKey(org.apache.hadoop.security.token.delegation.DelegationKey)" : [ "getKeyId" ],
  "org.apache.hadoop.jmx.JMXJsonServlet:writeAttribute(com.fasterxml.jackson.core.JsonGenerator,javax.management.ObjectName,javax.management.MBeanAttributeInfo)" : [ "writeAttribute" ],
  "org.apache.hadoop.fs.FilterFileSystem:canonicalizeUri(java.net.URI)" : [ "canonicalizeUri" ],
  "org.apache.hadoop.util.dynamic.DynMethods$Builder:hiddenImpl(java.lang.String,java.lang.String,java.lang.Class[])" : [ "hiddenImpl" ],
  "org.apache.hadoop.ha.HAServiceProtocolHelper:transitionToActive(org.apache.hadoop.ha.HAServiceProtocol,org.apache.hadoop.ha.HAServiceProtocol$StateChangeRequestInfo)" : [ "unwrapRemoteException" ],
  "org.apache.hadoop.fs.statistics.impl.DynamicIOStatisticsBuilder:withAtomicLongMaximum(java.lang.String,java.util.concurrent.atomic.AtomicLong)" : [ "withLongFunctionMaximum" ],
  "org.apache.hadoop.fs.audit.CommonAuditContext:noteEntryPoint(java.lang.Object)" : [ "setGlobalContextEntry" ],
  "org.apache.hadoop.fs.permission.FsCreateModes:equals(java.lang.Object)" : [ "equals", "getUnmasked" ],
  "org.apache.hadoop.ipc.internal.ShadedProtobufHelper:getFixedByteString(org.apache.hadoop.io.Text)" : [ "<init>", "toString", "copyBytes" ],
  "org.apache.hadoop.net.DomainNameResolverFactory:newInstance(org.apache.hadoop.conf.Configuration,java.net.URI,java.lang.String)" : [ "newInstance" ],
  "org.apache.hadoop.conf.ConfigRedactor:redactXml(java.lang.String,java.lang.String)" : [ "configIsSensitive" ],
  "org.apache.hadoop.security.token.delegation.SQLDelegationTokenSecretManager:removeStoredMasterKey(org.apache.hadoop.security.token.delegation.DelegationKey)" : [ "getKeyId" ],
  "org.apache.hadoop.fs.shell.Mkdir:processOptions(java.util.LinkedList)" : [ "<init>", "parse", "getOpt" ],
  "org.apache.hadoop.metrics2.sink.RollingFileSystemSink:loadConf()" : [ "<init>" ],
  "org.apache.hadoop.security.token.Token:write(java.io.DataOutput)" : [ "write", "writeVInt" ],
  "org.apache.hadoop.security.UserGroupInformation:isSecurityEnabled()" : [ "isAuthenticationMethodEnabled" ],
  "org.apache.hadoop.service.launcher.InterruptEscalator:interrupted(org.apache.hadoop.service.launcher.IrqHandler$InterruptData)" : [ "<init>", "toString", "halt", "getService", "terminate" ],
  "org.apache.hadoop.security.ShellBasedIdMapping:getGidAllowingUnknown(java.lang.String)" : [ "checkAndUpdateMaps", "getGid" ],
  "org.apache.hadoop.fs.shell.PathData:suffix(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.kms.ValueQueue:<init>(int,float,long,int,org.apache.hadoop.crypto.key.kms.ValueQueue$SyncGenerationPolicy,org.apache.hadoop.crypto.key.kms.ValueQueue$QueueRefiller)" : [ "checkArgument", "checkNotNull" ],
  "org.apache.hadoop.fs.FileSystem:moveFromLocalFile(org.apache.hadoop.fs.Path[],org.apache.hadoop.fs.Path)" : [ "copyFromLocalFile" ],
  "org.apache.hadoop.io.serializer.SerializationFactory:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>", "getTrimmedStrings", "add" ],
  "org.apache.hadoop.fs.FilterFs:setAcl(org.apache.hadoop.fs.Path,java.util.List)" : [ "setAcl" ],
  "org.apache.hadoop.fs.statistics.impl.StorageStatisticsFromIOStatistics:<init>(java.lang.String,java.lang.String,org.apache.hadoop.fs.statistics.IOStatistics)" : [ "<init>" ],
  "org.apache.hadoop.ipc.RpcClientUtil:getVersionSignatureMap(java.net.InetSocketAddress,java.lang.String,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:getAclStatus(org.apache.hadoop.fs.Path)" : [ "getAclStatus", "fullPath" ],
  "org.apache.hadoop.util.InstrumentedLock$SuppressedStats:snapshot()" : [ "<init>" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:newStat(java.lang.String,java.lang.String,java.lang.String,java.lang.String,boolean)" : [ "<init>", "checkMetricName" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:getLinkTarget(org.apache.hadoop.fs.Path)" : [ "getLinkTarget" ],
  "org.apache.hadoop.metrics2.impl.MetricCounterLong:<init>(org.apache.hadoop.metrics2.MetricsInfo,long)" : [ "<init>" ],
  "org.apache.hadoop.tools.protocolPB.GetUserMappingsProtocolClientSideTranslatorPB:getGroupsForUser(java.lang.String)" : [ "ipc" ],
  "org.apache.hadoop.metrics2.lib.MutableMetricsFactory:newForMethod(java.lang.Object,java.lang.reflect.Method,org.apache.hadoop.metrics2.annotation.Metric,org.apache.hadoop.metrics2.lib.MetricsRegistry)" : [ "<init>", "newForMethod", "getInfo", "add" ],
  "org.apache.hadoop.fs.store.DataBlocks$DiskBlock:innerClose()" : [ "closeBlock" ],
  "org.apache.hadoop.fs.shell.Ls:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.net.TableMapping$RawTableMapping:reloadCachedMappings(java.util.List)" : [ "reloadCachedMappings" ],
  "org.apache.hadoop.fs.statistics.impl.PairedDurationTrackerFactory:trackDuration(java.lang.String,long)" : [ "trackDuration" ],
  "org.apache.hadoop.crypto.key.KeyProviderCryptoExtension:createKeyProviderCryptoExtension(org.apache.hadoop.crypto.key.KeyProvider)" : [ "<init>", "getKeyProvider" ],
  "org.apache.hadoop.fs.FilterFs:satisfyStoragePolicy(org.apache.hadoop.fs.Path)" : [ "satisfyStoragePolicy" ],
  "org.apache.hadoop.service.AbstractService:isInState(org.apache.hadoop.service.Service$STATE)" : [ "isInState" ],
  "org.apache.hadoop.io.compress.BZip2Codec$BZip2CompressionInputStream:updatePos(boolean)" : [ "getProcessedByteCount" ],
  "org.apache.hadoop.util.dynamic.DynMethods$Builder:ctorImpl(java.lang.String,java.lang.Class[])" : [ "<init>", "impl", "buildChecked" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:onTimerEvent()" : [ "publishMetrics", "sampleMetrics" ],
  "org.apache.hadoop.io.ReadaheadPool:readaheadStream(java.lang.String,java.io.FileDescriptor,long,long,long,org.apache.hadoop.io.ReadaheadPool$ReadaheadRequest)" : [ "checkArgument", "submitReadahead" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:create(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,boolean,int,short,long,org.apache.hadoop.util.Progressable)" : [ "resolve", "getUriPath", "readOnlyMountTable" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.ByteBufferEncodingState:checkBuffers(java.nio.ByteBuffer[])" : [ "<init>" ],
  "org.apache.hadoop.conf.Configuration:size()" : [ "getProps" ],
  "org.apache.hadoop.util.StopWatch:toString()" : [ "now" ],
  "org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation:add(java.lang.String,long)" : [ "add" ],
  "org.apache.hadoop.fs.FileRange:createFileRange(long,int,java.lang.Object)" : [ "<init>" ],
  "org.apache.hadoop.fs.crypto.CryptoFSDataOutputStream:<init>(org.apache.hadoop.fs.FSDataOutputStream,org.apache.hadoop.crypto.CryptoCodec,int,byte[],byte[])" : [ "<init>" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner:checkKey()" : [ "atEnd", "readVInt", "reset", "isLastChunk", "getRemain" ],
  "org.apache.hadoop.fs.viewfs.ViewFsFileStatus:isFile()" : [ "isFile" ],
  "org.apache.hadoop.ipc.metrics.RetryCacheMetrics:getCacheUpdated()" : [ "value" ],
  "org.apache.hadoop.crypto.CryptoStreamUtils:checkBufferSize(org.apache.hadoop.crypto.CryptoCodec,int)" : [ "checkArgument", "getAlgorithmBlockSize" ],
  "org.apache.hadoop.ipc.WritableRpcEngine$Server:<init>(java.lang.Class,java.lang.Object,org.apache.hadoop.conf.Configuration,java.lang.String,int,int,int,int,boolean,org.apache.hadoop.security.token.SecretManager,java.lang.String,org.apache.hadoop.ipc.AlignmentContext)" : [ "<init>", "getProtocolInterfaces" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Factory:setWorkFactor(org.apache.hadoop.conf.Configuration,int)" : [ "setInt" ],
  "org.apache.hadoop.fs.impl.FileSystemMultipartUploader:createCollectorPath(org.apache.hadoop.fs.Path)" : [ "<init>", "mergePaths", "getParent", "getName" ],
  "org.apache.hadoop.conf.Configuration:getStreamReader(org.apache.hadoop.conf.Configuration$Resource,boolean)" : [ "getResource", "isParserRestricted", "parse", "toUri", "toString" ],
  "org.apache.hadoop.fs.Path:<init>(java.lang.String,org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.ha.ZKFailoverController:startRPC()" : [ "start" ],
  "org.apache.hadoop.fs.CompositeCrcFileChecksum:getBytes()" : [ "intToBytes" ],
  "org.apache.hadoop.io.ObjectWritable:readObject(java.io.DataInput,org.apache.hadoop.io.ObjectWritable,org.apache.hadoop.conf.Configuration)" : [ "<init>", "readObject", "readString", "loadClass", "newInstance", "tryInstantiateProtobuf" ],
  "org.apache.hadoop.fs.FileContext:<init>(org.apache.hadoop.fs.AbstractFileSystem,org.apache.hadoop.conf.Configuration)" : [ "get", "getCurrentUser", "getInitialWorkingDirectory", "getHomeDirectory", "getBoolean" ],
  "org.apache.hadoop.fs.FileSystem$Statistics:visitAll(org.apache.hadoop.fs.FileSystem$Statistics$StatisticsAggregator)" : [ "getData" ],
  "org.apache.hadoop.util.CrcComposer:newCrcComposer(org.apache.hadoop.util.DataChecksum$Type,long)" : [ "newStripedCrcComposer" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockOperations:requestCaching(int)" : [ "<init>", "checkNotNegative", "add" ],
  "org.apache.hadoop.fs.shell.CommandWithDestination:getRemoteDestination(java.util.LinkedList)" : [ "<init>", "expandAsGlob" ],
  "org.apache.hadoop.fs.PathIOException:<init>(java.lang.String,java.lang.Throwable)" : [ "<init>" ],
  "org.apache.hadoop.fs.statistics.impl.DynamicIOStatistics:addMinimumFunction(java.lang.String,java.util.function.Function)" : [ "addFunction" ],
  "org.apache.hadoop.fs.ContentSummary:toString(boolean,boolean)" : [ "toString" ],
  "org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool:select(java.nio.channels.SelectableChannel,int,long)" : [ "get", "now", "close", "release" ],
  "org.apache.hadoop.io.file.tfile.Chunk$ChunkEncoder:write(int)" : [ "flushBuffer" ],
  "org.apache.hadoop.io.Text:<init>(java.lang.String)" : [ "set" ],
  "org.apache.hadoop.net.StandardSocketFactory:createSocket(java.lang.String,int)" : [ "createSocket" ],
  "org.apache.hadoop.io.MapFile:rename(org.apache.hadoop.fs.FileSystem,java.lang.String,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext:confChanged(org.apache.hadoop.conf.Configuration)" : [ "<init>", "get", "getTrimmedStrings", "getLocal", "mkdirs", "exists", "isAbsolute", "makeQualified", "toUri" ],
  "org.apache.hadoop.io.VLongWritable:<init>(long)" : [ "set" ],
  "org.apache.hadoop.fs.store.DataBlocks$DiskBlockFactory:create(long,int,org.apache.hadoop.fs.store.BlockUploadStatistics)" : [ "<init>", "createTmpFileForWrite" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreImpl:addMinimumSample(java.lang.String,long)" : [ "maybeUpdateMinimum" ],
  "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker:getFileLength()" : [ "getLen" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:setStoragePolicy(org.apache.hadoop.fs.Path,java.lang.String)" : [ "setStoragePolicy", "fullPath" ],
  "org.apache.hadoop.security.alias.LocalKeyStoreProvider:initFileSystem(java.net.URI)" : [ "initFileSystem", "toString" ],
  "org.apache.hadoop.fs.FsShell:newShellInstance()" : [ "<init>" ],
  "org.apache.hadoop.io.BytesWritable:setSize(int)" : [ "getCapacity", "setCapacity" ],
  "org.apache.hadoop.fs.FilterFileSystem:getXAttrs(org.apache.hadoop.fs.Path,java.util.List)" : [ "getXAttrs" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:createKey(java.lang.String,org.apache.hadoop.crypto.key.KeyProvider$Options)" : [ "createKeyInternal" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsContextIntegration:setThreadIOStatisticsContext(org.apache.hadoop.fs.statistics.IOStatisticsContext)" : [ "removeForCurrentThread", "setForCurrentThread" ],
  "org.apache.hadoop.util.LightWeightResizableGSet:<init>()" : [ "<init>" ],
  "org.apache.hadoop.security.alias.LocalBouncyCastleFipsKeyStoreProvider:<init>(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.ipc.RPC$Builder:build()" : [ "<init>", "getProtocolEngine" ],
  "org.apache.hadoop.tools.TableListing$Builder:addField(java.lang.String,org.apache.hadoop.tools.TableListing$Justification)" : [ "addField" ],
  "org.apache.hadoop.metrics2.impl.MetricsRecordImpl:hashCode()" : [ "hashCode" ],
  "org.apache.hadoop.ipc.Server$Listener:doRead(java.nio.channels.SelectionKey)" : [ "setLastContact", "now", "readAndProcess", "shouldClose" ],
  "org.apache.hadoop.net.NetworkTopology:getDatanodesInRack(java.lang.String)" : [ "normalize" ],
  "org.apache.hadoop.security.UserGroupInformation:hasKerberosCredentials()" : [ "getAuthenticationMethod" ],
  "org.apache.hadoop.tools.CommandShell:run(java.lang.String[])" : [ "printShellUsage", "validate", "printException" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:setOwner(org.apache.hadoop.fs.Path,java.lang.String,java.lang.String)" : [ "setOwner", "pathToFile" ],
  "org.apache.hadoop.io.SequenceFile$Metadata:toString()" : [ "toString" ],
  "org.apache.hadoop.util.SysInfoLinux:<init>(java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.lang.String,long)" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.prefetch.FilePosition:isLastBlock()" : [ "isLastBlock", "blockNumber" ],
  "org.apache.hadoop.service.AbstractService:start()" : [ "isInState", "enterState", "serviceStart", "getName", "notifyListeners", "noteFailure", "stopQuietly", "convert" ],
  "org.apache.hadoop.security.KDiag:execute()" : [ "<init>", "title", "println", "validateKeyLength", "printSysprop", "endln", "printEnv", "printConfOpt", "isSimpleAuthentication", "failif", "getAndSet", "setConfiguration", "validateHadoopTokenFiles", "validateKrb5File", "printDefaultRealm", "validateSasl", "get", "validateKinitExecutable", "validateJAAS", "validateNTPConf", "validateShortName", "dumpKeytab", "loginFromKeytab", "getLoginUser", "dumpUGI", "validateUGI", "isLoginTicketBased", "isLoginKeytabBased" ],
  "org.apache.hadoop.security.SaslRpcServer$AuthMethod:read(java.io.DataInput)" : [ "valueOf" ],
  "org.apache.hadoop.util.StringUtils:unEscapeString(java.lang.String,char,char[])" : [ "hasChar" ],
  "org.apache.hadoop.io.BloomMapFile$Writer:close()" : [ "<init>", "close", "create", "write", "closeStream" ],
  "org.apache.hadoop.crypto.key.KeyProviderExtension:createKey(java.lang.String,org.apache.hadoop.crypto.key.KeyProvider$Options)" : [ "createKey" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:satisfyStoragePolicy(org.apache.hadoop.fs.Path)" : [ "readOnlyMountTable" ],
  "org.apache.hadoop.ipc.Client$Connection:run()" : [ "waitForWork", "receiveRpcResponse", "markClosed", "close" ],
  "org.apache.hadoop.net.unix.DomainSocketWatcher:sendCallbackAndRemove(java.lang.String,java.util.TreeMap,org.apache.hadoop.net.unix.DomainSocketWatcher$FdSet,int)" : [ "sendCallback" ],
  "org.apache.hadoop.fs.ContentSummary$Builder:typeConsumed(long[])" : [ "typeConsumed" ],
  "org.apache.hadoop.io.compress.GzipCodec:createDirectDecompressor()" : [ "<init>", "isNativeZlibLoaded" ],
  "org.apache.hadoop.fs.permission.AclEntry:toString()" : [ "toStringStable" ],
  "org.apache.hadoop.util.functional.TaskPool:foreach(java.lang.Object[])" : [ "<init>" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:configureSystem()" : [ "tag", "getHostname" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsSnapshot:setGauge(java.lang.String,long)" : [ "gauges" ],
  "org.apache.hadoop.ipc.Server:setupResponseForProtobuf(org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto,org.apache.hadoop.io.Writable)" : [ "getMessage", "getDelimitedLength" ],
  "org.apache.hadoop.io.compress.BlockCompressorStream:finish()" : [ "rawWriteInt", "compress" ],
  "org.apache.hadoop.fs.ChecksumFs:getChecksumFile(org.apache.hadoop.fs.Path)" : [ "<init>", "getParent", "getName" ],
  "org.apache.hadoop.util.HttpExceptionUtils:createServletExceptionResponse(javax.servlet.http.HttpServletResponse,int,java.lang.Throwable)" : [ "getOneLineMessage", "writer" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:getFileStatus(com.jcraft.jsch.ChannelSftp,com.jcraft.jsch.ChannelSftp$LsEntry,org.apache.hadoop.fs.Path)" : [ "<init>", "getFileStatus", "toUri", "isDirectory", "getLen", "getPermissions", "makeQualified", "getUri", "getWorkingDirectory" ],
  "org.apache.hadoop.fs.AbstractFileSystem:createMultipartUploader(org.apache.hadoop.fs.Path)" : [ "methodNotSupported" ],
  "org.apache.hadoop.ha.HealthMonitor$MonitorDaemon:run()" : [ "checkState" ],
  "org.apache.hadoop.fs.Globber:authorityFromPath(org.apache.hadoop.fs.Path)" : [ "toUri", "getUri", "getFSofPath", "fixRelativePart" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner:lowerBound(byte[],int,int)" : [ "<init>", "seekTo" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:getRecordNumByLocation(org.apache.hadoop.io.file.tfile.TFile$Reader$Location)" : [ "getRecordNumByLocation", "checkTFileDataIndex" ],
  "org.apache.hadoop.io.SequenceFile$Sorter:merge(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "merge", "getSegmentList" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:setReplication(org.apache.hadoop.fs.Path,short)" : [ "setReplication" ],
  "org.apache.hadoop.util.bloom.Key:compareTo(org.apache.hadoop.util.bloom.Key)" : [ "getBytes" ],
  "org.apache.hadoop.fs.store.ByteBufferInputStream:available()" : [ "checkOpenState" ],
  "org.apache.hadoop.security.token.delegation.DelegationKey:<init>()" : [ "<init>" ],
  "org.apache.hadoop.io.WritableUtils:writeCompressedStringArray(java.io.DataOutput,java.lang.String[])" : [ "writeCompressedString" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:access(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsAction)" : [ "access", "fullPath" ],
  "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream:getIOStatistics()" : [ "retrieveIOStatistics" ],
  "org.apache.hadoop.fs.statistics.impl.DynamicIOStatisticsBuilder:withAtomicIntegerMaximum(java.lang.String,java.util.concurrent.atomic.AtomicInteger)" : [ "withLongFunctionMaximum" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem:processThrowable(org.apache.hadoop.fs.viewfs.NflyFSystem$NflyNode,java.lang.String,java.lang.Throwable,java.util.List,org.apache.hadoop.fs.Path[])" : [ "getUri" ],
  "org.apache.hadoop.security.SecurityUtil$TruststoreKeystore:<init>(org.apache.hadoop.conf.Configuration)" : [ "get" ],
  "org.apache.hadoop.security.SecurityUtil$QualifiedHostResolver:getByExactName(java.lang.String)" : [ "getInetAddressByName" ],
  "org.apache.hadoop.util.functional.LazyAutoCloseableReference:eval()" : [ "eval", "checkState" ],
  "org.apache.hadoop.fs.FsServerDefaults:<init>(long,int,int,short,int,boolean,long,org.apache.hadoop.util.DataChecksum$Type)" : [ "<init>" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:getNativeFileLinkStatus(org.apache.hadoop.fs.Path,boolean)" : [ "<init>", "getFileStatus" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:mkdir(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,boolean)" : [ "fullPath" ],
  "org.apache.hadoop.io.file.tfile.Compression$FinishOnFlushCompressionStream:flush()" : [ "flush" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:getProcessingStdDev()" : [ "stddev" ],
  "org.apache.hadoop.crypto.JceSm4CtrCryptoCodec:calculateIV(byte[],long,byte[])" : [ "calculateIV", "getCipherSuite", "getAlgorithmBlockSize" ],
  "org.apache.hadoop.io.file.tfile.TFile:makeComparator(java.lang.String)" : [ "makeComparator" ],
  "org.apache.hadoop.io.LongWritable$Comparator:<init>()" : [ "<init>" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:registerSink(java.lang.String,java.lang.String,org.apache.hadoop.metrics2.MetricsSink)" : [ "checkNotNull", "newSink", "subset", "start" ],
  "org.apache.hadoop.fs.Globber:fixRelativePart(org.apache.hadoop.fs.Path)" : [ "fixRelativePart" ],
  "org.apache.hadoop.io.Text:toString()" : [ "decode" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:getTokenRealOwner(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier)" : [ "getRealUser", "toString", "getUser", "getUserName" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtobufRpcEngineCallbackImpl:error(java.lang.Throwable)" : [ "now", "setDeferredError" ],
  "org.apache.hadoop.fs.FileSystem:getCanonicalUri()" : [ "canonicalizeUri" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkNotNegative(long,java.lang.String)" : [ "checkArgument" ],
  "org.apache.hadoop.fs.FileUtil:createJarWithClassPath(java.lang.String,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,java.util.Map)" : [ "<init>", "replaceTokens", "toString", "getJarsInDirectory", "toUri", "isAbsolute", "join" ],
  "org.apache.hadoop.fs.impl.FsLinkResolution:resolve(org.apache.hadoop.fs.FileContext,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.impl.FsLinkResolution$FsLinkResolutionFunction)" : [ "<init>" ],
  "org.apache.hadoop.io.file.tfile.Chunk$ChunkDecoder:read(byte[],int,int)" : [ "checkEOF" ],
  "org.apache.hadoop.crypto.key.kms.ValueQueue:getLock(java.lang.String)" : [ "indexFor" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:renameSnapshot(org.apache.hadoop.fs.Path,java.lang.String,java.lang.String)" : [ "renameSnapshot", "resolve", "getUriPath" ],
  "org.apache.hadoop.fs.FsUrlStreamHandlerFactory:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>", "getFileSystemClass" ],
  "org.apache.hadoop.io.SequenceFile$Reader:handleChecksumException(org.apache.hadoop.fs.ChecksumException)" : [ "getBoolean", "getPosition", "sync", "getInt" ],
  "org.apache.hadoop.io.compress.Lz4Codec:createOutputStream(java.io.OutputStream)" : [ "createOutputStreamWithCodecPool" ],
  "org.apache.hadoop.fs.FilterFs:resolvePath(org.apache.hadoop.fs.Path)" : [ "resolvePath" ],
  "org.apache.hadoop.fs.FsShell:run(java.lang.String[])" : [ "<init>", "run", "init", "conf", "wrapHadoopConf", "build", "printUsage", "getInstance", "newScope", "getSpan", "join", "addKVAnnotation", "close", "displayError", "printInstanceUsage" ],
  "org.apache.hadoop.fs.AbstractFileSystem:open(org.apache.hadoop.fs.Path)" : [ "getServerDefaults", "getFileBufferSize" ],
  "org.apache.hadoop.fs.TrashPolicyDefault:makeTrashRelativePath(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "mergePaths" ],
  "org.apache.hadoop.fs.ChecksumFileSystem:isChecksumFile(org.apache.hadoop.fs.Path)" : [ "getName" ],
  "org.apache.hadoop.fs.impl.CombinedFileRange:merge(long,long,org.apache.hadoop.fs.FileRange,int,int)" : [ "append" ],
  "org.apache.hadoop.fs.ChecksumFs$ChecksumFSInputChecker:read(long,byte[],int,int)" : [ "<init>", "seek", "close" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:toString()" : [ "tags", "metrics" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkPathExistsAsFile(java.nio.file.Path,java.lang.String)" : [ "checkPathExists", "checkArgument" ],
  "org.apache.hadoop.net.AbstractDNSToSwitchMapping:isSingleSwitchByScriptPolicy()" : [ "get" ],
  "org.apache.hadoop.fs.shell.Command:isPathRecursable(org.apache.hadoop.fs.shell.PathData)" : [ "isDirectory" ],
  "org.apache.hadoop.service.ServiceStateModel:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.net.NetworkTopology:getInstance(org.apache.hadoop.conf.Configuration,org.apache.hadoop.net.InnerNode$Factory)" : [ "newInstance", "getClass", "init" ],
  "org.apache.hadoop.fs.shell.TouchCommands$Touch:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "touch" ],
  "org.apache.hadoop.fs.RawLocalFileSystem$AsyncHandler:completed(java.lang.Integer,java.lang.Integer)" : [ "failed" ],
  "org.apache.hadoop.util.GenericOptionsParser:<init>(java.lang.String[])" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ConfigUtil:addLinkRegex(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String,java.lang.String,java.lang.String)" : [ "getConfigViewFsPrefix", "set" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:<init>(java.io.InputStream,org.apache.hadoop.io.compress.SplittableCompressionCodec$READ_MODE)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.zstd.ZStandardCompressor:<init>()" : [ "<init>" ],
  "org.apache.hadoop.util.InstrumentedLock:<init>(java.lang.String,org.slf4j.Logger,java.util.concurrent.locks.Lock,long,long,org.apache.hadoop.util.Timer)" : [ "monotonicNow" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:getFsStatus()" : [ "<init>" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:addRpcLockWaitTime(long)" : [ "add" ],
  "org.apache.hadoop.tools.GetGroupsBase:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.io.erasurecode.codec.XORErasureCodec:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.io.erasurecode.ErasureCodecOptions)" : [ "<init>", "getSchema", "getNumParityUnits" ],
  "org.apache.hadoop.fs.impl.prefetch.BufferData:<init>(int,java.nio.ByteBuffer)" : [ "checkNotNegative", "checkNotNull" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Compressor:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>", "getBlockSize", "getWorkFactor" ],
  "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker:<init>(org.apache.hadoop.fs.ChecksumFileSystem,org.apache.hadoop.fs.Path)" : [ "<init>", "getInt" ],
  "org.apache.hadoop.ha.HAAdmin:checkManualStateManagementOK(org.apache.hadoop.ha.HAServiceTarget)" : [ "isAutoFailoverEnabled" ],
  "org.apache.hadoop.io.SequenceFile$Sorter$SortPass:flush(int,int,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec,boolean)" : [ "<init>", "suffix", "create", "getPos", "createWriter", "stream", "keyClass", "valueClass", "compression", "metadata", "appendRaw", "close", "writeVLong" ],
  "org.apache.hadoop.ipc.WritableRpcEngine:initialize()" : [ "registerProtocolEngine" ],
  "org.apache.hadoop.security.SecurityUtil:isOriginalTGT(javax.security.auth.kerberos.KerberosTicket)" : [ "isTGSPrincipal" ],
  "org.apache.hadoop.security.UserGroupInformation:forceReloginFromKeytab()" : [ "reloginFromKeytab" ],
  "org.apache.hadoop.security.token.delegation.SQLDelegationTokenSecretManager:storeDelegationKey(org.apache.hadoop.security.token.delegation.DelegationKey)" : [ "storeDelegationKey", "write", "getKeyId" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "rename", "connect", "disconnect" ],
  "org.apache.hadoop.fs.HarFileSystem:toFileStatus(org.apache.hadoop.fs.HarFileSystem$HarStatus)" : [ "<init>", "getPartFileStatus", "getModificationTime", "isDir", "getLength", "getReplication", "getBlockSize", "getAccessTime", "getPermission", "getOwner", "getGroup", "makeRelative" ],
  "org.apache.hadoop.util.functional.RemoteIterators$RangeExcludingLongIterator:next()" : [ "hasNext" ],
  "org.apache.hadoop.io.SequenceFile$Sorter:sort(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "sort" ],
  "org.apache.hadoop.security.KDiag:run(java.lang.String[])" : [ "popOptionWithArgument", "popOption", "verify", "addDefaultResource", "println", "usage", "execute" ],
  "org.apache.hadoop.io.nativeio.NativeIO$POSIX:munmap(java.nio.MappedByteBuffer)" : [ "getCleaner" ],
  "org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider:getCredentialEntry(java.lang.String)" : [ "<init>", "getPathAsString", "bytesToChars" ],
  "org.apache.hadoop.util.StopWatch:now()" : [ "monotonicNowNanos" ],
  "org.apache.hadoop.fs.HarFileSystem$HarFSDataInputStream$HarFsInputStream:skip(long)" : [ "seek" ],
  "org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler:getPassword(org.apache.hadoop.security.token.TokenIdentifier)" : [ "encodePassword", "retriableRetrievePassword" ],
  "org.apache.hadoop.io.erasurecode.codec.DummyErasureCodec:createDecoder()" : [ "<init>" ],
  "org.apache.hadoop.io.erasurecode.codec.DummyErasureCodec:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.io.erasurecode.ErasureCodecOptions)" : [ "<init>" ],
  "org.apache.hadoop.util.functional.TaskPool$Builder:run(org.apache.hadoop.util.functional.TaskPool$Task)" : [ "runParallel", "runSingleThreaded" ],
  "org.apache.hadoop.security.LdapGroupsMapping:getGroupsSet(java.lang.String)" : [ "doGetGroups", "switchBindUser", "failover" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:setGauge(java.lang.String,long)" : [ "getInnerStatistics" ],
  "org.apache.hadoop.security.Groups:getUserToGroupsMappingService(org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.net.TableMapping$RawTableMapping:load()" : [ "get" ],
  "org.apache.hadoop.fs.FileContext:getStatistics(java.net.URI)" : [ "getStatistics" ],
  "org.apache.hadoop.io.compress.lz4.Lz4Decompressor:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getXAttr(org.apache.hadoop.fs.Path,java.lang.String)" : [ "getXAttr", "resolve", "getUriPath" ],
  "org.apache.hadoop.fs.impl.AbstractFSBuilderImpl:opt(java.lang.String,float)" : [ "optLong" ],
  "org.apache.hadoop.net.InnerNodeImpl:<init>(java.lang.String,java.lang.String,org.apache.hadoop.net.InnerNode,int)" : [ "<init>" ],
  "org.apache.hadoop.conf.StorageUnit$2:getDefault(double)" : [ "toPBs" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:delete(org.apache.hadoop.fs.Path)" : [ "delete" ],
  "org.apache.hadoop.io.file.tfile.Utils:readVInt(java.io.DataInput)" : [ "readVLong" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Reader:<init>(org.apache.hadoop.fs.FSDataInputStream,long,org.apache.hadoop.conf.Configuration)" : [ "<init>", "seek", "size", "readAndVerify", "compatibleWith", "getMetaBlock", "close" ],
  "org.apache.hadoop.fs.FileSystem$Statistics:getRemoteReadTime()" : [ "<init>", "visitAll" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:unsetStoragePolicy(org.apache.hadoop.fs.Path)" : [ "unsetStoragePolicy", "fullPath" ],
  "org.apache.hadoop.fs.ChecksumFs:delete(org.apache.hadoop.fs.Path,boolean)" : [ "isDirectory", "getChecksumFile", "exists" ],
  "org.apache.hadoop.util.JvmPauseMonitor:main(java.lang.String[])" : [ "<init>", "newArrayList" ],
  "org.apache.hadoop.fs.http.HttpsFileSystem:rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "rename" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:stripOutRoot(org.apache.hadoop.fs.Path)" : [ "toUri", "isRoot" ],
  "org.apache.hadoop.io.MapFile$Writer:compression(org.apache.hadoop.io.SequenceFile$CompressionType)" : [ "compression" ],
  "org.apache.hadoop.conf.Configuration:getClassByName(java.lang.String)" : [ "getClassByNameOrNull" ],
  "org.apache.hadoop.crypto.CryptoOutputStream:<init>(java.io.OutputStream,org.apache.hadoop.crypto.CryptoCodec,byte[],byte[])" : [ "<init>" ],
  "org.apache.hadoop.ipc.Client:getCallId()" : [ "nextCallId" ],
  "org.apache.hadoop.security.Credentials:writeWritableOutputStream(java.io.DataOutputStream)" : [ "write" ],
  "org.apache.hadoop.fs.impl.AbstractFSBuilderImpl:rejectUnknownMandatoryKeys(java.util.Collection,java.lang.String)" : [ "rejectUnknownMandatoryKeys" ],
  "org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation:aggregateLocalStatesToGlobalMetrics(java.util.concurrent.ConcurrentMap)" : [ "addMetricIfNotExists", "snapshotInto" ],
  "org.apache.hadoop.ipc.metrics.RetryCacheMetrics:<init>(org.apache.hadoop.ipc.RetryCache)" : [ "<init>", "getCacheName" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:iostatistics_toPrettyString(java.lang.Object)" : [ "checkIoStatisticsAvailable", "invoke" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:getServerDefaults()" : [ "getServerDefaults", "fullPath" ],
  "org.apache.hadoop.security.UserGroupInformation:setAuthenticationMethod(org.apache.hadoop.security.SaslRpcServer$AuthMethod)" : [ "setAuthenticationMethod", "valueOf" ],
  "org.apache.hadoop.fs.shell.PathData:refreshStatus()" : [ "lookupStat", "toString", "setStat" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenManager:verifyToken(org.apache.hadoop.security.token.Token)" : [ "verifyToken", "decodeTokenIdentifier", "getPassword", "getUser" ],
  "org.apache.hadoop.fs.permission.AclEntryType:toString()" : [ "toStringStable" ],
  "org.apache.hadoop.net.SocketIOWithTimeout:connect(java.nio.channels.SocketChannel,java.net.SocketAddress,int)" : [ "now", "select", "timeoutExceptionString" ],
  "org.apache.hadoop.ipc.ProcessingDetails:toString()" : [ "get" ],
  "org.apache.hadoop.conf.Configuration:getEnumSet(java.lang.String,java.lang.Class,boolean)" : [ "get", "parseEnumSet" ],
  "org.apache.hadoop.fs.impl.FutureDataInputStreamBuilderImpl:bufferSize(int)" : [ "getThisBuilder" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:getActualUgi()" : [ "getCurrentUser", "logAllUserInfo", "getRealUser", "isSecurityEnabled", "containsKmsDt", "shouldRelogin", "getLoginUser" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:getXAttr(org.apache.hadoop.fs.Path,java.lang.String)" : [ "getXAttr", "fullPath" ],
  "org.apache.hadoop.fs.FilterFileSystem:getServerDefaults()" : [ "getServerDefaults" ],
  "org.apache.hadoop.fs.viewfs.InodeTree:getRemainingPath(java.lang.String[],int)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:getFileStatus(org.apache.hadoop.fs.Path)" : [ "<init>", "checkPathIsSlash", "getShortUserName", "getPrimaryGroupName", "makeQualified" ],
  "org.apache.hadoop.fs.http.HttpFileSystem:setWorkingDirectory(org.apache.hadoop.fs.Path)" : [ "setWorkingDirectory" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:uncaughtException(java.lang.Thread,java.lang.Throwable)" : [ "exit", "convertToExitException" ],
  "org.apache.hadoop.io.erasurecode.coder.DummyErasureEncoder:<init>(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Reader:getBlockIndexNear(long)" : [ "<init>", "getBlockRegionList", "lowerBound" ],
  "org.apache.hadoop.ipc.ResponseBuffer:toByteArray()" : [ "getFramedBuffer" ],
  "org.apache.hadoop.util.Shell$1:run()" : [ "isTimedOut" ],
  "org.apache.hadoop.io.SequenceFile$Writer$CompressionOption:<init>(org.apache.hadoop.io.SequenceFile$CompressionType)" : [ "<init>" ],
  "org.apache.hadoop.security.token.Token:buildCacheKey()" : [ "getBytes" ],
  "org.apache.hadoop.io.BloomMapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,java.lang.Class,java.lang.Class)" : [ "<init>" ],
  "org.apache.hadoop.util.Lists:newArrayList(java.util.Iterator)" : [ "newArrayList", "addAll" ],
  "org.apache.hadoop.io.compress.DecompressorStream:<init>(java.io.InputStream,org.apache.hadoop.io.compress.Decompressor,int)" : [ "<init>" ],
  "org.apache.hadoop.fs.FilterFileSystem:listStatusIterator(org.apache.hadoop.fs.Path)" : [ "listStatusIterator" ],
  "org.apache.hadoop.ipc.Server$Call:sendResponse()" : [ "doResponse" ],
  "org.apache.hadoop.io.retry.AsyncCallHandler$AsyncValue:waitAsyncValue(long,java.util.concurrent.TimeUnit)" : [ "wait" ],
  "org.apache.hadoop.security.UserGroupInformation:reloginFromTicketCache(boolean)" : [ "<init>", "shouldRelogin", "isFromTicket", "getLogin", "relogin" ],
  "org.apache.hadoop.util.ReflectionUtils:getFactory(org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.net.NetworkTopology:getLeaves(java.lang.String)" : [ "getNode" ],
  "org.apache.hadoop.util.HostsFileReader:refresh()" : [ "refresh" ],
  "org.apache.hadoop.fs.FileSystem:hasPathCapability(org.apache.hadoop.fs.Path,java.lang.String)" : [ "validatePathCapabilityArgs", "makeQualified", "supportsSymlinks", "areSymlinksEnabled" ],
  "org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec:<init>()" : [ "getLoadingFailureReason" ],
  "org.apache.hadoop.fs.impl.prefetch.FilePosition:throwIfInvalidBuffer()" : [ "checkState" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.util.RSUtil:initTables(int,int,byte[],int,byte[])" : [ "gfVectMulInit" ],
  "org.apache.hadoop.security.token.Token:decodeWritable(org.apache.hadoop.io.Writable,java.lang.String)" : [ "<init>", "reset" ],
  "org.apache.hadoop.ipc.Client:call(org.apache.hadoop.ipc.RPC$RpcKind,org.apache.hadoop.io.Writable,org.apache.hadoop.ipc.Client$ConnectionId,int,java.util.concurrent.atomic.AtomicBoolean,org.apache.hadoop.ipc.AlignmentContext)" : [ "createCall", "setAlignmentContext", "getConnection", "checkAsyncCall", "sendRpcRequest", "isAsynchronousMode", "releaseAsyncCall", "getRpcResponse" ],
  "org.apache.hadoop.ipc.RetryCache:waitForCompletion(org.apache.hadoop.ipc.RetryCache$CacheEntry)" : [ "get", "put", "incrCacheUpdated", "incrCacheHit", "checkNotNull" ],
  "org.apache.hadoop.io.compress.CompressionCodec$Util:createOutputStreamWithCodecPool(org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.conf.Configuration,java.io.OutputStream)" : [ "getCompressor", "returnCompressor", "setTrackedCompressor" ],
  "org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory:getPassword(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String)" : [ "getPassword" ],
  "org.apache.hadoop.fs.viewfs.ConfigUtil:getHomeDirValue(org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "get", "getConfigViewFsPrefix" ],
  "org.apache.hadoop.io.compress.CodecPool:getLeasedCompressorsCount(org.apache.hadoop.io.compress.CompressionCodec)" : [ "getLeaseCount" ],
  "org.apache.hadoop.security.token.DtFileOperations:appendTokenFiles(java.util.ArrayList,java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "<init>", "readTokenStorageFile", "getAllTokens", "addToken", "getService", "doFormattedWrite" ],
  "org.apache.hadoop.ipc.CallQueueManager:getPriorityLevel(org.apache.hadoop.security.UserGroupInformation)" : [ "getPriorityLevel" ],
  "org.apache.hadoop.util.bloom.Key:equals(java.lang.Object)" : [ "compareTo" ],
  "org.apache.hadoop.metrics2.source.JvmMetrics:setGcTimeMonitor(org.apache.hadoop.util.GcTimeMonitor)" : [ "checkNotNull" ],
  "org.apache.hadoop.ipc.Server$Responder:processResponse(java.util.LinkedList,boolean)" : [ "monotonicNowNanos", "incPending", "decPending" ],
  "org.apache.hadoop.io.SequenceFile$Sorter$SegmentDescriptor:nextRawKey()" : [ "<init>", "nextRawKey", "file", "bufferSize", "start", "length", "ignoreSync", "getKeyClass", "getValueClass", "reset" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationHandler:delegationTokenToJSON(org.apache.hadoop.security.token.Token)" : [ "encodeToUrlString" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:parentZNodeExists()" : [ "checkState" ],
  "org.apache.hadoop.ipc.RetryCache$CacheEntryWithPayload:<init>(byte[],int,java.lang.Object,long,boolean)" : [ "<init>" ],
  "org.apache.hadoop.fs.store.DataBlocks$ByteBufferBlockFactory$ByteBufferBlock:hasCapacity(long)" : [ "remainingCapacity" ],
  "org.apache.hadoop.util.IdentityHashStore:remove(java.lang.Object)" : [ "getElementIndex" ],
  "org.apache.hadoop.util.StopWatch:now(java.util.concurrent.TimeUnit)" : [ "now" ],
  "org.apache.hadoop.fs.FSDataInputStream:unbuffer()" : [ "unbuffer" ],
  "org.apache.hadoop.util.ShutdownHookManager:removeShutdownHook(java.lang.Runnable)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Compressor:getBytesWritten()" : [ "checkStream" ],
  "org.apache.hadoop.ipc.ProtocolProxy:fetchServerMethods(java.lang.reflect.Method)" : [ "<init>", "getProtocolVersion", "getFingerprint", "getMethods", "getProtocolName", "getVersion" ],
  "org.apache.hadoop.security.ShellBasedIdMapping:getUserName(int,java.lang.String)" : [ "checkAndUpdateMaps", "updateMapIncr" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner$Entry:get(org.apache.hadoop.io.BytesWritable,org.apache.hadoop.io.BytesWritable)" : [ "getKey", "getValue" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner$Entry:hashCode()" : [ "hashBytes", "getKeyLength" ],
  "org.apache.hadoop.ipc.metrics.DecayRpcSchedulerDetailedMetrics:<init>(java.lang.String)" : [ "<init>", "tag", "info" ],
  "org.apache.hadoop.ipc.FairCallQueue:put(java.lang.Object)" : [ "put" ],
  "org.apache.hadoop.metrics2.lib.MetricsSourceBuilder:build()" : [ "<init>" ],
  "org.apache.hadoop.conf.ConfServlet:writeResponse(org.apache.hadoop.conf.Configuration,java.io.Writer,java.lang.String)" : [ "writeResponse" ],
  "org.apache.hadoop.fs.impl.AbstractFSBuilderImpl:opt(java.lang.String,java.lang.String[])" : [ "setStrings", "getThisBuilder" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Compressor:<init>()" : [ "<init>" ],
  "org.apache.hadoop.ipc.FairCallQueue:add(java.lang.Object)" : [ "add" ],
  "org.apache.hadoop.security.UserGroupInformation:reloginFromKeytab(boolean)" : [ "reloginFromKeytab" ],
  "org.apache.hadoop.fs.shell.SnapshotCommands$RenameSnapshot:processArguments(java.util.LinkedList)" : [ "checkArgument", "renameSnapshot" ],
  "org.apache.hadoop.metrics2.util.MBeans:register(java.lang.String,java.lang.String,java.lang.Object)" : [ "register" ],
  "org.apache.hadoop.io.UTF8:<init>(org.apache.hadoop.io.UTF8)" : [ "set" ],
  "org.apache.hadoop.io.file.tfile.TFile$TFileIndex:write(java.io.DataOutput)" : [ "<init>", "write", "writeVInt", "size", "buffer", "getData", "getLength", "reset" ],
  "org.apache.hadoop.fs.FilterFs:access(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsAction)" : [ "access", "checkPath" ],
  "org.apache.hadoop.io.UTF8:writeString(java.io.DataOutput,java.lang.String)" : [ "utf8Length", "writeChars" ],
  "org.apache.hadoop.fs.Path:isWindowsAbsolutePath(java.lang.String,boolean)" : [ "startPositionWithoutWindowsDrive" ],
  "org.apache.hadoop.ipc.WritableRpcEngine$Server$WritableRpcInvoker:call(org.apache.hadoop.ipc.RPC$Server,java.lang.String,org.apache.hadoop.io.Writable,long)" : [ "<init>", "getRpcVersion", "getHighestSupportedProtocol", "getProtocolImplMap", "getMethodName", "getParameterClasses", "init", "setDetailedMetricsName", "getParameters" ],
  "org.apache.hadoop.fs.audit.CommonAuditContext:init()" : [ "put", "currentThreadID" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtobufRpcEngineCallbackImpl:setResponse(com.google.protobuf.Message)" : [ "now", "setDeferredResponse", "wrap" ],
  "org.apache.hadoop.fs.impl.FileSystemMultipartUploader:startUpload(org.apache.hadoop.fs.Path)" : [ "eval" ],
  "org.apache.hadoop.fs.TrashPolicyDefault:createCheckpoint(java.util.Date)" : [ "createCheckpoint", "getTrashRoots", "getPath" ],
  "org.apache.hadoop.security.token.delegation.SQLDelegationTokenSecretManager:createTokenIdent(byte[])" : [ "readFields" ],
  "org.apache.hadoop.io.compress.zlib.ZlibDecompressor:finalize()" : [ "end" ],
  "org.apache.hadoop.fs.Options$HandleOpt:moved(boolean)" : [ "<init>" ],
  "org.apache.hadoop.security.protocolPB.RefreshUserMappingsProtocolClientSideTranslatorPB:refreshSuperUserGroupsConfiguration()" : [ "ipc" ],
  "org.apache.hadoop.security.token.DtUtilShell:main(java.lang.String[])" : [ "<init>", "run" ],
  "org.apache.hadoop.fs.RawLocalFileSystem$DeprecatedRawLocalFileStatus:loadPermissionInfo()" : [ "isPermissionLoaded", "isAvailable", "loadPermissionInfoByNativeIO", "loadPermissionInfoByNonNativeIO" ],
  "org.apache.hadoop.net.unix.DomainSocket:getAttribute(int)" : [ "reference", "unreference" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.ByteArrayDecodingState:checkInputBuffers(byte[][])" : [ "<init>", "getNumDataUnits" ],
  "org.apache.hadoop.log.LogLevel$CLI:doGetLevel()" : [ "process" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem:getWorkingDirectory()" : [ "getWorkingDirectory" ],
  "org.apache.hadoop.security.KerberosAuthException:<init>(java.lang.String,java.lang.Throwable)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.BlockDecompressorStream:<init>(java.io.InputStream)" : [ "<init>" ],
  "org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext$PathIterator:next()" : [ "advance" ],
  "org.apache.hadoop.util.functional.FunctionalIO:toUncheckedFunction(org.apache.hadoop.util.functional.FunctionRaisingIOE)" : [ "unchecked" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedIO:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.prefetch.BufferPool:releaseReadyBlock(int)" : [ "getAll", "stateEqualsOneOf", "distance", "setDone" ],
  "org.apache.hadoop.fs.store.DataBlocks$ArrayBlockFactory:<init>(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.crypto.JceCtrCryptoCodec:setConf(org.apache.hadoop.conf.Configuration)" : [ "setProvider", "get" ],
  "org.apache.hadoop.util.FindClass:usage(java.lang.String[])" : [ "err", "explainResult" ],
  "org.apache.hadoop.util.LineReader:readDefaultLine(org.apache.hadoop.io.Text,int,int)" : [ "clear", "fillBuffer", "append" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:getTransferMode(org.apache.hadoop.conf.Configuration)" : [ "get" ],
  "org.apache.hadoop.io.compress.BZip2Codec$BZip2CompressionInputStream:read(byte[],int,int)" : [ "read", "internalReset", "updatePos" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:setupRandPartA()" : [ "updateCRC", "endBlock", "initBlock" ],
  "org.apache.hadoop.fs.viewfs.ViewFsFileStatus:getSymlink()" : [ "getSymlink" ],
  "org.apache.hadoop.metrics2.impl.MetricsCollectorImpl:addRecord(org.apache.hadoop.metrics2.MetricsInfo)" : [ "<init>" ],
  "org.apache.hadoop.ha.HAAdmin:transitionToActive(org.apache.commons.cli.CommandLine)" : [ "transitionToActive", "printUsage", "isOtherTargetNodeActive", "checkManualStateManagementOK", "getProxy", "createReqInfo" ],
  "org.apache.hadoop.fs.LocalFileSystem:<init>(org.apache.hadoop.fs.FileSystem)" : [ "<init>" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:setConfigurationFromURI(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>", "get", "set", "getInt", "setInt" ],
  "org.apache.hadoop.ipc.ProxyCombiner$CombinedProxyInvocationHandler:getConnectionId()" : [ "getConnectionIdForProxy" ],
  "org.apache.hadoop.fs.statistics.impl.DynamicIOStatisticsBuilder:withAtomicIntegerGauge(java.lang.String,java.util.concurrent.atomic.AtomicInteger)" : [ "withLongFunctionGauge" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:getDelegationTokens(java.lang.String)" : [ "getDelegationTokens", "getTargetFileSystem" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding:entryToString(java.util.Map$Entry)" : [ "entryToString" ],
  "org.apache.hadoop.util.VersionInfo:getProtocVersion()" : [ "_getProtocVersion" ],
  "org.apache.hadoop.util.IdentityHashStore:get(java.lang.Object)" : [ "getElementIndex" ],
  "org.apache.hadoop.security.Groups:getGroups(java.lang.String)" : [ "getGroupInternal" ],
  "org.apache.hadoop.util.bloom.DynamicBloomFilter:add(org.apache.hadoop.util.bloom.Key)" : [ "add", "getActiveStandardBF", "addRow" ],
  "org.apache.hadoop.security.RuleBasedLdapGroupsMapping:setConf(org.apache.hadoop.conf.Configuration)" : [ "setConf", "get" ],
  "org.apache.hadoop.io.compress.snappy.SnappyDecompressor:needsInput()" : [ "setInputFromSavedData" ],
  "org.apache.hadoop.fs.FsUrlStreamHandlerFactory:<init>()" : [ "<init>" ],
  "org.apache.hadoop.net.InnerNodeImpl:remove(org.apache.hadoop.net.Node)" : [ "isAncestor", "isParent", "getNextAncestorName", "getNumOfChildren" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Reader$BlockReader:getRawSize()" : [ "getRawSize", "getBlockRegion" ],
  "org.apache.hadoop.util.dynamic.DynConstructors$Ctor:invoke(java.lang.Object,java.lang.Object[])" : [ "checkArgument", "newInstance" ],
  "org.apache.hadoop.fs.shell.SnapshotCommands$CreateSnapshot:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "isDirectory", "toString" ],
  "org.apache.hadoop.net.unix.DomainSocketWatcher:addNotificationSocket(java.util.TreeMap,org.apache.hadoop.net.unix.DomainSocketWatcher$FdSet)" : [ "<init>", "reference" ],
  "org.apache.hadoop.io.compress.PassthroughCodec:setConf(org.apache.hadoop.conf.Configuration)" : [ "getTrimmed" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier:writeImpl(java.io.DataOutput)" : [ "write", "writeVLong", "writeVInt" ],
  "org.apache.hadoop.io.SequenceFile$Writer:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class)" : [ "<init>", "init", "create", "now" ],
  "org.apache.hadoop.fs.shell.CopyCommands$Get:processOptions(java.util.LinkedList)" : [ "<init>", "addOptionWithValue", "parse", "getOpt", "getOptValue" ],
  "org.apache.hadoop.io.compress.GzipCodec:createOutputStream(java.io.OutputStream,org.apache.hadoop.io.compress.Compressor)" : [ "<init>", "createOutputStream", "getInt" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:close()" : [ "close", "closeAll", "clear", "getMountPoints", "getTargetFileSystemForClose", "closeChildFileSystems", "isRootInternalDir", "getRootFallbackLink", "getTargetFileSystem" ],
  "org.apache.hadoop.fs.impl.prefetch.CachingBlockManager:getData(int)" : [ "tryAcquire" ],
  "org.apache.hadoop.fs.LocalDirAllocator:createTmpFileForWrite(java.lang.String,long,org.apache.hadoop.conf.Configuration)" : [ "createTmpFileForWrite", "obtainContext" ],
  "org.apache.hadoop.io.DoubleWritable:<init>(double)" : [ "set" ],
  "org.apache.hadoop.fs.FileSystem:getServerDefaults()" : [ "<init>", "getDefaultBlockSize", "getInt", "getDefaultReplication" ],
  "org.apache.hadoop.conf.Configuration$DeprecationContext:<init>(org.apache.hadoop.conf.Configuration$DeprecationContext,org.apache.hadoop.conf.Configuration$DeprecationDelta[])" : [ "<init>", "getKey", "getNewKeys", "getCustomMessage" ],
  "org.apache.hadoop.conf.Configuration$Resource:getRestrictParserDefault(java.lang.Object)" : [ "isInitialized", "getCurrentUser", "getRealUser" ],
  "org.apache.hadoop.util.KMSUtil:parseJSONKeyVersion(java.util.Map)" : [ "<init>", "checkNotNull" ],
  "org.apache.hadoop.io.SequenceFile:createWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class)" : [ "createWriter", "file", "keyClass", "valueClass" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:getQuotaUsage(org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.io.Text$Comparator:<init>()" : [ "<init>" ],
  "org.apache.hadoop.ipc.RetryCache$CacheEntryWithPayload:equals(java.lang.Object)" : [ "equals" ],
  "org.apache.hadoop.util.ComparableVersion:<init>(java.lang.String)" : [ "parseVersion" ],
  "org.apache.hadoop.fs.FileStatus:write(java.io.DataOutput)" : [ "convert" ],
  "org.apache.hadoop.fs.FilterFs:makeQualified(org.apache.hadoop.fs.Path)" : [ "makeQualified" ],
  "org.apache.hadoop.metrics2.lib.MutableRollingAverages:replaceScheduledTask(int,long,java.util.concurrent.TimeUnit)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.util.SampleStat:reset(long,double,double,org.apache.hadoop.metrics2.util.SampleStat$MinMax)" : [ "reset" ],
  "org.apache.hadoop.util.DataChecksum:mapByteToChecksumType(int)" : [ "<init>", "valueOf" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.ByteBufferEncodingState:convertToByteArrayState()" : [ "<init>" ],
  "org.apache.hadoop.util.Progress:addPhases(int)" : [ "addNewPhase" ],
  "org.apache.hadoop.fs.statistics.impl.DynamicIOStatistics:addCounterFunction(java.lang.String,java.util.function.Function)" : [ "addFunction" ],
  "org.apache.hadoop.util.bloom.HashFunction:hash(org.apache.hadoop.util.bloom.Key)" : [ "hash", "getBytes" ],
  "org.apache.hadoop.security.UserGroupInformation:getCredentials()" : [ "<init>", "getCredentialsInternal", "getAllTokens", "isPrivate" ],
  "org.apache.hadoop.fs.shell.SetReplication:waitForReplication()" : [ "refreshStatus", "getFileBlockLocations", "getLen", "getHosts" ],
  "org.apache.hadoop.io.erasurecode.coder.XORErasureDecoder:<init>(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileUtil:chmod(java.lang.String,java.lang.String)" : [ "chmod" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator:doDelegationTokenOperation(java.net.URL,org.apache.hadoop.security.authentication.client.AuthenticatedURL$Token,org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator$DelegationTokenOperation,java.lang.String,org.apache.hadoop.security.token.Token,boolean,java.lang.String)" : [ "encodeToUrlString", "requiresKerberosCredentials", "getDelegationToken", "setDelegationToken", "getHttpMethod", "validateResponse", "toLowerCase", "mapReader" ],
  "org.apache.hadoop.service.launcher.ServiceShutdownHook:<init>(org.apache.hadoop.service.Service)" : [ "run" ],
  "org.apache.hadoop.fs.shell.Display$TextRecordInputStream:close()" : [ "close" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL:<init>(org.apache.hadoop.security.authentication.client.ConnectionConfigurator)" : [ "<init>" ],
  "org.apache.hadoop.util.bloom.CountingBloomFilter:membershipTest(org.apache.hadoop.util.bloom.Key)" : [ "hash", "clear" ],
  "org.apache.hadoop.ipc.RetryCache:clear(org.apache.hadoop.ipc.RetryCache)" : [ "incrCacheClearedCounter" ],
  "org.apache.hadoop.fs.FileSystem$Statistics:getBytesReadErasureCoded()" : [ "<init>", "visitAll" ],
  "org.apache.hadoop.io.SequenceFile$Reader:next(org.apache.hadoop.io.DataOutputBuffer)" : [ "readRecordLength", "write", "handleChecksumException" ],
  "org.apache.hadoop.fs.crypto.CryptoFSDataOutputStream:getPos()" : [ "getPos" ],
  "org.apache.hadoop.util.dynamic.DynMethods$Builder:buildStaticChecked()" : [ "buildChecked", "asStatic" ],
  "org.apache.hadoop.io.compress.zstd.ZStandardCompressor:needsInput()" : [ "setInputFromSavedData" ],
  "org.apache.hadoop.net.SocksSocketFactory:setConf(org.apache.hadoop.conf.Configuration)" : [ "get", "setProxy" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkNotNullAndNotEmpty(short[],java.lang.String)" : [ "checkNotNull", "checkNotEmpty" ],
  "org.apache.hadoop.fs.FileSystem:removeFileSystemForTesting(java.net.URI,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem)" : [ "<init>" ],
  "org.apache.hadoop.ha.ZKFailoverController:run(java.lang.String[])" : [ "isAutoFailoverEnabled", "doAsLoginUserOrFatal" ],
  "org.apache.hadoop.io.SortedMapWritable:readFields(java.io.DataInput)" : [ "readFields", "newInstance" ],
  "org.apache.hadoop.crypto.key.kms.ValueQueue:submitRefillTask(java.lang.String,java.util.Queue)" : [ "put" ],
  "org.apache.hadoop.fs.Path:mergePaths(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "<init>", "toUri", "startPositionWithoutWindowsDrive" ],
  "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilterInitializer:initFilter(org.apache.hadoop.http.FilterContainer,org.apache.hadoop.conf.Configuration)" : [ "createFilterConfig" ],
  "org.apache.hadoop.fs.shell.find.BaseExpression:setOptions(org.apache.hadoop.fs.shell.find.FindOptions)" : [ "getChildren" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:setMeanStatistic(java.lang.String,org.apache.hadoop.fs.statistics.MeanStatistic)" : [ "getInnerStatistics" ],
  "org.apache.hadoop.crypto.key.CachingKeyProvider:rollNewVersion(java.lang.String,byte[])" : [ "invalidateCache" ],
  "org.apache.hadoop.security.UserGroupInformation:getGroupsSet()" : [ "getGroupsSet", "ensureInitialized", "getShortUserName" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:renameInternal(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "rename" ],
  "org.apache.hadoop.util.DataChecksum:verifyChunkedSums(java.nio.ByteBuffer,java.nio.ByteBuffer,java.lang.String,long)" : [ "verifyChunkedSums", "isAvailable", "verifyChunkedSumsByteArray", "verifyChunked" ],
  "org.apache.hadoop.io.SecureIOUtils:createForWrite(java.io.File,int)" : [ "insecureCreateForWrite", "getCreateForWriteFileOutputStream" ],
  "org.apache.hadoop.io.DataInputBuffer:<init>()" : [ "<init>" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RSLegacyRawDecoder:decode(java.nio.ByteBuffer[],int[],java.nio.ByteBuffer[])" : [ "decode", "adjustOrder" ],
  "org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream:read(byte[],int,int)" : [ "<init>", "incrementBytesRead", "incrementCounter" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RSRawDecoder:processErasures(int[])" : [ "generateDecodeMatrix", "initTables", "bytesToHex" ],
  "org.apache.hadoop.io.retry.RetryInvocationHandler$Call:processRetryInfo()" : [ "isFailover", "failover" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsSnapshot:<init>(org.apache.hadoop.fs.statistics.IOStatistics)" : [ "snapshot", "createMaps" ],
  "org.apache.hadoop.util.Shell:getReadlinkCommand(java.lang.String)" : [ "getWinUtilsPath" ],
  "org.apache.hadoop.ipc.FairCallQueue:removeNextElement()" : [ "getAndAdvanceCurrentIndex" ],
  "org.apache.hadoop.fs.shell.CopyCommandWithMultiThread:hasMoreThanOneSourcePaths(java.util.LinkedList)" : [ "refreshStatus" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:delete(org.apache.hadoop.fs.Path,boolean)" : [ "pathToFile", "listFiles", "fullyDelete" ],
  "org.apache.hadoop.net.NetworkTopology:getDistance(org.apache.hadoop.net.Node,org.apache.hadoop.net.Node)" : [ "getPath" ],
  "org.apache.hadoop.io.erasurecode.coder.DummyErasureDecoder:<init>(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.Delete$Rm:moveToTrash(org.apache.hadoop.fs.shell.PathData)" : [ "moveToAppropriateTrash" ],
  "org.apache.hadoop.util.functional.RemoteIterators:cleanupRemoteIterator(org.apache.hadoop.fs.RemoteIterator)" : [ "logIOStatisticsAtDebug", "cleanupWithLogger" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier:readFields(java.io.DataInput)" : [ "readFields", "readVLong", "readVInt" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider:getKeyVersions(java.lang.String)" : [ "getMetadata", "getVersions", "getKeyVersion" ],
  "org.apache.hadoop.conf.Configuration:main(java.lang.String[])" : [ "<init>", "writeXml" ],
  "org.apache.hadoop.service.ServiceStateModel:checkStateTransition(java.lang.String,org.apache.hadoop.service.Service$STATE,org.apache.hadoop.service.Service$STATE)" : [ "<init>", "isValidStateTransition" ],
  "org.apache.hadoop.util.curator.ZKCuratorManager:getZKAcls(org.apache.hadoop.conf.Configuration)" : [ "get", "resolveConfIndirection", "parseACLs" ],
  "org.apache.hadoop.ipc.RPC$Server:getSupportedProtocolVersions(org.apache.hadoop.ipc.RPC$RpcKind,java.lang.String)" : [ "<init>", "getProtocolImplMap" ],
  "org.apache.hadoop.net.InnerNodeImpl:getNextAncestorName(org.apache.hadoop.net.Node)" : [ "isAncestor" ],
  "org.apache.hadoop.fs.DelegationTokenRenewer$RenewAction:updateRenewalTime(long)" : [ "now" ],
  "org.apache.hadoop.metrics2.AbstractMetric:<init>(org.apache.hadoop.metrics2.MetricsInfo)" : [ "checkNotNull" ],
  "org.apache.hadoop.metrics2.lib.MutableCounterLong:<init>(org.apache.hadoop.metrics2.MetricsInfo,long)" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.FileSystemMultipartUploaderBuilder:getPermission()" : [ "getPermission" ],
  "org.apache.hadoop.fs.HarFileSystem:getFileBlockLocations(org.apache.hadoop.fs.FileStatus,long,long)" : [ "<init>", "getFileBlockLocations", "getFileHarStatus", "getPath", "getPartName", "getPartFileStatus", "getStartIndex", "fixBlockLocations" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine$Server:registerForDeferredResponse()" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:delete(org.apache.hadoop.fs.Path,boolean)" : [ "fullPath" ],
  "org.apache.hadoop.fs.shell.PathData:compareTo(org.apache.hadoop.fs.shell.PathData)" : [ "compareTo" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:iostatisticsContext_reset()" : [ "checkIoStatisticsContextAvailable", "invoke" ],
  "org.apache.hadoop.fs.shell.CommandFormat:<init>(java.lang.String,int,int,java.lang.String[])" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:<init>(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>", "initialize" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenManager$ZKSecretManager:createIdentifier()" : [ "<init>" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:init(java.lang.String)" : [ "inMiniClusterMode", "checkNotNull", "initMode", "start", "initSystemMBean" ],
  "org.apache.hadoop.ipc.Server$Connection:checkRpcHeaders(org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcRequestHeaderProto)" : [ "<init>" ],
  "org.apache.hadoop.io.WritableComparator:get(java.lang.Class,org.apache.hadoop.conf.Configuration)" : [ "<init>", "forceInit", "setConf" ],
  "org.apache.hadoop.conf.ConfigurationWithLogging:get(java.lang.String)" : [ "get", "redact" ],
  "org.apache.hadoop.io.MapFile$Reader:<init>(org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:rollNewVersion(java.lang.String)" : [ "rollNewVersionInternal" ],
  "org.apache.hadoop.fs.FileUtil:copy(java.io.File,org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,boolean,org.apache.hadoop.conf.Configuration)" : [ "<init>", "checkDest", "mkdirs", "listFiles", "create", "copyBytes", "closeStream", "fullyDelete" ],
  "org.apache.hadoop.net.NetworkTopology:countNumOfAvailableNodes(java.lang.String,java.util.Collection)" : [ "normalize", "getNode", "getPath", "isNodeInScope" ],
  "org.apache.hadoop.fs.impl.FileSystemMultipartUploader:<init>(org.apache.hadoop.fs.impl.FileSystemMultipartUploaderBuilder,org.apache.hadoop.fs.FileSystem)" : [ "<init>", "getBlockSize", "getChecksumOpt", "getPermission" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkPathExists(java.nio.file.Path,java.lang.String)" : [ "checkNotNull", "checkArgument" ],
  "org.apache.hadoop.conf.Configuration:addResource(org.apache.hadoop.fs.Path)" : [ "<init>", "addResourceObject" ],
  "org.apache.hadoop.fs.FileUtil:write(org.apache.hadoop.fs.FileContext,org.apache.hadoop.fs.Path,byte[])" : [ "create", "overwrite", "close" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:open(org.apache.hadoop.fs.Path,int)" : [ "resolve", "getUriPath" ],
  "org.apache.hadoop.fs.BufferedFSInputStream:readVectored(java.util.List,java.util.function.IntFunction)" : [ "readVectored" ],
  "org.apache.hadoop.net.unix.DomainSocket:unreference(boolean)" : [ "unreference", "unreferenceCheckClosed" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:createServiceURL(org.apache.hadoop.fs.Path)" : [ "toString" ],
  "org.apache.hadoop.util.Shell:checkIsBashSupported()" : [ "<init>", "execute" ],
  "org.apache.hadoop.fs.FilterFs:removeDefaultAcl(org.apache.hadoop.fs.Path)" : [ "removeDefaultAcl" ],
  "org.apache.hadoop.ipc.Client$IpcStreams:<init>(java.net.Socket,int)" : [ "setInputStream", "getInputStream", "setOutputStream", "getOutputStream" ],
  "org.apache.hadoop.io.compress.CompressionCodecFactory:<init>(org.apache.hadoop.conf.Configuration)" : [ "getCodecClasses", "addCodec", "newInstance" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:joinElectionInternal()" : [ "checkState", "reEstablishSession", "fatalError", "createLockNodeAsync" ],
  "org.apache.hadoop.io.retry.RetryProxy:create(java.lang.Class,java.lang.Object,java.util.Map)" : [ "<init>", "create" ],
  "org.apache.hadoop.service.launcher.InterruptEscalator:lookup(java.lang.String)" : [ "getName" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:newGauge(java.lang.String,java.lang.String,float)" : [ "newGauge", "info" ],
  "org.apache.hadoop.io.MapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.io.WritableComparator,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.util.Progressable)" : [ "<init>", "comparator", "valueClass", "compression", "progressable" ],
  "org.apache.hadoop.fs.TrashPolicyDefault$Emptier:ceiling(long,long)" : [ "floor" ],
  "org.apache.hadoop.ipc.ProtocolSignature:getProtocolSignature(int,long,java.lang.Class)" : [ "<init>", "getSigFingerprint" ],
  "org.apache.hadoop.io.MapWritable:readFields(java.io.DataInput)" : [ "readFields", "newInstance" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:getXAttrs(org.apache.hadoop.fs.Path,java.util.List)" : [ "<init>" ],
  "org.apache.hadoop.util.functional.RemoteIterators$WrappedJavaIterator:close()" : [ "close" ],
  "org.apache.hadoop.security.SaslPropertiesResolver:getClientProperties(java.net.InetAddress,int)" : [ "getClientProperties" ],
  "org.apache.hadoop.fs.FilterFs:openFileWithOptions(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.impl.OpenFileParameters)" : [ "openFileWithOptions" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:createNonRecursive(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,java.util.EnumSet,int,short,long,org.apache.hadoop.util.Progressable)" : [ "createNonRecursive", "resolve", "getUriPath", "readOnlyMountTable" ],
  "org.apache.hadoop.fs.PathExistsException:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.lib.MethodMetric:newImpl(org.apache.hadoop.metrics2.annotation.Metric$Type)" : [ "newCounter", "newGauge", "newTag", "checkArg" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyNode:hashCode()" : [ "hashCode" ],
  "org.apache.hadoop.fs.FileSystem:open(org.apache.hadoop.fs.PathHandle)" : [ "open", "getInt" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:iostatisticsSnapshot_load(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)" : [ "checkIoStatisticsAvailable", "invoke" ],
  "org.apache.hadoop.fs.shell.find.Find:registerCommands(org.apache.hadoop.fs.shell.CommandFactory)" : [ "addClass" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:getLocationNear(long)" : [ "<init>", "getBlockIndexNear" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Factory:getWorkFactor(org.apache.hadoop.conf.Configuration)" : [ "getInt" ],
  "org.apache.hadoop.ipc.Server:getQueueClass(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "getClass", "convertQueueClass" ],
  "org.apache.hadoop.util.GenericOptionsParser:validateFiles(java.lang.String)" : [ "validateFiles" ],
  "org.apache.hadoop.ipc.FairCallQueue$MetricsProxy:getInstance(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.io.BytesWritable:set(org.apache.hadoop.io.BytesWritable)" : [ "set" ],
  "org.apache.hadoop.io.BytesWritable$Comparator:<init>()" : [ "<init>" ],
  "org.apache.hadoop.ipc.Server$Handler:requeueCall(org.apache.hadoop.ipc.Server$Call)" : [ "incrRequeueCalls", "doResponse", "getRpcStatusProto" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkValid(boolean,java.lang.String)" : [ "checkArgument" ],
  "org.apache.hadoop.metrics2.lib.MutableRates:snapshot(org.apache.hadoop.metrics2.MetricsRecordBuilder,boolean)" : [ "snapshot" ],
  "org.apache.hadoop.crypto.key.CachingKeyProvider:<init>(org.apache.hadoop.crypto.key.KeyProvider,long,long)" : [ "<init>" ],
  "org.apache.hadoop.io.DefaultStringifier:fromString(java.lang.String)" : [ "reset" ],
  "org.apache.hadoop.fs.LocalFileSystem:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:access(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsAction)" : [ "access", "fullPath" ],
  "org.apache.hadoop.fs.Globber:<init>(org.apache.hadoop.fs.FileContext,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.PathFilter,boolean)" : [ "getTracer" ],
  "org.apache.hadoop.util.functional.FunctionalIO:toUncheckedIOExceptionSupplier(org.apache.hadoop.util.functional.CallableRaisingIOE)" : [ "unchecked" ],
  "org.apache.hadoop.fs.Path:getFileSystem(org.apache.hadoop.conf.Configuration)" : [ "get", "toUri" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:iostatistics_maximums(java.io.Serializable)" : [ "invoke" ],
  "org.apache.hadoop.fs.FilterFileSystem:removeAcl(org.apache.hadoop.fs.Path)" : [ "removeAcl" ],
  "org.apache.hadoop.io.retry.AsyncCallHandler$AsyncCallQueue$Processor:tryStart()" : [ "checkState" ],
  "org.apache.hadoop.io.WritableUtils:readVInt(java.io.DataInput)" : [ "readVLong" ],
  "org.apache.hadoop.fs.statistics.MeanStatistic:clone()" : [ "copy" ],
  "org.apache.hadoop.fs.FileSystem$DirListingIterator:next()" : [ "hasNext", "getEntries", "fetchMore" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler$MetricsProxy:getTotalCallVolume()" : [ "getTotalCallVolume" ],
  "org.apache.hadoop.security.ShellBasedIdMapping:clearNameMaps()" : [ "monotonicNow" ],
  "org.apache.hadoop.metrics2.sink.RollingFileSystemSink:getFileSystem()" : [ "<init>", "get", "toString" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:connectToZooKeeper()" : [ "createZooKeeper", "getScheme", "getAuth" ],
  "org.apache.hadoop.io.DefaultStringifier:loadArray(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.Class)" : [ "<init>", "get", "fromString", "toArray", "close" ],
  "org.apache.hadoop.fs.impl.AbstractFSBuilderImpl:must(java.lang.String,java.lang.String)" : [ "set", "getThisBuilder" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:getHomeDirectory(com.jcraft.jsch.ChannelSftp)" : [ "<init>" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator:cancelDelegationToken(java.net.URL,org.apache.hadoop.security.authentication.client.AuthenticatedURL$Token,org.apache.hadoop.security.token.Token,java.lang.String)" : [ "doDelegationTokenOperation" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner$Entry:getValue(byte[])" : [ "getValue" ],
  "org.apache.hadoop.ipc.RpcClientUtil:getProtocolMetaInfoProxy(java.lang.Object,org.apache.hadoop.conf.Configuration)" : [ "getProtocolEngine", "getDefaultSocketFactory", "getProxy" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InnerCache:closeAll()" : [ "close" ],
  "org.apache.hadoop.io.file.tfile.TFile$TFileIndex:upperBound(org.apache.hadoop.io.file.tfile.RawComparable)" : [ "upperBound" ],
  "org.apache.hadoop.fs.FileContext:makeQualified(org.apache.hadoop.fs.Path)" : [ "makeQualified", "getUri", "getWorkingDirectory" ],
  "org.apache.hadoop.ipc.Server$Connection:createSaslServer(org.apache.hadoop.security.SaslRpcServer$AuthMethod)" : [ "<init>", "getServerProperties", "create" ],
  "org.apache.hadoop.fs.shell.Head:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "isDirectory", "toString", "dumpToOffset" ],
  "org.apache.hadoop.io.compress.SplitCompressionInputStream:<init>(java.io.InputStream,long,long)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.lib.MethodMetric$2:snapshot(org.apache.hadoop.metrics2.MetricsRecordBuilder,boolean)" : [ "isLong", "isInt", "isFloat" ],
  "org.apache.hadoop.util.Shell:getQualifiedBin(java.lang.String)" : [ "getQualifiedBinInner", "getHadoopHomeDir" ],
  "org.apache.hadoop.fs.AbstractFileSystem:access(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsAction)" : [ "checkAccessPermissions" ],
  "org.apache.hadoop.conf.Configuration:loadProps(java.util.Properties,int,boolean)" : [ "loadResources" ],
  "org.apache.hadoop.security.KDiag:validateHadoopTokenFiles(org.apache.hadoop.conf.Configuration)" : [ "title", "println", "get", "getTrimmedStrings", "verifyFileIsValid", "verify" ],
  "org.apache.hadoop.io.retry.CallReturn:<init>(java.lang.Object)" : [ "<init>" ],
  "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker:hasCapability(java.lang.String)" : [ "hasCapability" ],
  "org.apache.hadoop.io.BloomMapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.io.WritableComparator,java.lang.Class)" : [ "<init>" ],
  "org.apache.hadoop.fs.FilterFs:getFileLinkStatus(org.apache.hadoop.fs.Path)" : [ "getFileLinkStatus", "checkPath" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RawErasureDecoder:allowVerboseDump()" : [ "allowVerboseDump" ],
  "org.apache.hadoop.fs.FsServerDefaults:<init>(long,int,int,short,int,boolean,long,org.apache.hadoop.util.DataChecksum$Type,java.lang.String,byte)" : [ "<init>" ],
  "org.apache.hadoop.conf.Configuration:getStorageSize(java.lang.String,java.lang.String,org.apache.hadoop.conf.StorageUnit)" : [ "checkState", "get", "parse", "convertStorageUnit", "getValue", "getUnit" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:addTokenForOwnerStats(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier)" : [ "getTokenRealOwner" ],
  "org.apache.hadoop.fs.LocalDirAllocator:<init>(java.lang.String)" : [ "getInstance" ],
  "org.apache.hadoop.io.VLongWritable:readFields(java.io.DataInput)" : [ "readVLong" ],
  "org.apache.hadoop.io.file.tfile.BCFile$MetaIndex:addEntry(org.apache.hadoop.io.file.tfile.BCFile$MetaIndexEntry)" : [ "getMetaName" ],
  "org.apache.hadoop.ipc.Server$Connection:processSaslToken(org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto)" : [ "buildSaslResponse" ],
  "org.apache.hadoop.util.functional.TaskPool$Builder:resetStatisticsContext()" : [ "setThreadIOStatisticsContext" ],
  "org.apache.hadoop.http.HttpServer2:addServlet(java.lang.String,java.lang.String,java.lang.Class)" : [ "addInternalServlet" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenManager:decodeToken(org.apache.hadoop.security.token.Token,org.apache.hadoop.io.Text)" : [ "<init>", "getIdentifier" ],
  "org.apache.hadoop.security.authorize.DefaultImpersonationProvider:init(java.lang.String)" : [ "<init>", "getValByRegex", "getAclKey" ],
  "org.apache.hadoop.metrics2.lib.MutableGaugeLong:snapshot(org.apache.hadoop.metrics2.MetricsRecordBuilder,boolean)" : [ "value" ],
  "org.apache.hadoop.ipc.Server:setLogSlowRPCThresholdTime(long)" : [ "getMetricsTimeUnit" ],
  "org.apache.hadoop.fs.FilterFs:getUri()" : [ "getUri" ],
  "org.apache.hadoop.fs.ftp.FTPInputStream:close()" : [ "<init>" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:sendMTFValues5(int,int)" : [ "bsW" ],
  "org.apache.hadoop.fs.FilterFileSystem:mkdirs(org.apache.hadoop.fs.Path)" : [ "mkdirs" ],
  "org.apache.hadoop.crypto.random.OsSecureRandom:nextBytes(byte[])" : [ "fillReservoir" ],
  "org.apache.hadoop.io.VIntWritable:readFields(java.io.DataInput)" : [ "readVInt" ],
  "org.apache.hadoop.fs.FileContext:getHomeDirectory()" : [ "getHomeDirectory" ],
  "org.apache.hadoop.util.concurrent.AsyncGetFuture:isDone()" : [ "callAsyncGet" ],
  "org.apache.hadoop.io.Text:writeString(java.io.DataOutput,java.lang.String,int)" : [ "encode", "writeVInt" ],
  "org.apache.hadoop.metrics2.util.Metrics2Util$NameValuePair:equals(java.lang.Object)" : [ "compareTo" ],
  "org.apache.hadoop.fs.FilterFs:createSnapshot(org.apache.hadoop.fs.Path,java.lang.String)" : [ "createSnapshot" ],
  "org.apache.hadoop.fs.HarFileSystem:getPathInHar(org.apache.hadoop.fs.Path)" : [ "<init>", "toUri", "compareTo", "getName", "getParent", "toString" ],
  "org.apache.hadoop.io.SequenceFile$Writer:hsync()" : [ "hsync" ],
  "org.apache.hadoop.io.wrappedio.WrappedStatistics:iostatisticsSnapshot_load(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)" : [ "uncheckIOExceptions" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:createConfiguration()" : [ "<init>" ],
  "org.apache.hadoop.metrics2.sink.ganglia.GangliaSink30:putMetrics(org.apache.hadoop.metrics2.MetricsRecord)" : [ "<init>", "name", "appendPrefix", "update", "metricsEntrySet", "getType", "getSlope", "calculateSlope", "emitMetric" ],
  "org.apache.hadoop.fs.viewfs.ConfigUtil:addLinkMerge(org.apache.hadoop.conf.Configuration,java.net.URI[])" : [ "addLinkMerge", "getDefaultMountTableName" ],
  "org.apache.hadoop.fs.shell.FsUsage$TableBuilder:isEmpty()" : [ "size" ],
  "org.apache.hadoop.security.UserGroupInformation:getTokens()" : [ "getCredentialsInternal", "getAllTokens" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker:call(org.apache.hadoop.ipc.RPC$Server,java.lang.String,org.apache.hadoop.io.Writable,long)" : [ "call", "getRequestHeader" ],
  "org.apache.hadoop.net.DNS:getHosts(java.lang.String)" : [ "getHosts" ],
  "org.apache.hadoop.io.SortedMapWritable:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.TrashPolicy:getInstance(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)" : [ "getClass", "newInstance" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Location:clone()" : [ "<init>" ],
  "org.apache.hadoop.io.compress.snappy.SnappyDecompressor$SnappyDirectDecompressor:reset()" : [ "reset" ],
  "org.apache.hadoop.security.KDiag:validateSasl(java.lang.String)" : [ "<init>", "title", "getTrimmed", "getClass", "println" ],
  "org.apache.hadoop.util.RunJar:unJarAndSave(java.io.InputStream,java.io.File,java.lang.String,java.util.regex.Pattern)" : [ "ensureDirectory", "unJar" ],
  "org.apache.hadoop.io.SequenceFile$Sorter:merge(org.apache.hadoop.fs.Path[],org.apache.hadoop.fs.Path,boolean)" : [ "<init>", "merge", "getLen", "preserveInput", "doSync" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockOperations:getCached(int)" : [ "<init>", "checkNotNegative", "add" ],
  "org.apache.hadoop.fs.Path:isAbsoluteAndSchemeAuthorityNull()" : [ "isUriPathAbsolute" ],
  "org.apache.hadoop.security.token.DtUtilShell$Print:execute()" : [ "printTokenFile" ],
  "org.apache.hadoop.http.HttpServer2$QuotingInputFilter:doFilter(javax.servlet.ServletRequest,javax.servlet.ServletResponse,javax.servlet.FilterChain)" : [ "<init>", "inferMimeType" ],
  "org.apache.hadoop.io.compress.SnappyCodec:createDecompressor()" : [ "<init>", "getInt" ],
  "org.apache.hadoop.fs.viewfs.ViewFsFileStatus:getOwner()" : [ "getOwner" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:mkdirs(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "mkdirsWithOptionalPermission" ],
  "org.apache.hadoop.conf.Configuration:setDouble(java.lang.String,double)" : [ "set" ],
  "org.apache.hadoop.security.SaslRpcServer:getIdentifier(java.lang.String,org.apache.hadoop.security.token.SecretManager)" : [ "<init>", "decodeIdentifier" ],
  "org.apache.hadoop.util.SysInfoLinux:getCpuFrequency()" : [ "readProcCpuInfoFile" ],
  "org.apache.hadoop.fs.LocalFileSystem:pathToFile(org.apache.hadoop.fs.Path)" : [ "pathToFile" ],
  "org.apache.hadoop.service.launcher.InterruptEscalator$ServiceForcedShutdown:<init>(org.apache.hadoop.service.Service,int)" : [ "run" ],
  "org.apache.hadoop.ha.ShellCommandFencer:tryFence(org.apache.hadoop.ha.HAServiceTarget,java.lang.String)" : [ "<init>", "parseArgs", "getTransitionTargetHAStatus", "setConfAsEnvVars", "addTargetInfoAsEnvVars", "start", "tryGetPid", "abbreviate", "join" ],
  "org.apache.hadoop.metrics2.lib.MutableMetricsFactory:getInfo(org.apache.hadoop.metrics2.annotation.Metric,java.lang.String)" : [ "info" ],
  "org.apache.hadoop.crypto.key.KeyProviderFactory:getProviders(org.apache.hadoop.conf.Configuration)" : [ "getStringCollection", "get" ],
  "org.apache.hadoop.metrics2.impl.MBeanInfoBuilder:gauge(org.apache.hadoop.metrics2.MetricsInfo,long)" : [ "newAttrInfo" ],
  "org.apache.hadoop.http.HttpServer2:toString()" : [ "checkState", "isAlive" ],
  "org.apache.hadoop.io.serializer.JavaSerialization$JavaSerializationDeserializer:deserialize(java.lang.Object)" : [ "deserialize" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:newRatesWithAggregation(java.lang.String)" : [ "checkMetricName" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:newGauge(org.apache.hadoop.metrics2.MetricsInfo,long)" : [ "<init>", "checkMetricName" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Decompressor:getBytesRead()" : [ "checkStream" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getDefaultBlockSize()" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:<init>()" : [ "<init>", "getCurrentUser", "now" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:getLinkTarget(org.apache.hadoop.fs.Path)" : [ "getFileLinkStatusInternal", "getSymlink" ],
  "org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream:skip(long)" : [ "incrementCounter" ],
  "org.apache.hadoop.io.file.tfile.TFile$TFileIndex:getLocationByRecordNum(long)" : [ "<init>", "upperBound" ],
  "org.apache.hadoop.util.SysInfoWindows:getAvailableVirtualMemorySize()" : [ "refreshIfNeeded" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:getBlockContainsKey(org.apache.hadoop.io.file.tfile.RawComparable,boolean)" : [ "<init>", "isSorted", "checkTFileDataIndex", "upperBound", "lowerBound" ],
  "org.apache.hadoop.util.VersionInfo:getRevision()" : [ "_getRevision" ],
  "org.apache.hadoop.io.SequenceFile:createWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class,int,short,long,boolean,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.io.SequenceFile$Metadata)" : [ "createWriter", "getFileContext", "bufferSize", "createParent", "donotCreateParent", "repFac", "blockSize" ],
  "org.apache.hadoop.io.file.tfile.Compression$Algorithm$2:createDecompressionStream(java.io.InputStream,org.apache.hadoop.io.compress.Decompressor,int)" : [ "getConf", "createInputStream", "setInt" ],
  "org.apache.hadoop.fs.FileContext:getFileStatus(org.apache.hadoop.fs.Path)" : [ "fixRelativePart" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider:constructOldPath(org.apache.hadoop.fs.Path)" : [ "<init>", "toString" ],
  "org.apache.hadoop.ha.HAAdmin:gracefulFailoverThroughZKFCs(org.apache.hadoop.ha.HAServiceTarget)" : [ "getRpcTimeoutToNewActive", "getZKFCProxy" ],
  "org.apache.hadoop.conf.Configuration:asXmlDocument(java.lang.String,org.apache.hadoop.conf.ConfigRedactor)" : [ "handleDeprecation", "appendXMLProperty" ],
  "org.apache.hadoop.security.ssl.SSLHostnameVerifier$AbstractVerifier:check(java.lang.String[],javax.net.ssl.SSLSocket)" : [ "check" ],
  "org.apache.hadoop.util.SysInfoLinux:getConf(java.lang.String)" : [ "<init>", "execute", "getOutput" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:getCurrentKey(java.lang.String)" : [ "doOp", "nextIdx" ],
  "org.apache.hadoop.ha.HAServiceProtocolHelper:transitionToObserver(org.apache.hadoop.ha.HAServiceProtocol,org.apache.hadoop.ha.HAServiceProtocol$StateChangeRequestInfo)" : [ "unwrapRemoteException" ],
  "org.apache.hadoop.util.bloom.Key:<init>(byte[])" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyStatus:isSymlink()" : [ "isSymlink" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:newCounter(org.apache.hadoop.metrics2.MetricsInfo,int)" : [ "<init>", "checkMetricName" ],
  "org.apache.hadoop.util.curator.ZKCuratorManager$HadoopZookeeperFactory:<init>(java.lang.String,java.lang.String,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:listStatusIterator(org.apache.hadoop.fs.Path)" : [ "listStatusIterator", "fullPath" ],
  "org.apache.hadoop.fs.ChecksumFs:listLocatedStatus(org.apache.hadoop.fs.Path)" : [ "listLocatedStatus" ],
  "org.apache.hadoop.fs.GlobalStorageStatistics:put(java.lang.String,org.apache.hadoop.fs.GlobalStorageStatistics$StorageStatisticsProvider)" : [ "checkNotNull", "getName" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:createScannerByByteRange(long,long)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.MetricsJsonBuilder:addGauge(org.apache.hadoop.metrics2.MetricsInfo,long)" : [ "tuple" ],
  "org.apache.hadoop.fs.impl.AbstractFSBuilderImpl:opt(java.lang.String,boolean)" : [ "opt" ],
  "org.apache.hadoop.fs.TrashPolicyDefault:createCheckpoint(org.apache.hadoop.fs.Path,java.util.Date)" : [ "<init>", "exists", "rename", "toUri", "suffix" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:<init>(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>", "createServiceURL", "extractKMSPath", "getDtService", "buildTokenService", "init", "getInt", "getFloat" ],
  "org.apache.hadoop.ipc.FairCallQueue:offer(java.lang.Object,long,java.util.concurrent.TimeUnit)" : [ "offer" ],
  "org.apache.hadoop.crypto.OpensslCipher:doFinal(java.nio.ByteBuffer)" : [ "checkState", "checkArgument" ],
  "org.apache.hadoop.fs.FilterFileSystem:getEnclosingRoot(org.apache.hadoop.fs.Path)" : [ "getEnclosingRoot" ],
  "org.apache.hadoop.io.compress.DecompressorStream:read()" : [ "read", "checkStream" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RawErasureDecoder:getNumParityUnits()" : [ "getNumParityUnits" ],
  "org.apache.hadoop.fs.shell.Command:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.FileContext:delete(org.apache.hadoop.fs.Path,boolean)" : [ "fixRelativePart" ],
  "org.apache.hadoop.ipc.RPC:getProtocolProxy(java.lang.Class,long,java.net.InetSocketAddress,org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory,int,org.apache.hadoop.io.retry.RetryPolicy,java.util.concurrent.atomic.AtomicBoolean)" : [ "isSecurityEnabled", "init", "getProtocolEngine" ],
  "org.apache.hadoop.util.VersionInfo:getVersion()" : [ "_getVersion" ],
  "org.apache.hadoop.ha.HealthMonitor:createProxy()" : [ "getHealthMonitorProxy" ],
  "org.apache.hadoop.ha.SshFenceByTcpPort:doFence(com.jcraft.jsch.Session,java.net.InetSocketAddress)" : [ "execCommand" ],
  "org.apache.hadoop.fs.shell.Delete$Rm:canBeSafelyDeleted(org.apache.hadoop.fs.shell.PathData)" : [ "getLong", "getContentSummary", "getFileCount", "confirmPrompt" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:setPermission(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "isAvailable", "chmod", "pathToFile", "toShort", "execCommand", "getSetPermissionCommand", "makeShellPath" ],
  "org.apache.hadoop.metrics2.sink.PrometheusMetricsSink:getMetricKey(java.lang.String,org.apache.hadoop.metrics2.AbstractMetric,java.util.List)" : [ "parseTopMetricsTags", "name" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Factory:getBzip2DecompressorType(org.apache.hadoop.conf.Configuration)" : [ "isNativeBzip2Loaded" ],
  "org.apache.hadoop.io.file.tfile.TFile:getFSInputBufferSize(org.apache.hadoop.conf.Configuration)" : [ "getInt" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Factory:getBlockSize(org.apache.hadoop.conf.Configuration)" : [ "getInt" ],
  "org.apache.hadoop.util.DiskChecker:checkDirInternal(org.apache.hadoop.fs.LocalFileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "mkdirsWithExistsAndPermissionCheck", "checkAccessByFileMethods", "pathToFile" ],
  "org.apache.hadoop.ipc.Server$Listener:doStop()" : [ "shutdown" ],
  "org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:processTokenAddOrUpdate(byte[])" : [ "<init>", "readFields" ],
  "org.apache.hadoop.fs.permission.FsPermission:toString()" : [ "implies" ],
  "org.apache.hadoop.util.JsonSerialization:save(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,java.lang.Object,boolean)" : [ "writeJsonAsBytes", "create" ],
  "org.apache.hadoop.fs.FilterFs:renameInternal(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "checkPath", "rename" ],
  "org.apache.hadoop.fs.FilterFileSystem:unsetStoragePolicy(org.apache.hadoop.fs.Path)" : [ "unsetStoragePolicy" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:getNumInProcessHandler()" : [ "getNumInProcessHandler" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:getFileStatus(org.apache.hadoop.fs.Path)" : [ "getFileStatus", "connect", "disconnect" ],
  "org.apache.hadoop.fs.HarFileSystem:open(org.apache.hadoop.fs.Path,int)" : [ "<init>", "getFileHarStatus", "isDir", "getPartName", "getStartIndex", "getLength" ],
  "org.apache.hadoop.io.wrappedio.WrappedIO:bulkDelete_pageSize(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)" : [ "uncheckIOExceptions" ],
  "org.apache.hadoop.fs.BlockLocation:<init>(java.lang.String[],java.lang.String[],java.lang.String[],long,long,boolean)" : [ "<init>" ],
  "org.apache.hadoop.ipc.WritableRpcEngine$Invocation:<init>(java.lang.reflect.Method,java.lang.Object[])" : [ "getProtocolVersion", "getFingerprint", "getProtocolName" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:newGauge(org.apache.hadoop.metrics2.MetricsInfo,float)" : [ "<init>", "checkMetricName" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:parseDecayFactor(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "getDouble" ],
  "org.apache.hadoop.fs.shell.Command:processNonexistentPath(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "toString" ],
  "org.apache.hadoop.io.compress.lz4.Lz4Compressor:compress(byte[],int,int)" : [ "setInputFromSavedData", "compressDirectBuf" ],
  "org.apache.hadoop.util.IdentityHashStore:realloc(int)" : [ "checkArgument", "putInternal" ],
  "org.apache.hadoop.fs.FSOutputSummer:write(byte[],int,int)" : [ "write1" ],
  "org.apache.hadoop.fs.permission.FsPermission:toOctal()" : [ "toShort" ],
  "org.apache.hadoop.io.file.tfile.TFile$TFileIndex:setFirstKey(byte[],int,int)" : [ "<init>", "buffer" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:getPriorityLevel(org.apache.hadoop.ipc.Schedulable)" : [ "getIdentity", "cachedOrComputedPriorityLevel" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:mkdir(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,boolean)" : [ "primitiveMkdir" ],
  "org.apache.hadoop.io.wrappedio.WrappedStatistics:iostatisticsSnapshot_retrieve(java.lang.Object)" : [ "retrieveIOStatistics", "iostatisticsSnapshot_create" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:getFileStatus(org.apache.hadoop.fs.Path)" : [ "getFileStatus", "connect", "disconnect" ],
  "org.apache.hadoop.crypto.key.KeyProviderExtension:getCurrentKey(java.lang.String)" : [ "getCurrentKey" ],
  "org.apache.hadoop.fs.impl.prefetch.SingleFilePerBlockCache:isCacheSpaceAvailable(long,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.LocalDirAllocator)" : [ "getTempFilePath" ],
  "org.apache.hadoop.io.serializer.JavaSerializationComparator:compare(java.lang.Object,java.lang.Object)" : [ "compare" ],
  "org.apache.hadoop.io.SequenceFile$Reader:readRecordLength()" : [ "getPos" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:toString()" : [ "isClassnameDefined" ],
  "org.apache.hadoop.fs.shell.TouchCommands$Touchz:touchz(org.apache.hadoop.fs.shell.PathData)" : [ "create", "close" ],
  "org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider:getPathAsString()" : [ "getPath", "toString" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:truncate(org.apache.hadoop.fs.Path,long)" : [ "truncate", "resolve", "getUriPath" ],
  "org.apache.hadoop.io.SequenceFile:getBufferSize(org.apache.hadoop.conf.Configuration)" : [ "getInt" ],
  "org.apache.hadoop.fs.FileSystem:createFileSystem(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>", "get", "newScope", "addKVAnnotation", "getFileSystemClass", "newInstance", "initialize", "cleanupWithLogger", "close" ],
  "org.apache.hadoop.util.bloom.CountingBloomFilter:<init>(int,int,int)" : [ "<init>", "buckets2words" ],
  "org.apache.hadoop.io.SequenceFile$Writer:getLength()" : [ "getPos" ],
  "org.apache.hadoop.fs.shell.PathData:uriToString(java.net.URI,boolean)" : [ "isWindowsAbsolutePath" ],
  "org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder:build()" : [ "<init>", "withMandatoryKeys", "withOptionalKeys", "withOptions", "withStatus", "getStatus", "withBufferSize", "getInt", "openFileWithOptions" ],
  "org.apache.hadoop.io.compress.ZStandardCodec:getBufferSize(org.apache.hadoop.conf.Configuration)" : [ "getInt" ],
  "org.apache.hadoop.fs.HarFileSystem$HarFSDataInputStream:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,long,long,int)" : [ "<init>" ],
  "org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue:adjustPriorityQueue(org.apache.hadoop.io.SequenceFile$Sorter$SegmentDescriptor)" : [ "getPosition", "nextRawKey", "updateProgress", "cleanup" ],
  "org.apache.hadoop.security.token.delegation.SQLDelegationTokenSecretManager:removeStoredToken(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier)" : [ "getSequenceNumber" ],
  "org.apache.hadoop.fs.ChecksumFs:<init>(org.apache.hadoop.fs.AbstractFileSystem)" : [ "<init>", "getServerDefaults", "getBytesPerChecksum" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$MRNflyNode:cloneStatus()" : [ "<init>", "getLen", "isDirectory", "getReplication", "getBlockSize", "getModificationTime", "getAccessTime", "isSymlink", "getSymlink", "getPath" ],
  "org.apache.hadoop.security.token.Token:encodeToUrlString()" : [ "encodeWritable" ],
  "org.apache.hadoop.fs.statistics.impl.WrappedIOStatistics:meanStatistics()" : [ "getWrapped" ],
  "org.apache.hadoop.fs.StorageType:getTypesSupportingQuota()" : [ "getNonTransientTypes" ],
  "org.apache.hadoop.util.Shell$ShellTimeoutTimerTask:<init>(org.apache.hadoop.util.Shell)" : [ "run" ],
  "org.apache.hadoop.io.AbstractMapWritable:readFields(java.io.DataInput)" : [ "addToMap" ],
  "org.apache.hadoop.ha.HAAdmin:parseOpts(java.lang.String,org.apache.commons.cli.Options,java.lang.String[])" : [ "parseOpts" ],
  "org.apache.hadoop.io.nativeio.NativeIO$POSIX:isAvailable()" : [ "isNativeCodeLoaded" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:listStatus(org.apache.hadoop.fs.Path)" : [ "resolve", "getUriPath", "isInternalDir", "fixFileStatus", "getChrootedPath" ],
  "org.apache.hadoop.util.dynamic.DynMethods$UnboundMethod$1:<init>(java.lang.reflect.Method,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.io.SequenceFile$Writer:writeFileHeader()" : [ "write", "writeString", "isCompressed", "isBlockCompressed" ],
  "org.apache.hadoop.util.bloom.DynamicBloomFilter:write(java.io.DataOutput)" : [ "write" ],
  "org.apache.hadoop.ha.FailoverController:getGracefulFenceTimeout(org.apache.hadoop.conf.Configuration)" : [ "getInt" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:newGauge(org.apache.hadoop.metrics2.MetricsInfo,int)" : [ "<init>", "checkMetricName" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:hasPathCapability(org.apache.hadoop.fs.Path,java.lang.String)" : [ "hasPathCapability", "fullPath" ],
  "org.apache.hadoop.io.compress.zlib.ZlibDecompressor:getBytesWritten()" : [ "checkStream" ],
  "org.apache.hadoop.fs.FileUtil:unTar(java.io.File,java.io.File)" : [ "unTarUsingJava", "unTarUsingTar" ],
  "org.apache.hadoop.fs.FilterFileSystem:openFile(org.apache.hadoop.fs.PathHandle)" : [ "openFile" ],
  "org.apache.hadoop.fs.shell.Count:processOptions(java.util.LinkedList)" : [ "<init>", "addOptionWithValue", "parse", "getOpt", "getOptValue", "getAndCheckStorageTypes", "getStorageTypeHeader", "getHeader", "getErasureCodingPolicyHeader", "getSnapshotHeader" ],
  "org.apache.hadoop.fs.VectoredReadUtils:validateAndSortRanges(java.util.List,java.util.Optional)" : [ "validateRangeRequest", "sortRangeList", "checkArgument" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getQuotaUsage(org.apache.hadoop.fs.Path)" : [ "getQuotaUsage", "resolve", "getUriPath" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.NativeXORRawEncoder:preferDirectBuffer()" : [ "preferDirectBuffer" ],
  "org.apache.hadoop.tools.TableListing$Builder:addField(java.lang.String,org.apache.hadoop.tools.TableListing$Justification,boolean)" : [ "<init>" ],
  "org.apache.hadoop.util.functional.RemoteIterators$CloseRemoteIterator:<init>(org.apache.hadoop.fs.RemoteIterator,java.io.Closeable)" : [ "<init>" ],
  "org.apache.hadoop.http.HttpServer2$QuotingInputFilter$RequestQuoter:getRequestURL()" : [ "quoteHtmlChars" ],
  "org.apache.hadoop.fs.shell.find.Find:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkGreaterOrEqual(long,java.lang.String,long,java.lang.String)" : [ "checkArgument" ],
  "org.apache.hadoop.ipc.RetryCache:waitForCompletion(org.apache.hadoop.ipc.RetryCache,byte[],int)" : [ "waitForCompletion", "skipRetryCache", "newEntry" ],
  "org.apache.hadoop.security.authorize.AccessControlList:removeGroup(java.lang.String)" : [ "isWildCardACLValue", "isAllAllowed" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:quitElection(boolean)" : [ "tryDeleteOwnBreadCrumbNode", "reset" ],
  "org.apache.hadoop.io.file.tfile.TFile$Writer:prepareAppendValue(int)" : [ "<init>", "getChunkBufferSize" ],
  "org.apache.hadoop.fs.Globber:glob()" : [ "<init>", "newScope", "addKVAnnotation", "toUri", "doGlob", "close" ],
  "org.apache.hadoop.ha.protocolPB.HAServiceProtocolClientSideTranslatorPB:monitorHealth()" : [ "ipc" ],
  "org.apache.hadoop.fs.VectoredReadUtils:sortRanges(java.util.List)" : [ "sortRangeList" ],
  "org.apache.hadoop.fs.FilterFs:truncate(org.apache.hadoop.fs.Path,long)" : [ "truncate", "checkPath" ],
  "org.apache.hadoop.fs.shell.TouchCommands$Touchz:processNonexistentPath(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "parentExists", "toString", "toUri", "touchz" ],
  "org.apache.hadoop.fs.FSOutputSummer:flushBuffer()" : [ "flushBuffer" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreImpl:setGauge(java.lang.String,long)" : [ "setAtomicLong" ],
  "org.apache.hadoop.fs.StorageType:parseStorageType(java.lang.String)" : [ "toUpperCase" ],
  "org.apache.hadoop.fs.shell.CopyCommands$AppendToFile:processArguments(java.util.LinkedList)" : [ "create", "close", "append", "copyBytes", "toFile", "closeStream" ],
  "org.apache.hadoop.util.LimitInputStream:<init>(java.io.InputStream,long)" : [ "checkNotNull", "checkArgument" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkLessOrEqual(long,java.lang.String,long,java.lang.String)" : [ "checkArgument" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme$ChildFsGetter:getNewInstance(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "createFileSystem", "newInstance" ],
  "org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:removeStoredToken(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier)" : [ "removeStoredToken" ],
  "org.apache.hadoop.ipc.Client:call(org.apache.hadoop.ipc.RPC$RpcKind,org.apache.hadoop.io.Writable,org.apache.hadoop.ipc.Client$ConnectionId,java.util.concurrent.atomic.AtomicBoolean)" : [ "call" ],
  "org.apache.hadoop.security.UserGroupInformation:getLoginUser()" : [ "ensureInitialized", "createLoginUser", "spawnAutoRenewalThreadForUserCreds" ],
  "org.apache.hadoop.fs.BufferedFSInputStream:read(long,byte[],int,int)" : [ "read" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:resolvePath(org.apache.hadoop.fs.Path)" : [ "resolvePath", "fullPath" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:incrReceivedBytes(int)" : [ "incr" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:setPriorityLevel(org.apache.hadoop.security.UserGroupInformation,int)" : [ "getIdentity", "newSchedulable" ],
  "org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec:calculateIV(byte[],long,byte[])" : [ "calculateIV", "getCipherSuite", "getAlgorithmBlockSize" ],
  "org.apache.hadoop.fs.shell.find.Name$Iname:<init>()" : [ "<init>" ],
  "org.apache.hadoop.io.OutputBuffer:getLength()" : [ "getLength" ],
  "org.apache.hadoop.fs.FilterFs:<init>(org.apache.hadoop.fs.AbstractFileSystem)" : [ "<init>", "getUri" ],
  "org.apache.hadoop.fs.FilterFileSystem:copyFromLocalFile(boolean,boolean,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "copyFromLocalFile" ],
  "org.apache.hadoop.io.erasurecode.coder.HHXORErasureDecodingStep:<init>(org.apache.hadoop.io.erasurecode.ECBlock[],int[],org.apache.hadoop.io.erasurecode.ECBlock[],org.apache.hadoop.io.erasurecode.rawcoder.RawErasureDecoder,org.apache.hadoop.io.erasurecode.rawcoder.RawErasureEncoder)" : [ "<init>", "getNumParityUnits", "initPiggyBackIndexWithoutPBVec", "getNumDataUnits", "initPiggyBackFullIndexVec" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:<init>(int,java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "<init>", "parseDecayFactor", "parseDecayPeriodMillis", "parseIdentityProvider", "parseCostProvider", "parseThresholds", "parseBackOffByResponseTimeEnabled", "parseBackOffResponseTimeThreshold", "parseServiceUserNames", "getInt", "checkArgument", "create", "init", "getMetricsTimeUnit", "getInstance", "recomputeScheduleCache" ],
  "org.apache.hadoop.io.ArrayPrimitiveWritable:<init>(java.lang.Class)" : [ "checkPrimitive" ],
  "org.apache.hadoop.util.GenericsUtil:toArray(java.util.List)" : [ "toArray", "getClass" ],
  "org.apache.hadoop.security.JniBasedUnixGroupsNetgroupMapping:cacheGroupsRefresh()" : [ "getNetgroupNames", "clear", "cacheGroupsAdd" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:renameInternal(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "renameInternal" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:getPermissions(org.apache.commons.net.ftp.FTPFile)" : [ "<init>", "getFsAction" ],
  "org.apache.hadoop.fs.FSInputChecker:read()" : [ "fill" ],
  "org.apache.hadoop.fs.permission.FsPermission:write(java.io.DataOutput)" : [ "toShort" ],
  "org.apache.hadoop.security.token.delegation.DelegationKey:write(java.io.DataOutput)" : [ "writeVInt", "writeVLong" ],
  "org.apache.hadoop.crypto.OpensslCtrCryptoCodec$OpensslCtrCipher:<init>(int,org.apache.hadoop.crypto.CipherSuite)" : [ "getInstance", "getName" ],
  "org.apache.hadoop.util.StringUtils:getFormattedTimeWithDiff(java.lang.String,long,long)" : [ "formatTimeDiff" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:setTimes(org.apache.hadoop.fs.Path,long,long)" : [ "pathToFile" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:createSymlink(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,boolean)" : [ "createSymlink" ],
  "org.apache.hadoop.fs.http.HttpsFileSystem:append(org.apache.hadoop.fs.Path,int,org.apache.hadoop.util.Progressable)" : [ "append" ],
  "org.apache.hadoop.util.curator.ZKCuratorManager:create(java.lang.String,java.util.List)" : [ "exists" ],
  "org.apache.hadoop.fs.FileSystem:isDirectory(org.apache.hadoop.fs.Path)" : [ "isDirectory" ],
  "org.apache.hadoop.io.SequenceFile$Writer:appendRaw(byte[],int,int,org.apache.hadoop.io.SequenceFile$ValueBytes)" : [ "checkAndWriteSync" ],
  "org.apache.hadoop.io.MapFile$Writer:checkKey(org.apache.hadoop.io.WritableComparable)" : [ "compare", "reset", "getData", "getLength" ],
  "org.apache.hadoop.io.Text:getTextLength()" : [ "toString" ],
  "org.apache.hadoop.fs.TrashPolicyDefault:getCurrentTrashDir(org.apache.hadoop.fs.Path)" : [ "<init>", "getTrashRoot" ],
  "org.apache.hadoop.net.NetworkTopology:getNode(java.lang.String)" : [ "normalize" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.util.RSUtil:encodeData(byte[],java.nio.ByteBuffer[],java.nio.ByteBuffer[])" : [ "gfMulTab" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockManager:release(org.apache.hadoop.fs.impl.prefetch.BufferData)" : [ "checkNotNull" ],
  "org.apache.hadoop.tracing.Tracer$Builder:build()" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:getDefaultBlockSize(org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.crypto.CryptoOutputStream:hasCapability(java.lang.String)" : [ "hasCapability" ],
  "org.apache.hadoop.conf.Configuration$Parser:handleStartElement()" : [ "handleStartProperty", "handleInclude" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyStatus:setPath(org.apache.hadoop.fs.Path)" : [ "setPath" ],
  "org.apache.hadoop.fs.FilterFs:getFsStatus(org.apache.hadoop.fs.Path)" : [ "getFsStatus" ],
  "org.apache.hadoop.fs.LocatedFileStatus:<init>(long,boolean,int,long,long,long,org.apache.hadoop.fs.permission.FsPermission,java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.BlockLocation[])" : [ "<init>", "getAclBit", "getEncryptedBit", "getErasureCodedBit" ],
  "org.apache.hadoop.fs.FsUrlStreamHandlerFactory:createURLStreamHandler(java.lang.String)" : [ "getFileSystemClass" ],
  "org.apache.hadoop.conf.Configuration:getDeprecatedKeyInfo(java.lang.String)" : [ "getDeprecatedKeyMap" ],
  "org.apache.hadoop.fs.FileSystem:getFileSystemClass(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "<init>", "loadFileSystems", "getClass", "findContainingJar", "findClassLocation" ],
  "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter:getProxyuserConfiguration(javax.servlet.FilterConfig)" : [ "<init>", "set" ],
  "org.apache.hadoop.metrics2.lib.DefaultMetricsSystem:sourceName(java.lang.String,boolean)" : [ "newSourceName" ],
  "org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream:hsync()" : [ "flush" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getContentSummary(org.apache.hadoop.fs.Path)" : [ "getContentSummary", "resolve", "getUriPath" ],
  "org.apache.hadoop.ipc.Server$ConnectionManager:register(java.nio.channels.SocketChannel,int,boolean)" : [ "isFull", "now", "add", "size" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:getKeyVersion(java.lang.String)" : [ "doOp", "nextIdx" ],
  "org.apache.hadoop.fs.impl.prefetch.CachingBlockManager:readBlock(org.apache.hadoop.fs.impl.prefetch.BufferData,boolean,org.apache.hadoop.fs.impl.prefetch.BufferData$State[])" : [ "stateEqualsOneOf", "throwIfStateIncorrect", "getBlockNumber", "getCached", "getBuffer", "setReady", "prefetch", "getRead", "getStartOffset", "getSize", "setDone", "end" ],
  "org.apache.hadoop.fs.FilterFileSystem:openFile(org.apache.hadoop.fs.Path)" : [ "openFile" ],
  "org.apache.hadoop.conf.StorageUnit$6:getDefault(double)" : [ "toKBs" ],
  "org.apache.hadoop.security.KDiag$KerberosDiagsFailure:<init>(java.lang.String,java.lang.String,java.lang.Object[])" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:writeJson(java.lang.Object,java.io.OutputStream)" : [ "writer" ],
  "org.apache.hadoop.fs.FSDataOutputStream:<init>(java.io.OutputStream,org.apache.hadoop.fs.FileSystem$Statistics)" : [ "<init>" ],
  "org.apache.hadoop.io.retry.AsyncCallHandler:getAsyncReturn()" : [ "getLowerLayerAsyncReturn" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter:init(javax.servlet.FilterConfig)" : [ "setExternalDelegationTokenSecretManager", "setHandlerAuthMethod", "getProxyuserConfiguration", "refreshSuperUserGroupsConfiguration" ],
  "org.apache.hadoop.fs.ChecksumFs:renameInternal(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,boolean)" : [ "isDirectory", "rename", "getChecksumFile", "exists" ],
  "org.apache.hadoop.security.protocolPB.RefreshUserMappingsProtocolClientSideTranslatorPB:refreshUserToGroupsMappings()" : [ "ipc" ],
  "org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor:decompress(byte[],int,int)" : [ "<init>", "executeHeaderState", "executeTrailerState" ],
  "org.apache.hadoop.util.StopWatch:<init>()" : [ "<init>" ],
  "org.apache.hadoop.io.nativeio.NativeIO:getCreateForWriteFileOutputStream(java.io.File,int)" : [ "<init>", "getErrno", "chmod", "getErrorCode" ],
  "org.apache.hadoop.security.alias.LocalJavaKeyStoreProvider:<init>(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.io.retry.RetryUtils$WrapperRetryPolicy:hashCode()" : [ "hashCode" ],
  "org.apache.hadoop.fs.FileSystem:copyFromLocalFile(boolean,boolean,org.apache.hadoop.fs.Path[],org.apache.hadoop.fs.Path)" : [ "copy", "getLocal" ],
  "org.apache.hadoop.io.ArrayFile$Writer:append(org.apache.hadoop.io.Writable)" : [ "append", "set", "get" ],
  "org.apache.hadoop.io.VLongWritable:write(java.io.DataOutput)" : [ "writeVLong" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$DelegationTokenSecretManagerMetrics:trackInvocation(org.apache.hadoop.util.functional.InvocationRaisingIOE,java.lang.String,org.apache.hadoop.metrics2.lib.MutableRate)" : [ "monotonicNow", "trackDurationOfInvocation", "incr" ],
  "org.apache.hadoop.security.UserGroupInformation$TicketCacheRenewalRunnable:relogin()" : [ "execCommand", "reloginFromTicketCache" ],
  "org.apache.hadoop.fs.Options$CreateOpts:repFac(short)" : [ "<init>" ],
  "org.apache.hadoop.security.SaslRpcClient:saslConnect(org.apache.hadoop.ipc.Client$IpcStreams)" : [ "<init>", "sendSaslMessage", "readResponse", "wrap", "getValue", "remaining", "selectSaslClient", "createSaslReply", "saslEvaluateToken" ],
  "org.apache.hadoop.ipc.Server:authorize(org.apache.hadoop.security.UserGroupInformation,java.lang.String,java.net.InetAddress)" : [ "<init>", "authorize", "getProtocolClass", "getConf" ],
  "org.apache.hadoop.util.SysInfoWindows:getCpuUsagePercentage()" : [ "refreshIfNeeded" ],
  "org.apache.hadoop.net.NetworkTopologyWithNodeGroup:getNodeGroup(java.lang.String)" : [ "normalize", "isNodeGroup", "isRack" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:add(java.lang.String,long)" : [ "<init>", "add", "newRate" ],
  "org.apache.hadoop.io.UTF8:skip(java.io.DataInput)" : [ "skipFully" ],
  "org.apache.hadoop.metrics2.impl.MetricsConfig:toString()" : [ "toString" ],
  "org.apache.hadoop.util.LineReader:<init>(java.io.InputStream,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getInt" ],
  "org.apache.hadoop.security.ShellBasedIdMapping:loadFullUserMap()" : [ "updateMapInternal", "monotonicNow" ],
  "org.apache.hadoop.ha.ZKFailoverController:initHM()" : [ "<init>", "addCallback", "addServiceStateCallback", "start" ],
  "org.apache.hadoop.fs.FileContext:createMultipartUploader(org.apache.hadoop.fs.Path)" : [ "resolve", "fixRelativePart" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.XORRawEncoder:doEncode(org.apache.hadoop.io.erasurecode.rawcoder.ByteArrayEncodingState)" : [ "resetOutputBuffers" ],
  "org.apache.hadoop.fs.impl.prefetch.CachingBlockManager:<init>(org.apache.hadoop.fs.impl.prefetch.BlockManagerParameters)" : [ "<init>", "getBlockData", "checkPositiveInteger", "getBufferPoolSize", "getFuturePool", "getPrefetchingStatistics", "getConf", "getFileSize", "getBlockSize", "createCache", "getMaxBlocksCount", "getTrackerFactory", "setDebug", "getLocalDirAllocator" ],
  "org.apache.hadoop.security.KDiag:warn(java.lang.String,java.lang.String,java.lang.Object[])" : [ "println" ],
  "org.apache.hadoop.io.SequenceFile$Writer$StreamOption:<init>(org.apache.hadoop.fs.FSDataOutputStream)" : [ "<init>" ],
  "org.apache.hadoop.util.ReadWriteDiskValidatorMetrics:diskCheckFailed()" : [ "incr", "set" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:shutdown()" : [ "stop", "unregister" ],
  "org.apache.hadoop.security.SaslRpcClient$WrappedInputStream:read(byte[],int,int)" : [ "readNextRpcPacket" ],
  "org.apache.hadoop.ipc.Server:isServerFailOverEnabledByQueue()" : [ "isServerFailOverEnabledByQueue" ],
  "org.apache.hadoop.ipc.Server:buildNegotiateResponse(java.util.List)" : [ "<init>" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:fatalError(java.lang.String)" : [ "reset" ],
  "org.apache.hadoop.crypto.key.KeyProviderDelegationTokenExtension:createKeyProviderDelegationTokenExtension(org.apache.hadoop.crypto.key.KeyProvider)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileSystem$Statistics:incrementReadOps(int)" : [ "getThreadStatistics" ],
  "org.apache.hadoop.fs.store.DataBlocks$DiskBlock:write(byte[],int,int)" : [ "write", "remainingCapacity" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyStatus:getPath()" : [ "getPath" ],
  "org.apache.hadoop.fs.FSDataOutputStreamBuilder:permission(org.apache.hadoop.fs.permission.FsPermission)" : [ "checkNotNull", "getThisBuilder" ],
  "org.apache.hadoop.security.LdapGroupsMapping:getDirContext()" : [ "setConfigurations", "get" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler$MetricsProxy:getCallVolumeSummary()" : [ "getCallVolumeSummary" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkNotNullAndNotEmpty(java.lang.String,java.lang.String)" : [ "checkNotNull", "checkArgument" ],
  "org.apache.hadoop.io.file.tfile.Chunk$ChunkDecoder:close()" : [ "checkEOF", "skip" ],
  "org.apache.hadoop.fs.ContentSummary:toString(boolean,boolean,boolean,boolean,java.util.List)" : [ "formatSize" ],
  "org.apache.hadoop.fs.FileSystem:resolvePath(org.apache.hadoop.fs.Path)" : [ "checkPath", "getPath" ],
  "org.apache.hadoop.fs.shell.CopyCommands$AppendToFile:expandArgument(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.util.LineReader:readLine(org.apache.hadoop.io.Text,int,int)" : [ "readCustomLine", "readDefaultLine" ],
  "org.apache.hadoop.io.SequenceFile$Writer:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class,int,short,long,org.apache.hadoop.util.Progressable,org.apache.hadoop.io.SequenceFile$Metadata)" : [ "<init>", "init", "create", "now" ],
  "org.apache.hadoop.fs.FilterFileSystem:startLocalOutput(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "startLocalOutput" ],
  "org.apache.hadoop.util.XMLUtils:setOptionalSecureTransformerAttributes(javax.xml.transform.TransformerFactory)" : [ "bestEffortSetAttribute" ],
  "org.apache.hadoop.ipc.RpcClientUtil:convertProtocolSignatureProtos(java.util.List)" : [ "<init>" ],
  "org.apache.hadoop.crypto.random.OpensslSecureRandom:next(int)" : [ "checkArgument", "nextBytes" ],
  "org.apache.hadoop.fs.FSDataInputStream:readVectored(java.util.List,java.util.function.IntFunction)" : [ "readVectored" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:getStoragePolicy(org.apache.hadoop.fs.Path)" : [ "getStoragePolicy" ],
  "org.apache.hadoop.fs.FilterFileSystem:getUsed()" : [ "getUsed" ],
  "org.apache.hadoop.fs.Globber:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.PathFilter,boolean)" : [ "get" ],
  "org.apache.hadoop.ipc.metrics.RpcDetailedMetrics:<init>(int)" : [ "<init>", "tag", "info" ],
  "org.apache.hadoop.fs.ChecksumFileSystem:create(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,boolean,int,short,long,org.apache.hadoop.util.Progressable)" : [ "create" ],
  "org.apache.hadoop.fs.TrashPolicyDefault:createCheckpoint()" : [ "createCheckpoint" ],
  "org.apache.hadoop.io.compress.BZip2Codec$BZip2CompressionOutputStream:finish()" : [ "finish", "internalReset" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.ByteBufferDecodingState:convertToByteArrayState()" : [ "<init>" ],
  "org.apache.hadoop.io.compress.GzipCodec$GzipZlibDecompressor:<init>()" : [ "<init>" ],
  "org.apache.hadoop.ipc.metrics.RetryCacheMetrics:create(org.apache.hadoop.ipc.RetryCache)" : [ "<init>", "instance" ],
  "org.apache.hadoop.io.erasurecode.coder.XORErasureEncoder:<init>(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileContext:getXAttr(org.apache.hadoop.fs.Path,java.lang.String)" : [ "fixRelativePart" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:<init>(org.apache.hadoop.fs.viewfs.InodeTree$INodeDir,long,org.apache.hadoop.security.UserGroupInformation,java.net.URI,org.apache.hadoop.fs.viewfs.InodeTree,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.fs.HarFileSystem:archivePath(org.apache.hadoop.fs.Path)" : [ "depth", "toString", "getParent" ],
  "org.apache.hadoop.util.LightWeightResizableGSet:remove(java.lang.Object)" : [ "remove" ],
  "org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl:run()" : [ "getCacheManipulator", "posixFadviseIfPossible" ],
  "org.apache.hadoop.fs.FilterFs:setOwner(org.apache.hadoop.fs.Path,java.lang.String,java.lang.String)" : [ "checkPath" ],
  "org.apache.hadoop.fs.shell.CommandWithDestination:processPathArgument(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "isDirectory", "getTargetPath", "makeQualified", "toString", "setTargetPath" ],
  "org.apache.hadoop.io.compress.BZip2Codec:getCompressorType()" : [ "getBzip2CompressorType" ],
  "org.apache.hadoop.io.compress.zlib.ZlibCompressor:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.permission.AclEntry:parseAclEntry(java.lang.String,boolean)" : [ "<init>", "setScope", "toUpperCase", "setType", "setName", "getFsAction", "setPermission", "build" ],
  "org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:getTokenInfoFromZK(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier,boolean)" : [ "getTokenInfoFromZK", "getNodePath", "getSequenceNumber" ],
  "org.apache.hadoop.metrics2.impl.MBeanInfoBuilder:gauge(org.apache.hadoop.metrics2.MetricsInfo,int)" : [ "newAttrInfo" ],
  "org.apache.hadoop.io.WritableComparator:compare(byte[],int,int,byte[],int,int)" : [ "compare", "reset" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:mainSort()" : [ "mainQSort3" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getUriPath(org.apache.hadoop.fs.Path)" : [ "makeAbsolute", "toUri" ],
  "org.apache.hadoop.io.EnumSetWritable:readFields(java.io.DataInput)" : [ "loadClass", "readString", "readObject" ],
  "org.apache.hadoop.ipc.RPC:setProtocolEngine(org.apache.hadoop.conf.Configuration,java.lang.Class,java.lang.Class)" : [ "get", "setClass" ],
  "org.apache.hadoop.io.WritableUtils:clone(org.apache.hadoop.io.Writable,org.apache.hadoop.conf.Configuration)" : [ "newInstance", "copy" ],
  "org.apache.hadoop.fs.FSInputChecker:readChecksumChunk(byte[],int,int)" : [ "needChecksum", "verifySums", "byteToHexString", "seek" ],
  "org.apache.hadoop.crypto.key.KeyShell$InvalidateCacheCommand:execute()" : [ "invalidateCache" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:parseDecayPeriodMillis(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "getLong" ],
  "org.apache.hadoop.ipc.CallQueueManager:addInternal(org.apache.hadoop.ipc.Schedulable,boolean)" : [ "isClientBackoffEnabled", "shouldBackOff", "throwBackoff" ],
  "org.apache.hadoop.security.KDiag:main(java.lang.String[])" : [ "<init>", "terminate", "exec", "toString", "halt" ],
  "org.apache.hadoop.fs.FilterFs:getUriPath(org.apache.hadoop.fs.Path)" : [ "getUriPath" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:mkdirsWithOptionalPermission(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "<init>", "getParent", "pathToFile", "mkOneDirWithMode" ],
  "org.apache.hadoop.io.erasurecode.ErasureCoderOptions:<init>(int,int)" : [ "<init>" ],
  "org.apache.hadoop.io.MapFile:fix(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class,boolean,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getInt", "exists", "file", "getKeyClass", "getValueClass", "newInstance", "createWriter", "keyClass", "valueClass", "getPosition", "isBlockCompressed", "next", "append", "set", "close" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:newSink(java.lang.String,java.lang.String,org.apache.hadoop.metrics2.impl.MetricsConfig)" : [ "newSink", "getPlugin" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedIO:openFile(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.FileStatus,java.lang.String)" : [ "openFileOnInstance", "instance" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding:measureDurationOfInvocation(org.apache.hadoop.fs.statistics.DurationTrackerFactory,java.lang.String,org.apache.hadoop.util.functional.InvocationRaisingIOE)" : [ "createTracker", "asDuration" ],
  "org.apache.hadoop.util.OperationDuration:toString()" : [ "getDurationString" ],
  "org.apache.hadoop.ipc.Server:updateDeferredMetrics(java.lang.String,long)" : [ "addDeferredRpcProcessingTime", "addDeferredProcessingTime" ],
  "org.apache.hadoop.metrics2.util.SampleStat:copyTo(org.apache.hadoop.metrics2.util.SampleStat)" : [ "reset" ],
  "org.apache.hadoop.ha.protocolPB.HAServiceProtocolServerSideTranslatorPB:transitionToObserver(org.apache.hadoop.thirdparty.protobuf.RpcController,org.apache.hadoop.ha.proto.HAServiceProtocolProtos$TransitionToObserverRequestProto)" : [ "convert" ],
  "org.apache.hadoop.util.Shell:getCheckProcessIsAliveCommand(java.lang.String)" : [ "getSignalKillCommand" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:getKeysMetadata(java.lang.String[])" : [ "createKeySets", "createURL", "createConnection", "call", "parseJSONMetadata" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:removeXAttr(org.apache.hadoop.fs.Path,java.lang.String)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:getMountPoints()" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem:<init>(java.net.URI[],org.apache.hadoop.conf.Configuration,int,java.util.EnumSet,org.apache.hadoop.fs.viewfs.FsGetter)" : [ "<init>", "newInstance", "getClass", "getNewInstance", "getRack", "getInstance", "sortByDistance" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyStatus:getSymlink()" : [ "getSymlink" ],
  "org.apache.hadoop.fs.FileSystem$Statistics:incrementBytesReadByDistance(int,long)" : [ "getThreadStatistics" ],
  "org.apache.hadoop.fs.shell.find.BaseExpression:getFileStatus(org.apache.hadoop.fs.shell.PathData,int)" : [ "isSymlink", "isFollowLink", "isFollowArgLink", "resolvePath", "getSymlink", "getFileSystem" ],
  "org.apache.hadoop.io.file.tfile.BoundedRangeFileInputStream:read(byte[])" : [ "read" ],
  "org.apache.hadoop.fs.shell.Truncate:processOptions(java.util.LinkedList)" : [ "<init>", "parse", "getOpt" ],
  "org.apache.hadoop.fs.HarFileSystem:decodeFileName(java.lang.String)" : [ "decodeString" ],
  "org.apache.hadoop.crypto.CryptoOutputStream:flush()" : [ "encrypt" ],
  "org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator:getOperatingSystemPageSize()" : [ "getOperatingSystemPageSize" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:getContentSummary(org.apache.hadoop.fs.Path)" : [ "<init>", "getContentSummary", "listStatus", "getPathWithoutSchemeAndAuthority", "getPath", "resolve", "toString", "getLength", "getFileCount", "getDirectoryCount", "length", "fileCount", "directoryCount", "build" ],
  "org.apache.hadoop.util.Classpath:terminate(int,java.lang.String)" : [ "terminate" ],
  "org.apache.hadoop.crypto.JceAesCtrCryptoCodec:createEncryptor()" : [ "<init>", "getCipherSuite" ],
  "org.apache.hadoop.security.UserGroupInformation:createRemoteUser(java.lang.String,org.apache.hadoop.security.SaslRpcServer$AuthMethod)" : [ "<init>", "setAuthenticationMethod" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler$MetricsProxy:getMetrics(org.apache.hadoop.metrics2.MetricsCollector,boolean)" : [ "getMetrics" ],
  "org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor:<init>()" : [ "newCrc32" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:addCost(java.lang.Object,long)" : [ "isServiceUser" ],
  "org.apache.hadoop.ipc.CallerContext:toString()" : [ "isContextValid" ],
  "org.apache.hadoop.fs.shell.Tail:registerCommands(org.apache.hadoop.fs.shell.CommandFactory)" : [ "addClass" ],
  "org.apache.hadoop.security.token.Token:equals(java.lang.Object)" : [ "equals" ],
  "org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:updateDelegationKey(org.apache.hadoop.security.token.delegation.DelegationKey)" : [ "addOrUpdateDelegationKey" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:createConnection()" : [ "connectToZooKeeper" ],
  "org.apache.hadoop.security.SecurityUtil:getServerPrincipal(java.lang.String,java.net.InetAddress)" : [ "getComponents", "replacePattern" ],
  "org.apache.hadoop.io.SequenceFile$Reader:getPosition()" : [ "getPos" ],
  "org.apache.hadoop.io.erasurecode.coder.ErasureDecoder:getErasedIndexes(org.apache.hadoop.io.erasurecode.ECBlock[])" : [ "getNumErasedBlocks", "isErased" ],
  "org.apache.hadoop.metrics2.MetricStringBuilder:addCounter(org.apache.hadoop.metrics2.MetricsInfo,long)" : [ "add" ],
  "org.apache.hadoop.util.SemaphoredDelegatingExecutor:<init>(java.util.concurrent.ExecutorService,int,boolean)" : [ "<init>" ],
  "org.apache.hadoop.io.SequenceFile$Reader:sync(long)" : [ "seek", "getPos" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler$MetricsProxy:getAverageResponseTime()" : [ "getAverageResponseTime" ],
  "org.apache.hadoop.fs.LocatedFileStatus:<init>()" : [ "<init>" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedIO:byteBufferPositionedReadable_readFully(java.io.InputStream,long,java.nio.ByteBuffer)" : [ "checkAvailable", "extractIOEs" ],
  "org.apache.hadoop.fs.ChecksumFileSystem:appendFile(org.apache.hadoop.fs.Path)" : [ "append" ],
  "org.apache.hadoop.security.KDiag:println()" : [ "println" ],
  "org.apache.hadoop.fs.statistics.DurationTrackerFactory:trackDuration(java.lang.String)" : [ "trackDuration" ],
  "org.apache.hadoop.io.erasurecode.coder.ErasureDecodingStep:performCoding(org.apache.hadoop.io.erasurecode.ECChunk[],org.apache.hadoop.io.erasurecode.ECChunk[])" : [ "decode" ],
  "org.apache.hadoop.util.functional.FutureIO:propagateOptions(org.apache.hadoop.fs.FSBuilder,org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String)" : [ "propagateOptions" ],
  "org.apache.hadoop.io.retry.RetryUtils:getDefaultRetryPolicy(org.apache.hadoop.conf.Configuration,java.lang.String,boolean,java.lang.String,java.lang.String,java.lang.String)" : [ "getMultipleLinearRandomRetry" ],
  "org.apache.hadoop.fs.FileSystem:copyToLocalFile(boolean,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,boolean)" : [ "getLocal", "copy" ],
  "org.apache.hadoop.fs.FileContext:getXAttrs(org.apache.hadoop.fs.Path)" : [ "fixRelativePart" ],
  "org.apache.hadoop.fs.impl.prefetch.CachingBlockManager:get(int)" : [ "<init>", "checkNotNegative", "acquire", "getInternal", "updateStatus", "toString", "continueRetry" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:sendMTFValues4()" : [ "bsW" ],
  "org.apache.hadoop.util.SemaphoredDelegatingExecutor:<init>(java.util.concurrent.ExecutorService,int,boolean,org.apache.hadoop.fs.statistics.DurationTrackerFactory)" : [ "stubDurationTrackerFactory" ],
  "org.apache.hadoop.net.unix.DomainSocketWatcher:close()" : [ "close" ],
  "org.apache.hadoop.metrics2.lib.MetricsSourceBuilder:add(java.lang.Object,java.lang.reflect.Method)" : [ "newForMethod" ],
  "org.apache.hadoop.fs.http.HttpFileSystem:append(org.apache.hadoop.fs.Path,int,org.apache.hadoop.util.Progressable)" : [ "append" ],
  "org.apache.hadoop.io.compress.lz4.Lz4Compressor:<init>(int)" : [ "<init>" ],
  "org.apache.hadoop.util.DiskChecker:checkDirWithDiskIo(java.io.File)" : [ "checkDirInternal", "doDiskIo" ],
  "org.apache.hadoop.fs.FileSystem:rename(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Options$Rename[])" : [ "<init>", "getFileLinkStatus", "isDirectory", "getParent" ],
  "org.apache.hadoop.ipc.RetryCache:addCacheEntry(byte[],int)" : [ "<init>", "put", "incrCacheUpdated" ],
  "org.apache.hadoop.fs.statistics.impl.StorageStatisticsFromIOStatistics:isTracked(java.lang.String)" : [ "counters", "gauges" ],
  "org.apache.hadoop.io.file.tfile.Compression:getCompressionAlgorithmByName(java.lang.String)" : [ "getName" ],
  "org.apache.hadoop.io.ObjectWritable$NullInstance:readFields(java.io.DataInput)" : [ "readString", "getClassByName" ],
  "org.apache.hadoop.security.token.DtFileOperations:printTokenFile(java.io.File,org.apache.hadoop.io.Text,org.apache.hadoop.conf.Configuration,java.io.PrintStream)" : [ "readTokenStorageFile", "printCredentials" ],
  "org.apache.hadoop.ha.PowerShellFencer:buildPSScript(java.lang.String,java.lang.String)" : [ "join" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenManager:createToken(org.apache.hadoop.security.UserGroupInformation,java.lang.String)" : [ "createToken" ],
  "org.apache.hadoop.io.Text:hashCode()" : [ "hashCode" ],
  "org.apache.hadoop.util.ReadWriteDiskValidatorMetrics:addReadFileLatency(long)" : [ "add" ],
  "org.apache.hadoop.io.SequenceFile$Writer$ReplicationOption:<init>(int)" : [ "<init>" ],
  "org.apache.hadoop.net.TableMapping$RawTableMapping:reloadCachedMappings()" : [ "load" ],
  "org.apache.hadoop.fs.viewfs.InodeTree:getRootFallbackLink()" : [ "checkState" ],
  "org.apache.hadoop.ipc.Client:<init>(java.lang.Class,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getDefaultSocketFactory" ],
  "org.apache.hadoop.fs.Path:checkNotSchemeWithRelative()" : [ "<init>", "toUri", "isUriPathAbsolute" ],
  "org.apache.hadoop.crypto.key.KeyShell$Command:warnIfTransientProvider()" : [ "isTransient" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockOperations:analyze(java.lang.StringBuilder)" : [ "append", "getIntList" ],
  "org.apache.hadoop.fs.statistics.impl.DynamicIOStatisticsBuilder:withAtomicLongGauge(java.lang.String,java.util.concurrent.atomic.AtomicLong)" : [ "withLongFunctionGauge" ],
  "org.apache.hadoop.ha.HealthMonitor:isHealthCheckFailedException(java.lang.Throwable)" : [ "unwrapRemoteException" ],
  "org.apache.hadoop.util.ReflectionUtils:newInstance(java.lang.Class,org.apache.hadoop.conf.Configuration,java.lang.Class[],java.lang.Object[])" : [ "setConf" ],
  "org.apache.hadoop.io.erasurecode.coder.HHXORErasureDecoder:release()" : [ "release" ],
  "org.apache.hadoop.io.compress.zlib.ZlibFactory:loadNativeZLib()" : [ "isNativeCodeLoaded", "isNativeZlibLoaded" ],
  "org.apache.hadoop.io.wrappedio.WrappedStatistics:iostatistics_maximums(java.io.Serializable)" : [ "applyToIOStatisticsSnapshot", "maximums" ],
  "org.apache.hadoop.io.BloomMapFile$Writer:initBloomFilter(org.apache.hadoop.conf.Configuration)" : [ "<init>", "getInt", "getFloat", "getHashType" ],
  "org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider:locateKeystore()" : [ "locatePassword", "get", "getPathAsString" ],
  "org.apache.hadoop.metrics2.lib.Interns:tag(org.apache.hadoop.metrics2.MetricsInfo,java.lang.String)" : [ "add" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:modifyAclEntries(org.apache.hadoop.fs.Path,java.util.List)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.ha.ShellCommandFencer:addTargetInfoAsEnvVars(org.apache.hadoop.ha.HAServiceTarget,java.util.Map)" : [ "getTransitionTargetHAStatus", "getFencingParameters" ],
  "org.apache.hadoop.util.IntrusiveCollection:remove(java.lang.Object)" : [ "removeElement" ],
  "org.apache.hadoop.security.UserGroupInformation:spawnAutoRenewalThreadForKeytab()" : [ "shouldRelogin", "isFromTicket", "getTGT", "getRefreshTime", "executeAutoRenewalTask", "getUserName" ],
  "org.apache.hadoop.util.ReadWriteDiskValidatorMetrics:addWriteFileLatency(long)" : [ "add" ],
  "org.apache.hadoop.net.unix.DomainSocketWatcher:kick()" : [ "getOutputStream", "write" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockOperations:getPrefetched(int)" : [ "<init>", "checkNotNegative", "add" ],
  "org.apache.hadoop.ha.FailoverController:failover(org.apache.hadoop.ha.HAServiceTarget,org.apache.hadoop.ha.HAServiceTarget,boolean,boolean)" : [ "<init>", "checkArgument", "preFailoverChecks", "tryGracefulFence", "fence", "transitionToActive", "getProxy", "createReqInfo" ],
  "org.apache.hadoop.io.WritableComparator:compareBytes(byte[],int,int,byte[],int,int)" : [ "compareTo" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedIO:openFileOnInstance(org.apache.hadoop.io.wrappedio.impl.DynamicWrappedIO,org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.FileStatus,java.lang.String)" : [ "fileSystem_openFile_available", "open", "fileSystem_openFile", "getPath" ],
  "org.apache.hadoop.util.Sets:newHashSet(java.lang.Object[])" : [ "newHashSetWithExpectedSize" ],
  "org.apache.hadoop.ha.ZKFailoverController:doGracefulFailover()" : [ "<init>", "getGracefulFenceTimeout", "checkArgument", "checkEligibleForFailover", "getCurrentActive", "cedeRemoteActive", "waitForActiveAttempt" ],
  "org.apache.hadoop.fs.FileSystem:create(org.apache.hadoop.fs.Path,boolean,int)" : [ "create", "getDefaultReplication", "getDefaultBlockSize" ],
  "org.apache.hadoop.fs.impl.prefetch.FilePosition:isWithinCurrentBuffer(long)" : [ "throwIfInvalidBuffer" ],
  "org.apache.hadoop.metrics2.MetricsJsonBuilder:addGauge(org.apache.hadoop.metrics2.MetricsInfo,double)" : [ "tuple" ],
  "org.apache.hadoop.fs.shell.Display$Cat:processOptions(java.util.LinkedList)" : [ "<init>", "parse", "getOpt" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:modifyAclEntries(org.apache.hadoop.fs.Path,java.util.List)" : [ "modifyAclEntries", "fullPath" ],
  "org.apache.hadoop.ipc.RpcClientException:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:getDeferredRpcProcessingSampleCount()" : [ "numSamples" ],
  "org.apache.hadoop.fs.LocalDirAllocator:getLocalPathForWrite(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "getLocalPathForWrite" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyStatus:toString()" : [ "toString" ],
  "org.apache.hadoop.security.UserGroupInformation:logoutUserFromKeytab()" : [ "<init>", "hasKerberosCredentials", "getKerberosLoginRenewalExecutor", "getLogin", "getKeytab", "getUserName", "logout", "setUser", "toString", "setKeytabFile" ],
  "org.apache.hadoop.io.compress.zlib.BuiltInGzipCompressor:init(org.apache.hadoop.conf.Configuration)" : [ "getCompressionLevel", "getCompressionStrategy", "compressionLevel", "compressionStrategy" ],
  "org.apache.hadoop.fs.FileUtil:execSetPermission(java.io.File,org.apache.hadoop.fs.permission.FsPermission)" : [ "isAvailable", "chmod", "toShort", "execCommand", "getSetPermissionCommand" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:modifyAclEntries(org.apache.hadoop.fs.Path,java.util.List)" : [ "modifyAclEntries", "fullPath" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:removeAcl(org.apache.hadoop.fs.Path)" : [ "removeAcl", "fullPath" ],
  "org.apache.hadoop.ipc.Client$IpcStreams:readResponse()" : [ "<init>", "readString" ],
  "org.apache.hadoop.io.BloomMapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.util.Progressable)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getTrashRoots(boolean)" : [ "<init>", "getTrashRoots", "getChildFileSystems", "getPath", "getBoolean", "getMountPoints", "getRootFallbackLink", "makeQualified", "getTargetFileSystem", "getShortUserName", "getFileStatus", "listStatus", "toUri" ],
  "org.apache.hadoop.io.SequenceFile$Reader:getDeserializer(org.apache.hadoop.io.serializer.SerializationFactory,java.lang.Class)" : [ "getDeserializer" ],
  "org.apache.hadoop.util.HostsFileReader:readFileToMap(java.lang.String,java.lang.String,java.util.Map)" : [ "readFileToMapWithFileInputStream" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:setPermission(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "setPermission", "resolve", "getUriPath" ],
  "org.apache.hadoop.service.ServiceStateException:convert(java.lang.String,java.lang.Throwable)" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkPositiveInteger(long,java.lang.String)" : [ "checkArgument" ],
  "org.apache.hadoop.io.compress.GzipCodec:createInputStream(java.io.InputStream,org.apache.hadoop.io.compress.Decompressor)" : [ "<init>", "createDecompressor", "getInt" ],
  "org.apache.hadoop.util.HeapSort:sort(org.apache.hadoop.util.IndexedSortable,int,int,org.apache.hadoop.util.Progressable)" : [ "downHeap" ],
  "org.apache.hadoop.security.SecurityUtil:setConfiguration(org.apache.hadoop.conf.Configuration)" : [ "setConfigurationInternal" ],
  "org.apache.hadoop.fs.FileContext:isSameFS(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "toUri" ],
  "org.apache.hadoop.fs.FileContext:setAcl(org.apache.hadoop.fs.Path,java.util.List)" : [ "fixRelativePart" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:meanStatistics()" : [ "getInnerStatistics" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:getFileLinkStatusInternal(org.apache.hadoop.fs.Path,boolean)" : [ "getNativeFileLinkStatus", "deprecatedGetFileStatus" ],
  "org.apache.hadoop.util.SysInfoWindows:getSystemInfoInfoFromShell()" : [ "<init>", "getWinUtilsFile", "execute", "getOutput", "stringifyException" ],
  "org.apache.hadoop.metrics2.source.JvmMetrics:getMemoryUsage(org.apache.hadoop.metrics2.MetricsRecordBuilder)" : [ "calculateMaxMemoryUsage" ],
  "org.apache.hadoop.security.ssl.DelegatingSSLSocketFactory:createSocket()" : [ "configureSocket" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:removeDefaultAcl(org.apache.hadoop.fs.Path)" : [ "removeDefaultAcl", "fullPath" ],
  "org.apache.hadoop.fs.impl.prefetch.FilePosition:bufferFullyRead()" : [ "throwIfInvalidBuffer", "relative" ],
  "org.apache.hadoop.util.SysInfoWindows:getCumulativeCpuTime()" : [ "refreshIfNeeded" ],
  "org.apache.hadoop.service.CompositeService:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:removeXAttr(org.apache.hadoop.fs.Path,java.lang.String)" : [ "removeXAttr", "fullPath" ],
  "org.apache.hadoop.fs.impl.prefetch.SingleFilePerBlockCache:put(int,java.nio.ByteBuffer,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.LocalDirAllocator)" : [ "<init>", "checkNotNull", "validateEntry", "addToLinkedListHead", "checkPositiveInteger", "getCacheFilePath", "writeFile", "getChecksum", "addToLinkedListAndEvictIfRequired" ],
  "org.apache.hadoop.io.SetFile$Reader:next(org.apache.hadoop.io.WritableComparable)" : [ "get" ],
  "org.apache.hadoop.util.UTF8ByteArrayUtils:findNthByte(byte[],byte,int)" : [ "findNthByte" ],
  "org.apache.hadoop.io.wrappedio.WrappedStatistics:iostatisticsContext_enabled()" : [ "enabled" ],
  "org.apache.hadoop.io.Text:write(java.io.DataOutput)" : [ "writeVInt" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:deleteKey(java.lang.String)" : [ "doOp", "nextIdx", "invalidateCache" ],
  "org.apache.hadoop.net.ScriptBasedMappingWithDependency:toString()" : [ "toString", "getRawMapping" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:bsGetInt()" : [ "bsR" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider:cleanupNewAndOld(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "renameOrFail" ],
  "org.apache.hadoop.fs.store.DataBlocks$DiskBlockFactory:createTmpFileForWrite(java.lang.String,long,org.apache.hadoop.conf.Configuration)" : [ "getLocalPathForWrite", "getParent", "toUri", "getName" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:getHomeDirectory()" : [ "<init>", "connect", "disconnect" ],
  "org.apache.hadoop.io.wrappedio.WrappedIO:byteBufferPositionedReadable_readFullyAvailable(java.io.InputStream)" : [ "getWrappedStream", "streamCapabilities_hasCapability" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:getFileChecksum(org.apache.hadoop.fs.Path)" : [ "getFileChecksum" ],
  "org.apache.hadoop.fs.HardLink:getLinkCount(java.io.File)" : [ "<init>", "execute", "getOutput", "getExitCode", "createIOException", "closeStream" ],
  "org.apache.hadoop.fs.impl.prefetch.BufferData:updateState(org.apache.hadoop.fs.impl.prefetch.BufferData$State,org.apache.hadoop.fs.impl.prefetch.BufferData$State[])" : [ "checkNotNull", "throwIfStateIncorrect" ],
  "org.apache.hadoop.fs.FileSystem$Statistics:getData()" : [ "<init>", "visitAll" ],
  "org.apache.hadoop.io.retry.RetryPolicy$RetryAction:<init>(org.apache.hadoop.io.retry.RetryPolicy$RetryAction$RetryDecision)" : [ "<init>" ],
  "org.apache.hadoop.ipc.metrics.RpcDetailedMetrics:init(java.lang.Class)" : [ "init" ],
  "org.apache.hadoop.util.LightWeightResizableGSet:getIterator(java.util.function.Consumer)" : [ "values" ],
  "org.apache.hadoop.io.file.tfile.TFile$Writer:prepareMetaBlock(java.lang.String)" : [ "prepareMetaBlock", "finishDataBlock" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkWithinRange(double,java.lang.String,double,double)" : [ "checkArgument" ],
  "org.apache.hadoop.io.erasurecode.coder.XORErasureDecoder:prepareDecodingStep(org.apache.hadoop.io.erasurecode.ECBlockGroup)" : [ "<init>", "createRawDecoder", "getOutputBlocks" ],
  "org.apache.hadoop.util.SysInfoWindows:getNetworkBytesRead()" : [ "refreshIfNeeded" ],
  "org.apache.hadoop.util.Lists:newArrayListWithExpectedSize(int)" : [ "computeArrayListCapacity" ],
  "org.apache.hadoop.fs.store.ByteBufferInputStream:hasRemaining()" : [ "checkOpenState" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:<init>(java.io.OutputStream,int)" : [ "<init>", "init" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:removeAcl(org.apache.hadoop.fs.Path)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.fs.FileSystem:listStatus(org.apache.hadoop.fs.Path[],org.apache.hadoop.fs.PathFilter)" : [ "listStatus" ],
  "org.apache.hadoop.fs.impl.FileSystemMultipartUploader:getPathHandle(org.apache.hadoop.fs.Path)" : [ "getPathHandle" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:getFileStatus(org.apache.commons.net.ftp.FTPClient,org.apache.hadoop.fs.Path)" : [ "<init>", "getFileStatus", "makeAbsolute", "getParent", "toUri", "getName" ],
  "org.apache.hadoop.util.ApplicationClassLoader:<init>(java.net.URL[],java.lang.ClassLoader,java.util.List)" : [ "getTrimmedStrings" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner:seekTo(org.apache.hadoop.io.file.tfile.RawComparable,boolean)" : [ "seekTo", "getBlockContainsKey", "compareTo", "atEnd", "getBlockIndex", "compareCursorKeyTo", "inBlockAdvance" ],
  "org.apache.hadoop.io.MultipleIOException:createIOException(java.util.List)" : [ "<init>" ],
  "org.apache.hadoop.io.SequenceFile$Sorter$SegmentDescriptor:close()" : [ "close" ],
  "org.apache.hadoop.util.Progress:toString()" : [ "toString" ],
  "org.apache.hadoop.fs.HarFileSystem:initializeMetadataCache(org.apache.hadoop.conf.Configuration)" : [ "<init>", "getInt" ],
  "org.apache.hadoop.fs.Options$CreateOpts:bufferSize(int)" : [ "<init>" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:parseThresholds(java.lang.String,org.apache.hadoop.conf.Configuration,int)" : [ "getInts", "getDefaultThresholds" ],
  "org.apache.hadoop.fs.FSDataOutputStreamBuilder:overwrite(boolean)" : [ "getThisBuilder" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:getDefaultPortIfDefined(org.apache.hadoop.fs.FileSystem)" : [ "getDefaultPort" ],
  "org.apache.hadoop.ipc.metrics.RetryCacheMetrics:incrCacheCleared()" : [ "incr" ],
  "org.apache.hadoop.util.dynamic.DynMethods$Builder:hiddenImpl(java.lang.String,java.lang.Class[])" : [ "hiddenImpl" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:instantiateService(org.apache.hadoop.conf.Configuration)" : [ "<init>", "checkArgument", "getClassLoader", "serviceCreationFailure" ],
  "org.apache.hadoop.security.UserGroupInformation:<init>(javax.security.auth.Subject)" : [ "getName" ],
  "org.apache.hadoop.util.dynamic.DynMethods$Builder:buildStatic()" : [ "build", "asStatic" ],
  "org.apache.hadoop.fs.statistics.MeanStatistic:<init>(org.apache.hadoop.fs.statistics.MeanStatistic)" : [ "set" ],
  "org.apache.hadoop.fs.store.ByteBufferInputStream:read()" : [ "available" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedIO:<init>(java.lang.String)" : [ "loadClass", "loadStaticMethod" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:iostatisticsSnapshot_aggregate(java.io.Serializable,java.lang.Object)" : [ "checkIoStatisticsAvailable", "invoke" ],
  "org.apache.hadoop.fs.FileSystem:checkPath(org.apache.hadoop.fs.Path)" : [ "checkArgument", "toUri", "getCanonicalUri", "getDefaultUri", "canonicalizeUri" ],
  "org.apache.hadoop.util.ProgramDriver:driver(java.lang.String[])" : [ "run" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner:inBlockAdvance(long)" : [ "checkKey", "isClosed", "close", "incRecordIndex" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:stopSources()" : [ "source", "stop" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState:getCompressionName()" : [ "getName" ],
  "org.apache.hadoop.ha.protocolPB.ZKFCProtocolClientSideTranslatorPB:cedeActive(int)" : [ "ipc" ],
  "org.apache.hadoop.security.SaslPropertiesResolver:setConf(org.apache.hadoop.conf.Configuration)" : [ "getTrimmedStrings", "toUpperCase", "getSaslQop", "join" ],
  "org.apache.hadoop.security.ShellBasedIdMapping:getGroupName(int,java.lang.String)" : [ "checkAndUpdateMaps", "updateMapIncr" ],
  "org.apache.hadoop.util.ProtoUtil:makeRpcRequestHeader(org.apache.hadoop.ipc.RPC$RpcKind,org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcRequestHeaderProto$OperationProto,int,int,byte[])" : [ "makeRpcRequestHeader" ],
  "org.apache.hadoop.net.NetworkTopologyWithNodeGroup:<init>()" : [ "<init>" ],
  "org.apache.hadoop.metrics2.util.Metrics2Util$TopN:offer(org.apache.hadoop.metrics2.util.Metrics2Util$NameValuePair)" : [ "updateTotal" ],
  "org.apache.hadoop.util.InstrumentedReadLock:startLockTiming()" : [ "monotonicNow" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:hasPathCapability(org.apache.hadoop.fs.Path,java.lang.String)" : [ "hasPathCapability", "validatePathCapabilityArgs", "areSymlinksEnabled" ],
  "org.apache.hadoop.fs.impl.prefetch.BufferData:throwIfStateIncorrect(org.apache.hadoop.fs.impl.prefetch.BufferData$State[])" : [ "checkNotNull", "stateEqualsOneOf" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier:<init>(org.apache.hadoop.io.Text,org.apache.hadoop.io.Text,org.apache.hadoop.io.Text)" : [ "setOwner", "setRenewer", "setRealUser" ],
  "org.apache.hadoop.fs.permission.FsPermission:getCachePoolDefault()" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockOperations$End:duration()" : [ "getTimestamp" ],
  "org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand:processOptions(java.util.LinkedList)" : [ "<init>", "popOptionWithArgument", "toUpperCase", "checkArgument", "popOption" ],
  "org.apache.hadoop.conf.Configuration:hasWarnedDeprecation(java.lang.String)" : [ "getDeprecatedKeyMap" ],
  "org.apache.hadoop.util.dynamic.DynConstructors$Builder:hiddenImpl(java.lang.Class[])" : [ "hiddenImpl" ],
  "org.apache.hadoop.http.HttpServer2:addPrometheusServlet(org.apache.hadoop.conf.Configuration)" : [ "<init>", "getBoolean", "getWebAppContext", "addServlet" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:getFsStatus()" : [ "<init>" ],
  "org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation:init(java.lang.Class,java.lang.String)" : [ "init" ],
  "org.apache.hadoop.net.AbstractDNSToSwitchMapping:isMappingSingleSwitch(org.apache.hadoop.net.DNSToSwitchMapping)" : [ "isSingleSwitch" ],
  "org.apache.hadoop.io.compress.zlib.ZlibDecompressor:<init>()" : [ "<init>" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.NativeRSRawErasureCoderFactory:createDecoder(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.io.MapFile$Reader:getKeyClass()" : [ "getKeyClass" ],
  "org.apache.hadoop.security.KDiag:validateUGI(java.lang.String,org.apache.hadoop.security.UserGroupInformation)" : [ "verify", "getAuthenticationMethod", "hasKerberosCredentials" ],
  "org.apache.hadoop.net.ScriptBasedMapping:setConf(org.apache.hadoop.conf.Configuration)" : [ "setConf", "getRawMapping" ],
  "org.apache.hadoop.io.MapFile$Writer:append(org.apache.hadoop.io.WritableComparable,org.apache.hadoop.io.Writable)" : [ "append", "checkKey", "getLength", "set" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:mainQSort3(org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream$Data,int,int,int)" : [ "mainSimpleSort", "med3", "vswap" ],
  "org.apache.hadoop.fs.FileSystem:getBlockSize(org.apache.hadoop.fs.Path)" : [ "getBlockSize" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsLogging:ioStatisticsSourceToString(java.lang.Object)" : [ "ioStatisticsToString", "retrieveIOStatistics" ],
  "org.apache.hadoop.util.Classpath:main(java.lang.String[])" : [ "<init>", "parse", "terminate", "getOpt", "createJarWithClassPath", "replaceFile" ],
  "org.apache.hadoop.crypto.CryptoInputStream:seek(long)" : [ "checkStream", "resetStreamOffset" ],
  "org.apache.hadoop.io.file.tfile.TFile$Writer:close()" : [ "close", "finishDataBlock", "prepareMetaBlock", "write", "cleanupWithLogger" ],
  "org.apache.hadoop.io.SequenceFile$Writer:metadata(org.apache.hadoop.io.SequenceFile$Metadata)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.lib.MutableRate:<init>(java.lang.String,java.lang.String,boolean)" : [ "<init>" ],
  "org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream:write(int)" : [ "flushBuffer" ],
  "org.apache.hadoop.fs.TrashPolicyDefault:initialize(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)" : [ "getFloat", "getBoolean" ],
  "org.apache.hadoop.fs.RawLocalFileSystem$DeprecatedRawLocalFileStatus:getPermission()" : [ "getPermission", "isPermissionLoaded", "loadPermissionInfo" ],
  "org.apache.hadoop.io.ArrayWritable:<init>(java.lang.Class,org.apache.hadoop.io.Writable[])" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:makeAbsolute(org.apache.hadoop.fs.Path)" : [ "<init>", "isAbsolute" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:getMetrics(org.apache.hadoop.metrics2.MetricsCollector,boolean)" : [ "snapshot" ],
  "org.apache.hadoop.io.retry.RetryPolicies$RetryLimited:shouldRetry(java.lang.Exception,int,int,boolean)" : [ "<init>", "getReason" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtobufRpcEngineCallbackImpl:<init>()" : [ "getServer", "getMethodName", "now" ],
  "org.apache.hadoop.fs.http.HttpFileSystem:getWorkingDirectory()" : [ "getWorkingDirectory" ],
  "org.apache.hadoop.util.CrcUtil:toMultiCrcString(byte[])" : [ "readInt" ],
  "org.apache.hadoop.fs.viewfs.ConfigUtil:setHomeDirConf(org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "setHomeDirConf", "getDefaultMountTableName" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:newCounter(org.apache.hadoop.metrics2.MetricsInfo,long)" : [ "<init>", "checkMetricName" ],
  "org.apache.hadoop.fs.ChecksumFileSystem:getSumBufferSize(int,int)" : [ "getInt" ],
  "org.apache.hadoop.util.functional.RemoteIterators$WrappedJavaIterator:getIOStatistics()" : [ "retrieveIOStatistics" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2:getProxy(java.lang.Class,long,java.net.InetSocketAddress,org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory,int,org.apache.hadoop.io.retry.RetryPolicy,java.util.concurrent.atomic.AtomicBoolean,org.apache.hadoop.ipc.AlignmentContext)" : [ "<init>" ],
  "org.apache.hadoop.io.retry.RetryPolicies$RetryLimited:equals(java.lang.Object)" : [ "toString" ],
  "org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory:createTrustManagersFromConfiguration(org.apache.hadoop.security.ssl.SSLFactory$Mode,java.lang.String,java.lang.String,long)" : [ "<init>", "resolvePropertyName", "getPassword", "getLong" ],
  "org.apache.hadoop.io.erasurecode.coder.ErasureDecoder:<init>(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>", "getNumDataUnits", "getNumParityUnits" ],
  "org.apache.hadoop.util.ServletUtil:getRawPath(javax.servlet.http.HttpServletRequest,java.lang.String)" : [ "checkArgument" ],
  "org.apache.hadoop.http.HttpServer2$Builder:createHttpChannelConnector(org.eclipse.jetty.server.Server,org.eclipse.jetty.server.HttpConfiguration)" : [ "getInt" ],
  "org.apache.hadoop.io.erasurecode.codec.XORErasureCodec:createDecoder()" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.CommandWithDestination:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "processPath", "getTargetPath" ],
  "org.apache.hadoop.util.StopWatch:stop()" : [ "monotonicNowNanos" ],
  "org.apache.hadoop.ha.HAAdmin:parseOpts(java.lang.String,org.apache.commons.cli.Options,java.lang.String[],java.util.Map)" : [ "printUsage" ],
  "org.apache.hadoop.conf.Configuration:updateConnectAddr(java.lang.String,java.net.InetSocketAddress)" : [ "getConnectAddress", "setSocketAddr" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:isSorted()" : [ "isSorted" ],
  "org.apache.hadoop.io.MapFile$Reader:get(org.apache.hadoop.io.WritableComparable,org.apache.hadoop.io.Writable)" : [ "seek", "getCurrentValue" ],
  "org.apache.hadoop.io.erasurecode.codec.DummyErasureCodec:createEncoder()" : [ "<init>" ],
  "org.apache.hadoop.util.LightWeightGSet:computeCapacity(long,double,java.lang.String)" : [ "<init>", "long2String" ],
  "org.apache.hadoop.metrics2.impl.MetricsConfig:getPluginLoader()" : [ "<init>" ],
  "org.apache.hadoop.http.HttpServer2$StackServlet:doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)" : [ "isInstrumentationAccessAllowed", "printThreadInfo", "logThreadInfo" ],
  "org.apache.hadoop.fs.FileSystem:create(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,java.util.EnumSet,int,short,long,org.apache.hadoop.util.Progressable)" : [ "create" ],
  "org.apache.hadoop.fs.FSDataOutputStream:getIOStatistics()" : [ "retrieveIOStatistics" ],
  "org.apache.hadoop.fs.FilterFileSystem:createSnapshot(org.apache.hadoop.fs.Path,java.lang.String)" : [ "createSnapshot" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:deleteSnapshot(org.apache.hadoop.fs.Path,java.lang.String)" : [ "deleteSnapshot", "resolve", "getUriPath" ],
  "org.apache.hadoop.metrics2.sink.StatsDSink$StatsD:createSocket()" : [ "wrapException" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:newGauge(java.lang.String,java.lang.String,long)" : [ "newGauge", "info" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:<init>(java.lang.String)" : [ "loadClass", "loadStaticMethod" ],
  "org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder$UnsafeComparer:compareTo(byte[],int,int,byte[],int,int)" : [ "lessThanUnsigned" ],
  "org.apache.hadoop.ipc.Client:setConnectTimeout(org.apache.hadoop.conf.Configuration,int)" : [ "setInt" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:create(org.apache.hadoop.fs.Path,boolean,int,short,long,org.apache.hadoop.util.Progressable)" : [ "create" ],
  "org.apache.hadoop.io.erasurecode.codec.RSErasureCodec:createEncoder()" : [ "<init>" ],
  "org.apache.hadoop.ipc.Client$Connection:setupIOstreams(java.util.concurrent.atomic.AtomicBoolean)" : [ "<init>", "setFallBackToSimpleAuth", "getTicket", "getRealUser", "getCurrentSpan", "addTimelineAnnotation", "setupConnection", "writeConnectionHeader", "doAs", "getAuthMethod", "handleSaslConnectionFailure", "setSaslClient", "getNegotiatedProperty", "writeConnectionContext", "touch", "markClosed", "close" ],
  "org.apache.hadoop.ha.NodeFencer:<init>(org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "parseMethods" ],
  "org.apache.hadoop.crypto.CryptoInputStream:decrypt(long,java.nio.ByteBuffer,int,int)" : [ "decrypt", "getBuffer", "getDecryptor", "updateDecryptor", "getPadding", "afterDecryption", "returnBuffer", "returnDecryptor" ],
  "org.apache.hadoop.http.HttpServer2:openListeners()" : [ "bindForPortRange", "bindForSinglePort" ],
  "org.apache.hadoop.net.NodeBase:getPathComponents(org.apache.hadoop.net.Node)" : [ "getPath" ],
  "org.apache.hadoop.io.erasurecode.coder.RSErasureEncoder:prepareEncodingStep(org.apache.hadoop.io.erasurecode.ECBlockGroup)" : [ "<init>", "checkCreateRSRawEncoder" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:write0(int)" : [ "writeRun" ],
  "org.apache.hadoop.fs.shell.CopyCommandWithMultiThread:copyFileToTarget(org.apache.hadoop.fs.shell.PathData,org.apache.hadoop.fs.shell.PathData)" : [ "copyFileToTarget" ],
  "org.apache.hadoop.ipc.ResponseBuffer:getFramedBuffer()" : [ "setSize" ],
  "org.apache.hadoop.jmx.JMXJsonServlet:isInstrumentationAccessAllowed(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)" : [ "isInstrumentationAccessAllowed" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:createFile(org.apache.hadoop.fs.Path)" : [ "createFile", "fullPath" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenManager:setExternalDelegationTokenSecretManager(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager)" : [ "stopThreads" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:listLocatedStatus(org.apache.hadoop.fs.Path)" : [ "listLocatedStatus", "fullPath" ],
  "org.apache.hadoop.fs.http.HttpFileSystem:listStatus(org.apache.hadoop.fs.Path)" : [ "listStatus" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:getTopCallers(int)" : [ "<init>", "offer" ],
  "org.apache.hadoop.ipc.Client:getTimeout(org.apache.hadoop.conf.Configuration)" : [ "getRpcTimeout", "getBoolean", "getPingInterval" ],
  "org.apache.hadoop.fs.DF:<init>(java.io.File,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getLong" ],
  "org.apache.hadoop.metrics2.impl.SinkQueue:clear()" : [ "checkConsumer" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RawErasureEncoder:allowChangeInputs()" : [ "allowChangeInputs" ],
  "org.apache.hadoop.ipc.Server:<init>(java.lang.String,int,java.lang.Class,int,int,int,org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.hadoop.security.token.SecretManager,java.lang.String)" : [ "<init>", "getInt", "getQueueClassPrefix", "getQueueClass", "getSchedulerClass", "getClientBackoffEnable", "getBoolean", "getAuthMethods", "buildNegotiateResponse", "getAddress", "create", "setLogSlowRPC", "setLogSlowRPCThresholdTime", "getLong", "setPurgeIntervalNanos", "isSecurityEnabled", "init", "getInstance", "addTerseLoggingExceptions" ],
  "org.apache.hadoop.fs.viewfs.ViewFsFileStatus:isDirectory()" : [ "isDirectory" ],
  "org.apache.hadoop.ipc.Server$Connection:processOneRpc(java.nio.ByteBuffer)" : [ "<init>", "wrap", "getMessage", "checkRpcHeaders", "processRpcOutOfBandRequest", "processRpcRequest", "getRpcStatusProto", "getRpcErrorCodeProto", "sendResponse" ],
  "org.apache.hadoop.ipc.RetryCache:incrCacheClearedCounter()" : [ "incrCacheCleared" ],
  "org.apache.hadoop.ha.SshFenceByTcpPort$Args:<init>(java.lang.String)" : [ "<init>", "parseConfiggedPort" ],
  "org.apache.hadoop.crypto.CryptoCodec:getInstance(org.apache.hadoop.conf.Configuration,org.apache.hadoop.crypto.CipherSuite)" : [ "getCodecClasses", "newInstance", "getName" ],
  "org.apache.hadoop.fs.FileSystem:getTrashRoot(org.apache.hadoop.fs.Path)" : [ "<init>", "makeQualified", "getHomeDirectory", "toUri" ],
  "org.apache.hadoop.net.NetUtils:getSocketFactoryFromProperty(org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "getClassByName", "newInstance" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:createPathHandle(org.apache.hadoop.fs.FileStatus,org.apache.hadoop.fs.Options$HandleOpt[])" : [ "<init>", "isDirectory", "isSymlink", "getPath", "toUri", "getOpt", "changed", "moved", "allowChange", "getModificationTime", "toString" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:cancelToken(org.apache.hadoop.security.token.Token,java.lang.String)" : [ "<init>", "getIdentifier", "readFields", "formatTokenId", "getUser", "getUserName", "getRenewer", "toString", "trackRemoveToken" ],
  "org.apache.hadoop.fs.permission.FsCreateModes:applyUMask(org.apache.hadoop.fs.permission.FsPermission,org.apache.hadoop.fs.permission.FsPermission)" : [ "applyUMask", "getUnmasked", "create" ],
  "org.apache.hadoop.fs.FilterFs:createInternal(org.apache.hadoop.fs.Path,java.util.EnumSet,org.apache.hadoop.fs.permission.FsPermission,int,short,long,org.apache.hadoop.util.Progressable,org.apache.hadoop.fs.Options$ChecksumOpt,boolean)" : [ "checkPath" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:getPriorityLevel(org.apache.hadoop.security.UserGroupInformation)" : [ "getIdentity", "newSchedulable", "cachedOrComputedPriorityLevel" ],
  "org.apache.hadoop.util.ComparableVersion:parseVersion(java.lang.String)" : [ "<init>", "toLowerCase", "parseItem", "normalize", "toString" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:getFileStatus(com.jcraft.jsch.ChannelSftp,org.apache.hadoop.fs.Path)" : [ "<init>", "makeAbsolute", "getParent", "makeQualified", "getUri", "getWorkingDirectory", "toUri", "getName" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$ExpiredTokenRemover:run()" : [ "now", "rollMasterKey" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:getFileChecksum(org.apache.hadoop.fs.Path)" : [ "getFileChecksum", "fullPath" ],
  "org.apache.hadoop.util.bloom.DynamicBloomFilter:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.FilterFileSystem:setWriteChecksum(boolean)" : [ "setWriteChecksum" ],
  "org.apache.hadoop.util.WeakReferenceMap:containsKey(java.lang.Object)" : [ "lookup", "resolve" ],
  "org.apache.hadoop.fs.impl.prefetch.CachingBlockManager:cancelPrefetches()" : [ "cancelPrefetches", "getAll", "stateEqualsOneOf", "requestCaching", "end" ],
  "org.apache.hadoop.io.compress.zlib.ZlibDecompressor:setInput(byte[],int,int)" : [ "setInputFromSavedData" ],
  "org.apache.hadoop.fs.FileContext:checkDependencies(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "isSameFS", "toString" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:addDecayedCallVolume(org.apache.hadoop.metrics2.MetricsRecordBuilder)" : [ "info", "getTotalCallVolume" ],
  "org.apache.hadoop.security.NetgroupCache:isCached(java.lang.String)" : [ "getGroups" ],
  "org.apache.hadoop.ipc.WeightedTimeCostProvider:init(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "getInt" ],
  "org.apache.hadoop.ipc.Server:queueCall(org.apache.hadoop.ipc.Server$Call)" : [ "internalQueueCall" ],
  "org.apache.hadoop.metrics2.sink.RollingFileSystemSink:getNonNegative(java.lang.String,int)" : [ "<init>" ],
  "org.apache.hadoop.security.HadoopKerberosName:setConfiguration(org.apache.hadoop.conf.Configuration)" : [ "getAuthenticationMethod", "get" ],
  "org.apache.hadoop.conf.Configuration:getConfResourceAsInputStream(java.lang.String)" : [ "getResource" ],
  "org.apache.hadoop.security.alias.JavaKeyStoreProvider:<init>(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:getKeyFromZK(int)" : [ "<init>", "getNodePath", "readFields" ],
  "org.apache.hadoop.conf.Configuration:addDeprecation(java.lang.String,java.lang.String)" : [ "addDeprecation" ],
  "org.apache.hadoop.log.LogLevel$CLI:parseSetLevelArgs(java.lang.String[],int)" : [ "<init>" ],
  "org.apache.hadoop.util.LightWeightCache:evictEntries()" : [ "evict" ],
  "org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider:noPasswordWarning()" : [ "noPasswordWarning" ],
  "org.apache.hadoop.conf.Configuration:writeXml(java.lang.String,java.io.Writer,org.apache.hadoop.conf.Configuration)" : [ "<init>", "asXmlDocument", "newSecureTransformerFactory" ],
  "org.apache.hadoop.fs.impl.prefetch.BoundedResourcePool:numAvailable()" : [ "numCreated" ],
  "org.apache.hadoop.io.wrappedio.WrappedStatistics:iostatistics_counters(java.io.Serializable)" : [ "applyToIOStatisticsSnapshot", "counters" ],
  "org.apache.hadoop.io.WritableUtils:toByteArray(org.apache.hadoop.io.Writable[])" : [ "<init>", "getData" ],
  "org.apache.hadoop.ipc.RemoteException:unwrapRemoteException(java.lang.Class[])" : [ "getClassName", "instantiateException" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:satisfyStoragePolicy(org.apache.hadoop.fs.Path)" : [ "satisfyStoragePolicy" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:getDefaultReplication(org.apache.hadoop.fs.Path)" : [ "getDefaultReplication", "fullPath" ],
  "org.apache.hadoop.io.nativeio.NativeIO:copyFileUnbuffered(java.io.File,java.io.File)" : [ "cleanupWithLogger" ],
  "org.apache.hadoop.fs.BlockLocation:setHosts(java.lang.String[])" : [ "internStringsInArray" ],
  "org.apache.hadoop.ha.ZKFailoverController:doFence(org.apache.hadoop.ha.HAServiceTarget)" : [ "<init>", "tryGracefulFence", "recordActiveAttempt", "fence" ],
  "org.apache.hadoop.ipc.ResponseBuffer$FramedBuffer:reset()" : [ "setSize" ],
  "org.apache.hadoop.io.SequenceFile$BlockCompressWriter:close()" : [ "close", "sync" ],
  "org.apache.hadoop.fs.ChecksumFs$ChecksumFSInputChecker:seek(long)" : [ "seek", "getFileLength" ],
  "org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:stopThreads()" : [ "stopThreads" ],
  "org.apache.hadoop.fs.MD5MD5CRC32GzipFileChecksum:<init>(int,long,org.apache.hadoop.io.MD5Hash)" : [ "<init>" ],
  "org.apache.hadoop.fs.FSInputChecker:verifySums(byte[],int,int)" : [ "<init>" ],
  "org.apache.hadoop.util.bloom.RetouchedBloomFilter:ratioRemove(int[])" : [ "computeRatio" ],
  "org.apache.hadoop.metrics2.MetricsJsonBuilder:add(org.apache.hadoop.metrics2.AbstractMetric)" : [ "tuple", "info", "toString" ],
  "org.apache.hadoop.util.functional.CommonCallableSupplier:waitForCompletionIgnoringExceptions(java.util.concurrent.CompletableFuture)" : [ "<init>", "close" ],
  "org.apache.hadoop.util.bloom.RetouchedBloomFilter:computeRatio()" : [ "getWeight" ],
  "org.apache.hadoop.fs.FileStatus:toString()" : [ "isDirectory", "isSymlink", "getSymlink", "hasAcl", "isEncrypted", "isErasureCoded" ],
  "org.apache.hadoop.fs.FileContext:mkdir(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,boolean)" : [ "fixRelativePart", "applyUMask", "getDirDefault", "getUMask" ],
  "org.apache.hadoop.fs.shell.Command:displayError(java.lang.String)" : [ "displayWarning" ],
  "org.apache.hadoop.conf.ConfigurationWithLogging:getLong(java.lang.String,long)" : [ "getLong" ],
  "org.apache.hadoop.util.SysInfoLinux:getPhysicalMemorySize()" : [ "readProcMemInfoFile" ],
  "org.apache.hadoop.util.SysInfoLinux:getNetworkBytesWritten()" : [ "readProcNetInfoFile" ],
  "org.apache.hadoop.fs.statistics.impl.DynamicIOStatisticsBuilder:withAtomicIntegerMinimum(java.lang.String,java.util.concurrent.atomic.AtomicInteger)" : [ "withLongFunctionMinimum" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL:cancelDelegationToken(java.net.URL,org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL$Token)" : [ "cancelDelegationToken" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:getXAttrs(org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.security.KDiag:println(java.lang.String,java.lang.Object[])" : [ "flush" ],
  "org.apache.hadoop.fs.Path:startPositionWithoutWindowsDrive(java.lang.String)" : [ "hasWindowsDrive" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:resolvePath(org.apache.hadoop.fs.Path)" : [ "resolvePath", "isInternalDir" ],
  "org.apache.hadoop.fs.impl.prefetch.CachingBlockManager:numAvailable()" : [ "numAvailable" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner$Entry:getKey(org.apache.hadoop.io.BytesWritable)" : [ "getKey", "setSize", "getKeyLength", "getBytes", "getLength" ],
  "org.apache.hadoop.util.Shell:runCommand()" : [ "<init>", "joinThread", "monotonicNow" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RSLegacyRawEncoder:doEncode(org.apache.hadoop.io.erasurecode.rawcoder.ByteArrayEncodingState)" : [ "resetOutputBuffers", "remainder" ],
  "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilterInitializer:createFilterConfig(org.apache.hadoop.conf.Configuration)" : [ "getFilterConfigMap", "getPropsWithPrefix" ],
  "org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner:run()" : [ "cleanUp" ],
  "org.apache.hadoop.util.HostsFileReader:setIncludesFile(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.io.Text:decode(byte[])" : [ "decode" ],
  "org.apache.hadoop.util.JsonSerialization:<init>(java.lang.Class,boolean,boolean)" : [ "checkArgument" ],
  "org.apache.hadoop.crypto.CryptoCodec:getInstance(org.apache.hadoop.conf.Configuration)" : [ "getInstance", "get", "convert" ],
  "org.apache.hadoop.fs.FilterFs:open(org.apache.hadoop.fs.Path)" : [ "open", "checkPath" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:mkdirs(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "mkdirs", "connect", "disconnect" ],
  "org.apache.hadoop.fs.FsShell:printInstanceHelp(java.io.PrintStream,org.apache.hadoop.fs.shell.Command)" : [ "getUsage", "getDescription", "createOptionTableListing", "addRow", "toString", "wrap" ],
  "org.apache.hadoop.security.LdapGroupsMapping$LdapSslSocketFactory:createKeyManagers()" : [ "createKeyStore", "getPasswordCharArray" ],
  "org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:storeDelegationKey(org.apache.hadoop.security.token.delegation.DelegationKey)" : [ "addOrUpdateDelegationKey" ],
  "org.apache.hadoop.io.UTF8:toStringChecked()" : [ "reset", "readChars" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:getResolvedQualifiedPath(org.apache.hadoop.fs.Path)" : [ "<init>", "toUri" ],
  "org.apache.hadoop.io.BytesWritable:equals(java.lang.Object)" : [ "equals" ],
  "org.apache.hadoop.util.JvmPauseMonitor:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.http.HttpFileSystem:delete(org.apache.hadoop.fs.Path,boolean)" : [ "delete" ],
  "org.apache.hadoop.fs.PathAccessDeniedException:<init>(java.lang.String,java.lang.Throwable)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem:create(org.apache.hadoop.fs.shell.PathData,boolean)" : [ "getFileDefault", "applyUMask", "getUMask", "getInt" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:setTimes(org.apache.hadoop.fs.Path,long,long)" : [ "fullPath" ],
  "org.apache.hadoop.io.file.tfile.Compression$Algorithm:getCompressor()" : [ "getCompressor" ],
  "org.apache.hadoop.fs.FileSystem:listStatusBatch(org.apache.hadoop.fs.Path,byte[])" : [ "<init>" ],
  "org.apache.hadoop.io.compress.bzip2.CRC:<init>()" : [ "initialiseCRC" ],
  "org.apache.hadoop.util.LineReader:readLine(org.apache.hadoop.io.Text,int)" : [ "readLine" ],
  "org.apache.hadoop.security.ssl.SSLHostnameVerifier$AbstractVerifier:check(java.lang.String,java.security.cert.X509Certificate)" : [ "check" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenManager$ZKSecretManager:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.io.Text)" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.CachingKeyProvider:rollNewVersion(java.lang.String)" : [ "rollNewVersion", "invalidateCache" ],
  "org.apache.hadoop.fs.store.DataBlocks$ArrayBlockFactory:create(long,int,org.apache.hadoop.fs.store.BlockUploadStatistics)" : [ "<init>" ],
  "org.apache.hadoop.http.ProfileServlet:getEvent(javax.servlet.http.HttpServletRequest)" : [ "fromInternalName" ],
  "org.apache.hadoop.io.ArrayPrimitiveWritable:write(java.io.DataOutput)" : [ "writeString", "writeBooleanArray", "writeCharArray", "writeByteArray", "writeShortArray", "writeIntArray", "writeLongArray", "writeFloatArray", "writeDoubleArray" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:listStatus(org.apache.hadoop.fs.Path)" : [ "fullPath" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:bsPutUByte(int)" : [ "bsW" ],
  "org.apache.hadoop.fs.impl.AbstractFSBuilderImpl:<init>(java.util.Optional,java.util.Optional)" : [ "<init>", "checkArgument", "checkNotNull" ],
  "org.apache.hadoop.fs.FileUtil:setPermission(java.io.File,org.apache.hadoop.fs.permission.FsPermission)" : [ "getUserAction", "getGroupAction", "getOtherAction", "isAvailable", "execSetPermission", "implies", "checkReturnValue" ],
  "org.apache.hadoop.service.AbstractService:recordLifecycleEvent()" : [ "getServiceState" ],
  "org.apache.hadoop.util.RunJar:run(java.lang.String[])" : [ "ensureDirectory", "get", "addShutdownHook", "skipUnjar", "unJar", "createClassLoader" ],
  "org.apache.hadoop.security.UserGroupInformation:initialize(org.apache.hadoop.conf.Configuration,boolean)" : [ "getAuthenticationMethod", "setConfiguration", "getLong", "get", "getBoolean", "getUserToGroupsMappingService", "getInts", "newQuantiles" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:fenceOldActive()" : [ "zkDoWithRetries", "isNodeDoesNotExist", "byteToHexString" ],
  "org.apache.hadoop.fs.shell.Command:getName()" : [ "getCommandField" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:drain(java.lang.String)" : [ "drain" ],
  "org.apache.hadoop.fs.sftp.SFTPInputStream:checkNotClosed()" : [ "toUri" ],
  "org.apache.hadoop.util.functional.FunctionalIO:uncheckIOExceptions(org.apache.hadoop.util.functional.CallableRaisingIOE)" : [ "unchecked" ],
  "org.apache.hadoop.tracing.TraceScope:close()" : [ "close" ],
  "org.apache.hadoop.fs.statistics.impl.DynamicIOStatistics:<init>()" : [ "<init>", "copy" ],
  "org.apache.hadoop.util.MachineList:includes(java.lang.String)" : [ "includes", "getByName" ],
  "org.apache.hadoop.fs.ChecksumFileSystem:create(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,boolean,boolean,int,short,long,org.apache.hadoop.util.Progressable)" : [ "<init>", "getParent", "exists", "mkdirs", "getChecksumFile" ],
  "org.apache.hadoop.util.curator.ZKCuratorManager:createRootDirRecursively(java.lang.String,java.util.List)" : [ "checkArgument", "create" ],
  "org.apache.hadoop.io.compress.DefaultCodec:createDirectDecompressor()" : [ "getZlibDirectDecompressor" ],
  "org.apache.hadoop.net.NetworkTopology:chooseRandom(java.lang.String)" : [ "chooseRandom" ],
  "org.apache.hadoop.io.ObjectWritable:writeObject(java.io.DataOutput,java.lang.Object,java.lang.Class,org.apache.hadoop.conf.Configuration)" : [ "writeObject" ],
  "org.apache.hadoop.conf.StorageSize:parse(java.lang.String)" : [ "<init>", "checkState" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Factory:getBzip2CompressorType(org.apache.hadoop.conf.Configuration)" : [ "isNativeBzip2Loaded" ],
  "org.apache.hadoop.fs.shell.MoveCommands$MoveFromLocal:postProcessPath(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "toString", "setOperation" ],
  "org.apache.hadoop.conf.ReconfigurableBase:getReconfigurationTaskStatus()" : [ "<init>" ],
  "org.apache.hadoop.crypto.OpensslCtrCryptoCodec:setConf(org.apache.hadoop.conf.Configuration)" : [ "getClass", "newInstance" ],
  "org.apache.hadoop.io.compress.zlib.ZlibCompressor:getBytesRead()" : [ "checkStream" ],
  "org.apache.hadoop.io.file.tfile.TFile$Writer:finishDataBlock(boolean)" : [ "<init>", "getCompressedSize", "getBuffer", "size", "addEntry", "close" ],
  "org.apache.hadoop.ha.HAServiceTarget:getHealthMonitorProxy(org.apache.hadoop.conf.Configuration,int)" : [ "getHealthMonitorProxy" ],
  "org.apache.hadoop.ipc.Server:isClientBackoffEnabled()" : [ "isClientBackoffEnabled" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:initialize(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "initialize" ],
  "org.apache.hadoop.fs.shell.Delete$Rmr:processOptions(java.util.LinkedList)" : [ "processOptions" ],
  "org.apache.hadoop.fs.FilterFileSystem:initialize(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "initialize" ],
  "org.apache.hadoop.io.compress.DecompressorStream:getCompressedData()" : [ "checkStream" ],
  "org.apache.hadoop.fs.impl.WrappedIOException:<init>(java.io.IOException)" : [ "checkNotNull" ],
  "org.apache.hadoop.ipc.RemoteException:<init>(java.lang.String,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getAclStatus(org.apache.hadoop.fs.Path)" : [ "getAclStatus", "resolve", "getUriPath" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:createWithRetries(java.lang.String,byte[],java.util.List,org.apache.zookeeper.CreateMode)" : [ "zkDoWithRetries" ],
  "org.apache.hadoop.fs.FileSystem:create(org.apache.hadoop.fs.Path,short,org.apache.hadoop.util.Progressable)" : [ "create", "getInt", "getDefaultBlockSize" ],
  "org.apache.hadoop.io.Text:readString(java.io.DataInput,int)" : [ "readVIntInRange", "decode" ],
  "org.apache.hadoop.util.SysInfoWindows:getNumCores()" : [ "getNumProcessors" ],
  "org.apache.hadoop.fs.shell.Test:processOptions(java.util.LinkedList)" : [ "<init>", "parse", "getOpts" ],
  "org.apache.hadoop.fs.FileUtil:copy(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.FileStatus,java.io.File,boolean,org.apache.hadoop.conf.Configuration)" : [ "getPath", "isDirectory", "getName", "awaitFuture", "openFile", "withFileStatus", "build", "copyBytes" ],
  "org.apache.hadoop.io.WritableUtils:skipCompressedByteArray(java.io.DataInput)" : [ "skipFully" ],
  "org.apache.hadoop.fs.shell.SnapshotCommands$RenameSnapshot:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "isDirectory", "toString" ],
  "org.apache.hadoop.net.unix.DomainSocket:accept()" : [ "<init>", "reference", "unreference" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationHandler:authenticate(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)" : [ "<init>", "getDelegationToken", "decodeFromUrlString", "verifyToken", "getShortUserName", "getUserName", "getType", "createServletExceptionResponse" ],
  "org.apache.hadoop.fs.FSBuilder:must(java.lang.String,long)" : [ "mustLong" ],
  "org.apache.hadoop.fs.LocalFileSystem:initialize(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "initialize" ],
  "org.apache.hadoop.util.DataChecksum:verifyChunked(org.apache.hadoop.util.DataChecksum$Type,java.util.zip.Checksum,java.nio.ByteBuffer,int,java.nio.ByteBuffer,java.lang.String,long)" : [ "throwChecksumException" ],
  "org.apache.hadoop.fs.ChecksumFileSystem:getChecksumFileLength(org.apache.hadoop.fs.Path,long)" : [ "getChecksumLength", "getBytesPerSum" ],
  "org.apache.hadoop.util.CombinedIPList:<init>(java.lang.String,java.lang.String,long)" : [ "<init>" ],
  "org.apache.hadoop.io.GenericWritable:readFields(java.io.DataInput)" : [ "newInstance" ],
  "org.apache.hadoop.fs.FilterFs:removeXAttr(org.apache.hadoop.fs.Path,java.lang.String)" : [ "removeXAttr" ],
  "org.apache.hadoop.fs.shell.find.Print:<init>()" : [ "<init>" ],
  "org.apache.hadoop.service.AbstractService:notifyListeners()" : [ "notifyListeners" ],
  "org.apache.hadoop.fs.shell.PathData:parentExists()" : [ "representsDirectory", "exists", "getParent" ],
  "org.apache.hadoop.fs.FilterFileSystem:getXAttrs(org.apache.hadoop.fs.Path)" : [ "getXAttrs" ],
  "org.apache.hadoop.security.LdapGroupsMapping:doGetGroups(java.lang.String,int)" : [ "getDirContext", "getRelativeDistinguishedName", "lookupGroup" ],
  "org.apache.hadoop.crypto.key.KeyShell:init(java.lang.String[])" : [ "options", "setBitLength", "setCipher", "setDescription", "set", "setBoolean", "printGenericCommandUsage", "setAttributes" ],
  "org.apache.hadoop.net.unix.DomainSocket:connect(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Writer$MetaBlockRegister:register(long,long,long)" : [ "<init>", "addEntry" ],
  "org.apache.hadoop.metrics2.lib.MutableRollingAverages$RatesRoller:run()" : [ "addRecord", "snapshot", "checkState", "getRecords", "getGlobalMetrics" ],
  "org.apache.hadoop.util.OperationDuration:getDurationString()" : [ "humanTime", "value" ],
  "org.apache.hadoop.fs.BBPartHandle:equals(java.lang.Object)" : [ "bytes" ],
  "org.apache.hadoop.ha.ZKFailoverController:getCurrentActive()" : [ "getActiveData" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:setupRandPartC()" : [ "updateCRC", "setupRandPartA" ],
  "org.apache.hadoop.net.ScriptBasedMapping:toString()" : [ "toString", "getRawMapping" ],
  "org.apache.hadoop.util.VersionInfo:getUser()" : [ "_getUser" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState:getCurrentPos()" : [ "getPos", "size" ],
  "org.apache.hadoop.fs.viewfs.ConfigUtil:setHomeDirConf(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String)" : [ "set", "getConfigViewFsPrefix" ],
  "org.apache.hadoop.io.WritableComparator:readLong(byte[],int)" : [ "readInt" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:deleteSnapshot(org.apache.hadoop.fs.Path,java.lang.String)" : [ "deleteSnapshot" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getServerDefaults()" : [ "<init>" ],
  "org.apache.hadoop.util.dynamic.DynMethods$Builder:impl(java.lang.Class,java.lang.Class[])" : [ "impl" ],
  "org.apache.hadoop.metrics2.impl.MetricsSourceAdapter:start()" : [ "startMBeans" ],
  "org.apache.hadoop.ipc.protocolPB.GenericRefreshProtocolClientSideTranslatorPB:refresh(java.lang.String,java.lang.String[])" : [ "ipc", "unpack" ],
  "org.apache.hadoop.ipc.Client$Call:<init>(org.apache.hadoop.ipc.RPC$RpcKind,org.apache.hadoop.io.Writable)" : [ "nextCallId" ],
  "org.apache.hadoop.fs.statistics.impl.EmptyIOStatisticsContextImpl:getAggregator()" : [ "getInstance" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme$ChildFsGetter:createFileSystem(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getClass", "newInstance", "initialize" ],
  "org.apache.hadoop.conf.Configuration:setPattern(java.lang.String,java.util.regex.Pattern)" : [ "set" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2:clearClientCache()" : [ "clearCache" ],
  "org.apache.hadoop.io.nativeio.SharedFileDescriptorFactory:getLoadingFailureReason()" : [ "isAvailable" ],
  "org.apache.hadoop.fs.shell.CopyCommands$Cp:processOptions(java.util.LinkedList)" : [ "<init>", "popPreserveOption", "addOptionWithValue", "parse", "getOpt", "getOptValue" ],
  "org.apache.hadoop.io.erasurecode.grouper.BlockGrouper:getRequiredNumDataBlocks()" : [ "getNumDataUnits" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL:<init>(org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator)" : [ "<init>" ],
  "org.apache.hadoop.io.file.tfile.Utils:readString(java.io.DataInput)" : [ "readVInt", "decode" ],
  "org.apache.hadoop.conf.Configuration:reloadExistingConfigurations()" : [ "reloadConfiguration" ],
  "org.apache.hadoop.conf.Configuration:getBoolean(java.lang.String,boolean)" : [ "getTrimmed", "equalsIgnoreCase" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockOperations:cancelPrefetches()" : [ "<init>", "add" ],
  "org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:processKeyAddOrUpdate(byte[])" : [ "<init>", "readFields", "getKeyId" ],
  "org.apache.hadoop.io.file.tfile.BCFile$MetaIndexEntry:<init>(java.io.DataInput)" : [ "<init>", "readString", "getCompressionAlgorithmByName" ],
  "org.apache.hadoop.ipc.RpcWritable:wrap(java.lang.Object)" : [ "<init>", "isUnshadedProtobufMessage" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsSupport:retrieveIOStatistics(java.lang.Object)" : [ "getIOStatistics" ],
  "org.apache.hadoop.security.alias.KeyStoreProvider:<init>(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.prefetch.BufferData:setPrefetch(java.util.concurrent.Future)" : [ "checkNotNull", "updateState" ],
  "org.apache.hadoop.fs.Options$HandleOpt:resolve(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Options$HandleOpt[])" : [ "resolve", "getPathHandle" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.util.RSUtil:getPrimitivePower(int,int)" : [ "power" ],
  "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker:readVectored(java.util.List,java.util.function.IntFunction)" : [ "readVectored", "getFileLength", "validateAndSortRanges", "mergeSortedRanges", "findChecksumRanges", "getUnderlying" ],
  "org.apache.hadoop.metrics2.filter.GlobFilter:compile(java.lang.String)" : [ "compile" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner:close()" : [ "parkCursorAtEnd" ],
  "org.apache.hadoop.metrics2.lib.DefaultMetricsSystem:initialize(java.lang.String)" : [ "init" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.DecodingValidator:validate(org.apache.hadoop.io.erasurecode.ECChunk[],int[],org.apache.hadoop.io.erasurecode.ECChunk[])" : [ "validate", "toBuffers" ],
  "org.apache.hadoop.metrics2.util.SampleStat:toString()" : [ "numSamples", "min", "mean", "stddev", "max" ],
  "org.apache.hadoop.fs.FsShell:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreImpl:addMeanStatisticSample(java.lang.String,long)" : [ "addSample" ],
  "org.apache.hadoop.io.SequenceFile$Writer:syncFs()" : [ "hflush" ],
  "org.apache.hadoop.util.bloom.BloomFilter:membershipTest(org.apache.hadoop.util.bloom.Key)" : [ "hash", "clear" ],
  "org.apache.hadoop.metrics2.impl.MetricGaugeFloat:<init>(org.apache.hadoop.metrics2.MetricsInfo,float)" : [ "<init>" ],
  "org.apache.hadoop.util.FindClass:loadResource(java.lang.String)" : [ "getResource", "err", "out" ],
  "org.apache.hadoop.fs.shell.Head:registerCommands(org.apache.hadoop.fs.shell.CommandFactory)" : [ "addClass" ],
  "org.apache.hadoop.io.compress.GzipCodec$GzipZlibCompressor:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.FileSystem:get(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "get", "getDefaultUri", "getBoolean", "createFileSystem" ],
  "org.apache.hadoop.io.compress.zlib.ZlibCompressor:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>", "getCompressionLevel", "getCompressionStrategy" ],
  "org.apache.hadoop.fs.WindowsGetSpaceUsed:<init>(org.apache.hadoop.fs.GetSpaceUsed$Builder)" : [ "<init>", "getPath", "getInterval", "getJitter", "getInitialUsed" ],
  "org.apache.hadoop.security.ShellBasedUnixGroupsMapping:getGroupsForUserCommand(java.lang.String)" : [ "getGroupsForUserCommand" ],
  "org.apache.hadoop.security.UserGroupInformation$AuthenticationMethod:valueOf(org.apache.hadoop.security.SaslRpcServer$AuthMethod)" : [ "getAuthMethod" ],
  "org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext:getAllLocalPathsToRead(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "confChanged" ],
  "org.apache.hadoop.fs.permission.FsPermission:<init>(int)" : [ "<init>" ],
  "org.apache.hadoop.fs.store.audit.HttpReferrerAuditHeader:buildHttpReferrer()" : [ "warn" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine:getServer(java.lang.Class,java.lang.Object,java.lang.String,int,int,int,int,boolean,org.apache.hadoop.conf.Configuration,org.apache.hadoop.security.token.SecretManager,java.lang.String,org.apache.hadoop.ipc.AlignmentContext)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.util.MBeans:unregister(javax.management.ObjectName)" : [ "removeMBeanName" ],
  "org.apache.hadoop.io.file.tfile.TFile$Writer:initDataBlock()" : [ "prepareDataBlock" ],
  "org.apache.hadoop.fs.shell.FsUsage$Du:processPathArgument(org.apache.hadoop.fs.shell.PathData)" : [ "isDirectory" ],
  "org.apache.hadoop.fs.BlockLocation:<init>()" : [ "<init>" ],
  "org.apache.hadoop.util.MergeSort:<init>(java.util.Comparator)" : [ "<init>" ],
  "org.apache.hadoop.io.ArrayFile$Reader:<init>(org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:reencryptEncryptedKeys(java.util.List)" : [ "doOp", "nextIdx" ],
  "org.apache.hadoop.fs.FilterFileSystem:setTimes(org.apache.hadoop.fs.Path,long,long)" : [ "setTimes" ],
  "org.apache.hadoop.crypto.CryptoInputStream:readFully(long,java.nio.ByteBuffer)" : [ "checkStream", "decrypt" ],
  "org.apache.hadoop.fs.LocatedFileStatus:<init>(org.apache.hadoop.fs.FileStatus,org.apache.hadoop.fs.BlockLocation[])" : [ "<init>", "getLen", "isDirectory", "getReplication", "getBlockSize", "getModificationTime", "getAccessTime", "getPermission", "getOwner", "getGroup", "getPath", "hasAcl", "isEncrypted", "isErasureCoded", "isSymlink", "getSymlink" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:newMutableRollingAverages(java.lang.String,java.lang.String)" : [ "<init>", "checkMetricName" ],
  "org.apache.hadoop.io.SequenceFile$Sorter$SegmentDescriptor:equals(java.lang.Object)" : [ "toString" ],
  "org.apache.hadoop.fs.shell.Truncate:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "isDirectory", "toString", "getLen", "truncate" ],
  "org.apache.hadoop.fs.impl.FileSystemMultipartUploader:abort(org.apache.hadoop.fs.UploadHandle,org.apache.hadoop.fs.Path)" : [ "<init>", "toByteArray", "eval" ],
  "org.apache.hadoop.security.ssl.FileMonitoringTimerTask:<init>(java.util.List,java.util.function.Consumer,java.util.function.Consumer)" : [ "checkNotNull", "run" ],
  "org.apache.hadoop.io.DataOutputBuffer$Buffer:setCount(int)" : [ "checkArgument" ],
  "org.apache.hadoop.util.StringUtils:equalsIgnoreCase(java.lang.String,java.lang.String)" : [ "checkNotNull" ],
  "org.apache.hadoop.io.wrappedio.WrappedStatistics:iostatistics_means(java.io.Serializable)" : [ "applyToIOStatisticsSnapshot" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:add(java.lang.String,org.apache.hadoop.metrics2.lib.MutableMetric)" : [ "checkMetricName" ],
  "org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation:init(java.lang.String[])" : [ "addMetricIfNotExists" ],
  "org.apache.hadoop.fs.FileSystem:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.ContentSummary$Builder:quota(long)" : [ "quota" ],
  "org.apache.hadoop.ipc.Client:<init>(java.lang.Class,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory)" : [ "getInt", "getBoolean", "getClientId" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:removeAcl(org.apache.hadoop.fs.Path)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.util.ShutdownHookManager:addShutdownHook(java.lang.Runnable,int)" : [ "<init>" ],
  "org.apache.hadoop.conf.Configuration:getClass(java.lang.String,java.lang.Class,java.lang.Class)" : [ "getClass" ],
  "org.apache.hadoop.service.CompositeService:stop(int,boolean)" : [ "getServices", "stopQuietly", "convert" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker:invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[])" : [ "now", "curThreadTracer", "newScope", "methodToTraceString", "call", "constructRpcRequest", "addTimelineAnnotation", "close", "isAsynchronousMode", "getAsyncRpcResponse", "getReturnMessage" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner:compareCursorKeyTo(org.apache.hadoop.io.file.tfile.RawComparable)" : [ "checkKey", "compareKeys" ],
  "org.apache.hadoop.io.DataOutputBuffer:getLength()" : [ "getLength" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:write(int)" : [ "write0" ],
  "org.apache.hadoop.metrics2.impl.MetricsSinkAdapter:refreshQueueSizeGauge()" : [ "set", "size" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider:deleteKey(java.lang.String)" : [ "getMetadata", "getVersions" ],
  "org.apache.hadoop.net.SocketOutputStream:transferToFully(java.nio.channels.FileChannel,long,int,org.apache.hadoop.io.LongWritable,org.apache.hadoop.io.LongWritable)" : [ "waitForWritable", "getChannel", "set" ],
  "org.apache.hadoop.util.SemaphoredDelegatingExecutor:toString()" : [ "getPermitCount", "getAvailablePermits", "getWaitingCount" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:deprecatedGetFileLinkStatusInternal(org.apache.hadoop.fs.Path)" : [ "<init>", "readLink", "toString", "getFileStatus", "getLen", "getReplication", "getBlockSize", "getModificationTime", "getAccessTime", "getPermission", "getOwner", "getGroup", "getDefault" ],
  "org.apache.hadoop.conf.ConfigurationWithLogging:getBoolean(java.lang.String,boolean)" : [ "getBoolean" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkNotNullAndNotEmpty(long[],java.lang.String)" : [ "checkNotNull", "checkNotEmpty" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:satisfyStoragePolicy(org.apache.hadoop.fs.Path)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.fs.AvroFSInput:seek(long)" : [ "seek" ],
  "org.apache.hadoop.security.alias.CredentialShell:promptForCredential()" : [ "getPasswordReader", "readPassword", "format" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:setTimes(org.apache.hadoop.fs.Path,long,long)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.util.dynamic.DynMethods$StaticMethod:invoke(java.lang.Object[])" : [ "invoke" ],
  "org.apache.hadoop.ha.NodeFencer:create(org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "<init>", "get" ],
  "org.apache.hadoop.metrics2.MetricStringBuilder:addGauge(org.apache.hadoop.metrics2.MetricsInfo,long)" : [ "add" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenIdentifier:<init>(org.apache.hadoop.io.Text)" : [ "<init>" ],
  "org.apache.hadoop.fs.LocatedFileStatus:<init>(long,boolean,int,long,long,long,org.apache.hadoop.fs.permission.FsPermission,java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,boolean,boolean,boolean,org.apache.hadoop.fs.BlockLocation[])" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkNotNullAndNotEmpty(byte[],java.lang.String)" : [ "checkNotNull", "checkNotEmpty" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server:<init>(java.lang.Class,java.lang.Object,org.apache.hadoop.conf.Configuration,java.lang.String,int,int,int,int,boolean,org.apache.hadoop.security.token.SecretManager,java.lang.String,org.apache.hadoop.ipc.AlignmentContext)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:bsPutInt(int)" : [ "bsW" ],
  "org.apache.hadoop.ipc.Client$Call:setException(java.io.IOException)" : [ "callComplete" ],
  "org.apache.hadoop.io.compress.GzipCodec:getCompressorType()" : [ "isNativeZlibLoaded" ],
  "org.apache.hadoop.util.WeakReferenceMap:get(java.lang.Object)" : [ "lookup", "resolve", "noteLost", "create" ],
  "org.apache.hadoop.io.MD5Hash:compareTo(org.apache.hadoop.io.MD5Hash)" : [ "compareBytes" ],
  "org.apache.hadoop.io.compress.BlockCompressorStream:<init>(java.io.OutputStream,org.apache.hadoop.io.compress.Compressor)" : [ "<init>" ],
  "org.apache.hadoop.security.UserGroupInformation:getLogin()" : [ "getLogin" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:rollNewVersion(java.lang.String,byte[])" : [ "checkNotNull", "rollNewVersionInternal" ],
  "org.apache.hadoop.fs.TrashPolicyDefault:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration)" : [ "initialize" ],
  "org.apache.hadoop.fs.FileUtil:makeShellPath(java.io.File,boolean)" : [ "makeShellPath" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RSLegacyRawDecoder:doDecodeImpl(byte[][],int[],int,int[],byte[][],int[])" : [ "substitute", "solveVandermondeSystem" ],
  "org.apache.hadoop.ipc.metrics.DecayRpcSchedulerDetailedMetrics:init(int)" : [ "init", "getQueueName", "getProcessingName" ],
  "org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>", "getLong", "getInt", "getBoolean", "get", "createCuratorClient" ],
  "org.apache.hadoop.fs.crypto.CryptoFSDataOutputStream:<init>(org.apache.hadoop.fs.FSDataOutputStream,org.apache.hadoop.crypto.CryptoCodec,byte[],byte[])" : [ "<init>", "getPos" ],
  "org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue:next()" : [ "adjustPriorityQueue", "getPosition", "getKey", "createValueBytes", "nextRawValue", "updateProgress" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:getRecordNumNear(long)" : [ "getRecordNumByLocation", "getLocationNear" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:removeXAttr(org.apache.hadoop.fs.Path,java.lang.String)" : [ "removeXAttr", "resolve", "getUriPath" ],
  "org.apache.hadoop.conf.Configuration$Parser:parseNext()" : [ "handleStartElement", "handleEndElement" ],
  "org.apache.hadoop.io.UTF8:readChars(java.io.DataInput,java.lang.StringBuilder,int)" : [ "reset", "write", "getData", "byteToHexString", "highSurrogate", "lowSurrogate" ],
  "org.apache.hadoop.ipc.metrics.RetryCacheMetrics:getCacheHit()" : [ "value" ],
  "org.apache.hadoop.conf.Configuration:addResource(java.lang.String)" : [ "<init>", "addResourceObject" ],
  "org.apache.hadoop.fs.Options$ChecksumOpt:processChecksumOpt(org.apache.hadoop.fs.Options$ChecksumOpt,org.apache.hadoop.fs.Options$ChecksumOpt)" : [ "processChecksumOpt" ],
  "org.apache.hadoop.security.SecurityUtil$QualifiedHostResolver:getByName(java.lang.String)" : [ "getByExactName", "getByNameWithSearch" ],
  "org.apache.hadoop.fs.FileSystem$Statistics:increaseRemoteReadTime(long)" : [ "getThreadStatistics" ],
  "org.apache.hadoop.metrics2.lib.MutableQuantiles:setQuantiles(java.lang.String,java.lang.String,java.lang.String,java.lang.String,java.text.DecimalFormat)" : [ "getInterval", "addQuantileInfo", "info" ],
  "org.apache.hadoop.util.Shell:run()" : [ "monotonicNow", "runCommand" ],
  "org.apache.hadoop.metrics2.impl.MetricsSourceAdapter:getAttribute(java.lang.String)" : [ "updateJmxCache" ],
  "org.apache.hadoop.util.StopWatch:start()" : [ "monotonicNowNanos" ],
  "org.apache.hadoop.metrics2.sink.FileSink:init(org.apache.commons.configuration2.SubsetConfiguration)" : [ "<init>" ],
  "org.apache.hadoop.io.serializer.avro.AvroReflectSerialization:getPackages()" : [ "getStrings" ],
  "org.apache.hadoop.fs.PathPermissionException:<init>(java.lang.String,java.lang.Throwable)" : [ "<init>" ],
  "org.apache.hadoop.ipc.ResponseBuffer:capacity()" : [ "capacity" ],
  "org.apache.hadoop.ipc.Server:logSlowRpcCalls(java.lang.String,org.apache.hadoop.ipc.Server$Call,org.apache.hadoop.ipc.ProcessingDetails)" : [ "getProcessingMean", "getProcessingStdDev", "getMetricsTimeUnit", "get", "getProcessingSampleCount", "getLogSlowRPCThresholdTime", "toString", "incrSlowRpc" ],
  "org.apache.hadoop.fs.FilterFs:getHomeDirectory()" : [ "getHomeDirectory" ],
  "org.apache.hadoop.ipc.WritableRpcEngine:ensureInitialized()" : [ "initialize" ],
  "org.apache.hadoop.fs.shell.CopyCommands$Merge:processArguments(java.util.LinkedList)" : [ "create", "getLen", "openForSequentialIO", "copyBytes", "writeDelimiter", "close" ],
  "org.apache.hadoop.fs.FileStatus:setPermission(org.apache.hadoop.fs.permission.FsPermission)" : [ "getFileDefault" ],
  "org.apache.hadoop.fs.QuotaUsage:getTypesQuotaUsage(boolean,java.util.List)" : [ "getTypeQuota", "getTypeConsumed", "formatSize" ],
  "org.apache.hadoop.io.SecureIOUtils:openForRandomRead(java.io.File,java.lang.String,java.lang.String,java.lang.String)" : [ "isSecurityEnabled", "forceSecureOpenForRandomRead" ],
  "org.apache.hadoop.metrics2.lib.DefaultMetricsSystem:removeMBeanName(javax.management.ObjectName)" : [ "removeObjectName" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.CoderUtil:resetBuffer(byte[],int,int)" : [ "getEmptyChunk" ],
  "org.apache.hadoop.io.compress.zlib.BuiltInGzipCompressor:<init>(org.apache.hadoop.conf.Configuration)" : [ "init", "newCrc32" ],
  "org.apache.hadoop.fs.StorageType:getConf(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.StorageType,java.lang.String)" : [ "get" ],
  "org.apache.hadoop.ha.HAAdmin:printUsage(java.io.PrintStream,java.util.Map)" : [ "getUsageString", "printGenericCommandUsage" ],
  "org.apache.hadoop.util.functional.TaskPool:foreach(org.apache.hadoop.fs.RemoteIterator)" : [ "<init>" ],
  "org.apache.hadoop.ha.ShellCommandFencer:setConfAsEnvVars(java.util.Map)" : [ "iterator" ],
  "org.apache.hadoop.io.WritableUtils:readVIntInRange(java.io.DataInput,int,int)" : [ "readVLong" ],
  "org.apache.hadoop.net.DNS:getIPs(java.lang.String,boolean)" : [ "getSubinterface", "getSubinterfaceInetAddrs" ],
  "org.apache.hadoop.io.MapWritable:<init>()" : [ "<init>" ],
  "org.apache.hadoop.metrics2.util.SampleQuantiles:toString()" : [ "snapshot" ],
  "org.apache.hadoop.fs.LocalFileSystem:reportChecksumFailure(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.FSDataInputStream,long,org.apache.hadoop.fs.FSDataInputStream,long)" : [ "<init>", "pathToFile", "getMount", "canWrite" ],
  "org.apache.hadoop.io.SequenceFile$Reader:getCurrentValue(java.lang.Object)" : [ "seekToCurrentValue", "deserializeValue", "getPosition", "getLength", "readVInt" ],
  "org.apache.hadoop.io.IOUtils:copyBytes(java.io.InputStream,java.io.OutputStream,long,boolean)" : [ "closeStream" ],
  "org.apache.hadoop.fs.BlockLocation:setNames(java.lang.String[])" : [ "internStringsInArray" ],
  "org.apache.hadoop.util.InstrumentedReadLock:unlock()" : [ "monotonicNow" ],
  "org.apache.hadoop.io.BloomMapFile$Reader:<init>(org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration,org.apache.hadoop.io.SequenceFile$Reader$Option[])" : [ "<init>", "initBloomFilter" ],
  "org.apache.hadoop.fs.shell.find.Name:registerExpression(org.apache.hadoop.fs.shell.find.ExpressionFactory)" : [ "addClass" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:exists(com.jcraft.jsch.ChannelSftp,org.apache.hadoop.fs.Path)" : [ "getFileStatus" ],
  "org.apache.hadoop.ipc.ResponseBuffer:reset()" : [ "reset" ],
  "org.apache.hadoop.util.functional.FutureIO:propagateOptions(org.apache.hadoop.fs.FSBuilder,org.apache.hadoop.conf.Configuration,java.lang.String,boolean)" : [ "getPropsWithPrefix" ],
  "org.apache.hadoop.fs.impl.FlagSet:copy()" : [ "<init>" ],
  "org.apache.hadoop.fs.FileSystem:newInstance(java.net.URI,org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "get", "getBestUGI", "doAs" ],
  "org.apache.hadoop.fs.DF:getFilesystem()" : [ "verifyExitCode", "parseOutput" ],
  "org.apache.hadoop.ipc.RpcClientUtil:isMethodSupported(java.lang.Object,java.lang.Class,org.apache.hadoop.ipc.RPC$RpcKind,long,java.lang.String)" : [ "<init>", "getServerAddress", "getVersionSignatureMap", "setProtocolEngine", "getProtocolMetaInfoProxy", "ipc", "convertProtocolSignatureProtos", "putVersionSignatureMap", "getFingerprint", "methodExists" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:getGaugeReference(java.lang.String)" : [ "getInnerStatistics" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:getStatus(org.apache.hadoop.fs.Path)" : [ "<init>", "getStatus", "listStatus", "getPathWithoutSchemeAndAuthority", "getPath", "resolve", "toString", "getCapacity", "getUsed", "getRemaining" ],
  "org.apache.hadoop.net.unix.DomainSocket:bindAndListen(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileSystemLinkResolver:resolve(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)" : [ "areSymlinksEnabled", "qualifySymlinkTarget", "resolveLink", "getFSofPath" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:getProcessingSampleCount()" : [ "numSamples" ],
  "org.apache.hadoop.fs.shell.PathData:<init>(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "<init>", "get", "stringToUri" ],
  "org.apache.hadoop.fs.ChecksumFileSystem:delete(org.apache.hadoop.fs.Path,boolean)" : [ "isDirectory", "getChecksumFile", "exists" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:renameInternal(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,boolean)" : [ "<init>", "renameInternal", "isInternalDir", "isLastInternalDirLink", "getTargetFileSystem", "getUri", "verifyRenameStrategy", "getMyFs", "fullPath" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:addCallVolumePerPriority(org.apache.hadoop.metrics2.MetricsRecordBuilder)" : [ "info" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine:getProxy(java.lang.Class,long,java.net.InetSocketAddress,org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory,int)" : [ "getProxy" ],
  "org.apache.hadoop.ha.protocolPB.ZKFCProtocolServerSideTranslatorPB:getProtocolSignature(java.lang.String,long,int)" : [ "getProtocolSignature", "getProtocolName", "getProtocolVersion" ],
  "org.apache.hadoop.fs.FileSystem:createNewFile(org.apache.hadoop.fs.Path)" : [ "exists", "create", "getInt", "close" ],
  "org.apache.hadoop.ipc.ProtobufHelper:getByteString(byte[])" : [ "getByteString" ],
  "org.apache.hadoop.security.ShellBasedUnixGroupsNetgroupMapping:execShellGetUserForNetgroup(java.lang.String)" : [ "execCommand", "getUsersForNetgroupCommand" ],
  "org.apache.hadoop.ha.ZKFailoverController:becomeActive()" : [ "<init>", "transitionToActive", "getProxy", "getRpcTimeoutToNewActive", "createReqInfo", "recordActiveAttempt", "stringifyException" ],
  "org.apache.hadoop.io.UTF8:<init>(java.lang.String)" : [ "set" ],
  "org.apache.hadoop.io.retry.RetryPolicies$FailoverOnNetworkExceptionRetry:<init>(org.apache.hadoop.io.retry.RetryPolicy,int)" : [ "<init>" ],
  "org.apache.hadoop.ipc.Server$ConnectionManager:isFull()" : [ "size" ],
  "org.apache.hadoop.security.token.DtFileOperations:getTokenFile(java.io.File,java.lang.String,org.apache.hadoop.io.Text,org.apache.hadoop.io.Text,java.lang.String,java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "<init>", "readTokenStorageFile", "matchService", "stripPrefix", "copyToken", "setService", "addToken", "doFormattedWrite" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockData:getRelativeOffset(int,long)" : [ "throwIfInvalidOffset", "getStartOffset" ],
  "org.apache.hadoop.fs.FileSystem:mkdirs(org.apache.hadoop.fs.Path)" : [ "getDirDefault" ],
  "org.apache.hadoop.fs.statistics.impl.DynamicIOStatisticsBuilder:withMeanStatisticFunction(java.lang.String,java.util.function.Function)" : [ "activeInstance", "addMeanStatisticFunction" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner:getRecordNum()" : [ "getRecordNumByLocation" ],
  "org.apache.hadoop.fs.FileUtil:unTarUsingTar(java.io.File,java.io.File,boolean)" : [ "<init>", "makeSecureShellPath", "execute" ],
  "org.apache.hadoop.fs.protocolPB.PBHelper:convert(org.apache.hadoop.fs.FileStatus)" : [ "convert", "getPath", "toString", "isDirectory", "isSymlink", "getSymlink", "getLen", "getReplication", "getBlockSize", "getAccessTime", "getModificationTime", "getOwner", "getGroup", "getPermission", "hasAcl", "isEncrypted", "isErasureCoded", "isSnapshotEnabled" ],
  "org.apache.hadoop.util.dynamic.DynMethods$BoundMethod:invokeChecked(java.lang.Object[])" : [ "invokeChecked" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:getFileChecksum(org.apache.hadoop.fs.Path)" : [ "checkPathIsSlash" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:coreServiceLaunch(org.apache.hadoop.conf.Configuration,org.apache.hadoop.service.Service,java.util.List,boolean,boolean)" : [ "<init>", "instantiateService", "register", "getServiceName", "noteEntryPoint", "unregister" ],
  "org.apache.hadoop.fs.LocatedFileStatus:equals(java.lang.Object)" : [ "equals" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:mkdirs(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "resolve", "getUriPath" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:shouldBackOff(org.apache.hadoop.ipc.Schedulable)" : [ "getAverageResponseTime", "getUserName" ],
  "org.apache.hadoop.fs.statistics.impl.PairedDurationTrackerFactory$PairedDurationTracker:asDuration()" : [ "asDuration" ],
  "org.apache.hadoop.io.MapFile$Writer$KeyClassOption:<init>(java.lang.Class)" : [ "<init>" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$DelegationTokenSecretManagerMetrics:trackStoreToken(org.apache.hadoop.util.functional.InvocationRaisingIOE)" : [ "trackInvocation" ],
  "org.apache.hadoop.util.concurrent.HadoopExecutors:newCachedThreadPool(java.util.concurrent.ThreadFactory)" : [ "<init>" ],
  "org.apache.hadoop.jmx.JMXJsonServlet:doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)" : [ "isInstrumentationAccessAllowed", "listBeans" ],
  "org.apache.hadoop.io.retry.AsyncCallHandler$AsyncCall:<init>(java.lang.reflect.Method,java.lang.Object[],boolean,int,org.apache.hadoop.io.retry.RetryInvocationHandler,org.apache.hadoop.io.retry.AsyncCallHandler)" : [ "<init>" ],
  "org.apache.hadoop.fs.FsShell:getCurrentTrashDir()" : [ "getCurrentTrashDir", "getTrash" ],
  "org.apache.hadoop.io.compress.DecompressorStream:<init>(java.io.InputStream,org.apache.hadoop.io.compress.Decompressor)" : [ "<init>" ],
  "org.apache.hadoop.service.launcher.InterruptEscalator:getService()" : [ "getService", "getOwner" ],
  "org.apache.hadoop.fs.store.DataBlocks$DataBlock:write(byte[],int,int)" : [ "verifyState", "checkArgument" ],
  "org.apache.hadoop.util.LineReader:<init>(java.io.InputStream,org.apache.hadoop.conf.Configuration,byte[])" : [ "getInt" ],
  "org.apache.hadoop.net.NetUtils:getCanonicalUri(java.net.URI,int)" : [ "canonicalizeHost" ],
  "org.apache.hadoop.http.HttpServer2:createWebAppContext(org.apache.hadoop.http.HttpServer2$Builder,org.apache.hadoop.security.authorize.AccessControlList,java.lang.String)" : [ "get", "addNoCacheFilter" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:delete(org.apache.hadoop.fs.Path,boolean)" : [ "<init>", "isInternalDir" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:processResult(int,java.lang.String,java.lang.Object,org.apache.zookeeper.data.Stat)" : [ "isStaleClient", "isSuccess", "becomeActive", "reJoinElectionAfterFailureToBecomeActive", "becomeStandby", "isNodeDoesNotExist", "enterNeutralMode", "joinElectionInternal", "shouldRetry", "monitorLockNodeAsync", "isSessionExpired", "fatalError" ],
  "org.apache.hadoop.metrics2.MetricStringBuilder:add(org.apache.hadoop.metrics2.MetricsTag)" : [ "tuple", "name", "value" ],
  "org.apache.hadoop.io.file.tfile.Compression$Algorithm$1:getCodec()" : [ "isSupported" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:listXAttrs(org.apache.hadoop.fs.Path)" : [ "listXAttrs", "fullPath" ],
  "org.apache.hadoop.io.compress.BlockDecompressorStream:getCompressedData()" : [ "rawReadInt" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:setPermission(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "fullPath" ],
  "org.apache.hadoop.metrics2.util.SampleQuantiles:insertBatch()" : [ "<init>", "allowableError" ],
  "org.apache.hadoop.conf.Configuration:setLong(java.lang.String,long)" : [ "set" ],
  "org.apache.hadoop.net.SocketInputStream:<init>(java.net.Socket,long)" : [ "<init>" ],
  "org.apache.hadoop.ipc.RpcServerException:<init>(java.lang.String,java.lang.Throwable)" : [ "<init>" ],
  "org.apache.hadoop.io.WritableComparator:<init>(java.lang.Class)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.lib.MutableRates:<init>(org.apache.hadoop.metrics2.lib.MetricsRegistry)" : [ "checkNotNull" ],
  "org.apache.hadoop.metrics2.lib.MutableRollingAverages:snapshot(org.apache.hadoop.metrics2.MetricsRecordBuilder,boolean)" : [ "info", "monotonicNow", "getSnapshotTimeStamp", "getCount", "getSum" ],
  "org.apache.hadoop.fs.GetSpaceUsed$Builder:getInterval()" : [ "getLong" ],
  "org.apache.hadoop.fs.FileStatus:<init>(long,boolean,int,long,long,long,org.apache.hadoop.fs.permission.FsPermission,java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,java.util.Set)" : [ "getDirDefault", "getDefault", "getFileDefault" ],
  "org.apache.hadoop.fs.VectoredReadUtils:readInDirectBuffer(org.apache.hadoop.fs.FileRange,java.nio.ByteBuffer,org.apache.hadoop.util.functional.Function4RaisingIOE)" : [ "validateRangeRequest" ],
  "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix:string2long(java.lang.String)" : [ "valueOf" ],
  "org.apache.hadoop.fs.impl.prefetch.FilePosition:bufferStartOffset()" : [ "throwIfInvalidBuffer" ],
  "org.apache.hadoop.util.JsonSerialization:load(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.FileStatus)" : [ "<init>", "getLen", "openFile", "withFileStatus", "awaitFuture", "build", "fromJsonStream", "toString" ],
  "org.apache.hadoop.fs.shell.Truncate:waitForRecovery()" : [ "refreshStatus", "getLen" ],
  "org.apache.hadoop.io.compress.lz4.Lz4Decompressor:setInput(byte[],int,int)" : [ "setInputFromSavedData" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:initialize(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>", "initialize", "getBoolean", "fsGetter", "getScheme", "supportAutoAddingFallbackOnNoMounts", "get", "getHomeDirectory" ],
  "org.apache.hadoop.fs.shell.CommandFormat$NotEnoughArgumentsException:getMessage()" : [ "getMessage" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:addRpcEnQueueTime(long)" : [ "add" ],
  "org.apache.hadoop.io.Text:writeString(java.io.DataOutput,java.lang.String)" : [ "encode", "writeVInt" ],
  "org.apache.hadoop.io.SequenceFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.io.SequenceFile$Writer$Option[])" : [ "<init>", "getValue", "getFileSystem", "getDefaultReplication", "getDefaultBlockSize", "exists", "file", "getKeyClass", "getValueClass", "metadata", "getMetadata", "getCompressionType", "getCompressionCodec", "close", "create", "getCodec", "init", "now" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:ioStatisticsContextAvailable()" : [ "available" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:makeAbsolute(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "<init>", "isAbsolute" ],
  "org.apache.hadoop.fs.impl.FSBuilderSupport:getLong(java.lang.String,long)" : [ "getLong", "getTrimmed", "warn" ],
  "org.apache.hadoop.net.unix.DomainSocket$DomainOutputStream:write(byte[],int,int)" : [ "reference" ],
  "org.apache.hadoop.security.UserGroupInformation$AutoRenewalForUserCredsRunnable:run()" : [ "now", "getUserName", "set", "incr", "value", "exponentialBackoffRetry", "getNextTgtRenewalTime" ],
  "org.apache.hadoop.fs.Globber:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.PathFilter)" : [ "get" ],
  "org.apache.hadoop.metrics2.lib.MutableMetricsFactory:getInfo(org.apache.hadoop.metrics2.annotation.Metric,java.lang.reflect.Field)" : [ "getInfo", "getName" ],
  "org.apache.hadoop.fs.impl.prefetch.BufferPool:acquire(int)" : [ "<init>", "updateStatus", "releaseReadyBlock", "tryAcquire", "continueRetry" ],
  "org.apache.hadoop.metrics2.impl.MetricsRecordBuilderImpl:setContext(java.lang.String)" : [ "tag" ],
  "org.apache.hadoop.io.compress.SnappyCodec:createOutputStream(java.io.OutputStream,org.apache.hadoop.io.compress.Compressor)" : [ "<init>", "getInt" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:listStatusForFallbackLink()" : [ "<init>", "getRootFallbackLink", "getTargetFileSystem", "getPathWithoutSchemeAndAuthority", "isRoot", "exists", "getPath", "getName", "setPath" ],
  "org.apache.hadoop.fs.protocolPB.PBHelper:convert(org.apache.hadoop.fs.FSProtos$FileStatusProto)" : [ "<init>", "convert", "weakIntern", "attributes" ],
  "org.apache.hadoop.ha.protocolPB.HAServiceProtocolServerSideTranslatorPB:transitionToActive(org.apache.hadoop.thirdparty.protobuf.RpcController,org.apache.hadoop.ha.proto.HAServiceProtocolProtos$TransitionToActiveRequestProto)" : [ "convert" ],
  "org.apache.hadoop.metrics2.lib.MethodMetric:newTag(java.lang.Class)" : [ "<init>" ],
  "org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer:<init>(org.apache.hadoop.conf.Configuration,java.lang.Class)" : [ "<init>" ],
  "org.apache.hadoop.fs.HarFileSystem:resolvePath(org.apache.hadoop.fs.Path)" : [ "resolvePath" ],
  "org.apache.hadoop.fs.AbstractFileSystem:getAllStatistics()" : [ "<init>" ],
  "org.apache.hadoop.fs.local.RawLocalFs:getServerDefaults(org.apache.hadoop.fs.Path)" : [ "getServerDefaults" ],
  "org.apache.hadoop.fs.impl.prefetch.FilePosition:toString()" : [ "blockNumber", "absolute" ],
  "org.apache.hadoop.io.MapFile$Reader:seek(org.apache.hadoop.io.WritableComparable)" : [ "seekInternal" ],
  "org.apache.hadoop.ipc.Server:getCallQueueLen()" : [ "size" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyStatus:<init>(org.apache.hadoop.fs.viewfs.ChRootedFileSystem,org.apache.hadoop.fs.FileStatus)" : [ "<init>", "stripOutRoot", "getPath" ],
  "org.apache.hadoop.conf.Configuration:writeXml(java.io.OutputStream)" : [ "writeXml" ],
  "org.apache.hadoop.fs.shell.MoveCommands$MoveFromLocal:processPath(org.apache.hadoop.fs.shell.PathData,org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "isDirectory", "toString" ],
  "org.apache.hadoop.ipc.Client:getPingInterval(org.apache.hadoop.conf.Configuration)" : [ "getInt" ],
  "org.apache.hadoop.util.functional.TaskPool:throwOne(java.util.Collection)" : [ "castAndThrow" ],
  "org.apache.hadoop.crypto.key.kms.KMSDelegationToken$KMSDelegationTokenIdentifier:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.Stat:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "getPermission", "toOctal", "getLen", "isDirectory", "isFile", "getGroup", "getName", "getBlockSize", "getReplication", "getOwner", "getAccessTime", "getModificationTime" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:delete(org.apache.hadoop.fs.Path,boolean)" : [ "delete", "fullPath" ],
  "org.apache.hadoop.fs.FileContext:deleteOnExit(org.apache.hadoop.fs.Path)" : [ "util", "exists", "get", "addShutdownHook" ],
  "org.apache.hadoop.fs.shell.find.Result:combine(org.apache.hadoop.fs.shell.find.Result)" : [ "<init>", "isPass", "isDescend" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:createHuffmanDecodingTables(int,int)" : [ "hbCreateDecodeTables" ],
  "org.apache.hadoop.io.BytesWritable:getSize()" : [ "getLength" ],
  "org.apache.hadoop.ipc.Server:getNumDroppedConnections()" : [ "getDroppedConnections" ],
  "org.apache.hadoop.ha.HealthMonitor:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.ha.HAServiceTarget)" : [ "<init>", "getLong", "getInt" ],
  "org.apache.hadoop.fs.FileContext:listCorruptFileBlocks(org.apache.hadoop.fs.Path)" : [ "fixRelativePart" ],
  "org.apache.hadoop.io.compress.DefaultCodec:getDecompressorType()" : [ "getZlibDecompressorType" ],
  "org.apache.hadoop.ipc.ProtobufWrapperLegacy:<init>(java.lang.Object)" : [ "checkArgument", "isUnshadedProtobufMessage" ],
  "org.apache.hadoop.fs.ChecksumFileSystem:createNonRecursive(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,java.util.EnumSet,int,short,long,org.apache.hadoop.util.Progressable)" : [ "create" ],
  "org.apache.hadoop.util.DiskValidatorFactory:getInstance(java.lang.Class)" : [ "newInstance" ],
  "org.apache.hadoop.io.retry.RetryPolicies:retryUpToMaximumCountWithProportionalSleep(int,long,java.util.concurrent.TimeUnit)" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockOperations$End:<init>(org.apache.hadoop.fs.impl.prefetch.BlockOperations$Operation)" : [ "<init>" ],
  "org.apache.hadoop.security.UserGroupInformation:createProxyUserForTesting(java.lang.String,org.apache.hadoop.security.UserGroupInformation,java.lang.String[])" : [ "ensureInitialized", "createProxyUser", "getShortUserName" ],
  "org.apache.hadoop.ipc.ProtobufHelper:getRemoteException(org.apache.hadoop.thirdparty.protobuf.ServiceException)" : [ "getRemoteException" ],
  "org.apache.hadoop.fs.permission.FsPermission:hashCode()" : [ "toShort" ],
  "org.apache.hadoop.util.curator.ZKCuratorManager:getStringData(java.lang.String,org.apache.zookeeper.data.Stat)" : [ "getData" ],
  "org.apache.hadoop.io.SequenceFile$Reader:init(boolean)" : [ "<init>", "readFields", "toStringChecked", "readString", "getClassByName", "newInstance", "getPos", "getDecompressor", "createInputStream", "getDeserializer", "getKeyClass", "getValueClass" ],
  "org.apache.hadoop.util.VersionInfo:getDate()" : [ "_getDate" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:parseServiceUserNames(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "getStringCollection" ],
  "org.apache.hadoop.util.curator.ZKCuratorManager:validateSslConfiguration(org.apache.hadoop.conf.Configuration)" : [ "get" ],
  "org.apache.hadoop.io.SequenceFile$Writer:append(org.apache.hadoop.io.Writable,org.apache.hadoop.io.Writable)" : [ "append" ],
  "org.apache.hadoop.util.LightWeightGSet$SetIterator:ensureNext()" : [ "nextNonemptyEntry" ],
  "org.apache.hadoop.io.Text:set(org.apache.hadoop.io.Text)" : [ "set", "getBytes", "getLength" ],
  "org.apache.hadoop.fs.HarFileSystem:getCanonicalUri()" : [ "getCanonicalUri" ],
  "org.apache.hadoop.security.Credentials:readTokenStorageFile(java.io.File,org.apache.hadoop.conf.Configuration)" : [ "<init>", "readTokenStorageStream", "cleanupWithLogger" ],
  "org.apache.hadoop.metrics2.util.SampleQuantiles:snapshot()" : [ "insertBatch", "query" ],
  "org.apache.hadoop.fs.ContentSummary$Builder:spaceQuota(long)" : [ "spaceQuota" ],
  "org.apache.hadoop.io.compress.CompressionCodecFactory:main(java.lang.String[])" : [ "<init>", "getCodec", "removeSuffix", "close" ],
  "org.apache.hadoop.net.NetworkTopologyWithNodeGroup:add(org.apache.hadoop.net.Node)" : [ "<init>", "getPath" ],
  "org.apache.hadoop.util.Shell:getGetPermissionCommand()" : [ "getWinUtilsPath" ],
  "org.apache.hadoop.util.ProtoUtil:getUgi(org.apache.hadoop.ipc.protobuf.IpcConnectionContextProtos$UserInformationProto)" : [ "createRemoteUser", "createProxyUser" ],
  "org.apache.hadoop.fs.store.DataBlocks$DataBlock:enterClosedState()" : [ "enterState" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:removeAcl(org.apache.hadoop.fs.Path)" : [ "removeAcl" ],
  "org.apache.hadoop.util.ConfTest:checkConf(java.io.InputStream)" : [ "parseConf", "join" ],
  "org.apache.hadoop.fs.FilterFileSystem:getStatus(org.apache.hadoop.fs.Path)" : [ "getStatus" ],
  "org.apache.hadoop.io.SequenceFile$Writer:bufferSize(int)" : [ "<init>" ],
  "org.apache.hadoop.security.UserGroupInformation:getBestUGI(java.lang.String,java.lang.String)" : [ "getCurrentUser", "createRemoteUser" ],
  "org.apache.hadoop.net.NetUtils:createSocketAddr(java.lang.String,int,java.lang.String)" : [ "createSocketAddr" ],
  "org.apache.hadoop.security.SaslRpcServer:init(org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.ipc.internal.ShadedProtobufHelper:protoFromToken(org.apache.hadoop.security.token.Token)" : [ "getByteString", "getIdentifier", "getPassword", "getFixedByteString", "getKind", "getService" ],
  "org.apache.hadoop.security.UserGroupInformation:createProxyUser(java.lang.String,org.apache.hadoop.security.UserGroupInformation)" : [ "<init>" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:getTopTokenRealOwners(int)" : [ "<init>", "offer" ],
  "org.apache.hadoop.metrics2.impl.MetricsSinkAdapter:publishMetricsFromQueue()" : [ "consumeAll", "refreshQueueSizeGauge", "clear" ],
  "org.apache.hadoop.fs.shell.Ls:processOptions(java.util.LinkedList)" : [ "<init>", "parse", "getOpt", "initialiseOrderComparator" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem:notFoundStatus(org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.fs.store.DataBlocks$DiskBlock:startUpload()" : [ "<init>", "startUpload" ],
  "org.apache.hadoop.io.ArrayWritable:readFields(java.io.DataInput)" : [ "newInstance" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:createConnection(java.net.URL,java.lang.String)" : [ "getDoAsUser", "getActualUgi", "doAs", "configureConnection" ],
  "org.apache.hadoop.util.GenericsUtil:isLog4jLogger(java.lang.Class)" : [ "isLog4jLogger" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding:snapshotMap(java.util.Map,java.util.function.Function)" : [ "copyMap" ],
  "org.apache.hadoop.metrics2.MetricsJsonBuilder:add(org.apache.hadoop.metrics2.MetricsTag)" : [ "tuple", "name", "value" ],
  "org.apache.hadoop.net.NetworkTopology:getDistanceByPath(org.apache.hadoop.net.Node,org.apache.hadoop.net.Node)" : [ "getPathComponents" ],
  "org.apache.hadoop.fs.FileSystem:newInstanceLocal(org.apache.hadoop.conf.Configuration)" : [ "newInstance" ],
  "org.apache.hadoop.ha.HAAdmin:checkParameterValidity(java.lang.String[])" : [ "checkParameterValidity" ],
  "org.apache.hadoop.http.HttpServer2:addDefaultServlets(org.apache.hadoop.conf.Configuration)" : [ "addServlet", "getBoolean" ],
  "org.apache.hadoop.fs.crypto.CryptoFSDataOutputStream:<init>(org.apache.hadoop.fs.FSDataOutputStream,org.apache.hadoop.crypto.CryptoCodec,int,byte[],byte[],boolean)" : [ "<init>", "getPos" ],
  "org.apache.hadoop.io.WritableUtils:writeStringArray(java.io.DataOutput,java.lang.String[])" : [ "writeString" ],
  "org.apache.hadoop.io.compress.snappy.SnappyDecompressor$SnappyDirectDecompressor:finished()" : [ "finished" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:getLinkTarget(org.apache.hadoop.fs.Path)" : [ "getLinkTarget" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme$ChildFsGetter:get(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "get", "createFileSystem" ],
  "org.apache.hadoop.io.erasurecode.CodecUtil:createDecoder(org.apache.hadoop.conf.Configuration,org.apache.hadoop.io.erasurecode.ErasureCodecOptions)" : [ "checkNotNull", "getCodecClassName", "getSchema", "getCodecName", "createCodec" ],
  "org.apache.hadoop.io.DataInputBuffer:reset(byte[],int,int)" : [ "reset" ],
  "org.apache.hadoop.util.Shell$ShellCommandExecutor:execute()" : [ "join" ],
  "org.apache.hadoop.fs.ChecksumFileSystem$FSDataBoundedInputStream:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,java.io.InputStream)" : [ "<init>" ],
  "org.apache.hadoop.crypto.CryptoInputStream:getIOStatistics()" : [ "retrieveIOStatistics" ],
  "org.apache.hadoop.io.compress.snappy.SnappyCompressor:reinit(org.apache.hadoop.conf.Configuration)" : [ "reset" ],
  "org.apache.hadoop.io.EnumSetWritable:write(java.io.DataOutput)" : [ "writeString", "writeObject" ],
  "org.apache.hadoop.io.SequenceFile$Writer:replication(short)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileUtil:maybeIgnoreMissingDirectory(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,java.io.FileNotFoundException)" : [ "hasPathCapability" ],
  "org.apache.hadoop.fs.CachingGetSpaceUsed:<init>(org.apache.hadoop.fs.GetSpaceUsed$Builder)" : [ "<init>", "getPath", "getInterval", "getJitter", "getInitialUsed" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:setupRandPartB()" : [ "setupRandPartA", "setupRandPartC" ],
  "org.apache.hadoop.ipc.Server:closeConnection(org.apache.hadoop.ipc.Server$Connection)" : [ "close" ],
  "org.apache.hadoop.fs.ChecksumFs:isChecksumFile(org.apache.hadoop.fs.Path)" : [ "getName" ],
  "org.apache.hadoop.fs.shell.Count:<init>()" : [ "<init>" ],
  "org.apache.hadoop.util.dynamic.DynMethods$Builder:hiddenImpl(java.lang.Class,java.lang.Class[])" : [ "hiddenImpl" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:append(org.apache.hadoop.fs.Path,int,org.apache.hadoop.util.Progressable)" : [ "<init>", "getFileStatus", "isDirectory", "createOutputStreamWithMode", "getLen" ],
  "org.apache.hadoop.io.nativeio.NativeIO$POSIX:getName(org.apache.hadoop.io.nativeio.NativeIO$POSIX$IdCache,int)" : [ "<init>" ],
  "org.apache.hadoop.io.SequenceFile$Sorter$SortPass:close()" : [ "close" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:getUriDefaultPort()" : [ "getDefaultPortIfDefined" ],
  "org.apache.hadoop.fs.shell.FsUsage$Du:setHumanReadable(boolean)" : [ "setHumanReadable" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:exitWithMessage(int,java.lang.String)" : [ "<init>", "terminate" ],
  "org.apache.hadoop.io.compress.BlockDecompressorStream:resetState()" : [ "resetState" ],
  "org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer:run()" : [ "closeAll" ],
  "org.apache.hadoop.fs.shell.FsUsage$Du:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "getContentSummary", "getLength", "getSnapshotLength", "getSnapshotSpaceConsumed", "getUsagesTable", "addRow" ],
  "org.apache.hadoop.metrics2.sink.GraphiteSink:init(org.apache.commons.configuration2.SubsetConfiguration)" : [ "<init>", "connect" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreImpl:incrementGauge(java.lang.String,long)" : [ "incAtomicLong" ],
  "org.apache.hadoop.fs.FileSystem:copyFromLocalFile(boolean,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "copyFromLocalFile" ],
  "org.apache.hadoop.io.SequenceFile$Writer:sync()" : [ "getPos" ],
  "org.apache.hadoop.util.dynamic.BindingUtils:loadStaticMethod(java.lang.Class,java.lang.Class,java.lang.String,java.lang.Class[])" : [ "loadInvocation", "available", "checkState", "isStatic" ],
  "org.apache.hadoop.metrics2.MetricsJsonBuilder:addCounter(org.apache.hadoop.metrics2.MetricsInfo,long)" : [ "tuple" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:supportsSymlinks()" : [ "supportsSymlinks" ],
  "org.apache.hadoop.io.WritableUtils:writeCompressedString(java.io.DataOutput,java.lang.String)" : [ "writeCompressedByteArray" ],
  "org.apache.hadoop.ha.ZKFailoverController:cedeActive(int)" : [ "getLoginUser", "doAs" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider:writeToNew(org.apache.hadoop.fs.Path)" : [ "create", "close" ],
  "org.apache.hadoop.io.BoundedByteArrayOutputStream:<init>(int,int)" : [ "<init>" ],
  "org.apache.hadoop.util.SemaphoredDelegatingExecutor:execute(java.lang.Runnable)" : [ "trackDuration" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:setStoragePolicy(org.apache.hadoop.fs.Path,java.lang.String)" : [ "setStoragePolicy", "resolve", "getUriPath" ],
  "org.apache.hadoop.io.SequenceFile$Sorter$SegmentDescriptor:compareTo(java.lang.Object)" : [ "toString" ],
  "org.apache.hadoop.fs.FSDataInputStream:maxReadSizeForVectorReads()" : [ "maxReadSizeForVectorReads" ],
  "org.apache.hadoop.io.ObjectWritable$NullInstance:<init>(java.lang.Class,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.security.token.delegation.web.PseudoDelegationTokenAuthenticator:<init>()" : [ "<init>" ],
  "org.apache.hadoop.util.ShutdownHookManager:getShutdownTimeout(org.apache.hadoop.conf.Configuration)" : [ "getTimeDuration" ],
  "org.apache.hadoop.metrics2.impl.MetricsConfig:getPlugin(java.lang.String)" : [ "<init>", "getClassName", "getPluginLoader", "subset" ],
  "org.apache.hadoop.fs.FileContext:open(org.apache.hadoop.fs.Path,int)" : [ "fixRelativePart" ],
  "org.apache.hadoop.util.StringUtils:formatPercent(double,int)" : [ "format" ],
  "org.apache.hadoop.io.compress.zstd.ZStandardDecompressor:needsInput()" : [ "setInputFromSavedData" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSelector:selectToken(org.apache.hadoop.io.Text,java.util.Collection)" : [ "equals", "getKind", "getService" ],
  "org.apache.hadoop.ipc.ProcessingDetails:set(org.apache.hadoop.ipc.ProcessingDetails$Timing,long,java.util.concurrent.TimeUnit)" : [ "set" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:createInternal(org.apache.hadoop.fs.Path,java.util.EnumSet,org.apache.hadoop.fs.permission.FsPermission,int,short,long,org.apache.hadoop.util.Progressable,org.apache.hadoop.fs.Options$ChecksumOpt,boolean)" : [ "fullPath" ],
  "org.apache.hadoop.fs.Globber:getFileStatus(org.apache.hadoop.fs.Path)" : [ "getFileStatus" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:sendMTFValues3(int,int)" : [ "hbAssignCodes" ],
  "org.apache.hadoop.security.http.CrossOriginFilter:doCrossFilter(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)" : [ "encodeHeader", "isCrossOrigin", "areOriginsAllowed", "isMethodAllowed", "areHeadersAllowed", "getAllowedMethodsHeader", "getAllowedHeadersHeader" ],
  "org.apache.hadoop.util.StringUtils:split(java.lang.String)" : [ "split" ],
  "org.apache.hadoop.util.concurrent.HadoopExecutors:newScheduledThreadPool(int,java.util.concurrent.ThreadFactory)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.impl.MetricsRecordImpl:equals(java.lang.Object)" : [ "equals" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:getFileBlockLocations(org.apache.hadoop.fs.Path,long,long)" : [ "getFileBlockLocations" ],
  "org.apache.hadoop.fs.shell.find.BaseExpression:finish()" : [ "getChildren" ],
  "org.apache.hadoop.io.WritableUtils:readStringSafely(java.io.DataInput,int)" : [ "readVInt", "decode" ],
  "org.apache.hadoop.ipc.Client:checkAsyncCall()" : [ "<init>", "isAsynchronousMode" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme:getMountTableConfigLoader(org.apache.hadoop.conf.Configuration)" : [ "getClass", "get", "newInstance" ],
  "org.apache.hadoop.ipc.WeightedTimeCostProvider:getCost(org.apache.hadoop.ipc.ProcessingDetails)" : [ "get" ],
  "org.apache.hadoop.ipc.Client:toString()" : [ "byteToHexString" ],
  "org.apache.hadoop.io.SequenceFile$Writer:progressable(org.apache.hadoop.util.Progressable)" : [ "<init>" ],
  "org.apache.hadoop.fs.DUHelper:main(java.lang.String[])" : [ "getFolderUsage" ],
  "org.apache.hadoop.ipc.Server:getRemoteIp()" : [ "getHostInetAddress" ],
  "org.apache.hadoop.fs.shell.CopyCommands$Cp:popPreserveOption(java.util.List)" : [ "getAttribute" ],
  "org.apache.hadoop.fs.impl.prefetch.BoundedResourcePool:<init>(int)" : [ "checkPositiveInteger" ],
  "org.apache.hadoop.net.NetworkTopology:getNodeForNetworkLocation(org.apache.hadoop.net.Node)" : [ "getNode" ],
  "org.apache.hadoop.util.StringUtils:getFormattedTimeWithDiff(org.apache.commons.lang3.time.FastDateFormat,long,long)" : [ "getFormattedTimeWithDiff" ],
  "org.apache.hadoop.ha.SshFenceByTcpPort$Args:parseConfiggedPort(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.io.retry.RetryUtils$WrapperRetryPolicy:equals(java.lang.Object)" : [ "equals" ],
  "org.apache.hadoop.fs.crypto.CryptoFSDataInputStream:<init>(org.apache.hadoop.fs.FSDataInputStream,org.apache.hadoop.crypto.CryptoCodec,int,byte[],byte[])" : [ "<init>" ],
  "org.apache.hadoop.io.DataInputByteBuffer:getPosition()" : [ "getPosition" ],
  "org.apache.hadoop.crypto.key.UserProvider:deleteKey(java.lang.String)" : [ "<init>", "getMetadata", "getVersions", "removeSecretKey" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:setOwner(org.apache.hadoop.fs.Path,java.lang.String,java.lang.String)" : [ "fullPath" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationHandler:setExternalDelegationTokenSecretManager(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager)" : [ "setExternalDelegationTokenSecretManager" ],
  "org.apache.hadoop.metrics2.util.SampleQuantiles:query(double)" : [ "checkState", "allowableError" ],
  "org.apache.hadoop.util.LightWeightResizableGSet:<init>(int,float)" : [ "<init>" ],
  "org.apache.hadoop.io.MapFile$Merger:mergePass()" : [ "newInstance", "next", "compare", "append" ],
  "org.apache.hadoop.fs.Path:<init>(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "initialize" ],
  "org.apache.hadoop.ha.FailoverController:createReqInfo()" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.prefetch.BufferPool:canRelease(org.apache.hadoop.fs.impl.prefetch.BufferData)" : [ "stateEqualsOneOf" ],
  "org.apache.hadoop.fs.local.LocalFs:<init>(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.util.SysInfoWindows:getNumVCoresUsed()" : [ "refreshIfNeeded" ],
  "org.apache.hadoop.util.functional.RemoteIterators$WrappingRemoteIterator:sourceHasNext()" : [ "getSource", "cleanupWithLogger", "close" ],
  "org.apache.hadoop.fs.DelegationTokenRenewer$RenewAction:cancel()" : [ "cancel" ],
  "org.apache.hadoop.fs.FileSystem$Statistics:incrementLargeReadOps(int)" : [ "getThreadStatistics" ],
  "org.apache.hadoop.util.ReflectionUtils:newInstance(java.lang.Class,org.apache.hadoop.conf.Configuration)" : [ "newInstance" ],
  "org.apache.hadoop.net.NetUtils:getHostDetailsAsString(java.lang.String,int,java.lang.String)" : [ "quoteHost" ],
  "org.apache.hadoop.util.DataChecksum:getHeader()" : [ "getChecksumHeaderSize" ],
  "org.apache.hadoop.security.UserGroupInformation:isHadoopLogin()" : [ "getLogin" ],
  "org.apache.hadoop.fs.FileContext:truncate(org.apache.hadoop.fs.Path,long)" : [ "fixRelativePart" ],
  "org.apache.hadoop.fs.FutureDataInputStreamBuilder:build()" : [ "build" ],
  "org.apache.hadoop.net.NetUtils:createSocketAddrUnresolved(java.lang.String)" : [ "createSocketAddr" ],
  "org.apache.hadoop.io.retry.RetryPolicy$RetryAction:<init>(org.apache.hadoop.io.retry.RetryPolicy$RetryAction$RetryDecision,long)" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.FutureDataInputStreamBuilderImpl:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)" : [ "<init>", "initFromFS" ],
  "org.apache.hadoop.fs.permission.FsCreateModes:toString()" : [ "toString", "getUnmasked" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:incrAuthorizationSuccesses()" : [ "incr" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:addServiceUserRawCallVolume(org.apache.hadoop.metrics2.MetricsRecordBuilder)" : [ "info", "getTotalServiceUserRawCallVolume" ],
  "org.apache.hadoop.log.LogLevel$Servlet:doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)" : [ "hasAdministratorAccess", "initHTML", "getParameter", "isLog4jLogger", "process" ],
  "org.apache.hadoop.fs.FileSystem:createNonRecursive(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,boolean,int,short,long,org.apache.hadoop.util.Progressable)" : [ "createNonRecursive" ],
  "org.apache.hadoop.util.Timer:now()" : [ "now" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:parseCommandArgs(org.apache.hadoop.conf.Configuration,java.util.List)" : [ "<init>", "checkNotNull", "createGenericOptionsParser", "isParseSuccessful", "getCommandLine", "getRemainingArgs", "verifyConfigurationFilesExist" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:removeAclEntries(org.apache.hadoop.fs.Path,java.util.List)" : [ "removeAclEntries", "resolve", "getUriPath" ],
  "org.apache.hadoop.io.retry.RetryPolicies$RetryUpToMaximumTimeWithFixedSleep:getReason()" : [ "constructReasonString" ],
  "org.apache.hadoop.fs.impl.AbstractFSBuilderImpl:must(java.lang.String,double)" : [ "mustLong" ],
  "org.apache.hadoop.io.SequenceFile$Writer:blockSize(long)" : [ "<init>" ],
  "org.apache.hadoop.security.ssl.SSLFactory:init()" : [ "getHostnameVerifier" ],
  "org.apache.hadoop.util.ComparableVersion:compareTo(org.apache.hadoop.util.ComparableVersion)" : [ "compareTo" ],
  "org.apache.hadoop.util.IdentityHashStore:<init>(int)" : [ "checkArgument", "realloc" ],
  "org.apache.hadoop.net.NetworkTopology:decommissionNode(org.apache.hadoop.net.Node)" : [ "getPath", "interRemoveNodeWithEmptyRack" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:removeXAttr(org.apache.hadoop.fs.Path,java.lang.String)" : [ "removeXAttr" ],
  "org.apache.hadoop.io.erasurecode.CodecUtil:createRawEncoderWithFallback(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "getBoolean", "getRawCoderNames", "createRawCoderFactory" ],
  "org.apache.hadoop.io.erasurecode.CodecUtil:createCodec(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.hadoop.io.erasurecode.ErasureCodecOptions)" : [ "getClassByName" ],
  "org.apache.hadoop.security.KDiag:dumpTokens(org.apache.hadoop.security.UserGroupInformation)" : [ "getCredentials", "getAllTokens", "title", "println", "getKind", "endln" ],
  "org.apache.hadoop.io.compress.CodecPool:payback(java.util.Map,java.lang.Object)" : [ "getClass" ],
  "org.apache.hadoop.io.retry.CallReturn:<init>(java.lang.Object,java.lang.Throwable,org.apache.hadoop.io.retry.CallReturn$State)" : [ "checkArgument" ],
  "org.apache.hadoop.fs.FilterFileSystem:listCorruptFileBlocks(org.apache.hadoop.fs.Path)" : [ "listCorruptFileBlocks" ],
  "org.apache.hadoop.net.unix.DomainSocket$DomainOutputStream:close()" : [ "close" ],
  "org.apache.hadoop.fs.impl.prefetch.SingleFilePerBlockCache:toString()" : [ "getStats", "getIntList", "blocks" ],
  "org.apache.hadoop.security.Groups:parseStaticMapping(org.apache.hadoop.conf.Configuration)" : [ "<init>", "get", "getStringCollection" ],
  "org.apache.hadoop.fs.DelegationTokenRenewer$RenewAction:getDelay(java.util.concurrent.TimeUnit)" : [ "now" ],
  "org.apache.hadoop.fs.MD5MD5CRC32GzipFileChecksum:<init>()" : [ "<init>" ],
  "org.apache.hadoop.util.dynamic.DynMethods$UnboundMethod:bind(java.lang.Object)" : [ "checkState", "isStatic", "checkArgument" ],
  "org.apache.hadoop.io.retry.RetryPolicies$RetryLimited:hashCode()" : [ "toString" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:disconnect(com.jcraft.jsch.ChannelSftp)" : [ "disconnect" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.ByteArrayEncodingState:convertToByteBufferState()" : [ "<init>", "cloneAsDirectByteBuffer" ],
  "org.apache.hadoop.log.LogLevel$CLI:sendLogLevelRequest()" : [ "<init>", "doGetLevel", "doSetLevel" ],
  "org.apache.hadoop.fs.FileSystem$Statistics:getWriteOps()" : [ "<init>", "visitAll" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker:getProtocolImpl(org.apache.hadoop.ipc.RPC$Server,java.lang.String,long)" : [ "<init>", "getProtocolImplMap", "getHighestSupportedProtocol" ],
  "org.apache.hadoop.fs.FilterFileSystem:getFileBlockLocations(org.apache.hadoop.fs.FileStatus,long,long)" : [ "getFileBlockLocations" ],
  "org.apache.hadoop.io.compress.zlib.ZlibCompressor:reinit(org.apache.hadoop.conf.Configuration)" : [ "reset", "getCompressionLevel", "getCompressionStrategy", "compressionLevel", "compressionStrategy", "windowBits" ],
  "org.apache.hadoop.io.file.tfile.Compression:getSupportedAlgorithms()" : [ "getName" ],
  "org.apache.hadoop.fs.impl.prefetch.BufferData:toString()" : [ "getBufferStr", "getFutureStr" ],
  "org.apache.hadoop.http.ProfileServlet$Event:fromInternalName(java.lang.String)" : [ "getInternalName" ],
  "org.apache.hadoop.crypto.CryptoInputStream:available()" : [ "checkStream" ],
  "org.apache.hadoop.io.SequenceFile$Writer:filesystem(org.apache.hadoop.fs.FileSystem)" : [ "<init>" ],
  "org.apache.hadoop.conf.Configuration$DeprecatedKeyInfo:getWarningMessage(java.lang.String)" : [ "getWarningMessage" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.XORRawErasureCoderFactory:createEncoder(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.io.MD5Hash:setDigest(java.lang.String)" : [ "charToNibble" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:getXAttrs(org.apache.hadoop.fs.Path)" : [ "getXAttrs" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:exists(org.apache.commons.net.ftp.FTPClient,org.apache.hadoop.fs.Path)" : [ "getFileStatus" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:newCounter(java.lang.String,java.lang.String,long)" : [ "newCounter", "info" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockOperations:requestPrefetch(int)" : [ "<init>", "checkNotNegative", "add" ],
  "org.apache.hadoop.service.ServiceStateException:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.store.ByteBufferInputStream:mark(int)" : [ "position", "checkOpenState" ],
  "org.apache.hadoop.fs.shell.find.And:registerExpression(org.apache.hadoop.fs.shell.find.ExpressionFactory)" : [ "addClass" ],
  "org.apache.hadoop.io.file.tfile.TFile$Writer$ValueRegister:close()" : [ "incRecordCount", "finishDataBlock" ],
  "org.apache.hadoop.util.ThreadUtil:sleepAtLeastIgnoreInterrupts(long)" : [ "now" ],
  "org.apache.hadoop.io.retry.AsyncCallHandler:getLowerLayerAsyncReturn()" : [ "checkNotNull" ],
  "org.apache.hadoop.ipc.metrics.RpcDetailedMetrics:create(int)" : [ "<init>", "instance" ],
  "org.apache.hadoop.conf.Configuration:addResourceObject(org.apache.hadoop.conf.Configuration$Resource)" : [ "isParserRestricted", "loadProps" ],
  "org.apache.hadoop.fs.FileSystem:getFileChecksum(org.apache.hadoop.fs.Path)" : [ "getFileChecksum" ],
  "org.apache.hadoop.fs.Options$CreateOpts:blockSize(long)" : [ "<init>" ],
  "org.apache.hadoop.fs.FilterFileSystem:primitiveCreate(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,java.util.EnumSet,int,short,long,org.apache.hadoop.util.Progressable,org.apache.hadoop.fs.Options$ChecksumOpt)" : [ "primitiveCreate" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:connect()" : [ "connect", "checkNotClosed", "get", "getInt" ],
  "org.apache.hadoop.io.SequenceFile$Sorter:merge(org.apache.hadoop.fs.Path[],org.apache.hadoop.fs.Path)" : [ "merge", "exists", "getParent", "cloneFileAttributes", "writeFile", "close" ],
  "org.apache.hadoop.io.compress.snappy.SnappyDecompressor:setInput(byte[],int,int)" : [ "setInputFromSavedData" ],
  "org.apache.hadoop.io.InputBuffer:reset(byte[],int,int)" : [ "reset" ],
  "org.apache.hadoop.io.SequenceFile$Reader$StartOption:<init>(long)" : [ "<init>" ],
  "org.apache.hadoop.security.ShellBasedUnixGroupsMapping:resolvePartialGroupNames(java.lang.String,java.lang.String,java.lang.String)" : [ "<init>", "createGroupIDExecutor", "execute", "parsePartialGroupNames", "getOutput" ],
  "org.apache.hadoop.crypto.key.KeyProviderCryptoExtension:close()" : [ "close" ],
  "org.apache.hadoop.net.SocketInputWrapper:getReadableByteChannel()" : [ "checkState" ],
  "org.apache.hadoop.fs.impl.FileSystemMultipartUploaderBuilder:getBlockSize()" : [ "getBlockSize" ],
  "org.apache.hadoop.security.SecurityUtil:buildDTServiceName(java.net.URI,int)" : [ "createSocketAddr", "buildTokenService", "toString" ],
  "org.apache.hadoop.ha.ZKFailoverController:doCedeActive(int)" : [ "getGracefulFenceTimeout", "recheckElectability", "getCurrentUser", "getRemoteAddress", "getProxy", "createReqInfo", "quitElection" ],
  "org.apache.hadoop.fs.shell.MoveCommands$MoveFromLocal:processOptions(java.util.LinkedList)" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:close()" : [ "close", "getKMSUrl" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:<init>(java.net.URI,org.apache.hadoop.crypto.key.kms.KMSClientProvider[],org.apache.hadoop.conf.Configuration)" : [ "<init>", "monotonicNow" ],
  "org.apache.hadoop.io.SequenceFile$BlockCompressWriter:appendRaw(byte[],int,int,org.apache.hadoop.io.SequenceFile$ValueBytes)" : [ "writeVInt", "getLength", "sync" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:getXAttrs(org.apache.hadoop.fs.Path,java.util.List)" : [ "getXAttrs", "fullPath" ],
  "org.apache.hadoop.io.Text:charAt(int)" : [ "bytesToCodePoint" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:setDataConnectionMode(org.apache.commons.net.ftp.FTPClient,org.apache.hadoop.conf.Configuration)" : [ "get" ],
  "org.apache.hadoop.conf.Configuration:updateConnectAddr(java.lang.String,java.lang.String,java.lang.String,java.net.InetSocketAddress)" : [ "updateConnectAddr", "get", "getTrimmed", "createSocketAddrForHost" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:numDroppedConnections()" : [ "getNumDroppedConnections" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:initSystemMBean()" : [ "checkNotNull", "register" ],
  "org.apache.hadoop.fs.FileUtil:grantPermissions(java.io.File)" : [ "setExecutable", "setReadable", "setWritable" ],
  "org.apache.hadoop.net.NetUtils:getOutputStream(java.net.Socket)" : [ "getOutputStream" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockData:getStartOffset(int)" : [ "throwIfInvalidBlockNumber" ],
  "org.apache.hadoop.util.LightWeightGSet:computeCapacity(double,java.lang.String)" : [ "computeCapacity" ],
  "org.apache.hadoop.fs.CompositeCrcFileChecksum:toString()" : [ "getAlgorithmName" ],
  "org.apache.hadoop.util.ShutdownHookManager:shutdownExecutor(org.apache.hadoop.conf.Configuration)" : [ "getShutdownTimeout" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:iostatisticsSnapshot_toJsonString(java.io.Serializable)" : [ "checkIoStatisticsAvailable", "invoke" ],
  "org.apache.hadoop.fs.impl.prefetch.BoundedResourcePool:toString()" : [ "numCreated", "numAvailable" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:getFileChecksum(org.apache.hadoop.fs.Path)" : [ "checkPathIsSlash" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL:selectDelegationToken(java.net.URL,org.apache.hadoop.security.Credentials)" : [ "buildTokenService", "getToken" ],
  "org.apache.hadoop.crypto.key.UserProvider:rollNewVersion(java.lang.String,byte[])" : [ "<init>", "getMetadata", "getBitLength", "addVersion", "addSecretKey", "serialize" ],
  "org.apache.hadoop.ha.HAAdmin:printUsage(java.io.PrintStream)" : [ "printUsage" ],
  "org.apache.hadoop.io.compress.CompressionInputStream:close()" : [ "returnDecompressor" ],
  "org.apache.hadoop.security.UserGroupInformation:createRemoteUser(java.lang.String)" : [ "createRemoteUser" ],
  "org.apache.hadoop.security.UserGroupInformation:getKerberosLoginRenewalExecutor()" : [ "ensureInitialized" ],
  "org.apache.hadoop.security.token.Token:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.FilterFileSystem:<init>(org.apache.hadoop.fs.FileSystem)" : [ "<init>" ],
  "org.apache.hadoop.ipc.WeightedRoundRobinMultiplexer:getAndAdvanceCurrentIndex()" : [ "getCurrentIndex", "advanceIndex" ],
  "org.apache.hadoop.fs.statistics.impl.WrappedIOStatistics:maximums()" : [ "getWrapped" ],
  "org.apache.hadoop.crypto.CryptoInputStream:hasCapability(java.lang.String)" : [ "toLowerCase" ],
  "org.apache.hadoop.crypto.CryptoOutputStream:<init>(java.io.OutputStream,org.apache.hadoop.crypto.CryptoCodec,byte[],byte[],long)" : [ "<init>" ],
  "org.apache.hadoop.conf.Configuration:clear()" : [ "getProps", "getOverlay" ],
  "org.apache.hadoop.io.OutputBuffer:write(java.io.InputStream,int)" : [ "write" ],
  "org.apache.hadoop.util.GcTimeMonitor:calculateGCTimePercentageWithinObservedInterval()" : [ "setValues" ],
  "org.apache.hadoop.fs.HarFileSystem:getStatus(org.apache.hadoop.fs.Path)" : [ "getStatus" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.ByteBufferDecodingState:<init>(org.apache.hadoop.io.erasurecode.rawcoder.RawErasureDecoder,java.nio.ByteBuffer[],int[],java.nio.ByteBuffer[])" : [ "findFirstValidInput", "checkInputBuffers", "checkOutputBuffers" ],
  "org.apache.hadoop.fs.store.DataBlocks$BlockUploadData:toByteArray()" : [ "checkState" ],
  "org.apache.hadoop.fs.statistics.impl.DynamicIOStatisticsBuilder:withAtomicIntegerCounter(java.lang.String,java.util.concurrent.atomic.AtomicInteger)" : [ "withLongFunctionCounter" ],
  "org.apache.hadoop.net.NetworkTopology:getWeightUsingNetworkLocation(org.apache.hadoop.net.Node,org.apache.hadoop.net.Node)" : [ "normalizeNetworkLocationPath" ],
  "org.apache.hadoop.security.token.delegation.web.HttpUserGroupInformation:get()" : [ "getHttpUserGroupInformationInContext" ],
  "org.apache.hadoop.metrics2.util.Servers:parse(java.lang.String,int)" : [ "newArrayList", "createSocketAddr" ],
  "org.apache.hadoop.io.erasurecode.grouper.BlockGrouper:makeBlockGroup(org.apache.hadoop.io.erasurecode.ECBlock[],org.apache.hadoop.io.erasurecode.ECBlock[])" : [ "<init>" ],
  "org.apache.hadoop.ha.HAAdmin:printUsage(java.io.PrintStream,java.lang.String)" : [ "printUsage" ],
  "org.apache.hadoop.fs.viewfs.InodeTree:getRootLink()" : [ "checkState" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:getContentSummary(org.apache.hadoop.fs.Path)" : [ "getContentSummary", "fullPath" ],
  "org.apache.hadoop.ha.HAServiceProtocolHelper:transitionToStandby(org.apache.hadoop.ha.HAServiceProtocol,org.apache.hadoop.ha.HAServiceProtocol$StateChangeRequestInfo)" : [ "unwrapRemoteException" ],
  "org.apache.hadoop.fs.Path:getParent()" : [ "getParentUtil" ],
  "org.apache.hadoop.http.HttpServer2$Builder:build()" : [ "<init>", "checkNotNull", "checkState", "getFilterProperties", "loadSSLConfiguration", "getInt", "getBoolean", "createHttpChannelConnector", "createHttpsChannelConnector" ],
  "org.apache.hadoop.security.token.Token:renew(org.apache.hadoop.conf.Configuration)" : [ "getRenewer" ],
  "org.apache.hadoop.util.MachineList:<init>(java.util.Collection,org.apache.hadoop.util.MachineList$InetAddressFactory)" : [ "getByName" ],
  "org.apache.hadoop.ipc.ResponseBuffer:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:append(org.apache.hadoop.fs.Path,int,org.apache.hadoop.util.Progressable)" : [ "append", "fullPath" ],
  "org.apache.hadoop.fs.AbstractFileSystem:getStatistics(java.net.URI)" : [ "<init>", "getBaseUri" ],
  "org.apache.hadoop.io.compress.DecompressorStream:close()" : [ "close" ],
  "org.apache.hadoop.util.RunJar:unJar(java.io.File,java.io.File)" : [ "unJar" ],
  "org.apache.hadoop.fs.FileSystem$DirListingIterator:hasNext()" : [ "getEntries", "hasMore" ],
  "org.apache.hadoop.service.launcher.IrqHandler:bind()" : [ "checkState" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:open(org.apache.hadoop.fs.Path,int)" : [ "fullPath" ],
  "org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule:commit()" : [ "<init>", "getCanonicalUser", "isSecurityEnabled", "getName" ],
  "org.apache.hadoop.security.SaslRpcClient$SaslClientCallbackHandler:<init>(org.apache.hadoop.security.token.Token)" : [ "encodeIdentifier", "getIdentifier", "encodePassword", "getPassword" ],
  "org.apache.hadoop.fs.ContentSummary:formatSize(long,boolean)" : [ "long2String" ],
  "org.apache.hadoop.util.WeakReferenceMap:put(java.lang.Object,java.lang.Object)" : [ "resolve" ],
  "org.apache.hadoop.io.SequenceFile$Sorter:mergePass(org.apache.hadoop.fs.Path)" : [ "cloneFileAttributes", "suffix", "merge", "writeFile", "close" ],
  "org.apache.hadoop.http.HttpServer2:addJerseyResourcePackage(java.lang.String,java.lang.String)" : [ "addJerseyResourcePackage" ],
  "org.apache.hadoop.io.erasurecode.coder.util.HHUtil:getPiggyBacksFromInput(java.nio.ByteBuffer[],int[],int,int,org.apache.hadoop.io.erasurecode.rawcoder.RawErasureEncoder)" : [ "allocateByteBuffer", "encode", "cloneBufferData" ],
  "org.apache.hadoop.fs.FileUtil:copy(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,java.io.File,boolean,org.apache.hadoop.conf.Configuration)" : [ "copy" ],
  "org.apache.hadoop.io.InputBuffer:<init>()" : [ "<init>" ],
  "org.apache.hadoop.util.DiskChecker:checkDirWithDiskIo(org.apache.hadoop.fs.LocalFileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "checkDirInternal", "doDiskIo", "pathToFile" ],
  "org.apache.hadoop.io.wrappedio.WrappedStatistics:iostatistics_gauges(java.io.Serializable)" : [ "applyToIOStatisticsSnapshot", "gauges" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner:<init>(org.apache.hadoop.io.file.tfile.TFile$Reader,org.apache.hadoop.io.file.tfile.TFile$Reader$Location,org.apache.hadoop.io.file.tfile.TFile$Reader$Location)" : [ "<init>", "checkTFileDataIndex", "compareTo", "initBlock", "getBlockIndex", "inBlockAdvance", "getRecordIndex" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:setStoragePolicy(org.apache.hadoop.fs.Path,java.lang.String)" : [ "readOnlyMountTable" ],
  "org.apache.hadoop.io.AbstractMapWritable:<init>()" : [ "addToMap" ],
  "org.apache.hadoop.fs.FilterFileSystem:getLinkTarget(org.apache.hadoop.fs.Path)" : [ "getLinkTarget" ],
  "org.apache.hadoop.io.MapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.io.WritableComparator,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.util.Progressable)" : [ "<init>", "comparator", "valueClass", "compression", "progressable" ],
  "org.apache.hadoop.util.SignalLogger:register(org.slf4j.Logger)" : [ "<init>" ],
  "org.apache.hadoop.ipc.Client$Connection$1:run()" : [ "isLoginTicketBased", "getHostname", "reloginFromTicketCache", "reloginFromKeytab", "isLoginKeytabBased", "getUserName", "getAddress", "wrapException", "getLoginUser" ],
  "org.apache.hadoop.fs.GlobExpander:expandLeftmost(org.apache.hadoop.fs.GlobExpander$StringWithOffset)" : [ "<init>", "leftmostOuterCurlyContainingSlash" ],
  "org.apache.hadoop.util.InstrumentedWriteLock:<init>(java.lang.String,org.slf4j.Logger,java.util.concurrent.locks.ReentrantReadWriteLock,long,long,org.apache.hadoop.util.Timer)" : [ "<init>" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:open(org.apache.hadoop.fs.Path,int)" : [ "<init>", "connect", "makeAbsolute", "getFileStatus", "isDirectory", "disconnect", "getParent", "toUri", "getName" ],
  "org.apache.hadoop.io.compress.BZip2Codec$BZip2CompressionInputStream:internalReset()" : [ "<init>", "readStreamHeader" ],
  "org.apache.hadoop.ipc.Server$Connection:doSaslReply(org.apache.hadoop.thirdparty.protobuf.Message)" : [ "wrap", "sendResponse" ],
  "org.apache.hadoop.io.DefaultStringifier:<init>(org.apache.hadoop.conf.Configuration,java.lang.Class)" : [ "<init>", "getSerializer", "getDeserializer" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Decompressor:getBytesWritten()" : [ "checkStream" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding:snapshotMap(java.util.Map)" : [ "snapshotMap", "passthroughFn" ],
  "org.apache.hadoop.fs.FileSystem:getStatistics(java.lang.String,java.lang.Class)" : [ "<init>", "checkArgument", "put" ],
  "org.apache.hadoop.fs.LocatedFileStatus:<init>(long,boolean,int,long,long,long,org.apache.hadoop.fs.permission.FsPermission,java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,java.util.Set,org.apache.hadoop.fs.BlockLocation[])" : [ "<init>" ],
  "org.apache.hadoop.security.UserGroupInformation:print()" : [ "getUserName", "getGroupNames" ],
  "org.apache.hadoop.fs.BlockLocation:<init>(java.lang.String[],java.lang.String[],long,long,boolean)" : [ "<init>" ],
  "org.apache.hadoop.fs.statistics.impl.DynamicIOStatisticsBuilder:build()" : [ "activeInstance" ],
  "org.apache.hadoop.fs.impl.prefetch.CachingBlockManager:addToCacheAndRelease(org.apache.hadoop.fs.impl.prefetch.BufferData,java.util.concurrent.Future,java.time.Instant)" : [ "setDone", "stateEqualsOneOf", "getBlockNumber", "addToCache", "getBuffer", "cachePut", "end", "duration" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:<init>(java.lang.String)" : [ "info" ],
  "org.apache.hadoop.ipc.ClientCache:getClient(org.apache.hadoop.conf.Configuration)" : [ "getClient" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:incrementCounter(java.lang.String,long)" : [ "getInnerStatistics" ],
  "org.apache.hadoop.io.erasurecode.coder.DummyErasureDecoder:prepareDecodingStep(org.apache.hadoop.io.erasurecode.ECBlockGroup)" : [ "<init>" ],
  "org.apache.hadoop.ipc.ObserverRetryOnActiveException:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.io.IOUtils:closeStreams(java.io.Closeable[])" : [ "cleanupWithLogger" ],
  "org.apache.hadoop.security.alias.UserProvider:getAliases()" : [ "getAllSecretKeys", "toString" ],
  "org.apache.hadoop.io.Text:set(java.lang.String)" : [ "encode" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.util.GaloisField:solveVandermondeSystem(int[],int[])" : [ "solveVandermondeSystem" ],
  "org.apache.hadoop.io.compress.zstd.ZStandardDecompressor:<init>(int)" : [ "reset" ],
  "org.apache.hadoop.io.wrappedio.WrappedStatistics:iostatisticsSnapshot_create()" : [ "iostatisticsSnapshot_create" ],
  "org.apache.hadoop.ipc.Server$Call:abortResponse(java.lang.Throwable)" : [ "doResponse" ],
  "org.apache.hadoop.ipc.Server$FatalRpcServerException:<init>(org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$RpcErrorCodeProto,java.io.IOException)" : [ "<init>" ],
  "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter:toLowerCase(javax.servlet.http.HttpServletRequest)" : [ "toLowerCase", "containsUpperCase" ],
  "org.apache.hadoop.conf.ConfServlet:doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)" : [ "isInstrumentationAccessAllowed", "parseAcceptHeader", "writeResponse", "getConfFromContext" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RSLegacyRawErasureCoderFactory:createEncoder(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.io.Text:find(java.lang.String)" : [ "find" ],
  "org.apache.hadoop.fs.statistics.impl.DynamicIOStatisticsBuilder:withLongFunctionCounter(java.lang.String,java.util.function.ToLongFunction)" : [ "activeInstance", "addCounterFunction" ],
  "org.apache.hadoop.util.CacheableIPList:isIn(java.lang.String)" : [ "isIn", "reset" ],
  "org.apache.hadoop.util.functional.RemoteIterators:toList(org.apache.hadoop.fs.RemoteIterator)" : [ "foreach" ],
  "org.apache.hadoop.io.UTF8:equals(java.lang.Object)" : [ "compareBytes" ],
  "org.apache.hadoop.ipc.RPC$Server:initProtocolMetaInfo(org.apache.hadoop.conf.Configuration)" : [ "<init>", "setProtocolEngine", "addProtocol" ],
  "org.apache.hadoop.fs.shell.find.Find:parseExpression(java.util.Deque)" : [ "getExpression", "isExpression" ],
  "org.apache.hadoop.fs.FilterFileSystem:getAclStatus(org.apache.hadoop.fs.Path)" : [ "getAclStatus" ],
  "org.apache.hadoop.security.UserGroupInformation:setAuthenticationMethod(org.apache.hadoop.security.UserGroupInformation$AuthenticationMethod)" : [ "setAuthenticationMethod" ],
  "org.apache.hadoop.crypto.OpensslCtrCryptoCodec$OpensslCtrCipher:decrypt(java.nio.ByteBuffer,java.nio.ByteBuffer)" : [ "process" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding:fromStorageStatistics(org.apache.hadoop.fs.StorageStatistics)" : [ "dynamicIOStatistics", "withLongFunctionCounter", "getName", "build" ],
  "org.apache.hadoop.fs.impl.FileSystemMultipartUploaderBuilder:getChecksumOpt()" : [ "getChecksumOpt" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:isValidName(java.lang.String)" : [ "<init>", "isValidName", "fullPath", "toUri" ],
  "org.apache.hadoop.ipc.Client$ConnectionId:<init>(java.net.InetSocketAddress,java.lang.Class,org.apache.hadoop.security.UserGroupInformation,int,org.apache.hadoop.io.retry.RetryPolicy,org.apache.hadoop.conf.Configuration)" : [ "getInt", "getBoolean", "getPingInterval" ],
  "org.apache.hadoop.ha.NodeFencer:createFenceMethod(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String)" : [ "<init>", "newInstance" ],
  "org.apache.hadoop.fs.impl.prefetch.BufferPool:releaseDoneBlocks()" : [ "getAll", "stateEqualsOneOf", "release" ],
  "org.apache.hadoop.fs.FileRange:createFileRange(long,int)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:write(byte[],int,int)" : [ "write0" ],
  "org.apache.hadoop.io.compress.DefaultCodec:createDecompressor()" : [ "getZlibDecompressor" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:getAclStatus(org.apache.hadoop.fs.Path)" : [ "getAclStatus" ],
  "org.apache.hadoop.fs.FileUtil:checkDependencies(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)" : [ "makeQualified", "toString" ],
  "org.apache.hadoop.io.SequenceFile$Writer:appendIfExists(boolean)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.MetricStringBuilder:addGauge(org.apache.hadoop.metrics2.MetricsInfo,double)" : [ "add" ],
  "org.apache.hadoop.security.JniBasedUnixGroupsNetgroupMapping:getGroups(java.lang.String)" : [ "getGroups", "getNetgroups" ],
  "org.apache.hadoop.fs.RawLocalFileSystem$DeprecatedRawLocalFileStatus:isPermissionLoaded()" : [ "getOwner" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:sendMTFValues1(int,int)" : [ "hbMakeCodeLengths" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:getInitialWorkingDirectory()" : [ "getInitialWorkingDirectory" ],
  "org.apache.hadoop.security.authorize.ProxyUsers:refreshSuperUserGroupsConfiguration(org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "checkArgument", "getInstance", "refresh" ],
  "org.apache.hadoop.fs.PathNotFoundException:<init>(java.lang.String,java.lang.Throwable)" : [ "<init>" ],
  "org.apache.hadoop.io.nativeio.NativeIO$POSIX:chmod(java.lang.String,int)" : [ "<init>", "getErrorCode" ],
  "org.apache.hadoop.fs.impl.prefetch.ExecutorServiceFuturePool:shutdown(org.slf4j.Logger,long,java.util.concurrent.TimeUnit)" : [ "shutdown" ],
  "org.apache.hadoop.util.ChunkedArrayList:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.statistics.impl.EvaluatingStatisticsMap:<init>()" : [ "<init>", "passthroughFn" ],
  "org.apache.hadoop.util.Sets:newHashSet(java.util.Iterator)" : [ "newHashSet", "addAll" ],
  "org.apache.hadoop.io.WritableFactories:newInstance(java.lang.Class)" : [ "newInstance" ],
  "org.apache.hadoop.util.ComparableVersion:parseItem(boolean,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.security.Groups$GroupCacheLoader:fetchGroupSet(java.lang.String)" : [ "monotonicNow", "getGroupsSet", "addGetGroups" ],
  "org.apache.hadoop.fs.permission.FsPermission:readFields(java.io.DataInput)" : [ "fromShort" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:setTimeout(org.apache.commons.net.ftp.FTPClient,org.apache.hadoop.conf.Configuration)" : [ "getLong" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:listStatusIterator(org.apache.hadoop.fs.Path)" : [ "listStatusIterator", "isInternalDir" ],
  "org.apache.hadoop.security.ssl.SSLHostnameVerifier$AbstractVerifier:check(java.lang.String[],java.security.cert.X509Certificate)" : [ "getCNs", "getDNSSubjectAlts" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker:getReturnMessage(java.lang.reflect.Method,org.apache.hadoop.ipc.RpcWritable$Buffer)" : [ "getReturnProtoType", "getValue" ],
  "org.apache.hadoop.util.FindClass:getResource(java.lang.String)" : [ "getResource" ],
  "org.apache.hadoop.ipc.Server$Connection:readAndProcess()" : [ "shouldClose", "setServiceClass", "setupHttpRequestOnIpcPortResponse", "setupBadVersionResponse", "initializeAuthContext", "checkDataLength", "processOneRpc" ],
  "org.apache.hadoop.util.functional.RemoteIterators:foreach(org.apache.hadoop.fs.RemoteIterator,org.apache.hadoop.util.functional.ConsumerRaisingIOE)" : [ "cleanupRemoteIterator" ],
  "org.apache.hadoop.security.UserGroupInformation$TestingGroups:<init>(org.apache.hadoop.security.Groups)" : [ "<init>" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:retrievePassword(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier)" : [ "checkToken", "getPassword" ],
  "org.apache.hadoop.fs.impl.FsLinkResolution:<init>(org.apache.hadoop.fs.impl.FsLinkResolution$FsLinkResolutionFunction)" : [ "checkNotNull" ],
  "org.apache.hadoop.security.token.Token:identifierToString(java.lang.StringBuilder)" : [ "decodeIdentifier", "addBinaryBuffer" ],
  "org.apache.hadoop.net.ScriptBasedMappingWithDependency:getDependency(java.lang.String)" : [ "getDependency", "normalizeHostName", "getRawMapping" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:modifyAclEntries(org.apache.hadoop.fs.Path,java.util.List)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.net.NodeBase:equals(java.lang.Object)" : [ "getPath" ],
  "org.apache.hadoop.fs.HarFileSystem$HarFSDataInputStream$HarFsInputStream:read(byte[])" : [ "read" ],
  "org.apache.hadoop.io.serializer.SerializationFactory:add(org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "getClassByName", "newInstance" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:makeAbsolute(org.apache.hadoop.fs.Path)" : [ "<init>", "isAbsolute" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyOutputStream:write(byte[],int,int)" : [ "osException", "mayThrow" ],
  "org.apache.hadoop.fs.impl.AbstractFSBuilderImpl:optLong(java.lang.String,long)" : [ "opt" ],
  "org.apache.hadoop.fs.FileSystem:getDefaultReplication(org.apache.hadoop.fs.Path)" : [ "getDefaultReplication" ],
  "org.apache.hadoop.util.SysInfoWindows:getNetworkBytesWritten()" : [ "refreshIfNeeded" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:hasPathCapability(org.apache.hadoop.fs.Path,java.lang.String)" : [ "<init>", "hasPathCapability", "validatePathCapabilityArgs", "resolve", "getUriPath" ],
  "org.apache.hadoop.http.PrometheusServlet:doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)" : [ "instance", "getPrometheusSink", "writeMetrics" ],
  "org.apache.hadoop.io.BooleanWritable:<init>(boolean)" : [ "set" ],
  "org.apache.hadoop.ipc.ClientCache:getClient(org.apache.hadoop.conf.Configuration,javax.net.SocketFactory,java.lang.Class)" : [ "<init>", "incCount" ],
  "org.apache.hadoop.fs.permission.AclStatus:getEffectivePermission(org.apache.hadoop.fs.permission.AclEntry,org.apache.hadoop.fs.permission.FsPermission)" : [ "checkArgument", "getName", "getType", "getScope", "getPermission", "and", "getGroupAction" ],
  "org.apache.hadoop.metrics2.impl.MetricCounterInt:<init>(org.apache.hadoop.metrics2.MetricsInfo,int)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.CodecPool:getCompressor(org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.conf.Configuration)" : [ "borrow", "updateLeaseCount" ],
  "org.apache.hadoop.ipc.CallQueueManager:offer(java.lang.Object,long,java.util.concurrent.TimeUnit)" : [ "offer" ],
  "org.apache.hadoop.conf.Configuration$Resource:<init>(java.lang.Object)" : [ "<init>" ],
  "org.apache.hadoop.util.dynamic.DynMethods$UnboundMethod:invokeChecked(java.lang.Object,java.lang.Object[])" : [ "throwIfInstance" ],
  "org.apache.hadoop.crypto.CryptoOutputStream:<init>(java.io.OutputStream,org.apache.hadoop.crypto.CryptoCodec,int,byte[],byte[])" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:access(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsAction)" : [ "access", "resolve", "getUriPath" ],
  "org.apache.hadoop.io.SequenceFile$Sorter:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.io.RawComparator,java.lang.Class,java.lang.Class,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.fs.RawLocalFileSystem$DeprecatedRawLocalFileStatus:getGroup()" : [ "getGroup", "isPermissionLoaded", "loadPermissionInfo" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtobufRpcEngineCallbackImpl:<init>()" : [ "getServer", "getMethodName", "now" ],
  "org.apache.hadoop.fs.HarFileSystem:getHarHash(org.apache.hadoop.fs.Path)" : [ "toString" ],
  "org.apache.hadoop.ipc.Server$ConnectionManager:closeIdle(boolean)" : [ "now", "size", "getLastContact", "close" ],
  "org.apache.hadoop.net.ScriptBasedMappingWithDependency$RawScriptBasedMappingWithDependency:setConf(org.apache.hadoop.conf.Configuration)" : [ "setConf", "get" ],
  "org.apache.hadoop.io.MapFile$Reader:midKey()" : [ "readIndex" ],
  "org.apache.hadoop.fs.ChecksumFs:setReplication(org.apache.hadoop.fs.Path,short)" : [ "getChecksumFile", "exists" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkGreater(long,java.lang.String,long,java.lang.String)" : [ "checkArgument" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:<init>(org.apache.hadoop.crypto.key.kms.KMSClientProvider[],long,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:iostatisticsContext_enabled()" : [ "ioStatisticsAvailable", "invoke" ],
  "org.apache.hadoop.io.BinaryComparable:equals(java.lang.Object)" : [ "compareTo" ],
  "org.apache.hadoop.io.SequenceFile$Metadata:equals(java.lang.Object)" : [ "equals" ],
  "org.apache.hadoop.fs.impl.FutureIOSupport:raiseInnerCause(java.util.concurrent.CompletionException)" : [ "raiseInnerCause" ],
  "org.apache.hadoop.io.MapFile$Writer:setIndexInterval(org.apache.hadoop.conf.Configuration,int)" : [ "setInt" ],
  "org.apache.hadoop.security.CompositeGroupsMapping:loadMappingProviders()" : [ "getStrings", "getClass", "addMappingProvider" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:configureSinks()" : [ "getInstanceConfigs", "getClassName", "newSink", "start", "sink" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getTrashRoot(org.apache.hadoop.fs.Path)" : [ "<init>", "getTrashRoot", "resolve", "getUriPath", "getBoolean", "toUri", "getHomeDirectory", "toString", "getShortUserName" ],
  "org.apache.hadoop.io.file.tfile.Compression$Algorithm:returnDecompressor(org.apache.hadoop.io.compress.Decompressor)" : [ "returnDecompressor" ],
  "org.apache.hadoop.fs.shell.CommandFormat:addOptionWithValue(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL:openConnection(java.net.URL,org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL$Token,java.lang.String)" : [ "checkNotNull", "getCurrentUser", "getCredentials", "getAllTokens", "numberOfTokens", "selectDelegationToken", "useQueryStringForDelegationToken", "encodeToUrlString", "augmentURL" ],
  "org.apache.hadoop.io.SequenceFile$Reader$LengthOption:<init>(long)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:unsetStoragePolicy(org.apache.hadoop.fs.Path)" : [ "unsetStoragePolicy", "fullPath" ],
  "org.apache.hadoop.ipc.RpcWritable$Buffer:getValue(java.lang.Object)" : [ "wrap" ],
  "org.apache.hadoop.fs.FilterFileSystem:setStoragePolicy(org.apache.hadoop.fs.Path,java.lang.String)" : [ "setStoragePolicy" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:readOnlyMountTable(java.lang.String,org.apache.hadoop.fs.Path)" : [ "readOnlyMountTable", "toString" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher$MinimalGenericOptionsParser:<init>(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.Options,java.lang.String[])" : [ "<init>" ],
  "org.apache.hadoop.ha.ShellCommandFencer:checkArgs(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.RegexMountPoint:resolve(java.lang.String,boolean)" : [ "getPathToResolve", "getSrcPathRegex", "getSrcPattern", "getDstPath", "getVarInDestPathMap", "replaceRegexCaptureGroupInPath", "getRemainingPathStr", "buildResolveResultForRegexMountPoint" ],
  "org.apache.hadoop.fs.ChecksumFs:open(org.apache.hadoop.fs.Path,int)" : [ "<init>" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:gauges()" : [ "getInnerStatistics" ],
  "org.apache.hadoop.net.DNS:getIPsAsInetAddressList(java.lang.String,boolean)" : [ "getSubinterface", "getSubinterfaceInetAddrs" ],
  "org.apache.hadoop.util.SysInfoLinux:getStorageBytesRead()" : [ "readProcDisksInfoFile" ],
  "org.apache.hadoop.security.SaslRpcClient$WrappedInputStream:read(byte[])" : [ "read" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler$MetricsProxy:unregisterSource(java.lang.String)" : [ "instance", "unregister" ],
  "org.apache.hadoop.util.JvmPauseMonitor:serviceStart()" : [ "<init>", "serviceStart" ],
  "org.apache.hadoop.ipc.protocolPB.GenericRefreshProtocolClientSideTranslatorPB:close()" : [ "stopProxy" ],
  "org.apache.hadoop.http.HttpServer2$Builder:setEnabledProtocols(org.eclipse.jetty.util.ssl.SslContextFactory)" : [ "get", "getTrimmedStrings" ],
  "org.apache.hadoop.io.Text:decode(byte[],int,int,boolean)" : [ "decode" ],
  "org.apache.hadoop.fs.Options$HandleOpt:exact()" : [ "changed", "moved" ],
  "org.apache.hadoop.io.compress.zstd.ZStandardDecompressor:<init>()" : [ "<init>" ],
  "org.apache.hadoop.security.ssl.ReloadingX509KeystoreManager:loadFrom(java.nio.file.Path)" : [ "loadKeyManager" ],
  "org.apache.hadoop.security.LdapGroupsMapping:getPasswordFromCredentialProviders(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String)" : [ "getPasswordFromCredentialProviders" ],
  "org.apache.hadoop.fs.store.audit.HttpReferrerAuditHeader:extractQueryParameters(java.lang.String)" : [ "maybeStripWrappedQuotes" ],
  "org.apache.hadoop.security.SecurityUtil:getAuthenticationMethod(org.apache.hadoop.conf.Configuration)" : [ "get", "toUpperCase" ],
  "org.apache.hadoop.fs.impl.prefetch.FilePosition:blockNumber()" : [ "throwIfInvalidBuffer", "getBlockNumber" ],
  "org.apache.hadoop.metrics2.source.JvmMetrics$Singleton:shutdown()" : [ "instance" ],
  "org.apache.hadoop.security.authorize.ImpersonationProvider:authorize(org.apache.hadoop.security.UserGroupInformation,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ConfigUtil:addLinkFallback(org.apache.hadoop.conf.Configuration,java.lang.String,java.net.URI)" : [ "set", "getConfigViewFsPrefix" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:openFileWithOptions(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.impl.OpenFileParameters)" : [ "openFileWithOptions" ],
  "org.apache.hadoop.fs.impl.AbstractFSBuilderImpl:mustDouble(java.lang.String,double)" : [ "must" ],
  "org.apache.hadoop.ipc.WritableRpcEngine$Invoker:invoke(java.lang.Object,java.lang.reflect.Method,java.lang.Object[])" : [ "<init>", "monotonicNow", "curThreadTracer", "newScope", "methodToTraceString", "call", "close", "get" ],
  "org.apache.hadoop.ha.protocolPB.ZKFCProtocolClientSideTranslatorPB:close()" : [ "stopProxy" ],
  "org.apache.hadoop.fs.shell.find.ExpressionFactory:createExpression(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "createExpression" ],
  "org.apache.hadoop.metrics2.MetricsJsonBuilder:addCounter(org.apache.hadoop.metrics2.MetricsInfo,int)" : [ "tuple" ],
  "org.apache.hadoop.fs.FileSystem:clearStatistics()" : [ "reset" ],
  "org.apache.hadoop.conf.Configuration:handleDeprecation(org.apache.hadoop.conf.Configuration$DeprecationContext,java.lang.String)" : [ "getDeprecatedKeyMap", "getAndSetAccessed", "logDeprecation", "updatePropertiesWithDeprecatedKeys", "getOverlay", "getReverseDeprecatedKeyMap", "getProps" ],
  "org.apache.hadoop.security.SaslRpcClient:sendSaslMessage(java.io.OutputStream,org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto)" : [ "<init>", "writeTo" ],
  "org.apache.hadoop.fs.sftp.SFTPConnectionPool:shutdown()" : [ "disconnect", "getHost" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RSRawErasureCoderFactory:createDecoder(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.ipc.Server$RpcCall:doResponse(java.lang.Throwable,org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto$RpcStatusProto)" : [ "stringifyException" ],
  "org.apache.hadoop.io.retry.RetryPolicies$RetryLimited:getReason()" : [ "constructReasonString" ],
  "org.apache.hadoop.fs.PathIsNotEmptyDirectoryException:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.AvroFSInput:<init>(org.apache.hadoop.fs.FileContext,org.apache.hadoop.fs.Path)" : [ "getFileStatus", "getLen", "awaitFuture", "openFile", "withFileStatus", "build" ],
  "org.apache.hadoop.fs.FileSystem:loadFileSystems()" : [ "getScheme", "findContainingJar" ],
  "org.apache.hadoop.security.HadoopKerberosName:main(java.lang.String[])" : [ "<init>", "setConfiguration" ],
  "org.apache.hadoop.fs.Path:getOptionalParentPath()" : [ "getParentUtil" ],
  "org.apache.hadoop.util.SysInfoWindows:getPhysicalMemorySize()" : [ "refreshIfNeeded" ],
  "org.apache.hadoop.ipc.Client$ConnectionId:equals(java.lang.Object)" : [ "isEqual" ],
  "org.apache.hadoop.io.retry.AsyncCallHandler$AsyncCallQueue$Processor:kill(org.apache.hadoop.util.Daemon)" : [ "checkState" ],
  "org.apache.hadoop.security.alias.CredentialShell$CreateCommand:execute()" : [ "promptForCredential" ],
  "org.apache.hadoop.fs.FileContext$FCDataOutputStreamBuilder:build()" : [ "blockSize", "bufferSize", "repFac", "perms", "checksumParam", "progress", "createParent", "create" ],
  "org.apache.hadoop.io.file.tfile.TFile:getFSOutputBufferSize(org.apache.hadoop.conf.Configuration)" : [ "getInt" ],
  "org.apache.hadoop.util.bloom.CountingBloomFilter:and(org.apache.hadoop.util.bloom.Filter)" : [ "buckets2words" ],
  "org.apache.hadoop.io.erasurecode.coder.RSErasureDecoder:prepareDecodingStep(org.apache.hadoop.io.erasurecode.ECBlockGroup)" : [ "<init>", "checkCreateRSRawDecoder" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:getDeferredRpcProcessingMean()" : [ "mean" ],
  "org.apache.hadoop.ipc.Server$RpcCall:toString()" : [ "toString" ],
  "org.apache.hadoop.util.GenericOptionsParser:getLibJars(org.apache.hadoop.conf.Configuration)" : [ "<init>", "get", "getFileSystem", "getLocal", "pathToFile" ],
  "org.apache.hadoop.net.unix.DomainSocket:<init>(java.lang.String,int)" : [ "<init>" ],
  "org.apache.hadoop.io.BloomMapFile$Reader:<init>(org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.io.WritableComparator,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.fs.InvalidPathException:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem:<init>(java.net.URI[],org.apache.hadoop.conf.Configuration,int,java.util.EnumSet)" : [ "<init>" ],
  "org.apache.hadoop.conf.ConfigurationWithLogging:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.util.ApplicationClassLoader:loadClass(java.lang.String)" : [ "loadClass" ],
  "org.apache.hadoop.fs.FilterFileSystem:completeLocalOutput(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "completeLocalOutput" ],
  "org.apache.hadoop.security.alias.LocalKeyStoreProvider:stashOriginalFilePermissions()" : [ "getGetPermissionCommand", "execCommand" ],
  "org.apache.hadoop.fs.impl.prefetch.CachingBlockManager:createCache(int,org.apache.hadoop.fs.statistics.DurationTrackerFactory)" : [ "<init>" ],
  "org.apache.hadoop.security.WhitelistBasedResolver:getServerProperties(java.lang.String)" : [ "getServerProperties" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.CoderUtil:findFirstValidInput(java.lang.Object[])" : [ "<init>" ],
  "org.apache.hadoop.ipc.ProtobufWrapperLegacy:writeTo(org.apache.hadoop.ipc.ResponseBuffer)" : [ "ensureCapacity" ],
  "org.apache.hadoop.conf.Configuration:getPasswordFromConfig(java.lang.String)" : [ "getBoolean", "get" ],
  "org.apache.hadoop.fs.ByteBufferUtil:fallbackRead(java.io.InputStream,org.apache.hadoop.io.ByteBufferPool,int)" : [ "streamHasByteBufferRead", "checkState" ],
  "org.apache.hadoop.fs.FileSystem:create(org.apache.hadoop.fs.Path,short)" : [ "create", "getInt", "getDefaultBlockSize" ],
  "org.apache.hadoop.io.compress.CompressionCodecFactory:addCodec(org.apache.hadoop.io.compress.CompressionCodec)" : [ "toLowerCase" ],
  "org.apache.hadoop.util.SysInfoWindows:<init>()" : [ "reset" ],
  "org.apache.hadoop.io.UTF8:hashCode()" : [ "hashBytes" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:checkIoStatisticsAvailable()" : [ "checkAvailable" ],
  "org.apache.hadoop.security.Groups$TimerToTickerAdapter:read()" : [ "monotonicNow" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner:entry()" : [ "checkKey" ],
  "org.apache.hadoop.io.SequenceFile:createWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class,int,short,long,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.util.Progressable,org.apache.hadoop.io.SequenceFile$Metadata)" : [ "createWriter", "file", "keyClass", "valueClass", "bufferSize", "replication", "blockSize", "compression", "progressable", "metadata" ],
  "org.apache.hadoop.fs.LocalDirAllocator:obtainContext(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.ipc.RetryCache$CacheEntryWithPayload:hashCode()" : [ "hashCode" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:finalize()" : [ "finish" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:setContext(java.lang.String)" : [ "tag" ],
  "org.apache.hadoop.fs.viewfs.RegexMountPoint:replaceRegexCaptureGroupInPath(java.lang.String,java.util.regex.Matcher,java.lang.String,java.util.Set)" : [ "getRegexGroupValueFromMather" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:truncate(org.apache.hadoop.fs.Path,long)" : [ "truncate", "fullPath" ],
  "org.apache.hadoop.security.CompositeGroupsMapping:prepareConf(java.lang.String)" : [ "<init>", "iterator", "set" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner:<init>(org.apache.hadoop.io.file.tfile.TFile$Reader,org.apache.hadoop.io.file.tfile.RawComparable,org.apache.hadoop.io.file.tfile.RawComparable)" : [ "<init>", "begin", "getBlockContainsKey", "end", "inBlockAdvance", "set", "seekTo" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RSRawEncoder:<init>(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>", "getFieldSize", "genCauchyMatrix", "dumpMatrix", "initTables", "bytesToHex" ],
  "org.apache.hadoop.http.AdminAuthorizedServlet:doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)" : [ "hasAdministratorAccess" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:getFileStatus(org.apache.hadoop.fs.Path)" : [ "getFileStatus", "fullPath" ],
  "org.apache.hadoop.io.compress.CodecPool:getDecompressor(org.apache.hadoop.io.compress.CompressionCodec)" : [ "borrow", "updateLeaseCount" ],
  "org.apache.hadoop.util.Sets:newTreeSet(java.lang.Iterable)" : [ "newTreeSet", "addAll" ],
  "org.apache.hadoop.fs.FileStatus:hashCode()" : [ "hashCode", "getPath" ],
  "org.apache.hadoop.fs.FileContext:setStoragePolicy(org.apache.hadoop.fs.Path,java.lang.String)" : [ "fixRelativePart" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getChildFileSystems()" : [ "getChildFileSystems", "getMountPoints", "initializeMountedFileSystems", "isRootInternalDir", "getRootFallbackLink", "getTargetFileSystem" ],
  "org.apache.hadoop.util.Shell:<init>()" : [ "<init>" ],
  "org.apache.hadoop.security.protocolPB.RefreshAuthorizationPolicyProtocolClientSideTranslatorPB:refreshServiceAcl()" : [ "ipc" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider:<init>(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>", "unnestUri", "getFileSystem", "locateKeystore" ],
  "org.apache.hadoop.net.SocketInputWrapper:setTimeout(long)" : [ "setTimeout" ],
  "org.apache.hadoop.ipc.Server:getRpcRequestWrapper(org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcKindProto)" : [ "convert" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2$RpcProtobufRequest:<init>()" : [ "<init>" ],
  "org.apache.hadoop.util.functional.RemoteIterators$FilteringRemoteIterator:hasNext()" : [ "fetch" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler$MetricsProxy:registerMetrics2Source(java.lang.String)" : [ "instance" ],
  "org.apache.hadoop.fs.statistics.impl.StorageStatisticsFromIOStatistics:getLongStatistics()" : [ "counters", "gauges", "toLongStatistic" ],
  "org.apache.hadoop.util.bloom.CountingBloomFilter:delete(org.apache.hadoop.util.bloom.Key)" : [ "membershipTest", "hash", "clear" ],
  "org.apache.hadoop.fs.FSInputChecker:read1(byte[],int,int)" : [ "readChecksumChunk", "fill" ],
  "org.apache.hadoop.util.FindClass:printStack(java.lang.Throwable,java.lang.String,java.lang.Object[])" : [ "err" ],
  "org.apache.hadoop.crypto.key.KeyProviderExtension:rollNewVersion(java.lang.String)" : [ "rollNewVersion" ],
  "org.apache.hadoop.ipc.Server$Responder:doRespond(org.apache.hadoop.ipc.Server$RpcCall)" : [ "processResponse" ],
  "org.apache.hadoop.conf.Configuration:iterator()" : [ "getProps" ],
  "org.apache.hadoop.io.compress.SnappyCodec:createCompressor()" : [ "<init>", "getInt" ],
  "org.apache.hadoop.io.compress.CodecPool:getLeasedDecompressorsCount(org.apache.hadoop.io.compress.CompressionCodec)" : [ "getLeaseCount" ],
  "org.apache.hadoop.metrics2.lib.DefaultMetricsSystem:setInstance(org.apache.hadoop.metrics2.MetricsSystem)" : [ "setImpl" ],
  "org.apache.hadoop.conf.Configuration:get(java.lang.String)" : [ "handleDeprecation", "substituteVars", "getProps" ],
  "org.apache.hadoop.io.SecureIOUtils:forceSecureOpenForRandomRead(java.io.File,java.lang.String,java.lang.String,java.lang.String)" : [ "getFstat", "checkStat", "getOwner", "getGroup" ],
  "org.apache.hadoop.fs.ContentSummary:<init>(org.apache.hadoop.fs.ContentSummary$Builder)" : [ "<init>" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler$MetricsProxy:getInstance(java.lang.String,int,org.apache.hadoop.ipc.DecayRpcScheduler)" : [ "<init>", "setDelegate" ],
  "org.apache.hadoop.util.CrcComposer:newStripedCrcComposer(org.apache.hadoop.util.DataChecksum$Type,long,long)" : [ "<init>", "getCrcPolynomialForType", "getMonomial" ],
  "org.apache.hadoop.io.retry.RetryInvocationHandler:close()" : [ "close" ],
  "org.apache.hadoop.fs.CreateFlag:validate(java.lang.Object,boolean,java.util.EnumSet)" : [ "<init>", "validate" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory:createProvider(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>", "toString", "createProviders" ],
  "org.apache.hadoop.fs.shell.Command:getDescription()" : [ "isDeprecated", "getReplacementCommand", "getCommandField" ],
  "org.apache.hadoop.fs.FSOutputSummer:resetChecksumBufSize()" : [ "setChecksumBufSize", "getBytesPerChecksum" ],
  "org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool:get(java.nio.channels.SelectableChannel)" : [ "trimIdleSelectors", "now" ],
  "org.apache.hadoop.conf.Configuration:addDeprecations(org.apache.hadoop.conf.Configuration$DeprecationDelta[])" : [ "<init>" ],
  "org.apache.hadoop.util.Timer:monotonicNowNanos()" : [ "monotonicNowNanos" ],
  "org.apache.hadoop.fs.FileSystem:createFile(org.apache.hadoop.fs.Path)" : [ "createDataOutputStreamBuilder", "create", "overwrite" ],
  "org.apache.hadoop.net.NetworkTopology:interRemoveNodeWithEmptyRack(org.apache.hadoop.net.Node)" : [ "getNode", "countEmptyRacks" ],
  "org.apache.hadoop.fs.FilterFileSystem:access(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsAction)" : [ "access" ],
  "org.apache.hadoop.io.retry.AsyncCallHandler$AsyncCallQueue:addCall(org.apache.hadoop.io.retry.AsyncCallHandler$AsyncCall)" : [ "offer", "tryStart" ],
  "org.apache.hadoop.io.wrappedio.WrappedStatistics:iostatisticsSnapshot_aggregate(java.io.Serializable,java.lang.Object)" : [ "requireIOStatisticsSnapshot", "checkArgument", "applyToIOStatisticsSnapshot" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider:tryLoadFromPath(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "<init>", "loadFromPath", "isBadorWrongPassword", "renameOrFail", "toString" ],
  "org.apache.hadoop.ipc.Server:logException(org.slf4j.Logger,java.lang.Throwable,org.apache.hadoop.ipc.Server$Call)" : [ "isSuppressedLog", "isTerseLog" ],
  "org.apache.hadoop.fs.UnionStorageStatistics:<init>(java.lang.String,org.apache.hadoop.fs.StorageStatistics[])" : [ "<init>", "checkArgument" ],
  "org.apache.hadoop.util.dynamic.DynConstructors$Builder:impl(java.lang.String,java.lang.Class[])" : [ "impl" ],
  "org.apache.hadoop.fs.QuotaUsage:isTypeQuotaSet()" : [ "getTypesSupportingQuota" ],
  "org.apache.hadoop.conf.Configuration:appendXMLProperty(org.w3c.dom.Document,org.w3c.dom.Element,java.lang.String,org.apache.hadoop.conf.ConfigRedactor)" : [ "redactXml" ],
  "org.apache.hadoop.io.compress.DecompressorStream:read(byte[],int,int)" : [ "checkStream", "decompress" ],
  "org.apache.hadoop.security.ssl.DelegatingSSLSocketFactory:createSocket(java.net.InetAddress,int,java.net.InetAddress,int)" : [ "configureSocket" ],
  "org.apache.hadoop.util.Shell:checkWindowsCommandLineLength(java.lang.String[])" : [ "join" ],
  "org.apache.hadoop.fs.shell.FsUsage$TableBuilder:printToStream(java.io.PrintStream)" : [ "isEmpty" ],
  "org.apache.hadoop.io.SequenceFile$Sorter:sort(org.apache.hadoop.fs.Path[],org.apache.hadoop.fs.Path,boolean)" : [ "exists", "sortPass", "mergePass", "getParent" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter:initializeAuthHandler(java.lang.String,javax.servlet.FilterConfig)" : [ "setCurator" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider$KMSTokenRenewer:createKeyProvider(org.apache.hadoop.security.token.Token,org.apache.hadoop.conf.Configuration)" : [ "getService", "toString", "getKeyProviderUri", "createKeyProviderFromUri" ],
  "org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider:noPasswordError()" : [ "noPasswordError" ],
  "org.apache.hadoop.fs.FileSystem:getPathHandle(org.apache.hadoop.fs.FileStatus,org.apache.hadoop.fs.Options$HandleOpt[])" : [ "createPathHandle", "path" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState:<init>(org.apache.hadoop.io.file.tfile.Compression$Algorithm,org.apache.hadoop.fs.FSDataInputStream,org.apache.hadoop.io.file.tfile.BCFile$BlockRegion,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getDecompressor", "getOffset", "getCompressedSize", "getFSInputBufferSize", "returnDecompressor" ],
  "org.apache.hadoop.io.ElasticByteBufferPool$Key:equals(java.lang.Object)" : [ "compareTo" ],
  "org.apache.hadoop.util.curator.ZKCuratorManager$HadoopZookeeperFactory:newZooKeeper(java.lang.String,int,org.apache.zookeeper.Watcher,boolean,org.apache.zookeeper.client.ZKClientConfig)" : [ "isJaasConfigurationSet", "setJaasConfiguration", "setSslConfiguration" ],
  "org.apache.hadoop.util.Progress:complete()" : [ "startNextPhase" ],
  "org.apache.hadoop.conf.StorageUnit$3:getDefault(double)" : [ "toTBs" ],
  "org.apache.hadoop.fs.HarFileSystem:getServerDefaults(org.apache.hadoop.fs.Path)" : [ "getServerDefaults" ],
  "org.apache.hadoop.io.file.tfile.BCFile$MetaIndex:write(java.io.DataOutput)" : [ "write", "writeVInt" ],
  "org.apache.hadoop.util.CrcComposer:update(byte[],int,int,long)" : [ "update", "readInt" ],
  "org.apache.hadoop.fs.store.DataBlocks$ByteBufferBlockFactory$ByteBufferBlock:toString()" : [ "dataSize", "remainingCapacity" ],
  "org.apache.hadoop.fs.viewfs.RegexMountPoint:getRemainingPathStr(java.lang.String,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.util.SysInfoLinux:getVirtualMemorySize()" : [ "getPhysicalMemorySize" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenManager:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.io.Text)" : [ "<init>", "getBoolean" ],
  "org.apache.hadoop.fs.impl.prefetch.SingleFilePerBlockCache:deleteBlockFileAndEvictCache(org.apache.hadoop.fs.impl.prefetch.SingleFilePerBlockCache$Entry)" : [ "trackDuration" ],
  "org.apache.hadoop.fs.FilterFileSystem:getServerDefaults(org.apache.hadoop.fs.Path)" : [ "getServerDefaults" ],
  "org.apache.hadoop.io.compress.CompressionCodec$Util:createInputStreamWithCodecPool(org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.conf.Configuration,java.io.InputStream)" : [ "getDecompressor", "returnDecompressor", "setTrackedDecompressor" ],
  "org.apache.hadoop.util.InstrumentedReadLock:<init>(java.lang.String,org.slf4j.Logger,java.util.concurrent.locks.ReentrantReadWriteLock,long,long,org.apache.hadoop.util.Timer)" : [ "<init>" ],
  "org.apache.hadoop.fs.ChecksumFileSystem$FSDataBoundedInputStream:getFileLength()" : [ "getContentSummary", "getLength" ],
  "org.apache.hadoop.metrics2.lib.MutableCounterInt:incr()" : [ "incr" ],
  "org.apache.hadoop.service.AbstractService:unregisterGlobalListener(org.apache.hadoop.service.ServiceStateChangeListener)" : [ "remove" ],
  "org.apache.hadoop.util.ExitUtil:halt(int)" : [ "halt" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:startupShutdownMessage(java.lang.String,java.util.List)" : [ "getHostname", "createStartupShutdownMessage" ],
  "org.apache.hadoop.ipc.ClientId:toString(byte[])" : [ "checkArgument", "getMsb", "getLsb" ],
  "org.apache.hadoop.fs.QuotaUsage:toString(boolean,boolean,java.util.List)" : [ "getTypesQuotaUsage", "getQuotaUsage" ],
  "org.apache.hadoop.io.BloomMapFile:delete(org.apache.hadoop.fs.FileSystem,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.Count:getAndCheckStorageTypes(java.lang.String)" : [ "getTypesSupportingQuota", "parseStorageType" ],
  "org.apache.hadoop.fs.FileSystem:getAdditionalTokenIssuers()" : [ "getChildFileSystems" ],
  "org.apache.hadoop.fs.impl.prefetch.SingleFilePerBlockCache:addToLinkedListAndEvictIfRequired(org.apache.hadoop.fs.impl.prefetch.SingleFilePerBlockCache$Entry)" : [ "addToHeadOfLinkedList", "deleteBlockFileAndEvictCache" ],
  "org.apache.hadoop.metrics2.impl.MetricsSinkAdapter:<init>(java.lang.String,java.lang.String,org.apache.hadoop.metrics2.MetricsSink,java.lang.String,org.apache.hadoop.metrics2.MetricsFilter,org.apache.hadoop.metrics2.MetricsFilter,org.apache.hadoop.metrics2.MetricsFilter,int,int,int,float,int)" : [ "<init>", "checkNotNull", "checkArg", "newRate", "newCounter", "newGauge" ],
  "org.apache.hadoop.util.LightWeightGSet$SetIterator:remove()" : [ "remove", "ensureNext" ],
  "org.apache.hadoop.metrics2.lib.DefaultMetricsFactory:getAnnotatedMetricsFactory()" : [ "getInstance" ],
  "org.apache.hadoop.util.Shell:checkHadoopHome()" : [ "checkHadoopHomeInner" ],
  "org.apache.hadoop.ipc.WritableRpcEngine:getClient(org.apache.hadoop.conf.Configuration)" : [ "getClient" ],
  "org.apache.hadoop.fs.FileContext:getAclStatus(org.apache.hadoop.fs.Path)" : [ "fixRelativePart" ],
  "org.apache.hadoop.ipc.RPC:getServerAddress(java.lang.Object)" : [ "getConnectionIdForProxy", "getAddress" ],
  "org.apache.hadoop.fs.shell.FsUsage$Du:processOptions(java.util.LinkedList)" : [ "<init>", "parse", "setHumanReadable", "getOpt" ],
  "org.apache.hadoop.metrics2.lib.MutableStat:add(long)" : [ "add" ],
  "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker:available()" : [ "available" ],
  "org.apache.hadoop.security.Credentials:writeProtobufOutputStream(java.io.DataOutputStream)" : [ "writeProto" ],
  "org.apache.hadoop.conf.Configuration:<init>(boolean)" : [ "getClassLoader" ],
  "org.apache.hadoop.security.LdapGroupsMapping:getPassword(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String)" : [ "getPassword" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner$Entry:getValue(org.apache.hadoop.io.BytesWritable)" : [ "getValueStream", "getRemain", "setSize", "getBytes", "getLength" ],
  "org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider:<init>(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "initFileSystem", "locateKeystore" ],
  "org.apache.hadoop.metrics2.lib.MethodMetric:<init>(java.lang.Object,java.lang.reflect.Method,org.apache.hadoop.metrics2.MetricsInfo,org.apache.hadoop.metrics2.annotation.Metric$Type)" : [ "checkNotNull", "checkArg", "newImpl" ],
  "org.apache.hadoop.conf.Configuration:setClass(java.lang.String,java.lang.Class,java.lang.Class)" : [ "set" ],
  "org.apache.hadoop.fs.GetSpaceUsed$Builder:getKlass()" : [ "getClass" ],
  "org.apache.hadoop.fs.FileSystem:closeAll()" : [ "closeAll", "debugLogFileSystemClose" ],
  "org.apache.hadoop.ipc.Server:refreshServiceAcl(org.apache.hadoop.conf.Configuration,org.apache.hadoop.security.authorize.PolicyProvider)" : [ "refresh" ],
  "org.apache.hadoop.net.unix.DomainSocket:sendFileDescriptors(java.io.FileDescriptor[],byte[],int,int)" : [ "reference", "unreference" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:isIOStatisticsSource(java.lang.Object)" : [ "ioStatisticsAvailable", "invoke" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$DelegationTokenSecretManagerMetrics:trackUpdateToken(org.apache.hadoop.util.functional.InvocationRaisingIOE)" : [ "trackInvocation" ],
  "org.apache.hadoop.security.UserGroupInformation$KeytabRenewalRunnable:relogin()" : [ "reloginFromKeytab" ],
  "org.apache.hadoop.fs.DUHelper:calculateFolderSize(java.lang.String)" : [ "getFileSize" ],
  "org.apache.hadoop.fs.FSBuilder:opt(java.lang.String,int)" : [ "optLong" ],
  "org.apache.hadoop.fs.store.audit.HttpReferrerAuditHeader:set(java.lang.String,java.lang.String)" : [ "addAttribute" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:getWorkingDirectory(com.jcraft.jsch.ChannelSftp)" : [ "getHomeDirectory" ],
  "org.apache.hadoop.io.SequenceFile$Reader:seekToCurrentValue()" : [ "readBuffer", "readVInt" ],
  "org.apache.hadoop.fs.FileUtil:getJarsInDirectory(java.lang.String,boolean)" : [ "<init>", "suffix", "getLocalFSFileContext", "getFileContext", "toUri", "util", "globStatus", "getPath" ],
  "org.apache.hadoop.fs.FileSystem:close()" : [ "debugLogFileSystemClose", "processDeleteOnExit", "remove" ],
  "org.apache.hadoop.ha.ZKFailoverController:initRPC()" : [ "<init>" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding:pairedTrackerFactory(org.apache.hadoop.fs.statistics.DurationTrackerFactory,org.apache.hadoop.fs.statistics.DurationTrackerFactory)" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.KeyProviderCryptoExtension$DefaultCryptoExtension:reencryptEncryptedKey(org.apache.hadoop.crypto.key.KeyProviderCryptoExtension$EncryptedKeyVersion)" : [ "getEncryptionKeyName", "getCurrentKey", "checkNotNull", "checkArgument", "getEncryptedKeyVersion", "getVersionName", "equals", "decryptEncryptedKey", "getInstance", "getConf", "generateEncryptedKey", "getMaterial", "getEncryptedKeyIv" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:decayCurrentCosts()" : [ "isServiceUser", "recomputeScheduleCache", "updateAverageResponseTime" ],
  "org.apache.hadoop.util.concurrent.AsyncGetFuture:get(long,java.util.concurrent.TimeUnit)" : [ "callAsyncGet" ],
  "org.apache.hadoop.fs.ContentSummary:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.FileUtil:symLink(java.lang.String,java.lang.String)" : [ "<init>", "getPathWithoutSchemeAndAuthority", "toString", "getSymlinkCommand", "isAbsolute", "execute", "getExitCode", "join", "stringifyException" ],
  "org.apache.hadoop.io.MapFile$Reader:<init>(org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.io.WritableComparator,org.apache.hadoop.conf.Configuration)" : [ "<init>", "comparator" ],
  "org.apache.hadoop.security.UserGroupInformation$HadoopConfiguration:getKerberosEntry()" : [ "prependFileAuthority" ],
  "org.apache.hadoop.net.DNS:getDefaultHost(java.lang.String,java.lang.String,boolean)" : [ "getHosts" ],
  "org.apache.hadoop.fs.FsShell:close()" : [ "close" ],
  "org.apache.hadoop.fs.statistics.impl.EmptyIOStatisticsContextImpl:snapshot()" : [ "<init>" ],
  "org.apache.hadoop.fs.ChecksumFs$ChecksumFSInputChecker:<init>(org.apache.hadoop.fs.ChecksumFs,org.apache.hadoop.fs.Path)" : [ "<init>", "getFileBufferSize" ],
  "org.apache.hadoop.fs.FsUrlConnection:connect()" : [ "<init>", "checkState", "get", "open" ],
  "org.apache.hadoop.security.UserGroupInformation:logAllUserInfo(org.slf4j.Logger,org.apache.hadoop.security.UserGroupInformation)" : [ "logUserInfo", "getCurrentUser", "getRealUser", "getLoginUser" ],
  "org.apache.hadoop.security.ShellBasedUnixGroupsMapping:createGroupIDExecutor(java.lang.String)" : [ "<init>", "getGroupsIDForUserCommand" ],
  "org.apache.hadoop.net.InnerNodeImpl:getLeaf(int,org.apache.hadoop.net.Node)" : [ "getNumOfLeaves", "isLeafParent", "getNumOfChildren", "isAncestor" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyStatus:hashCode()" : [ "hashCode" ],
  "org.apache.hadoop.security.Credentials:readTokenStorageStream(java.io.DataInputStream)" : [ "valueOf", "readFields", "readProto" ],
  "org.apache.hadoop.util.hash.Hash:getInstance(int)" : [ "getInstance" ],
  "org.apache.hadoop.io.serializer.DeserializerComparator:compare(byte[],int,int,byte[],int,int)" : [ "reset" ],
  "org.apache.hadoop.metrics2.lib.MutableCounter:<init>(org.apache.hadoop.metrics2.MetricsInfo)" : [ "checkNotNull" ],
  "org.apache.hadoop.fs.Path:suffix(java.lang.String)" : [ "<init>", "getParent", "getName" ],
  "org.apache.hadoop.util.ProgramDriver:addClass(java.lang.String,java.lang.Class,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.http.HttpsFileSystem:hasPathCapability(org.apache.hadoop.fs.Path,java.lang.String)" : [ "hasPathCapability" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedIO:isAvailable()" : [ "instance", "loaded" ],
  "org.apache.hadoop.util.Shell:getGroupsIDForUserCommand(java.lang.String)" : [ "getWinUtilsPath", "bashQuote" ],
  "org.apache.hadoop.util.BasicDiskValidator:checkStatus(java.io.File)" : [ "checkDir" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler$DecayTask:<init>(org.apache.hadoop.ipc.DecayRpcScheduler,java.util.Timer)" : [ "run" ],
  "org.apache.hadoop.conf.Configuration:getTrimmedStrings(java.lang.String,java.lang.String[])" : [ "getTrimmedStrings", "get" ],
  "org.apache.hadoop.fs.FileSystem$Cache:<init>(org.apache.hadoop.conf.Configuration)" : [ "getInt", "checkArgument" ],
  "org.apache.hadoop.io.compress.CompressorStream:<init>(java.io.OutputStream,org.apache.hadoop.io.compress.Compressor)" : [ "<init>" ],
  "org.apache.hadoop.security.UserGroupInformation:isLoginTicketBased()" : [ "getLoginUser", "isFromTicket" ],
  "org.apache.hadoop.ipc.CallerContext$Builder:append(java.lang.String)" : [ "isValid" ],
  "org.apache.hadoop.ipc.Client$IpcStreams:close()" : [ "closeStream" ],
  "org.apache.hadoop.security.UserGroupInformation$RealUser:hashCode()" : [ "hashCode" ],
  "org.apache.hadoop.conf.Configuration:substituteCommonVariables(java.lang.String)" : [ "substituteVars" ],
  "org.apache.hadoop.util.DataChecksum:newCrc32C()" : [ "<init>", "createChecksum" ],
  "org.apache.hadoop.fs.FileStatus:isDir()" : [ "isDirectory" ],
  "org.apache.hadoop.io.serializer.JavaSerializationComparator:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ConfigUtil:addLinkNfly(org.apache.hadoop.conf.Configuration,java.lang.String,java.net.URI[])" : [ "addLinkNfly", "getDefaultMountTableName" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationHandler:init(java.util.Properties)" : [ "initTokenManager", "initJsonFactory" ],
  "org.apache.hadoop.security.ShellBasedUnixGroupsMapping:getGroups(java.lang.String)" : [ "getUnixGroups" ],
  "org.apache.hadoop.io.erasurecode.grouper.BlockGrouper:getRequiredNumParityBlocks()" : [ "getNumParityUnits" ],
  "org.apache.hadoop.metrics2.impl.MetricsConfig:<init>(org.apache.commons.configuration2.Configuration,java.lang.String)" : [ "toLowerCase" ],
  "org.apache.hadoop.util.KMSUtil:checkNotEmpty(java.lang.String,java.lang.String)" : [ "checkNotNull" ],
  "org.apache.hadoop.util.DiskChecker:mkdirsWithExistsAndPermissionCheck(org.apache.hadoop.fs.LocalFileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "pathToFile", "mkdirsWithExistsCheck", "getPermission", "equals" ],
  "org.apache.hadoop.ipc.Server:getListenerAddress()" : [ "getAddress" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider:flush()" : [ "<init>", "constructNewPath", "constructOldPath", "renameOrFail", "toString", "backupToOld", "writeToNew", "revertFromOld", "cleanupNewAndOld", "resetKeyStoreState" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider:createKey(java.lang.String,byte[],org.apache.hadoop.crypto.key.KeyProvider$Options)" : [ "<init>", "checkArgument", "toLowerCase", "getCipher", "getBitLength", "getDescription", "getAttributes", "innerSetKeyVersion" ],
  "org.apache.hadoop.fs.FileSystem:initialize(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "getDefaultUri", "getStatistics", "getBoolean" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Writer:prepareMetaBlock(java.lang.String,org.apache.hadoop.io.file.tfile.Compression$Algorithm)" : [ "<init>", "getMetaByName" ],
  "org.apache.hadoop.fs.viewfs.RegexMountPoint:getPathToResolve(java.lang.String,boolean)" : [ "toString" ],
  "org.apache.hadoop.fs.MD5MD5CRC32FileChecksum:readFields(java.io.DataInput)" : [ "read" ],
  "org.apache.hadoop.io.compress.DecompressorStream:decompress(byte[],int,int)" : [ "getCompressedData" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreImpl:setCounter(java.lang.String,long)" : [ "setAtomicLong" ],
  "org.apache.hadoop.io.ArrayPrimitiveWritable:<init>(java.lang.Object)" : [ "set" ],
  "org.apache.hadoop.fs.impl.DefaultBulkDeleteOperation:bulkDelete(java.util.Collection)" : [ "validateBulkDeletePaths", "pair" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:deleteKey(java.lang.String)" : [ "checkNotEmpty", "createURL", "createConnection", "call" ],
  "org.apache.hadoop.util.LineReader:<init>(java.io.InputStream)" : [ "<init>" ],
  "org.apache.hadoop.util.bloom.DynamicBloomFilter:addRow()" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:removeAclEntries(org.apache.hadoop.fs.Path,java.util.List)" : [ "removeAclEntries", "fullPath" ],
  "org.apache.hadoop.security.token.delegation.SQLDelegationTokenSecretManager:getDelegationKey(int)" : [ "<init>", "getDelegationKey", "readFields" ],
  "org.apache.hadoop.util.DataChecksum:calculateChunkedSums(java.nio.ByteBuffer,java.nio.ByteBuffer)" : [ "calculateChunkedSums", "isAvailable" ],
  "org.apache.hadoop.fs.FSBuilder:opt(java.lang.String,long)" : [ "optLong" ],
  "org.apache.hadoop.fs.statistics.impl.StatisticDurationTracker:close()" : [ "incrementCounter" ],
  "org.apache.hadoop.http.HttpServer2$Builder:getPasswordString(org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "getPassword" ],
  "org.apache.hadoop.net.SocketIOWithTimeout:<init>(java.nio.channels.SelectableChannel,long)" : [ "checkChannelValidity" ],
  "org.apache.hadoop.util.bloom.Filter:readFields(java.io.DataInput)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.zstd.ZStandardDecompressor:decompress(byte[],int,int)" : [ "checkStream", "populateUncompressedBuffer" ],
  "org.apache.hadoop.io.file.tfile.Utils:writeString(java.io.DataOutput,java.lang.String)" : [ "<init>", "getBytes", "getLength", "writeVInt" ],
  "org.apache.hadoop.util.CrcUtil:toSingleCrcString(byte[])" : [ "readInt" ],
  "org.apache.hadoop.io.compress.BZip2Codec$BZip2CompressionInputStream:read()" : [ "read" ],
  "org.apache.hadoop.fs.shell.find.Find:getOptions()" : [ "createOptions" ],
  "org.apache.hadoop.io.compress.BZip2Codec:createInputStream(java.io.InputStream,org.apache.hadoop.io.compress.Decompressor,long,long,org.apache.hadoop.io.compress.SplittableCompressionCodec$READ_MODE)" : [ "<init>" ],
  "org.apache.hadoop.fs.ChecksumFs$ChecksumFSOutputSummer:close()" : [ "close" ],
  "org.apache.hadoop.util.functional.RemoteIterators$CloseRemoteIterator:close()" : [ "close" ],
  "org.apache.hadoop.conf.Configuration:setIfUnset(java.lang.String,java.lang.String)" : [ "get", "set" ],
  "org.apache.hadoop.util.DiskValidatorFactory:getInstance(java.lang.String)" : [ "<init>", "getInstance" ],
  "org.apache.hadoop.util.FindClass:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.util.functional.LazyAtomicReference:lazyAtomicReferenceFromSupplier(java.util.function.Supplier)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.impl.MetricsCollectorImpl:addRecord(java.lang.String)" : [ "addRecord", "info" ],
  "org.apache.hadoop.io.erasurecode.codec.RSErasureCodec:createDecoder()" : [ "<init>" ],
  "org.apache.hadoop.fs.PartialListing:<init>(org.apache.hadoop.fs.Path,java.util.List)" : [ "<init>" ],
  "org.apache.hadoop.io.file.tfile.Chunk$ChunkEncoder:write(byte[])" : [ "write" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:delete(org.apache.commons.net.ftp.FTPClient,org.apache.hadoop.fs.Path,boolean)" : [ "<init>", "makeAbsolute", "toUri", "getPath", "getFileStatus", "isFile", "listStatus" ],
  "org.apache.hadoop.http.ProfilerDisabledServlet:doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)" : [ "setResponseHeader" ],
  "org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream:read()" : [ "<init>", "incrementBytesRead", "incrementCounter" ],
  "org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReference:cleanUp()" : [ "add" ],
  "org.apache.hadoop.ipc.Server$Call:doResponse(java.lang.Throwable)" : [ "doResponse" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:mkdirs(org.apache.commons.net.ftp.FTPClient,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "<init>", "makeAbsolute", "getName", "exists", "getParent", "getDirDefault", "toUri", "isFile" ],
  "org.apache.hadoop.fs.viewfs.ViewFsFileStatus:getPermission()" : [ "getPermission" ],
  "org.apache.hadoop.io.WritableUtils:readCompressedStringArray(java.io.DataInput)" : [ "readCompressedString" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:getFileStatus(org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.service.launcher.ServiceLaunchException:<init>(int,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.lib.MutableQuantiles$RolloverSample:<init>(org.apache.hadoop.metrics2.lib.MutableQuantiles)" : [ "run" ],
  "org.apache.hadoop.util.ExitUtil:terminate(int)" : [ "terminate" ],
  "org.apache.hadoop.metrics2.util.SampleStat:stddev()" : [ "variance" ],
  "org.apache.hadoop.net.AbstractDNSToSwitchMapping:dumpTopology()" : [ "getSwitchMap" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2:getProtocolMetaInfoProxy(org.apache.hadoop.ipc.Client$ConnectionId,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Compressor:reset()" : [ "checkStream" ],
  "org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler:handle(javax.security.auth.callback.Callback[])" : [ "getIdentifier", "getPassword", "getUserName" ],
  "org.apache.hadoop.metrics2.util.MBeans:getMBeanName(java.lang.String,java.lang.String,java.util.Map)" : [ "newMBeanName" ],
  "org.apache.hadoop.fs.FileContext:deleteSnapshot(org.apache.hadoop.fs.Path,java.lang.String)" : [ "fixRelativePart" ],
  "org.apache.hadoop.fs.viewfs.RegexMountPointResolvedDstPathReplaceInterceptor:serializeToString()" : [ "getConfigName" ],
  "org.apache.hadoop.util.Shell:getQualifiedBinInner(java.io.File,java.lang.String)" : [ "addOsText", "fileNotFoundException" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL:renewDelegationToken(java.net.URL,org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL$Token,java.lang.String)" : [ "checkNotNull" ],
  "org.apache.hadoop.fs.impl.MultipartUploaderBuilderImpl:<init>(org.apache.hadoop.fs.FileContext,org.apache.hadoop.fs.Path)" : [ "<init>", "checkNotNull", "getServerDefaults", "getFileBufferSize", "getReplication", "getBlockSize" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyOutputStream:mayThrow(java.util.List)" : [ "createIOException" ],
  "org.apache.hadoop.io.MapFile$Writer:valueClass(java.lang.Class)" : [ "valueClass" ],
  "org.apache.hadoop.util.JvmPauseMonitor$Monitor:run()" : [ "<init>", "reset", "start", "now" ],
  "org.apache.hadoop.fs.Globber:createGlobber(org.apache.hadoop.fs.FileContext)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.Command:processPaths(org.apache.hadoop.fs.shell.PathData,org.apache.hadoop.fs.RemoteIterator)" : [ "processPaths", "getListingGroupSize", "cleanupRemoteIterator" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyStatus:getModificationTime()" : [ "getModificationTime" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.AbstractNativeRawEncoder:<init>(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.Truncate:processArguments(java.util.LinkedList)" : [ "waitForRecovery" ],
  "org.apache.hadoop.ipc.Server:setupResponse(org.apache.hadoop.ipc.Server$RpcCall,org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto,org.apache.hadoop.io.Writable)" : [ "setupResponseForProtobuf", "setupResponseForWritable", "toString", "setResponse" ],
  "org.apache.hadoop.metrics2.sink.RollingFileSystemSink:stringifySecurityProperty(java.lang.String)" : [ "get" ],
  "org.apache.hadoop.io.SequenceFile$CompressedBytes:writeUncompressedBytes(java.io.DataOutputStream)" : [ "<init>", "reset" ],
  "org.apache.hadoop.fs.FileSystem:listStatus(java.util.ArrayList,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.PathFilter)" : [ "checkNotNull", "getPath" ],
  "org.apache.hadoop.fs.shell.CommandWithDestination:processPath(org.apache.hadoop.fs.shell.PathData,org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "isSymlink", "toString", "isFile", "copyFileToTarget", "isDirectory" ],
  "org.apache.hadoop.util.SemaphoredDelegatingExecutor:submit(java.lang.Runnable)" : [ "trackDuration" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:setOwner(org.apache.hadoop.fs.Path,java.lang.String,java.lang.String)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:setPermission(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "setPermission", "fullPath" ],
  "org.apache.hadoop.util.IntrusiveCollection:toArray(java.lang.Object[])" : [ "toArray", "iterator" ],
  "org.apache.hadoop.io.compress.ZStandardCodec:createInputStream(java.io.InputStream,org.apache.hadoop.io.compress.Decompressor)" : [ "<init>", "checkNativeCodeLoaded", "getDecompressionBufferSize" ],
  "org.apache.hadoop.io.erasurecode.coder.ErasureEncodingStep:performCoding(org.apache.hadoop.io.erasurecode.ECChunk[],org.apache.hadoop.io.erasurecode.ECChunk[])" : [ "encode" ],
  "org.apache.hadoop.service.launcher.HadoopUncaughtExceptionHandler:<init>()" : [ "<init>" ],
  "org.apache.hadoop.security.token.DtUtilShell$Edit:execute()" : [ "aliasTokenFile" ],
  "org.apache.hadoop.metrics2.sink.GraphiteSink:putMetrics(org.apache.hadoop.metrics2.MetricsRecord)" : [ "<init>", "name", "value", "write", "close" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:incrAuthorizationFailures()" : [ "incr" ],
  "org.apache.hadoop.io.nativeio.NativeIO$POSIX:getStat(java.lang.String)" : [ "<init>", "getName", "getErrorCode" ],
  "org.apache.hadoop.conf.Configuration$IntegerRanges:iterator()" : [ "<init>" ],
  "org.apache.hadoop.io.ArrayPrimitiveWritable:checkArray(java.lang.Object)" : [ "<init>" ],
  "org.apache.hadoop.security.authorize.AccessControlList:getGroupsString()" : [ "getString" ],
  "org.apache.hadoop.io.wrappedio.WrappedStatistics:iostatistics_toPrettyString(java.lang.Object)" : [ "ioStatisticsToPrettyString" ],
  "org.apache.hadoop.net.unix.DomainSocket:shutdown()" : [ "reference", "unreference" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:createSymlink(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,boolean)" : [ "createSymlink", "readOnlyMountTable" ],
  "org.apache.hadoop.fs.FilterFs:getXAttr(org.apache.hadoop.fs.Path,java.lang.String)" : [ "getXAttr" ],
  "org.apache.hadoop.util.DataChecksum:verifyChunked(org.apache.hadoop.util.DataChecksum$Type,java.util.zip.Checksum,byte[],int,int,int,byte[],int,java.lang.String,long)" : [ "throwChecksumException" ],
  "org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream:write(byte[],int,int)" : [ "<init>", "incrementCounter" ],
  "org.apache.hadoop.conf.Configuration:getTrimmedStringCollection(java.lang.String)" : [ "getTrimmedStringCollection", "get" ],
  "org.apache.hadoop.util.Shell$ShellTimeoutTimerTask:run()" : [ "getProcess" ],
  "org.apache.hadoop.ipc.Client$Connection$RpcRequestSender:run()" : [ "sendRequest", "toByteArray", "flush", "closeStream" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:createKeyInternal(java.lang.String,byte[],org.apache.hadoop.crypto.key.KeyProvider$Options)" : [ "checkNotEmpty", "checkNotNull", "getCipher", "getBitLength", "getDescription", "getAttributes", "createURL", "createConnection", "call", "parseJSONKeyVersion" ],
  "org.apache.hadoop.io.compress.BZip2Codec$BZip2CompressionInputStream:<init>(java.io.InputStream)" : [ "<init>" ],
  "org.apache.hadoop.io.UTF8:set(java.lang.String)" : [ "utf8Length", "reset", "writeChars", "getData" ],
  "org.apache.hadoop.fs.FSLinkResolver:resolve(org.apache.hadoop.fs.FileContext,org.apache.hadoop.fs.Path)" : [ "getFSofPath", "areSymlinksEnabled", "qualifySymlinkTarget", "getUri", "getLinkTarget" ],
  "org.apache.hadoop.security.token.DtFileOperations:matchService(org.apache.hadoop.security.token.DtFetcher,org.apache.hadoop.io.Text,java.lang.String)" : [ "toString", "equals" ],
  "org.apache.hadoop.util.SysInfo:newInstance()" : [ "<init>" ],
  "org.apache.hadoop.io.nativeio.NativeIO$POSIX:assertCodeLoaded()" : [ "isAvailable" ],
  "org.apache.hadoop.fs.FileStatus:isFile()" : [ "isDirectory", "isSymlink" ],
  "org.apache.hadoop.tools.GetGroupsBase:run(java.lang.String[])" : [ "getCurrentUser", "getUserName", "getUgmProtocol" ],
  "org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext:getLocalPathToRead(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "<init>", "confChanged", "exists" ],
  "org.apache.hadoop.ipc.Server:isServerFailOverEnabled()" : [ "isServerFailOverEnabled" ],
  "org.apache.hadoop.io.SequenceFile$Writer:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class,org.apache.hadoop.util.Progressable,org.apache.hadoop.io.SequenceFile$Metadata)" : [ "<init>", "init", "create", "now" ],
  "org.apache.hadoop.fs.http.HttpsFileSystem:setWorkingDirectory(org.apache.hadoop.fs.Path)" : [ "setWorkingDirectory" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockData:isLastBlock(int)" : [ "throwIfInvalidBlockNumber" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedIO:fileSystem_openFile_available()" : [ "available" ],
  "org.apache.hadoop.security.KDiag:error(java.lang.String,java.lang.String,java.lang.Object[])" : [ "println" ],
  "org.apache.hadoop.util.bloom.DynamicBloomFilter:or(org.apache.hadoop.util.bloom.Filter)" : [ "or" ],
  "org.apache.hadoop.io.file.tfile.BoundedRangeFileInputStream:read()" : [ "read" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:createGenericOptionsParser(org.apache.hadoop.conf.Configuration,java.lang.String[])" : [ "<init>" ],
  "org.apache.hadoop.fs.FileContext$Util:copy(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "copy" ],
  "org.apache.hadoop.ha.HAServiceTarget:getZKFCProxy(org.apache.hadoop.conf.Configuration,int)" : [ "<init>", "setInt", "getDefaultSocketFactory" ],
  "org.apache.hadoop.ipc.Server:updateMetrics(org.apache.hadoop.ipc.Server$Call,long,boolean)" : [ "monotonicNowNanos", "getProcessingDetails", "set", "get", "getMetricsTimeUnit", "addRpcEnQueueTime", "addRpcQueueTime", "isResponseDeferred", "addRpcLockWaitTime", "addRpcProcessingTime", "addRpcResponseTime", "getDetailedMetricsName", "addProcessingTime", "addOverallProcessingTime", "addResponseTime", "isLogSlowRPC", "logSlowRpcCalls", "getReturnStatus", "incrRpcCallSuccesses" ],
  "org.apache.hadoop.fs.shell.Test:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "isDirectory", "isFile", "getLen", "testAccess" ],
  "org.apache.hadoop.metrics2.lib.MutableStat:add(long,long)" : [ "add" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme:fsGetter()" : [ "<init>", "getScheme" ],
  "org.apache.hadoop.ipc.Server:getSchedulerClass(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "getClass", "setClass", "convertSchedulerClass" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:exit(int,java.lang.String)" : [ "terminate" ],
  "org.apache.hadoop.crypto.key.CachingKeyProvider:invalidateCache(java.lang.String)" : [ "invalidateCache" ],
  "org.apache.hadoop.fs.QuotaUsage:formatSize(long,boolean)" : [ "long2String" ],
  "org.apache.hadoop.io.MapFile$Writer:compression(org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec)" : [ "compression" ],
  "org.apache.hadoop.http.HtmlQuoting:main(java.lang.String[])" : [ "quoteHtmlChars", "unquoteHtmlChars" ],
  "org.apache.hadoop.security.JniBasedUnixGroupsNetgroupMappingWithFallback:<init>()" : [ "isNativeCodeLoaded" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockAppender:close()" : [ "finish", "getRawSize", "getStartPos", "getCurrentPos" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:unsetStoragePolicy(org.apache.hadoop.fs.Path)" : [ "unsetStoragePolicy" ],
  "org.apache.hadoop.ipc.RefreshResponse:successResponse()" : [ "<init>" ],
  "org.apache.hadoop.ipc.Client$Connection:cleanupCalls()" : [ "setException" ],
  "org.apache.hadoop.fs.shell.find.Name:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.BlockLocation:<init>(java.lang.String[],java.lang.String[],java.lang.String[],java.lang.String[],long,long,boolean)" : [ "<init>" ],
  "org.apache.hadoop.io.retry.RetryPolicies:failoverOnNetworkException(int)" : [ "failoverOnNetworkException" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker:<init>(java.lang.Class,org.apache.hadoop.ipc.Client$ConnectionId,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory,org.apache.hadoop.ipc.AlignmentContext)" : [ "getClient", "getProtocolName", "getProtocolVersion" ],
  "org.apache.hadoop.ha.HAAdmin:getAllServiceState()" : [ "getTargetIds", "getProxy", "getState" ],
  "org.apache.hadoop.io.retry.RetryPolicies$MultipleLinearRandomRetry:hashCode()" : [ "toString" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreImpl:trackDuration(java.lang.String,long)" : [ "<init>", "stubDurationTracker" ],
  "org.apache.hadoop.fs.RawLocalFileSystem$DeprecatedRawLocalFileStatus:write(java.io.DataOutput)" : [ "write", "isPermissionLoaded", "loadPermissionInfo" ],
  "org.apache.hadoop.conf.ReconfigurableBase$ReconfigurationThread:run()" : [ "<init>", "getChangedProperties", "redact", "isPropertyReconfigurable", "set", "unset", "now" ],
  "org.apache.hadoop.fs.impl.FutureDataInputStreamBuilderImpl:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.PathHandle)" : [ "<init>", "initFromFS" ],
  "org.apache.hadoop.fs.HarFileSystem:getDefaultBlockSize(org.apache.hadoop.fs.Path)" : [ "getDefaultBlockSize" ],
  "org.apache.hadoop.security.SecurityUtil:setAuthenticationMethod(org.apache.hadoop.security.UserGroupInformation$AuthenticationMethod,org.apache.hadoop.conf.Configuration)" : [ "set", "toLowerCase" ],
  "org.apache.hadoop.fs.impl.prefetch.BoundedResourcePool:release(java.lang.Object)" : [ "checkNotNull" ],
  "org.apache.hadoop.security.KDiag$KerberosDiagsFailure:<init>(java.lang.String,java.lang.Throwable,java.lang.String,java.lang.Object[])" : [ "<init>" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Reader:getMetaBlock(java.lang.String)" : [ "<init>", "getMetaByName", "getRegion", "createReader", "getCompressionAlgorithm" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:getXAttr(org.apache.hadoop.fs.Path,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.CommandFormat$TooManyArgumentsException:getMessage()" : [ "getMessage" ],
  "org.apache.hadoop.net.unix.DomainSocket$DomainChannel:close()" : [ "close" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:serviceCreationFailure(java.lang.Exception)" : [ "<init>" ],
  "org.apache.hadoop.util.ShutdownThreadsHelper:shutdownExecutorService(java.util.concurrent.ExecutorService)" : [ "shutdownExecutorService" ],
  "org.apache.hadoop.fs.shell.PathData:checkIfExists(org.apache.hadoop.fs.shell.PathData$FileTypeRequirement)" : [ "<init>", "toString", "isDirectory" ],
  "org.apache.hadoop.security.authorize.DefaultImpersonationProvider:authorize(org.apache.hadoop.security.UserGroupInformation,java.net.InetAddress)" : [ "<init>", "getRealUser", "getShortUserName", "isUserAllowed", "getUserName", "getProxySuperuserIpConfKey", "includes" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:createInternal(org.apache.hadoop.fs.Path,java.util.EnumSet,org.apache.hadoop.fs.permission.FsPermission,int,short,long,org.apache.hadoop.util.Progressable,org.apache.hadoop.fs.Options$ChecksumOpt,boolean)" : [ "<init>", "checkNotNull", "equals", "getRootFallbackLink", "getChildren", "getName", "getTargetFileSystem", "getPathWithoutSchemeAndAuthority", "getUri", "readOnlyMountTable" ],
  "org.apache.hadoop.io.compress.zlib.ZlibFactory:getZlibDirectDecompressor(org.apache.hadoop.conf.Configuration)" : [ "<init>", "isNativeZlibLoaded" ],
  "org.apache.hadoop.util.bloom.RetouchedBloomFilter:<init>()" : [ "<init>" ],
  "org.apache.hadoop.service.launcher.IrqHandler:<init>(java.lang.String,org.apache.hadoop.service.launcher.IrqHandler$Interrupted)" : [ "checkArgument" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner$Entry:compareTo(byte[])" : [ "compareTo" ],
  "org.apache.hadoop.fs.viewfs.InodeTree:createLink(java.lang.String,java.lang.String,org.apache.hadoop.fs.viewfs.InodeTree$LinkType,java.lang.String,org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.conf.Configuration)" : [ "<init>", "isAbsoluteAndSchemeAuthorityNull", "breakIntoPathComponents", "checkState", "isInternalDir", "getRootDir", "resolveInternal", "addDir", "setInternalDirFs", "addDirLink", "getStrings", "stringToURI", "addLink" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:listXAttrs(org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.Command:getUsage()" : [ "getName", "isDeprecated", "getCommandField" ],
  "org.apache.hadoop.util.LightWeightGSet:remove(int,java.lang.Object)" : [ "convert" ],
  "org.apache.hadoop.fs.FileSystem$Statistics:reset()" : [ "<init>", "visitAll" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationHandler:managementOperation(org.apache.hadoop.security.authentication.server.AuthenticationToken,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)" : [ "<init>", "getParameter", "toUpperCase", "isManagementOperation", "getHttpMethod", "requiresKerberosCredentials", "createRemoteUser", "getDoAs", "createProxyUser", "authorize", "createServletExceptionResponse", "createToken", "delegationTokenToJSON", "decodeFromUrlString", "renewToken", "getShortUserName", "cancelToken" ],
  "org.apache.hadoop.ipc.CallQueueManager:isServerFailOverEnabledByQueue()" : [ "isServerFailOverEnabled" ],
  "org.apache.hadoop.net.unix.DomainSocketWatcher$NotificationHandler:handle(org.apache.hadoop.net.unix.DomainSocket)" : [ "getInputStream", "read" ],
  "org.apache.hadoop.metrics2.sink.RollingFileSystemSink:rollLogDirIfNeeded()" : [ "initFs", "findCurrentDirectory", "rollLogDir", "throwMetricsException", "updateFlushTime", "scheduleFlush" ],
  "org.apache.hadoop.io.SequenceFile$Sorter$LinkedSegmentsDescriptor:equals(java.lang.Object)" : [ "equals" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:getTag(java.lang.String)" : [ "getTag" ],
  "org.apache.hadoop.metrics2.sink.ganglia.GangliaSink30:init(org.apache.commons.configuration2.SubsetConfiguration)" : [ "init" ],
  "org.apache.hadoop.fs.HarFileSystem:getDefaultReplication()" : [ "getDefaultReplication" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:newGauge(java.lang.String,java.lang.String,int)" : [ "newGauge", "info" ],
  "org.apache.hadoop.util.Shell:getSetPermissionCommand(java.lang.String,boolean,java.lang.String)" : [ "getSetPermissionCommand" ],
  "org.apache.hadoop.fs.impl.AbstractMultipartUploader:checkPath(org.apache.hadoop.fs.Path)" : [ "checkArgument", "toString" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:doOp(org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$ProviderCallable,int,boolean)" : [ "<init>", "getKMSUrl", "getInt" ],
  "org.apache.hadoop.ipc.ProtocolMetaInfoServerSideTranslatorPB:getProtocolSignature(org.apache.hadoop.thirdparty.protobuf.RpcController,org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$GetProtocolSignatureRequestProto)" : [ "getProtocolSignature", "getProtocolVersionForRpcKind", "getMethods" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem:listLocatedStatus(org.apache.hadoop.fs.Path)" : [ "listLocatedStatus" ],
  "org.apache.hadoop.fs.HarFileSystem:hasPathCapability(org.apache.hadoop.fs.Path,java.lang.String)" : [ "validatePathCapabilityArgs" ],
  "org.apache.hadoop.fs.shell.CopyCommands$Put:processArguments(java.util.LinkedList)" : [ "processArguments", "toString" ],
  "org.apache.hadoop.ipc.Server$Connection:saslProcess(org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto)" : [ "<init>", "processSaslMessage", "incrAuthenticationFailures", "stringifyException", "getTrueCause", "toString", "getLoginUser", "isLoginSuccess", "getAuthorizedUgi", "incrAuthenticationSuccesses", "doSaslReply", "disposeSasl" ],
  "org.apache.hadoop.fs.statistics.DurationStatisticSummary:<init>(java.lang.String,boolean,long,long,long,org.apache.hadoop.fs.statistics.MeanStatistic)" : [ "clone" ],
  "org.apache.hadoop.util.OperationDuration:<init>()" : [ "time" ],
  "org.apache.hadoop.fs.FileSystem$Cache:get(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getInternal" ],
  "org.apache.hadoop.fs.FileSystem$Statistics:incrementWriteOps(int)" : [ "getThreadStatistics" ],
  "org.apache.hadoop.fs.http.HttpsFileSystem:listStatus(org.apache.hadoop.fs.Path)" : [ "listStatus" ],
  "org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem:writeStreamToFile(java.io.InputStream,org.apache.hadoop.fs.shell.PathData,boolean,boolean)" : [ "create", "copyBytes", "closeStream" ],
  "org.apache.hadoop.fs.viewfs.ViewFsFileStatus:hashCode()" : [ "hashCode" ],
  "org.apache.hadoop.fs.store.DataBlocks$DataBlock:enterState(org.apache.hadoop.fs.store.DataBlocks$DataBlock$DestState,org.apache.hadoop.fs.store.DataBlocks$DataBlock$DestState)" : [ "verifyState" ],
  "org.apache.hadoop.fs.impl.prefetch.Validate:checkNotNullAndNotEmpty(java.lang.Iterable,java.lang.String)" : [ "checkNotNull", "checkNotEmpty" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:getLastKey()" : [ "getLastKey", "checkTFileDataIndex" ],
  "org.apache.hadoop.fs.MD5MD5CRC32CastagnoliFileChecksum:<init>(int,long,org.apache.hadoop.io.MD5Hash)" : [ "<init>" ],
  "org.apache.hadoop.fs.store.DataBlocks$DiskBlock:flush()" : [ "flush" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.ByteArrayDecodingState:convertToByteBufferState()" : [ "<init>", "cloneAsDirectByteBuffer" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:addTimedOperation(java.lang.String,java.time.Duration)" : [ "getInnerStatistics" ],
  "org.apache.hadoop.fs.Path:<init>(java.lang.String,java.lang.String,java.lang.String)" : [ "checkPathArg", "hasWindowsDrive", "initialize" ],
  "org.apache.hadoop.net.NetUtils:createSocketAddrForHost(java.lang.String,int)" : [ "getStaticResolution", "getByName" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:getEntryComparator()" : [ "isSorted" ],
  "org.apache.hadoop.service.launcher.AbstractLaunchableService:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.FilterFs:getAllStoragePolicies()" : [ "getAllStoragePolicies" ],
  "org.apache.hadoop.fs.FileContext:listLocatedStatus(org.apache.hadoop.fs.Path)" : [ "fixRelativePart" ],
  "org.apache.hadoop.io.DataInputBuffer:getLength()" : [ "getLength" ],
  "org.apache.hadoop.io.file.tfile.TFileDumper$Align:format(long,int,org.apache.hadoop.io.file.tfile.TFileDumper$Align)" : [ "format" ],
  "org.apache.hadoop.metrics2.lib.MutableInverseQuantiles:<init>(java.lang.String,java.lang.String,java.lang.String,java.lang.String,int)" : [ "<init>" ],
  "org.apache.hadoop.fs.FilterFileSystem:setAcl(org.apache.hadoop.fs.Path,java.util.List)" : [ "setAcl" ],
  "org.apache.hadoop.fs.viewfs.ViewFsFileStatus:getGroup()" : [ "getGroup" ],
  "org.apache.hadoop.fs.shell.Command:expandArgument(java.lang.String)" : [ "<init>", "expandAsGlob" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationHandler:destroy()" : [ "destroy" ],
  "org.apache.hadoop.fs.impl.FlagSet:<init>(java.lang.Class,java.lang.String,java.util.EnumSet)" : [ "mapEnumNamesToValues" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider:rollNewVersion(java.lang.String,byte[])" : [ "getMetadata", "getBitLength", "addVersion", "innerSetKeyVersion", "getCipher" ],
  "org.apache.hadoop.fs.FsShellPermissions$Chmod:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "applyNewPermission", "getPermission", "toShort", "setPermission" ],
  "org.apache.hadoop.ipc.RetryCache:skipRetryCache(byte[],int)" : [ "isRpcInvocation" ],
  "org.apache.hadoop.metrics2.impl.MetricsConfig:toString(org.apache.commons.configuration2.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:initialize(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>", "initialize" ],
  "org.apache.hadoop.crypto.OpensslCipher:getInstance(java.lang.String)" : [ "getInstance" ],
  "org.apache.hadoop.io.compress.DefaultCodec:createInputStream(java.io.InputStream)" : [ "createInputStreamWithCodecPool" ],
  "org.apache.hadoop.io.erasurecode.coder.RSErasureDecoder:release()" : [ "release" ],
  "org.apache.hadoop.fs.impl.AbstractFSBuilderImpl:opt(java.lang.String,long)" : [ "optLong" ],
  "org.apache.hadoop.metrics2.MetricsJsonBuilder:addGauge(org.apache.hadoop.metrics2.MetricsInfo,int)" : [ "tuple" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Writer:<init>(org.apache.hadoop.fs.FSDataOutputStream,java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getPos", "write" ],
  "org.apache.hadoop.service.ServiceStateModel:ensureCurrentState(org.apache.hadoop.service.Service$STATE)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ConfigUtil:addLinkMergeSlash(org.apache.hadoop.conf.Configuration,java.lang.String,java.net.URI)" : [ "set", "getConfigViewFsPrefix" ],
  "org.apache.hadoop.fs.HarFileSystem:<init>(org.apache.hadoop.fs.FileSystem)" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.AbstractFSBuilderImpl:must(java.lang.String,float)" : [ "mustLong" ],
  "org.apache.hadoop.ha.HAAdmin:transitionToStandby(org.apache.commons.cli.CommandLine)" : [ "transitionToStandby", "printUsage", "checkManualStateManagementOK", "getProxy", "createReqInfo" ],
  "org.apache.hadoop.fs.viewfs.InodeTree$INodeDir:addDir(java.lang.String,org.apache.hadoop.security.UserGroupInformation)" : [ "<init>", "isRoot" ],
  "org.apache.hadoop.fs.FileUtil:copy(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path[],org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,boolean,boolean,org.apache.hadoop.conf.Configuration)" : [ "copy", "isDirectory" ],
  "org.apache.hadoop.security.token.DtUtilShell$Get:validate()" : [ "isGenericUrl" ],
  "org.apache.hadoop.fs.viewfs.ViewFsFileStatus:getAccessTime()" : [ "getAccessTime" ],
  "org.apache.hadoop.ipc.WritableRpcEngine:getProxy(java.lang.Class,long,java.net.InetSocketAddress,org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory,int,org.apache.hadoop.io.retry.RetryPolicy)" : [ "getProxy" ],
  "org.apache.hadoop.util.SequentialNumber:skipTo(long)" : [ "getCurrentValue" ],
  "org.apache.hadoop.fs.BufferedFSInputStream:skip(long)" : [ "seek", "getPos" ],
  "org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:getDelegationKey(int)" : [ "getKeyFromZK" ],
  "org.apache.hadoop.io.nativeio.NativeIO:link(java.io.File,java.io.File)" : [ "createHardLink" ],
  "org.apache.hadoop.security.http.CrossOriginFilter:initializeAllowedMethods(javax.servlet.FilterConfig)" : [ "getAllowedMethodsHeader" ],
  "org.apache.hadoop.util.XMLUtils:newSecureTransformerFactory()" : [ "setOptionalSecureTransformerAttributes" ],
  "org.apache.hadoop.fs.FSInputChecker:readAndDiscard(int)" : [ "readChecksumChunk" ],
  "org.apache.hadoop.security.token.delegation.SQLDelegationTokenSecretManager:cancelToken(org.apache.hadoop.security.token.Token,java.lang.String)" : [ "cancelToken", "createTokenIdent", "getIdentifier" ],
  "org.apache.hadoop.conf.Configuration$IntegerRanges:<init>(java.lang.String)" : [ "convertToInt" ],
  "org.apache.hadoop.util.WeakReferenceMap:remove(java.lang.Object)" : [ "resolve" ],
  "org.apache.hadoop.security.alias.CredentialShell$DeleteCommand:validate()" : [ "confirmPrompt" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:stopSinks()" : [ "sink", "stop" ],
  "org.apache.hadoop.util.curator.ZKCuratorManager:setData(java.lang.String,java.lang.String,int)" : [ "setData" ],
  "org.apache.hadoop.fs.impl.prefetch.BoundedResourcePool:close()" : [ "close" ],
  "org.apache.hadoop.fs.sftp.SFTPConnectionPool:disconnect(com.jcraft.jsch.ChannelSftp)" : [ "stringifyException", "returnToPool" ],
  "org.apache.hadoop.security.token.Token:hashCode()" : [ "hashBytes" ],
  "org.apache.hadoop.conf.Configuration:get(java.lang.String,java.lang.String)" : [ "handleDeprecation", "substituteVars", "getProps" ],
  "org.apache.hadoop.metrics2.impl.MetricsSinkAdapter:snapshot(org.apache.hadoop.metrics2.MetricsRecordBuilder,boolean)" : [ "snapshot" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreImpl:getMeanStatistic(java.lang.String)" : [ "lookup" ],
  "org.apache.hadoop.net.SocketInputStream$Reader:<init>(java.nio.channels.ReadableByteChannel,long)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Decompressor:reset()" : [ "checkStream" ],
  "org.apache.hadoop.util.SysInfoLinux:main(java.lang.String[])" : [ "<init>", "getPhysicalMemorySize", "getVirtualMemorySize", "getAvailablePhysicalMemorySize", "getAvailableVirtualMemorySize", "getNumProcessors", "getCpuFrequency", "getCumulativeCpuTime", "getNetworkBytesRead", "getNetworkBytesWritten", "getStorageBytesRead", "getStorageBytesWritten", "getCpuUsagePercentage" ],
  "org.apache.hadoop.util.functional.FutureIO:cancelAllFuturesAndAwaitCompletion(java.util.Collection,boolean,java.time.Duration)" : [ "now", "awaitFuture" ],
  "org.apache.hadoop.fs.FileSystem:openFileWithOptions(org.apache.hadoop.fs.PathHandle,org.apache.hadoop.fs.impl.OpenFileParameters)" : [ "rejectUnknownMandatoryKeys", "getMandatoryKeys", "open", "getBufferSize" ],
  "org.apache.hadoop.util.InstrumentedWriteLock:unlock()" : [ "monotonicNow" ],
  "org.apache.hadoop.fs.FilterFileSystem:getUsed(org.apache.hadoop.fs.Path)" : [ "getUsed" ],
  "org.apache.hadoop.util.Shell:execCommand(java.lang.String[])" : [ "execCommand" ],
  "org.apache.hadoop.io.serializer.avro.AvroReflectSerialization:accept(java.lang.Class)" : [ "getPackages" ],
  "org.apache.hadoop.ipc.Server$RpcCall:getRemotePort()" : [ "getRemotePort" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:recomputeScheduleCache()" : [ "computePriorityLevel" ],
  "org.apache.hadoop.io.WritableComparator:compare(java.lang.Object,java.lang.Object)" : [ "compare" ],
  "org.apache.hadoop.security.KDiag:<init>()" : [ "<init>" ],
  "org.apache.hadoop.io.file.tfile.TFile$Writer$KeyRegister:close()" : [ "getBuffer", "size", "writeVInt", "getFirstKey", "setFirstKey", "isSorted", "getRecordCount", "getComparator", "compare" ],
  "org.apache.hadoop.io.erasurecode.coder.HHXORErasureEncoder:checkCreateRSRawEncoder()" : [ "createRawEncoder" ],
  "org.apache.hadoop.io.SetFile$Reader:<init>(org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.io.WritableComparator,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:formatTokenId(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier)" : [ "getSequenceNumber" ],
  "org.apache.hadoop.conf.Configuration:setBooleanIfUnset(java.lang.String,boolean)" : [ "setIfUnset" ],
  "org.apache.hadoop.net.unix.DomainSocketWatcher:sendCallback(java.lang.String,java.util.TreeMap,org.apache.hadoop.net.unix.DomainSocketWatcher$FdSet,int)" : [ "checkNotNull", "getDomainSocket", "getHandler", "unreferenceCheckClosed", "checkArgument", "cleanupWithLogger" ],
  "org.apache.hadoop.util.bloom.Key:<init>(byte[],double)" : [ "set" ],
  "org.apache.hadoop.io.erasurecode.CodecRegistry:getCoderByName(java.lang.String,java.lang.String)" : [ "getCoders" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:renewDelegationToken(org.apache.hadoop.security.token.Token)" : [ "doOp", "nextIdx" ],
  "org.apache.hadoop.metrics2.impl.SinkQueue:consume(org.apache.hadoop.metrics2.impl.SinkQueue$Consumer)" : [ "waitForData", "_dequeue", "clearConsumerLock" ],
  "org.apache.hadoop.security.token.delegation.web.MultiSchemeDelegationTokenAuthenticationHandler:authenticate(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)" : [ "authenticate" ],
  "org.apache.hadoop.fs.FileSystem:newInstance(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "newInstance", "getDefaultUri", "getUnique" ],
  "org.apache.hadoop.fs.impl.prefetch.BoundedResourcePool:acquire()" : [ "acquireHelper" ],
  "org.apache.hadoop.ipc.Server:getAuxiliaryPortEstablishedQOP()" : [ "isOnAuxiliaryPort", "getEstablishedQOP" ],
  "org.apache.hadoop.util.VersionInfo:_getBuildVersion()" : [ "_getVersion", "_getRevision", "_getUser", "_getSrcChecksum" ],
  "org.apache.hadoop.metrics2.sink.RollingFileSystemSink:createLogFile(org.apache.hadoop.fs.Path)" : [ "<init>", "create", "exists", "getNextIdToTry", "toString" ],
  "org.apache.hadoop.io.erasurecode.coder.ErasureEncoder:getOutputBlocks(org.apache.hadoop.io.erasurecode.ECBlockGroup)" : [ "getParityBlocks" ],
  "org.apache.hadoop.conf.Configuration:dumpDeprecatedKeys()" : [ "getDeprecatedKeyMap" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:delete(org.apache.hadoop.fs.Path)" : [ "delete" ],
  "org.apache.hadoop.security.ShellBasedIdMapping:updateMapInternal(org.apache.hadoop.thirdparty.com.google.common.collect.BiMap,java.lang.String,java.lang.String,java.lang.String,java.util.Map)" : [ "parseId", "reportDuplicateEntry" ],
  "org.apache.hadoop.fs.impl.prefetch.FilePosition:relative()" : [ "throwIfInvalidBuffer" ],
  "org.apache.hadoop.crypto.CipherSuite:convert(java.lang.String)" : [ "getName" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Writer:prepareMetaBlock(java.lang.String)" : [ "prepareMetaBlock", "getDefaultCompressionAlgorithm" ],
  "org.apache.hadoop.fs.FileSystem:create(org.apache.hadoop.fs.Path,boolean,int,org.apache.hadoop.util.Progressable)" : [ "create", "getDefaultReplication", "getDefaultBlockSize" ],
  "org.apache.hadoop.ipc.Server$Listener:doAccept(java.nio.channels.SelectionKey)" : [ "getReader", "register", "cleanupWithLogger", "addConnection" ],
  "org.apache.hadoop.security.UserGroupInformation:getGroups()" : [ "getGroups", "ensureInitialized", "getShortUserName" ],
  "org.apache.hadoop.metrics2.lib.MutableGaugeInt:<init>(org.apache.hadoop.metrics2.MetricsInfo,int)" : [ "<init>" ],
  "org.apache.hadoop.crypto.CryptoInputStream:<init>(java.io.InputStream,org.apache.hadoop.crypto.CryptoCodec,byte[],byte[])" : [ "<init>", "getBufferSize" ],
  "org.apache.hadoop.util.LightWeightResizableGSet:get(java.lang.Object)" : [ "get" ],
  "org.apache.hadoop.metrics2.util.MetricsCache:update(org.apache.hadoop.metrics2.MetricsRecord,boolean)" : [ "name", "value" ],
  "org.apache.hadoop.fs.shell.TouchCommands$Touch:updateTime(org.apache.hadoop.fs.shell.PathData)" : [ "setTimes" ],
  "org.apache.hadoop.fs.shell.Command:runAll()" : [ "expandAsGlob", "run", "displayError" ],
  "org.apache.hadoop.io.MapFile$Reader:close()" : [ "close" ],
  "org.apache.hadoop.io.SequenceFile$BlockCompressWriter:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.io.SequenceFile$Writer$Option[])" : [ "<init>", "getInt" ],
  "org.apache.hadoop.io.compress.GzipCodec:getDecompressorType()" : [ "isNativeZlibLoaded" ],
  "org.apache.hadoop.fs.FsShell:printHelp(java.io.PrintStream,java.lang.String)" : [ "printInfo" ],
  "org.apache.hadoop.io.compress.DecompressorStream:<init>(java.io.InputStream)" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.FileSystemMultipartUploader:innerPutPart(org.apache.hadoop.fs.Path,java.io.InputStream,int,org.apache.hadoop.fs.UploadHandle,long)" : [ "<init>", "toByteArray", "mergePaths", "createFile", "checksumOpt", "permission", "blockSize", "getBufferSize", "cleanupWithLogger", "from", "toString", "close" ],
  "org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider:innerSetCredential(java.lang.String,char[])" : [ "<init>" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Factory:isNativeBzip2Loaded(org.apache.hadoop.conf.Configuration)" : [ "get", "isNativeCodeLoaded", "initSymbols" ],
  "org.apache.hadoop.util.HostsFileReader:readFileToSet(java.lang.String,java.lang.String,java.util.Set)" : [ "readFileToSetWithFileInputStream" ],
  "org.apache.hadoop.security.token.DtFileOperations:doFormattedWrite(java.io.File,java.lang.String,org.apache.hadoop.security.Credentials,org.apache.hadoop.conf.Configuration)" : [ "writeTokenStorageFile", "fileToPath" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:deleteWithRetries(java.lang.String,int)" : [ "zkDoWithRetries" ],
  "org.apache.hadoop.service.launcher.ServiceShutdownHook:unregister()" : [ "get", "removeShutdownHook" ],
  "org.apache.hadoop.fs.shell.Delete:registerCommands(org.apache.hadoop.fs.shell.CommandFactory)" : [ "addClass" ],
  "org.apache.hadoop.io.compress.lz4.Lz4Decompressor:decompress(byte[],int,int)" : [ "decompressDirectBuf" ],
  "org.apache.hadoop.util.DataChecksum:calculateChunkedSums(byte[],int,int,byte[],int)" : [ "isAvailable", "calculateChunkedSumsByteArray" ],
  "org.apache.hadoop.io.compress.BZip2Codec$BZip2CompressionOutputStream:write(byte[],int,int)" : [ "write", "internalReset" ],
  "org.apache.hadoop.fs.FileContext:clearStatistics()" : [ "clearStatistics" ],
  "org.apache.hadoop.ipc.Client$Connection:shouldAuthenticateOverKrb()" : [ "getLoginUser", "getCurrentUser", "getRealUser", "hasKerberosCredentials", "equals" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:concat(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path[])" : [ "copyBytes", "close" ],
  "org.apache.hadoop.security.SaslRpcClient$WrappedInputStream:read()" : [ "read" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.XORRawDecoder:doDecode(org.apache.hadoop.io.erasurecode.rawcoder.ByteBufferDecodingState)" : [ "resetOutputBuffers" ],
  "org.apache.hadoop.util.SysInfoLinux:readProcMemInfoFile(boolean)" : [ "safeParseLong" ],
  "org.apache.hadoop.fs.VectoredReadUtils:readRangeFrom(org.apache.hadoop.fs.PositionedReadable,org.apache.hadoop.fs.FileRange,java.util.function.IntFunction)" : [ "validateRangeRequest", "readNonByteBufferPositionedReadable" ],
  "org.apache.hadoop.util.functional.RemoteIterators$FilteringRemoteIterator:<init>(org.apache.hadoop.fs.RemoteIterator,org.apache.hadoop.util.functional.FunctionRaisingIOE)" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.FutureIOSupport:propagateOptions(org.apache.hadoop.fs.FSBuilder,org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String)" : [ "propagateOptions" ],
  "org.apache.hadoop.ha.ZKFailoverController:verifyChangedServiceState(org.apache.hadoop.ha.HAServiceProtocol$HAServiceState)" : [ "recheckElectability", "quitElection" ],
  "org.apache.hadoop.fs.shell.Count:registerCommands(org.apache.hadoop.fs.shell.CommandFactory)" : [ "addClass" ],
  "org.apache.hadoop.io.MapFile$Reader:open(org.apache.hadoop.fs.Path,org.apache.hadoop.io.WritableComparator,org.apache.hadoop.conf.Configuration,org.apache.hadoop.io.SequenceFile$Reader$Option[])" : [ "<init>", "createDataFileReader", "getPosition", "getKeyClass", "get", "prependOptions", "file" ],
  "org.apache.hadoop.fs.BatchedRemoteIterator:next()" : [ "makeRequestIfNeeded" ],
  "org.apache.hadoop.io.LongWritable:<init>(long)" : [ "set" ],
  "org.apache.hadoop.util.bloom.RetouchedBloomFilter:readFields(java.io.DataInput)" : [ "<init>", "readFields", "createVector" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.AbstractNativeRawDecoder:<init>(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.log.LogThrottlingHelper:record(double[])" : [ "record", "monotonicNow" ],
  "org.apache.hadoop.security.KDiag:printDefaultRealm()" : [ "<init>", "println", "warn", "error", "stringifyException" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:serviceMain(java.util.List)" : [ "<init>", "exitWithUsageMessage", "launchServiceAndExit" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:complete()" : [ "bsGetInt", "reportCRCError" ],
  "org.apache.hadoop.security.http.RestCsrfPreventionFilter:doFilter(javax.servlet.ServletRequest,javax.servlet.ServletResponse,javax.servlet.FilterChain)" : [ "<init>", "handleHttpInteraction" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:setOwner(org.apache.hadoop.fs.Path,java.lang.String,java.lang.String)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.ipc.RPC:waitForProxy(java.lang.Class,long,java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration,int,long)" : [ "waitForProtocolProxy", "getProxy" ],
  "org.apache.hadoop.fs.FilterFileSystem:satisfyStoragePolicy(org.apache.hadoop.fs.Path)" : [ "satisfyStoragePolicy" ],
  "org.apache.hadoop.fs.ftp.FtpFs:getServerDefaults()" : [ "getServerDefaults" ],
  "org.apache.hadoop.fs.ByteBufferUtil:streamHasByteBufferRead(java.io.InputStream)" : [ "getWrappedStream" ],
  "org.apache.hadoop.fs.RawLocalFileSystem$DeprecatedRawLocalFileStatus:loadPermissionInfoByNonNativeIO()" : [ "execCommand", "toUri", "getGetPermissionCommand", "valueOf", "removeDomain", "getExitCode", "stringifyException" ],
  "org.apache.hadoop.fs.FilterFs:listCorruptFileBlocks(org.apache.hadoop.fs.Path)" : [ "listCorruptFileBlocks" ],
  "org.apache.hadoop.net.SocketOutputStream:<init>(java.nio.channels.WritableByteChannel,long)" : [ "<init>", "checkChannelValidity" ],
  "org.apache.hadoop.io.compress.zstd.ZStandardDecompressor:setInput(byte[],int,int)" : [ "setInputFromSavedData" ],
  "org.apache.hadoop.ipc.FairCallQueue:poll()" : [ "removeNextElement" ],
  "org.apache.hadoop.io.compress.snappy.SnappyDecompressor:decompressDirect(java.nio.ByteBuffer,java.nio.ByteBuffer)" : [ "decompressDirectBuf" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:unregisterSource(java.lang.String)" : [ "stop", "removeSourceName" ],
  "org.apache.hadoop.fs.shell.CopyCommands$Put:processOptions(java.util.LinkedList)" : [ "<init>", "addOptionWithValue", "parse", "getOptValue", "getOpt" ],
  "org.apache.hadoop.fs.statistics.impl.StatisticDurationTracker:toString()" : [ "toString" ],
  "org.apache.hadoop.fs.shell.find.BaseExpression:addChildren(java.util.Deque,int)" : [ "addChild" ],
  "org.apache.hadoop.fs.FsUrlConnection:getInputStream()" : [ "connect" ],
  "org.apache.hadoop.fs.shell.PathData:<init>(org.apache.hadoop.fs.FileSystem,java.lang.String)" : [ "<init>", "lookupStat" ],
  "org.apache.hadoop.ha.NodeFencer:parseMethod(org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "<init>", "createFenceMethod" ],
  "org.apache.hadoop.conf.ReconfigurableBase:setReconfigurationUtil(org.apache.hadoop.conf.ReconfigurationUtil)" : [ "checkNotNull" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:generateEncryptedKey(java.lang.String)" : [ "getNext" ],
  "org.apache.hadoop.io.file.tfile.Chunk$ChunkEncoder:write(byte[],int,int)" : [ "writeBufData" ],
  "org.apache.hadoop.util.StringUtils:join(char,java.lang.String[])" : [ "join" ],
  "org.apache.hadoop.metrics2.lib.DefaultMetricsSystem:instance()" : [ "getImpl" ],
  "org.apache.hadoop.fs.impl.FileSystemMultipartUploaderBuilder:getFS()" : [ "getFS" ],
  "org.apache.hadoop.io.erasurecode.coder.HHXORErasureEncodingStep:<init>(org.apache.hadoop.io.erasurecode.ECBlock[],org.apache.hadoop.io.erasurecode.ECBlock[],org.apache.hadoop.io.erasurecode.rawcoder.RawErasureEncoder,org.apache.hadoop.io.erasurecode.rawcoder.RawErasureEncoder)" : [ "<init>", "initPiggyBackIndexWithoutPBVec", "getNumDataUnits", "getNumParityUnits" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:endBlock()" : [ "getFinalCRC", "reportCRCError" ],
  "org.apache.hadoop.util.Progress:toString(java.lang.StringBuilder)" : [ "phase" ],
  "org.apache.hadoop.util.HttpExceptionUtils:createJerseyExceptionResponse(javax.ws.rs.core.Response$Status,java.lang.Throwable)" : [ "getOneLineMessage" ],
  "org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec:createEncryptor()" : [ "<init>", "getCipherSuite" ],
  "org.apache.hadoop.fs.FileStatus:readFields(java.io.DataInput)" : [ "convert", "isDirectory", "getLen", "getReplication", "getBlockSize", "getModificationTime", "getAccessTime", "setPermission", "getPermission", "setOwner", "getOwner", "setGroup", "getGroup", "setSymlink", "isSymlink", "getSymlink", "setPath", "getPath", "attributes", "hasAcl", "isEncrypted", "isErasureCoded", "isSnapshotEnabled" ],
  "org.apache.hadoop.fs.statistics.impl.DynamicIOStatisticsBuilder:withAtomicLongMinimum(java.lang.String,java.util.concurrent.atomic.AtomicLong)" : [ "withLongFunctionMinimum" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:iostatisticsSnapshot_create(java.lang.Object)" : [ "checkIoStatisticsAvailable", "invoke" ],
  "org.apache.hadoop.fs.store.DataBlocks:validateWriteArgs(byte[],int,int)" : [ "checkNotNull" ],
  "org.apache.hadoop.http.lib.StaticUserWebFilter:initFilter(org.apache.hadoop.http.FilterContainer,org.apache.hadoop.conf.Configuration)" : [ "getUsernameFromConf" ],
  "org.apache.hadoop.ipc.WritableRpcEngine$Invocation:write(java.io.DataOutput)" : [ "writeString", "writeObject" ],
  "org.apache.hadoop.io.compress.zstd.ZStandardDecompressor$ZStandardDirectDecompressor:finished()" : [ "finished" ],
  "org.apache.hadoop.fs.MD5MD5CRC32FileChecksum:toString()" : [ "getAlgorithmName" ],
  "org.apache.hadoop.io.compress.GzipCodec$GzipZlibCompressor:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>", "getCompressionLevel", "getCompressionStrategy" ],
  "org.apache.hadoop.fs.ftp.FtpFs:<init>(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:createKey(java.lang.String,org.apache.hadoop.crypto.key.KeyProvider$Options)" : [ "doOp", "nextIdx" ],
  "org.apache.hadoop.fs.Path:isUriPathAbsolute()" : [ "startPositionWithoutWindowsDrive" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:iostatistics_minimums(java.io.Serializable)" : [ "invoke" ],
  "org.apache.hadoop.conf.Configuration:addDeprecation(java.lang.String,java.lang.String,java.lang.String)" : [ "addDeprecation" ],
  "org.apache.hadoop.metrics2.impl.MBeanInfoBuilder:<init>(java.lang.String,java.lang.String)" : [ "newArrayList" ],
  "org.apache.hadoop.net.NetUtils:normalizeHostNames(java.util.Collection)" : [ "normalizeHostName" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedIO:fileSystem_openFile(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,java.lang.String,org.apache.hadoop.fs.FileStatus,java.lang.Long,java.util.Map)" : [ "checkAvailable", "extractIOEs" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner:atEnd()" : [ "compareTo" ],
  "org.apache.hadoop.net.unix.DomainSocket$DomainInputStream:read(byte[],int,int)" : [ "reference" ],
  "org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue:close()" : [ "cleanup" ],
  "org.apache.hadoop.util.HostsFileReader:getExcludedHosts()" : [ "getExcludedHosts" ],
  "org.apache.hadoop.security.protocolPB.RefreshUserMappingsProtocolClientSideTranslatorPB:close()" : [ "stopProxy" ],
  "org.apache.hadoop.net.NetworkTopologyWithNodeGroup:remove(org.apache.hadoop.net.Node)" : [ "getPath" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL:obtainDelegationTokenAuthenticator(org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator,org.apache.hadoop.security.authentication.client.ConnectionConfigurator)" : [ "setConnectionConfigurator" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:listXAttrs(org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileStatus:getSymlink()" : [ "isSymlink" ],
  "org.apache.hadoop.fs.FSDataOutputStream:hasCapability(java.lang.String)" : [ "hasCapability" ],
  "org.apache.hadoop.crypto.CryptoInputStream:freeBuffers()" : [ "freeDB", "cleanBufferPool" ],
  "org.apache.hadoop.fs.Globber:listStatus(org.apache.hadoop.fs.Path)" : [ "listStatus", "util" ],
  "org.apache.hadoop.ha.protocolPB.HAServiceProtocolClientSideTranslatorPB:convert(org.apache.hadoop.ha.HAServiceProtocol$StateChangeRequestInfo)" : [ "getSource" ],
  "org.apache.hadoop.fs.store.DataBlocks$ByteBufferBlockFactory:releaseBuffer(java.nio.ByteBuffer)" : [ "returnBuffer" ],
  "org.apache.hadoop.crypto.key.KeyProvider:getCurrentKey(java.lang.String)" : [ "buildVersionName", "getVersions" ],
  "org.apache.hadoop.fs.DF:getPercentUsed()" : [ "getCapacity", "getAvailable" ],
  "org.apache.hadoop.io.Text:readWithKnownLength(java.io.DataInput,int)" : [ "ensureCapacity" ],
  "org.apache.hadoop.fs.FileSystem:globStatus(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.PathFilter)" : [ "<init>", "glob" ],
  "org.apache.hadoop.conf.ReconfigurationException:<init>(java.lang.String,java.lang.String,java.lang.String)" : [ "constructMessage" ],
  "org.apache.hadoop.conf.Configuration:addDeprecation(java.lang.String,java.lang.String[],java.lang.String)" : [ "<init>", "addDeprecations" ],
  "org.apache.hadoop.security.UserGroupInformation:addCredentials(org.apache.hadoop.security.Credentials)" : [ "getCredentialsInternal", "addAll" ],
  "org.apache.hadoop.security.ShellBasedIdMapping:isExpired()" : [ "monotonicNow" ],
  "org.apache.hadoop.metrics2.MetricStringBuilder:addGauge(org.apache.hadoop.metrics2.MetricsInfo,int)" : [ "add" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:setDataWithRetries(java.lang.String,byte[],int)" : [ "zkDoWithRetries" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:setXAttr(org.apache.hadoop.fs.Path,java.lang.String,byte[],java.util.EnumSet)" : [ "setXAttr", "resolve", "getUriPath" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:createSecretKey(byte[])" : [ "createSecretKey" ],
  "org.apache.hadoop.security.ShellBasedUnixGroupsNetgroupMapping:getGroups(java.lang.String)" : [ "getGroups", "getNetgroups" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.EncodingState:checkParameters(java.lang.Object[],java.lang.Object[])" : [ "<init>", "getNumDataUnits", "getNumParityUnits" ],
  "org.apache.hadoop.ipc.Server$Connection:processConnectionContext(org.apache.hadoop.ipc.RpcWritable$Buffer)" : [ "<init>", "getMessage", "getUgi", "setAuthenticationMethod", "getUserName", "createProxyUser", "authorizeConnection", "incrUserConnections", "getShortUserName" ],
  "org.apache.hadoop.fs.impl.FileSystemMultipartUploaderBuilder:getBufferSize()" : [ "getBufferSize" ],
  "org.apache.hadoop.net.unix.DomainSocket:close()" : [ "setClosed", "getReferenceCount" ],
  "org.apache.hadoop.fs.FileUtil:setReadable(java.io.File,boolean)" : [ "chmod" ],
  "org.apache.hadoop.fs.AbstractFileSystem:openFileWithOptions(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.impl.OpenFileParameters)" : [ "rejectUnknownMandatoryKeys", "getMandatoryKeys", "eval" ],
  "org.apache.hadoop.conf.StorageUnit$5:getDefault(double)" : [ "toMBs" ],
  "org.apache.hadoop.ha.protocolPB.HAServiceProtocolServerSideTranslatorPB:getServiceStatus(org.apache.hadoop.thirdparty.protobuf.RpcController,org.apache.hadoop.ha.proto.HAServiceProtocolProtos$GetServiceStatusRequestProto)" : [ "getState", "isReadyToBecomeActive", "getNotReadyReason" ],
  "org.apache.hadoop.io.compress.zlib.ZlibDecompressor$ZlibDirectDecompressor:<init>()" : [ "<init>" ],
  "org.apache.hadoop.security.SecurityUtil:doAsCurrentUser(java.security.PrivilegedExceptionAction)" : [ "doAsUser", "getCurrentUser" ],
  "org.apache.hadoop.fs.FilterFs:createMultipartUploader(org.apache.hadoop.fs.Path)" : [ "createMultipartUploader" ],
  "org.apache.hadoop.fs.HarFileSystem:makeQualified(org.apache.hadoop.fs.Path)" : [ "<init>", "isAbsolute", "toUri" ],
  "org.apache.hadoop.ipc.FairCallQueue:offerQueues(int,org.apache.hadoop.ipc.Schedulable,boolean)" : [ "offerQueue" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:getFileLinkStatus(org.apache.hadoop.fs.Path)" : [ "getFileLinkStatus", "fullPath" ],
  "org.apache.hadoop.io.wrappedio.WrappedStatistics:iostatisticsContext_reset()" : [ "getCurrentIOStatisticsContext" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:removeTokenForOwnerStats(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier)" : [ "getTokenRealOwner" ],
  "org.apache.hadoop.fs.shell.Display$Cat:getInputStream(org.apache.hadoop.fs.shell.PathData)" : [ "openForSequentialIO" ],
  "org.apache.hadoop.util.LineReader:getIOStatistics()" : [ "retrieveIOStatistics" ],
  "org.apache.hadoop.io.retry.AsyncCallHandler$ConcurrentQueue:checkEmpty()" : [ "monotonicNow" ],
  "org.apache.hadoop.fs.impl.CombinedFileRange:toString()" : [ "toString" ],
  "org.apache.hadoop.ha.SshFenceByTcpPort:execCommand(com.jcraft.jsch.Session,java.lang.String)" : [ "<init>", "start", "join", "cleanup" ],
  "org.apache.hadoop.fs.shell.find.Name:apply(org.apache.hadoop.fs.shell.PathData,int)" : [ "getName", "toLowerCase", "matches" ],
  "org.apache.hadoop.io.BloomMapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.io.WritableComparator,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileSystemStorageStatistics:getLongStatistics()" : [ "<init>", "getData" ],
  "org.apache.hadoop.util.LightWeightCache:iterator()" : [ "iterator" ],
  "org.apache.hadoop.security.SaslInputStream:read()" : [ "readMoreData" ],
  "org.apache.hadoop.io.compress.zlib.ZlibDecompressor:getRemaining()" : [ "checkStream" ],
  "org.apache.hadoop.crypto.JceCtrCryptoCodec$JceCtrCipher:decrypt(java.nio.ByteBuffer,java.nio.ByteBuffer)" : [ "process" ],
  "org.apache.hadoop.util.InstrumentedWriteLock:<init>(java.lang.String,org.slf4j.Logger,java.util.concurrent.locks.ReentrantReadWriteLock,long,long)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileContext:getXAttrs(org.apache.hadoop.fs.Path,java.util.List)" : [ "fixRelativePart" ],
  "org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator:getMemlockLimit()" : [ "getMemlockLimit" ],
  "org.apache.hadoop.fs.http.HttpsFileSystem:delete(org.apache.hadoop.fs.Path,boolean)" : [ "delete" ],
  "org.apache.hadoop.io.retry.RetryInvocationHandler$Call:invokeMethod()" : [ "invokeMethod", "setCallIdAndRetryCount" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:open(org.apache.hadoop.fs.Path,int)" : [ "checkPathIsSlash" ],
  "org.apache.hadoop.security.KDiag:validateKeyLength()" : [ "println", "verify" ],
  "org.apache.hadoop.io.erasurecode.coder.util.HHUtil:getPiggyBackForDecode(java.nio.ByteBuffer[][],java.nio.ByteBuffer[][],int,int,int,int)" : [ "findFirstValidInput", "allocateByteBuffer", "add" ],
  "org.apache.hadoop.util.ClassUtil:findContainingJar(java.lang.Class)" : [ "findContainingResource" ],
  "org.apache.hadoop.io.retry.RetryInvocationHandler$Call:processWaitTimeAndRetryInfo()" : [ "getWaitTime", "monotonicNow", "processRetryInfo" ],
  "org.apache.hadoop.service.CompositeService:serviceStop()" : [ "serviceStop", "stop" ],
  "org.apache.hadoop.fs.FilterFileSystem:makeQualified(org.apache.hadoop.fs.Path)" : [ "<init>", "makeQualified", "toUri" ],
  "org.apache.hadoop.metrics2.impl.MBeanInfoBuilder:gauge(org.apache.hadoop.metrics2.MetricsInfo,float)" : [ "newAttrInfo" ],
  "org.apache.hadoop.util.ShutdownHookManager$HookEntry:<init>(java.lang.Runnable,int)" : [ "<init>", "getShutdownTimeout" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider:loadAndReturnPerm(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "loadFromPath", "renameOrFail", "isBadorWrongPassword" ],
  "org.apache.hadoop.fs.Path:makeQualified(org.apache.hadoop.fs.FileSystem)" : [ "makeQualified" ],
  "org.apache.hadoop.fs.FileContext:access(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsAction)" : [ "fixRelativePart" ],
  "org.apache.hadoop.fs.HarFileSystem$HarMetaData:addPartFileStatuses(org.apache.hadoop.fs.Path)" : [ "getPath" ],
  "org.apache.hadoop.security.ssl.DelegatingSSLSocketFactory:createSocket(java.lang.String,int,java.net.InetAddress,int)" : [ "configureSocket" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:useStatIfAvailable()" : [ "isAvailable" ],
  "org.apache.hadoop.crypto.CryptoInputStream:seekToNewSource(long)" : [ "checkArgument", "checkStream", "resetStreamOffset" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$DelegationTokenSecretManagerMetrics:create()" : [ "<init>", "instance", "register" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:getFileLinkStatus(org.apache.hadoop.fs.Path)" : [ "<init>", "getChildren", "toUri", "isLink", "getLink", "getTargetFileSystem", "getUri", "getMyFs", "getLen", "getReplication", "getBlockSize", "getModificationTime", "getAccessTime", "getPermission", "getOwner", "getGroup", "getTargetLink", "makeQualified", "getShortUserName", "getPrimaryGroupName" ],
  "org.apache.hadoop.io.compress.SnappyCodec:createInputStream(java.io.InputStream,org.apache.hadoop.io.compress.Decompressor)" : [ "<init>", "getInt" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:hasPathCapability(org.apache.hadoop.fs.Path,java.lang.String)" : [ "hasPathCapability" ],
  "org.apache.hadoop.metrics2.impl.MetricsSourceAdapter:stopMBeans()" : [ "unregister" ],
  "org.apache.hadoop.fs.FsShell:main(java.lang.String[])" : [ "<init>", "newShellInstance", "setQuietMode", "run", "close" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem:setWorkingDirectory(org.apache.hadoop.fs.Path)" : [ "setWorkingDirectory" ],
  "org.apache.hadoop.util.hash.Hash:getHashType(org.apache.hadoop.conf.Configuration)" : [ "get", "parseHashType" ],
  "org.apache.hadoop.io.retry.RetryInvocationHandler:getFailoverCount()" : [ "getFailoverCount" ],
  "org.apache.hadoop.security.alias.KeyStoreProvider:keystoreExists()" : [ "exists" ],
  "org.apache.hadoop.fs.FileUtil:rename(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Options$Rename[])" : [ "rename" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator:getDelegationToken(java.net.URL,org.apache.hadoop.security.authentication.client.AuthenticatedURL$Token,java.lang.String)" : [ "getDelegationToken" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding:createTracker(org.apache.hadoop.fs.statistics.DurationTrackerFactory,java.lang.String)" : [ "trackDuration" ],
  "org.apache.hadoop.metrics2.lib.MutableGaugeLong:decr()" : [ "decr" ],
  "org.apache.hadoop.fs.PathIOException:getPath()" : [ "<init>" ],
  "org.apache.hadoop.util.StringUtils:byteToHexString(byte[],int,int)" : [ "format" ],
  "org.apache.hadoop.fs.shell.FsUsage$Df:setUsagesTable(org.apache.hadoop.fs.shell.FsUsage$TableBuilder)" : [ "setUsagesTable" ],
  "org.apache.hadoop.metrics2.sink.RollingFileSystemSink:rollLogDir()" : [ "<init>", "mkdirs", "createOrAppendLogFile", "createLogFile" ],
  "org.apache.hadoop.fs.statistics.impl.EmptyIOStatisticsContextImpl:getIOStatistics()" : [ "getInstance" ],
  "org.apache.hadoop.fs.shell.AclCommands$GetfaclCommand:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "getOwner", "getGroup", "getPermission", "getStickyBit", "getOtherAction", "implies", "hasAcl", "getAclStatus", "getEntries", "getAclFromPermAndEntries", "printAclEntriesForSingleScope", "getAccessEntries", "getDefaultEntries" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:readOnlyMountTable(java.lang.String,org.apache.hadoop.fs.Path)" : [ "readOnlyMountTable", "toString" ],
  "org.apache.hadoop.io.wrappedio.WrappedStatistics:requireIOStatisticsSnapshot(java.io.Serializable)" : [ "checkArgument" ],
  "org.apache.hadoop.security.ShellBasedUnixGroupsNetgroupMapping:getUsersForNetgroup(java.lang.String)" : [ "execShellGetUserForNetgroup" ],
  "org.apache.hadoop.metrics2.impl.MetricsConfigException:<init>(java.lang.String,java.lang.Throwable)" : [ "<init>" ],
  "org.apache.hadoop.security.SaslPlainServer:getAuthorizationID()" : [ "throwIfNotComplete" ],
  "org.apache.hadoop.security.SaslRpcClient:getInputStream(java.io.InputStream)" : [ "useWrap" ],
  "org.apache.hadoop.fs.TrashPolicyDefault$Emptier:run()" : [ "now", "ceiling", "getTrashRoots", "isDirectory", "getPath", "close" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider:tryLoadIncompleteFlush(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "<init>", "exists", "loadAndReturnPerm" ],
  "org.apache.hadoop.conf.ConfigurationWithLogging:getInt(java.lang.String,int)" : [ "getInt" ],
  "org.apache.hadoop.security.ShellBasedUnixGroupsMapping:getUnixGroups(java.lang.String)" : [ "createGroupExecutor", "execute", "resolveFullGroupNames", "getOutput", "handleExecutorTimeout", "resolvePartialGroupNames" ],
  "org.apache.hadoop.io.retry.RetryInvocationHandler:newCall(java.lang.reflect.Method,java.lang.Object[],boolean,int)" : [ "<init>", "isAsynchronousMode", "newAsyncCall" ],
  "org.apache.hadoop.util.StringUtils:humanReadableInt(long)" : [ "long2String" ],
  "org.apache.hadoop.io.compress.CodecPool:getCompressor(org.apache.hadoop.io.compress.CompressionCodec)" : [ "getCompressor" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:createSymlink(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,boolean)" : [ "areSymlinksEnabled", "toUri", "toString", "mkdirs", "getParent", "symLink", "makeAbsolute" ],
  "org.apache.hadoop.io.UTF8:toString()" : [ "reset", "readChars" ],
  "org.apache.hadoop.fs.shell.find.ExpressionFactory:getExpression(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "createExpression" ],
  "org.apache.hadoop.security.authorize.AuthorizationException:<init>(java.lang.Throwable)" : [ "<init>" ],
  "org.apache.hadoop.ipc.Server$Call:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.FileUtil:copy(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,boolean,boolean,org.apache.hadoop.conf.Configuration)" : [ "copy" ],
  "org.apache.hadoop.security.UserGroupInformation:isFromTicket()" : [ "hasKerberosCredentials", "isHadoopLogin", "getKeytab" ],
  "org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem:<init>(org.apache.hadoop.fs.FileSystem)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileSystem:getContentSummary(org.apache.hadoop.fs.Path)" : [ "<init>", "isFile", "getLen", "length", "fileCount", "directoryCount", "spaceConsumed", "build", "isDirectory", "getPath", "getLength", "getFileCount", "getDirectoryCount" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding:publishAsStorageStatistics(java.lang.String,java.lang.String,org.apache.hadoop.fs.statistics.IOStatistics)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileUtil:unTarUsingJava(java.io.InputStream,java.io.File,boolean)" : [ "unpackEntries", "cleanupWithLogger" ],
  "org.apache.hadoop.metrics2.MetricStringBuilder:addCounter(org.apache.hadoop.metrics2.MetricsInfo,int)" : [ "add" ],
  "org.apache.hadoop.ipc.RetryCache$CacheEntry:hashCode()" : [ "hashCode" ],
  "org.apache.hadoop.util.RunJar:unJar(java.io.File,java.io.File,java.util.regex.Pattern)" : [ "ensureDirectory", "copyBytes" ],
  "org.apache.hadoop.util.bloom.DynamicBloomFilter:membershipTest(org.apache.hadoop.util.bloom.Key)" : [ "membershipTest" ],
  "org.apache.hadoop.util.KMSUtil:toJSON(org.apache.hadoop.crypto.key.KeyProviderCryptoExtension$EncryptedKeyVersion)" : [ "toJSON", "getEncryptionKeyVersionName", "getEncryptedKeyIv", "getEncryptedKeyVersion" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.NativeXORRawErasureCoderFactory:createDecoder(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getFileChecksum(org.apache.hadoop.fs.Path,long)" : [ "getFileChecksum", "resolve", "getUriPath" ],
  "org.apache.hadoop.io.compress.zlib.ZlibFactory:getZlibDecompressorType(org.apache.hadoop.conf.Configuration)" : [ "isNativeZlibLoaded" ],
  "org.apache.hadoop.service.CompositeService:serviceStart()" : [ "serviceStart", "getServices" ],
  "org.apache.hadoop.ipc.ClientCache:getClient(org.apache.hadoop.conf.Configuration,javax.net.SocketFactory)" : [ "getClient" ],
  "org.apache.hadoop.fs.ftp.FtpConfigKeys:getServerDefaults()" : [ "<init>" ],
  "org.apache.hadoop.security.UserGroupInformation:getKeytab()" : [ "getLogin", "getConfiguration", "getParameters" ],
  "org.apache.hadoop.fs.PartialListing:<init>(org.apache.hadoop.fs.Path,java.util.List,org.apache.hadoop.ipc.RemoteException)" : [ "checkArgument" ],
  "org.apache.hadoop.net.InnerNodeImpl:equals(java.lang.Object)" : [ "equals" ],
  "org.apache.hadoop.fs.impl.prefetch.CachingBlockManager$PrefetchTask:get()" : [ "getBlockNumber" ],
  "org.apache.hadoop.security.UserGroupInformation:getCurrentUser()" : [ "<init>", "ensureInitialized", "getLoginUser" ],
  "org.apache.hadoop.io.erasurecode.ECBlockGroup:getErasedCount()" : [ "isErased" ],
  "org.apache.hadoop.fs.FilterFs:removeAcl(org.apache.hadoop.fs.Path)" : [ "removeAcl" ],
  "org.apache.hadoop.util.ToolRunner:run(org.apache.hadoop.conf.Configuration,org.apache.hadoop.util.Tool,java.lang.String[])" : [ "<init>", "getCurrent", "build", "setCurrent", "noteEntryPoint", "getRemainingArgs" ],
  "org.apache.hadoop.metrics2.lib.Interns:info(java.lang.String,java.lang.String)" : [ "add" ],
  "org.apache.hadoop.fs.FilterFileSystem:hasPathCapability(org.apache.hadoop.fs.Path,java.lang.String)" : [ "hasPathCapability", "validatePathCapabilityArgs", "makeQualified" ],
  "org.apache.hadoop.security.ssl.ReloadingX509TrustManager:<init>(java.lang.String,java.lang.String,java.lang.String)" : [ "loadTrustManager" ],
  "org.apache.hadoop.fs.Options$CreateOpts:progress(org.apache.hadoop.util.Progressable)" : [ "<init>" ],
  "org.apache.hadoop.fs.FilterFileSystem:setXAttr(org.apache.hadoop.fs.Path,java.lang.String,byte[])" : [ "setXAttr" ],
  "org.apache.hadoop.ipc.CallQueueManager:setPriorityLevel(org.apache.hadoop.security.UserGroupInformation,int)" : [ "setPriorityLevel" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:stopMetricsMBeans()" : [ "stopMBeans" ],
  "org.apache.hadoop.fs.FsShell$UnknownCommandException:<init>()" : [ "<init>" ],
  "org.apache.hadoop.io.retry.RetryInvocationHandler$ProxyDescriptor:failover(long,java.lang.reflect.Method,int)" : [ "getString" ],
  "org.apache.hadoop.fs.CreateFlag:validate(java.util.EnumSet)" : [ "<init>" ],
  "org.apache.hadoop.security.UserGroupInformation:isFromKeytab()" : [ "hasKerberosCredentials", "isHadoopLogin", "getKeytab" ],
  "org.apache.hadoop.conf.ConfigRedactor:<init>(org.apache.hadoop.conf.Configuration)" : [ "get", "getTrimmedStrings" ],
  "org.apache.hadoop.util.Progress:getProgress()" : [ "getInternal" ],
  "org.apache.hadoop.util.curator.ZKCuratorManager:create(java.lang.String)" : [ "create" ],
  "org.apache.hadoop.fs.Globber:doGlob()" : [ "<init>", "schemeFromPath", "authorityFromPath", "toUri", "getPath", "expand", "fixRelativePart", "getPathComponents", "isWindowsAbsolutePath", "unescapePathComponent", "hasPattern", "setPath", "listStatus", "getFileStatus", "isDirectory", "equals", "getName", "accept" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:getFileLinkStatus(org.apache.hadoop.fs.Path)" : [ "getFileLinkStatus", "isSymlink", "setSymlink", "getLinkTarget" ],
  "org.apache.hadoop.security.SaslRpcClient:selectSaslClient(java.util.List)" : [ "<init>", "isValidAuthType", "createSaslClient" ],
  "org.apache.hadoop.fs.FileSystem:canonicalizeUri(java.net.URI)" : [ "getDefaultPort" ],
  "org.apache.hadoop.fs.permission.PermissionStatus:readFields(java.io.DataInput)" : [ "readString", "read" ],
  "org.apache.hadoop.security.UserGroupInformation:hasSufficientTimeElapsed(long)" : [ "getLastLogin" ],
  "org.apache.hadoop.fs.FileUtil:unTarUsingJava(java.io.File,java.io.File,boolean)" : [ "unpackEntries", "cleanupWithLogger" ],
  "org.apache.hadoop.fs.shell.find.Find:isPathRecursable(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "isDirectory", "isSymlink", "resolvePath", "getSymlink", "toString", "getOptions", "isFollowLink", "isFollowArgLink" ],
  "org.apache.hadoop.util.StringUtils:getStringCollection(java.lang.String)" : [ "getStringCollection" ],
  "org.apache.hadoop.security.UserGroupInformation:getUserName()" : [ "getName" ],
  "org.apache.hadoop.io.file.tfile.BCFile$MetaIndexEntry:write(java.io.DataOutput)" : [ "write", "writeString", "getName" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner$Entry:equals(java.lang.Object)" : [ "compareTo", "getKeyLength" ],
  "org.apache.hadoop.net.StandardSocketFactory:createSocket(java.net.InetAddress,int)" : [ "createSocket" ],
  "org.apache.hadoop.ipc.Server:addAuxiliaryListener(int)" : [ "setIsAuxiliary", "getAddress" ],
  "org.apache.hadoop.net.NetworkTopology:recommissionNode(org.apache.hadoop.net.Node)" : [ "getPath", "interAddNodeWithEmptyRack" ],
  "org.apache.hadoop.fs.FileSystem:createMultipartUploader(org.apache.hadoop.fs.Path)" : [ "methodNotSupported" ],
  "org.apache.hadoop.metrics2.sink.RollingFileSystemSink:init(org.apache.commons.configuration2.SubsetConfiguration)" : [ "<init>", "getNonNegative", "getRollInterval", "loadConf", "setConfiguration", "isSecurityEnabled", "checkIfPropertyExists", "login" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState:finish()" : [ "returnDecompressor" ],
  "org.apache.hadoop.metrics2.source.JvmMetrics:getGcInfo(java.lang.String)" : [ "info" ],
  "org.apache.hadoop.fs.impl.prefetch.BufferPool:close()" : [ "getAll", "getActionFuture" ],
  "org.apache.hadoop.io.ReadaheadPool:getInstance()" : [ "<init>", "isAvailable" ],
  "org.apache.hadoop.fs.ChecksumFileSystem$FSDataBoundedInputStream:seek(long)" : [ "seek", "getFileLength" ],
  "org.apache.hadoop.util.ConfigurationHelper:mapEnumNamesToValues(java.lang.String,java.lang.Class)" : [ "checkArgument" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler$MetricsProxy:getSchedulingDecisionSummary()" : [ "getSchedulingDecisionSummary" ],
  "org.apache.hadoop.fs.FilterFs:setPermission(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "checkPath" ],
  "org.apache.hadoop.io.MapFile$Reader:finalKey(org.apache.hadoop.io.WritableComparable)" : [ "getPosition", "readIndex", "seek", "reset", "next" ],
  "org.apache.hadoop.fs.shell.Display$Text:getInputStream(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "getInputStream", "seek", "getCodec" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:<init>(java.lang.String,int,java.lang.String,java.util.List,java.util.List,org.apache.hadoop.ha.ActiveStandbyElector$ActiveStandbyElectorCallback,int,boolean,org.apache.hadoop.security.SecurityUtil$TruststoreKeystore)" : [ "<init>", "createConnection", "reEstablishSession" ],
  "org.apache.hadoop.fs.http.HttpsFileSystem:mkdirs(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "mkdirs" ],
  "org.apache.hadoop.tools.TableListing:toString()" : [ "getRow" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsContextImpl:snapshot()" : [ "<init>" ],
  "org.apache.hadoop.util.InstrumentedLock:startLockTiming()" : [ "monotonicNow" ],
  "org.apache.hadoop.util.KMSUtil:getKeyProviderUri(org.apache.hadoop.conf.Configuration)" : [ "getKeyProviderUri" ],
  "org.apache.hadoop.io.retry.RetryPolicies$MultipleLinearRandomRetry:parseCommaSeparatedString(java.lang.String)" : [ "<init>", "parsePositiveInt" ],
  "org.apache.hadoop.fs.LocatedFileStatus:hashCode()" : [ "hashCode" ],
  "org.apache.hadoop.io.SetFile:<init>()" : [ "<init>" ],
  "org.apache.hadoop.security.SecurityUtil:setSslConfiguration(org.apache.zookeeper.client.ZKClientConfig,org.apache.hadoop.security.SecurityUtil$TruststoreKeystore)" : [ "setSslConfiguration" ],
  "org.apache.hadoop.security.ssl.SSLHostnameVerifier$AbstractVerifier:isLocalhost(java.lang.String)" : [ "toLowerCase" ],
  "org.apache.hadoop.crypto.CryptoInputStream:getCounter(long)" : [ "getAlgorithmBlockSize" ],
  "org.apache.hadoop.fs.viewfs.RegexMountPoint:initializeInterceptors()" : [ "split", "create" ],
  "org.apache.hadoop.ipc.RPC:getProtocolProxy(java.lang.Class,long,java.net.InetSocketAddress,org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory,int,org.apache.hadoop.io.retry.RetryPolicy,java.util.concurrent.atomic.AtomicBoolean,org.apache.hadoop.ipc.AlignmentContext)" : [ "isSecurityEnabled", "init", "getProtocolEngine" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:listStatus(org.apache.hadoop.fs.Path)" : [ "<init>", "pathToFile", "list", "getFileStatus" ],
  "org.apache.hadoop.fs.Path:getPathWithoutSchemeAndAuthority(org.apache.hadoop.fs.Path)" : [ "<init>", "isUriPathAbsolute", "toUri" ],
  "org.apache.hadoop.metrics2.impl.MetricsBufferBuilder:add(java.lang.String,java.lang.Iterable)" : [ "<init>" ],
  "org.apache.hadoop.fs.CreateFlag:validateForAppend(java.util.EnumSet)" : [ "<init>", "validate" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RawErasureEncoder:getNumDataUnits()" : [ "getNumDataUnits" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystemUtil:isViewFileSystem(org.apache.hadoop.fs.FileSystem)" : [ "getScheme" ],
  "org.apache.hadoop.io.compress.DecompressorStream:<init>(java.io.InputStream,org.apache.hadoop.io.compress.Decompressor,int,int)" : [ "<init>" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:createNonRecursive(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,java.util.EnumSet,int,short,long,org.apache.hadoop.util.Progressable)" : [ "<init>", "exists", "createOutputStreamWithMode" ],
  "org.apache.hadoop.util.FindClass:dumpResource(java.lang.String)" : [ "getResource", "err", "printStack" ],
  "org.apache.hadoop.io.file.tfile.TFile$Writer:append(byte[],int,int,byte[],int,int)" : [ "prepareAppendKey", "prepareAppendValue" ],
  "org.apache.hadoop.fs.FileSystem$Statistics:getBytesRead()" : [ "<init>", "visitAll" ],
  "org.apache.hadoop.util.ProgramDriver:printUsage(java.util.Map)" : [ "getDescription" ],
  "org.apache.hadoop.crypto.random.OsSecureRandom:setConf(org.apache.hadoop.conf.Configuration)" : [ "get", "close" ],
  "org.apache.hadoop.fs.viewfs.InodeTree:<init>(org.apache.hadoop.conf.Configuration,java.lang.String,java.net.URI,boolean)" : [ "<init>", "getDefaultMountTableName", "getHomeDirValue", "isNestedMountPointSupported", "getCurrentUser", "toString", "checkMntEntryKeyEqualsTarget", "buildLinkRegexEntry", "checkNotNull", "getRootDir", "setInternalDirFs", "setRoot", "getLinkEntries", "getLinkType", "getTarget", "addRegexMountEntry", "createLink", "getSrc", "getSettings", "getUgi", "getConfig", "addFallbackLink", "iterator" ],
  "org.apache.hadoop.io.compress.DecompressorStream:available()" : [ "checkStream" ],
  "org.apache.hadoop.security.authorize.AccessControlList:isUserAllowed(org.apache.hadoop.security.UserGroupInformation)" : [ "isUserInList" ],
  "org.apache.hadoop.fs.FSDataOutputStreamBuilder:getPermission()" : [ "getFileDefault" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:getKeyNear(long)" : [ "<init>", "getBlockIndexNear", "checkTFileDataIndex", "getEntry" ],
  "org.apache.hadoop.io.retry.AsyncCallHandler$1:isDone()" : [ "isDone" ],
  "org.apache.hadoop.fs.DelegationTokenRenewer$RenewAction:equals(java.lang.Object)" : [ "equals" ],
  "org.apache.hadoop.net.unix.DomainSocket:isOpen()" : [ "isOpen" ],
  "org.apache.hadoop.ipc.Server$Connection:authorizeConnection()" : [ "<init>", "getRealUser", "authorize", "getHostAddress", "getHostInetAddress", "incrAuthorizationSuccesses", "incrAuthorizationFailures" ],
  "org.apache.hadoop.fs.impl.prefetch.FilePosition:data()" : [ "throwIfInvalidBuffer" ],
  "org.apache.hadoop.fs.RawLocalFileSystem$DeprecatedRawLocalFileStatus:loadPermissionInfoByNativeIO()" : [ "<init>", "toUri", "getStat", "getOwner", "getGroup", "getMode" ],
  "org.apache.hadoop.fs.shell.find.Print:apply(org.apache.hadoop.fs.shell.PathData,int)" : [ "getOut", "toString" ],
  "org.apache.hadoop.util.functional.CommonCallableSupplier:waitForCompletion(java.util.concurrent.CompletableFuture)" : [ "<init>", "raiseInnerCause", "close" ],
  "org.apache.hadoop.fs.shell.AclCommands:registerCommands(org.apache.hadoop.fs.shell.CommandFactory)" : [ "addClass" ],
  "org.apache.hadoop.util.XMLUtils:transform(java.io.InputStream,java.io.InputStream,java.io.Writer)" : [ "newSecureTransformerFactory" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreBuilderImpl:build()" : [ "<init>" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2:registerProtocolEngine()" : [ "registerProtocolEngine" ],
  "org.apache.hadoop.fs.HarFileSystem:fixBlockLocations(org.apache.hadoop.fs.BlockLocation[],long,long,long)" : [ "getOffset", "getLength", "setOffset", "setLength" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.util.GaloisField:getInstance()" : [ "getInstance" ],
  "org.apache.hadoop.io.FloatWritable$Comparator:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockData:throwIfInvalidBlockNumber(int)" : [ "checkWithinRange" ],
  "org.apache.hadoop.io.retry.RetryPolicies$RetryUpToMaximumCountWithProportionalSleep:<init>(int,long,java.util.concurrent.TimeUnit)" : [ "<init>" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding:trackDurationOfSupplier(org.apache.hadoop.fs.statistics.DurationTrackerFactory,java.lang.String,java.util.function.Supplier)" : [ "createTracker" ],
  "org.apache.hadoop.util.Shell$ShellCommandExecutor:<init>(java.lang.String[],java.io.File)" : [ "<init>" ],
  "org.apache.hadoop.http.HttpServer2$QuotingInputFilter$RequestQuoter:getServerName()" : [ "quoteHtmlChars" ],
  "org.apache.hadoop.util.concurrent.HadoopExecutors:newScheduledThreadPool(int)" : [ "<init>" ],
  "org.apache.hadoop.ha.ZKFailoverController:doRun(java.lang.String[])" : [ "initZK", "badArg", "formatZK", "parentZNodeExists", "initRPC", "initHM", "startRPC", "mainLoop", "stopAndJoin", "quitElection", "shutdown", "join" ],
  "org.apache.hadoop.io.compress.ZStandardCodec:createDirectDecompressor()" : [ "<init>", "getDecompressionBufferSize" ],
  "org.apache.hadoop.util.HostsFileReader:readXmlFileToMapWithFileInputStream(java.lang.String,java.lang.String,java.io.InputStream,java.util.Map)" : [ "newSecureDocumentBuilderFactory", "readFirstTagValue", "getTrimmedStrings" ],
  "org.apache.hadoop.security.authorize.AccessControlList:addUser(java.lang.String)" : [ "isWildCardACLValue", "isAllAllowed" ],
  "org.apache.hadoop.security.UserGroupInformation:unprotectedRelogin(org.apache.hadoop.security.UserGroupInformation$HadoopLoginContext,boolean)" : [ "<init>", "getSubjectLock", "now", "hasSufficientTimeElapsed", "setLastLogin", "getUserName", "logout", "newLoginContext", "getAppName", "getConfiguration", "login", "fixKerberosTicketOrder", "setLogin", "setUser" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:iostatistics_counters(java.io.Serializable)" : [ "invoke" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockOperations:addToCache(int)" : [ "<init>", "checkNotNegative", "add" ],
  "org.apache.hadoop.fs.FileContext:getAllStatistics()" : [ "getAllStatistics" ],
  "org.apache.hadoop.net.DNS:getIPs(java.lang.String)" : [ "getIPs" ],
  "org.apache.hadoop.io.MapFile$Reader:seekInternal(org.apache.hadoop.io.WritableComparable)" : [ "seekInternal" ],
  "org.apache.hadoop.fs.impl.MultipartUploaderBuilderImpl:getPermission()" : [ "getFileDefault" ],
  "org.apache.hadoop.io.erasurecode.CodecUtil:createRawDecoderWithFallback(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "getBoolean", "getRawCoderNames", "createRawCoderFactory" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:removeAclEntries(org.apache.hadoop.fs.Path,java.util.List)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.fs.ChecksumFs:createInternal(org.apache.hadoop.fs.Path,java.util.EnumSet,org.apache.hadoop.fs.permission.FsPermission,int,short,long,org.apache.hadoop.util.Progressable,org.apache.hadoop.fs.Options$ChecksumOpt,boolean)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:merge(org.apache.hadoop.fs.FileStatus[],org.apache.hadoop.fs.FileStatus[])" : [ "getPath", "getName" ],
  "org.apache.hadoop.io.compress.SnappyCodec:createOutputStream(java.io.OutputStream)" : [ "createOutputStreamWithCodecPool" ],
  "org.apache.hadoop.ipc.RPC:getProtocolProxy(java.lang.Class,long,org.apache.hadoop.ipc.Client$ConnectionId,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory)" : [ "getProtocolProxy" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsContext:setThreadIOStatisticsContext(org.apache.hadoop.fs.statistics.IOStatisticsContext)" : [ "setThreadIOStatisticsContext" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:incrAuthenticationSuccesses()" : [ "incr" ],
  "org.apache.hadoop.fs.FilterFileSystem:appendFile(org.apache.hadoop.fs.Path)" : [ "appendFile" ],
  "org.apache.hadoop.util.ReadWriteDiskValidatorMetrics:getMetric(java.lang.String)" : [ "<init>", "instance", "sourceName" ],
  "org.apache.hadoop.metrics2.lib.MutableCounterInt:snapshot(org.apache.hadoop.metrics2.MetricsRecordBuilder,boolean)" : [ "value" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:delete(com.jcraft.jsch.ChannelSftp,org.apache.hadoop.fs.Path,boolean)" : [ "<init>", "makeAbsolute", "toUri", "getPath", "getFileStatus", "isDirectory", "listStatus" ],
  "org.apache.hadoop.ipc.Server:doKerberosRelogin()" : [ "getLoginUser", "isLoginSuccess", "isLoginKeytabBased", "forceReloginFromKeytab", "isLoginTicketBased", "forceReloginFromTicketCache", "reloginFromKeytab", "reloginFromTicketCache" ],
  "org.apache.hadoop.metrics2.sink.StatsDSink:putMetrics(org.apache.hadoop.metrics2.MetricsRecord)" : [ "info", "name", "value", "writeMetric" ],
  "org.apache.hadoop.io.file.tfile.BCFile$BlockRegion:<init>(java.io.DataInput)" : [ "readVLong" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:getKeysMetadata(java.lang.String[])" : [ "doOp", "nextIdx" ],
  "org.apache.hadoop.crypto.CryptoInputStream:readFully(long,byte[])" : [ "readFully" ],
  "org.apache.hadoop.fs.shell.Tail:expandArgument(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.find.Find:getExpression(java.lang.Class)" : [ "getExpressionFactory", "createExpression" ],
  "org.apache.hadoop.fs.statistics.MeanStatistic:setSamplesAndSum(long,long)" : [ "setSamples", "setSum" ],
  "org.apache.hadoop.ha.HAAdmin:run(java.lang.String[])" : [ "runCmd" ],
  "org.apache.hadoop.ha.FailoverController:tryGracefulFence(org.apache.hadoop.ha.HAServiceTarget)" : [ "getProxy", "createReqInfo", "stopProxy" ],
  "org.apache.hadoop.net.NetUtils:getSocketFactory(org.apache.hadoop.conf.Configuration,java.lang.Class)" : [ "get", "getSocketFactoryFromProperty", "getDefaultSocketFactory" ],
  "org.apache.hadoop.metrics2.lib.MutableRates:init(java.lang.Class)" : [ "newRate" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:listStatus(org.apache.hadoop.fs.Path)" : [ "<init>", "checkPathIsSlash", "listStatusForFallbackLink", "getChildren", "makeQualified", "isLink", "getLink", "getShortUserName", "getPrimaryGroupName", "getTargetLink", "getTargetFileSystem", "getMyFs", "getLen", "isDirectory", "getReplication", "getBlockSize", "getModificationTime", "getAccessTime", "getPermission", "getOwner", "getGroup", "merge" ],
  "org.apache.hadoop.io.DataInputByteBuffer:reset(java.nio.ByteBuffer[])" : [ "reset" ],
  "org.apache.hadoop.util.HostsFileReader:refreshInternal(java.lang.String,java.lang.String,boolean)" : [ "<init>", "readFileToSet", "readFileToMap" ],
  "org.apache.hadoop.io.DataOutputBuffer:getData()" : [ "getData" ],
  "org.apache.hadoop.security.UserGroupInformation:logUserInfo(org.slf4j.Logger,java.lang.String,org.apache.hadoop.security.UserGroupInformation)" : [ "getCredentials", "getTokenMap" ],
  "org.apache.hadoop.io.compress.zstd.ZStandardCompressor:getBytesRead()" : [ "checkStream" ],
  "org.apache.hadoop.fs.store.DataBlocks$ByteBufferBlockFactory:requestBuffer(int)" : [ "getBuffer" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:mkdirs(org.apache.hadoop.fs.Path)" : [ "mkdirs", "resolve", "getUriPath" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:getFileStatus(org.apache.hadoop.fs.Path)" : [ "getFileLinkStatusInternal" ],
  "org.apache.hadoop.metrics2.lib.MutableGaugeFloat:<init>(org.apache.hadoop.metrics2.MetricsInfo,float)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:getAclStatus(org.apache.hadoop.fs.Path)" : [ "checkPathIsSlash", "owner", "getShortUserName", "group", "getPrimaryGroupName", "addEntries", "getMinimalAcl", "stickyBit", "build" ],
  "org.apache.hadoop.fs.FileSystem$Statistics:getBytesReadByDistance(int)" : [ "getData", "getBytesReadLocalHost", "getBytesReadDistanceOfOneOrTwo", "getBytesReadDistanceOfThreeOrFour", "getBytesReadDistanceOfFiveOrLarger" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:setTimes(org.apache.hadoop.fs.Path,long,long)" : [ "setTimes", "resolve", "getUriPath" ],
  "org.apache.hadoop.util.InstrumentedReadLock:<init>(java.lang.String,org.slf4j.Logger,java.util.concurrent.locks.ReentrantReadWriteLock,long,long)" : [ "<init>" ],
  "org.apache.hadoop.security.SaslRpcClient:getServerPrincipal(org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto$SaslAuth)" : [ "getServerPrincipal", "getKerberosInfo", "get", "compile" ],
  "org.apache.hadoop.io.retry.CallReturn:<init>(org.apache.hadoop.io.retry.CallReturn$State)" : [ "<init>" ],
  "org.apache.hadoop.security.CompositeGroupsMapping:getGroupsSet(java.lang.String)" : [ "getGroupsSet" ],
  "org.apache.hadoop.util.curator.ZKCuratorManager:safeSetData(java.lang.String,byte[],int,java.util.List,java.lang.String)" : [ "createTransaction", "setData", "commit" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:listStatus(org.apache.hadoop.fs.Path)" : [ "listStatus", "fullPath" ],
  "org.apache.hadoop.fs.FilterFs:getFileStatus(org.apache.hadoop.fs.Path)" : [ "checkPath" ],
  "org.apache.hadoop.util.InstrumentedLock:check(long,long,boolean)" : [ "monotonicNow", "incrementSuppressed", "snapshot", "logWarning", "logWaitWarning" ],
  "org.apache.hadoop.io.SecureIOUtils:forceSecureOpenFSDataInputStream(java.io.File,java.lang.String,java.lang.String)" : [ "<init>", "open", "getFstat", "getFileDescriptor", "checkStat", "getOwner", "getGroup" ],
  "org.apache.hadoop.io.SequenceFile$Sorter$SegmentDescriptor:nextRawValue(org.apache.hadoop.io.SequenceFile$ValueBytes)" : [ "nextRawValue" ],
  "org.apache.hadoop.fs.BatchedRemoteIterator:hasNext()" : [ "makeRequestIfNeeded" ],
  "org.apache.hadoop.util.ZKUtil$BadAclFormatException:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.ipc.Server$Connection:unwrapPacketAndProcessRpcs(byte[])" : [ "shouldClose", "processOneRpc" ],
  "org.apache.hadoop.io.WeakReferencedElasticByteBufferPool:putBuffer(java.nio.ByteBuffer)" : [ "<init>", "getBufferTree" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:setupBlock()" : [ "initTT", "setupRandPartA", "setupNoRandPartA" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:getFileLinkStatus(org.apache.hadoop.fs.Path)" : [ "getFileLinkStatus" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RSRawDecoder:prepareDecoding(java.lang.Object[],int[])" : [ "getValidIndexes", "processErasures" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreImpl:addTimedOperation(java.lang.String,java.time.Duration)" : [ "addTimedOperation" ],
  "org.apache.hadoop.util.Sets:newHashSet(java.lang.Iterable)" : [ "newHashSet", "cast" ],
  "org.apache.hadoop.util.FindClass:createClassInstance(java.lang.String)" : [ "getClass", "loadedClass", "out", "printStack" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockOperations:getRead(int)" : [ "<init>", "checkNotNegative", "add" ],
  "org.apache.hadoop.metrics2.filter.AbstractPatternFilter:init(org.apache.commons.configuration2.SubsetConfiguration)" : [ "<init>", "setIncludePattern", "setExcludePattern", "setIncludeTagPattern", "setExcludeTagPattern" ],
  "org.apache.hadoop.util.QuickSort:sortInternal(org.apache.hadoop.util.IndexedSortable,int,int,org.apache.hadoop.util.Progressable,int)" : [ "fix" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.util.GaloisField:add(int[],int[])" : [ "add" ],
  "org.apache.hadoop.log.LogLevel$CLI:parseGetLevelArgs(java.lang.String[],int)" : [ "<init>" ],
  "org.apache.hadoop.util.bloom.RetouchedBloomFilter:minimumFnRemove(int[])" : [ "getWeight" ],
  "org.apache.hadoop.fs.FileSystem$Cache$Key:<init>(java.net.URI,org.apache.hadoop.conf.Configuration,long)" : [ "toLowerCase", "getCurrentUser" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider:resetKeyStoreState(org.apache.hadoop.fs.Path)" : [ "loadFromPath" ],
  "org.apache.hadoop.util.bloom.CountingBloomFilter:readFields(java.io.DataInput)" : [ "readFields", "buckets2words" ],
  "org.apache.hadoop.io.retry.CallReturn:<init>(java.lang.Throwable)" : [ "<init>", "checkNotNull" ],
  "org.apache.hadoop.fs.FSBuilder:must(java.lang.String,int)" : [ "mustLong" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:supportsSymlinks()" : [ "supportsSymlinks" ],
  "org.apache.hadoop.fs.store.DataBlocks:createFactory(java.lang.String,org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getXAttrs(org.apache.hadoop.fs.Path,java.util.List)" : [ "getXAttrs", "resolve", "getUriPath" ],
  "org.apache.hadoop.ipc.Server:internalQueueCall(org.apache.hadoop.ipc.Server$Call)" : [ "internalQueueCall" ],
  "org.apache.hadoop.service.ServiceOperations:stopQuietly(org.apache.hadoop.service.Service)" : [ "stopQuietly" ],
  "org.apache.hadoop.fs.FsShell:getTrash()" : [ "<init>" ],
  "org.apache.hadoop.ipc.Client$IpcStreams:setSaslClient(org.apache.hadoop.security.SaslRpcClient)" : [ "setInputStream", "getInputStream", "setOutputStream", "getOutputStream" ],
  "org.apache.hadoop.conf.ReconfigurationUtil:getChangedProperties(org.apache.hadoop.conf.Configuration,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getRaw", "get", "iterator" ],
  "org.apache.hadoop.ipc.Server$Handler:run()" : [ "run", "take", "monotonicNowNanos", "isCallCoordinated", "getClientStateId", "requeueCall", "activateSpan", "addTimelineAnnotation", "setCurrent", "getRemoteUser", "isOpen", "doAs", "stringifyException", "cleanupWithLogger", "updateMetrics", "isResponseDeferred", "getDetailedMetricsName", "getProcessingDetails" ],
  "org.apache.hadoop.fs.FileUtil:fullyDelete(java.io.File)" : [ "fullyDelete" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RawErasureEncoder:getNumParityUnits()" : [ "getNumParityUnits" ],
  "org.apache.hadoop.fs.local.LocalConfigKeys:getServerDefaults()" : [ "<init>" ],
  "org.apache.hadoop.metrics2.impl.MetricsRecordBuilderImpl:addCounter(org.apache.hadoop.metrics2.MetricsInfo,int)" : [ "<init>" ],
  "org.apache.hadoop.fs.HarFileSystem:checkPath(org.apache.hadoop.fs.Path)" : [ "checkPath" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:createKey(java.lang.String,byte[],org.apache.hadoop.crypto.key.KeyProvider$Options)" : [ "doOp", "nextIdx" ],
  "org.apache.hadoop.crypto.key.KeyProviderCryptoExtension$EncryptedKeyVersion:createForDecryption(java.lang.String,java.lang.String,byte[],byte[])" : [ "<init>" ],
  "org.apache.hadoop.util.functional.TaskPool$Builder:<init>(java.lang.Iterable)" : [ "<init>", "remoteIteratorFromIterable" ],
  "org.apache.hadoop.fs.FilterFileSystem:setVerifyChecksum(boolean)" : [ "setVerifyChecksum" ],
  "org.apache.hadoop.io.file.tfile.BCFile$Reader:createReader(org.apache.hadoop.io.file.tfile.Compression$Algorithm,org.apache.hadoop.io.file.tfile.BCFile$BlockRegion)" : [ "<init>" ],
  "org.apache.hadoop.util.LightWeightResizableGSet:put(java.lang.Object)" : [ "put", "expandIfNecessary" ],
  "org.apache.hadoop.service.CompositeService:serviceInit(org.apache.hadoop.conf.Configuration)" : [ "serviceInit", "getServices" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:mkdirs(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "<init>", "isRoot", "getChildren", "toString", "getRootFallbackLink", "getTargetFileSystem", "getPathWithoutSchemeAndAuthority", "equals", "getName", "readOnlyMountTable" ],
  "org.apache.hadoop.io.ArrayPrimitiveWritable:checkDeclaredComponentType(java.lang.Class)" : [ "<init>" ],
  "org.apache.hadoop.util.functional.RemoteIterators$SingletonIterator:next()" : [ "hasNext" ],
  "org.apache.hadoop.ha.NodeFencer:fence(org.apache.hadoop.ha.HAServiceTarget)" : [ "fence" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:addTimedOperation(java.lang.String,long)" : [ "getInnerStatistics" ],
  "org.apache.hadoop.fs.FSOutputSummer:flush()" : [ "flushBuffer" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:parseBackOffResponseTimeThreshold(java.lang.String,org.apache.hadoop.conf.Configuration,int)" : [ "getTimeDurations", "getDefaultBackOffResponseTimeThresholds" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:getCallVolumeSummary()" : [ "getDecayedCallCosts" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:tag(org.apache.hadoop.metrics2.MetricsInfo,java.lang.String,boolean)" : [ "tag", "checkTagName" ],
  "org.apache.hadoop.net.SocketIOWithTimeout:doIO(java.nio.ByteBuffer,int)" : [ "select", "timeoutExceptionString" ],
  "org.apache.hadoop.fs.FsServerDefaults:readFields(java.io.DataInput)" : [ "readEnum" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider:getKeyVersion(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.InternalOperations:rename(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Options$Rename[])" : [ "rename" ],
  "org.apache.hadoop.io.ShortWritable:<init>(short)" : [ "set" ],
  "org.apache.hadoop.fs.FileSystemStorageStatistics:<init>(java.lang.String,org.apache.hadoop.fs.FileSystem$Statistics)" : [ "<init>", "checkArgument", "getData" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsLogging:mapToSortedString(java.lang.StringBuilder,java.lang.String,java.util.Map,java.util.function.Predicate)" : [ "mapToString", "sortedMap" ],
  "org.apache.hadoop.security.RuleBasedLdapGroupsMapping:getGroupsSet(java.lang.String)" : [ "getGroupsSet", "toLowerCase", "toUpperCase" ],
  "org.apache.hadoop.io.compress.BlockCompressorStream:<init>(java.io.OutputStream,org.apache.hadoop.io.compress.Compressor,int,int)" : [ "<init>" ],
  "org.apache.hadoop.io.file.tfile.ByteArray:<init>(org.apache.hadoop.io.BytesWritable)" : [ "<init>", "getBytes", "getLength" ],
  "org.apache.hadoop.security.protocolPB.RefreshAuthorizationPolicyProtocolClientSideTranslatorPB:close()" : [ "stopProxy" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$DelegationTokenInformation:<init>(long,byte[])" : [ "<init>" ],
  "org.apache.hadoop.crypto.CryptoOutputStream:<init>(java.io.OutputStream,org.apache.hadoop.crypto.CryptoCodec,int,byte[],byte[],long)" : [ "<init>" ],
  "org.apache.hadoop.io.MapFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.util.Progressable)" : [ "<init>", "keyClass", "valueClass", "compression", "progressable" ],
  "org.apache.hadoop.fs.shell.Test:registerCommands(org.apache.hadoop.fs.shell.CommandFactory)" : [ "addClass" ],
  "org.apache.hadoop.fs.AbstractFileSystem:checkPath(org.apache.hadoop.fs.Path)" : [ "<init>", "toUri", "isUriPathAbsolute", "getUri" ],
  "org.apache.hadoop.fs.FileSystem:getCanonicalServiceName()" : [ "getChildFileSystems", "buildDTServiceName", "getDefaultPort" ],
  "org.apache.hadoop.io.SequenceFile$Metadata:write(java.io.DataOutput)" : [ "write" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader:<init>(org.apache.hadoop.fs.FSDataInputStream,long,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getMetaBlock", "close", "getComparator", "getBlockCount" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding:trackDurationOfInvocation(org.apache.hadoop.fs.statistics.DurationTrackerFactory,java.lang.String,org.apache.hadoop.util.functional.InvocationRaisingIOE)" : [ "measureDurationOfInvocation" ],
  "org.apache.hadoop.fs.impl.FlagSet:buildFlagSet(java.lang.Class,org.apache.hadoop.conf.Configuration,java.lang.String,boolean)" : [ "getEnumSet", "createFlagSet" ],
  "org.apache.hadoop.ipc.Server$Connection:processSaslMessage(org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcSaslProto)" : [ "<init>", "buildSaslNegotiateResponse", "switchToSimple", "createSaslServer", "processSaslToken" ],
  "org.apache.hadoop.io.retry.AsyncCallHandler:newAsyncCall(java.lang.reflect.Method,java.lang.Object[],boolean,int,org.apache.hadoop.io.retry.RetryInvocationHandler)" : [ "<init>" ],
  "org.apache.hadoop.io.erasurecode.coder.RSErasureDecoder:<init>(org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "<init>" ],
  "org.apache.hadoop.ipc.Server$RpcCall:getHostInetAddress()" : [ "getHostInetAddress" ],
  "org.apache.hadoop.fs.FileSystem$Statistics:getReadOps()" : [ "<init>", "visitAll" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:<init>(java.lang.String,int,java.lang.String,java.util.List,java.util.List,org.apache.hadoop.ha.ActiveStandbyElector$ActiveStandbyElectorCallback,int,org.apache.hadoop.security.SecurityUtil$TruststoreKeystore)" : [ "<init>" ],
  "org.apache.hadoop.ipc.CallQueueManager:addResponseTime(java.lang.String,org.apache.hadoop.ipc.Schedulable,org.apache.hadoop.ipc.ProcessingDetails)" : [ "addResponseTime" ],
  "org.apache.hadoop.fs.local.LocalFs:<init>(org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:append(org.apache.hadoop.fs.Path,int,org.apache.hadoop.util.Progressable)" : [ "readOnlyMountTable" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:getLinkTarget(org.apache.hadoop.fs.Path)" : [ "getLinkTarget", "fullPath" ],
  "org.apache.hadoop.fs.FilterFs:delete(org.apache.hadoop.fs.Path,boolean)" : [ "checkPath" ],
  "org.apache.hadoop.fs.shell.AclCommands$GetfaclCommand:printAclEntriesForSingleScope(org.apache.hadoop.fs.permission.AclStatus,org.apache.hadoop.fs.permission.FsPermission,java.util.List)" : [ "isMinimalAcl", "toStringStable", "printExtendedAclEntry" ],
  "org.apache.hadoop.io.erasurecode.CodecUtil:createEncoder(org.apache.hadoop.conf.Configuration,org.apache.hadoop.io.erasurecode.ErasureCodecOptions)" : [ "checkNotNull", "getCodecClassName", "getSchema", "getCodecName", "createCodec" ],
  "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer:hasCapability(java.lang.String)" : [ "hasCapability", "isProbeForSyncable" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyOutputStream:cleanupAllTmpFiles()" : [ "delete" ],
  "org.apache.hadoop.fs.FsShell:printHelp(java.io.PrintStream)" : [ "printInfo" ],
  "org.apache.hadoop.crypto.key.KeyProviderCryptoExtension$DefaultCryptoExtension:generateEncryptedKey(java.lang.String)" : [ "generateEncryptedKey", "getCurrentKey", "checkNotNull", "getInstance", "getConf", "getMaterial", "getAlgorithmBlockSize" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream:writeRun()" : [ "updateCRC", "endBlock", "initBlock" ],
  "org.apache.hadoop.crypto.CryptoInputStream:cleanBufferPool()" : [ "freeDB" ],
  "org.apache.hadoop.util.DataChecksum:newDataChecksum(java.io.DataInputStream)" : [ "<init>", "newDataChecksum", "mapByteToChecksumType" ],
  "org.apache.hadoop.io.compress.GzipCodec:createDecompressor()" : [ "<init>", "isNativeZlibLoaded" ],
  "org.apache.hadoop.fs.shell.PathData:equals(java.lang.Object)" : [ "equals" ],
  "org.apache.hadoop.fs.Globber:schemeFromPath(org.apache.hadoop.fs.Path)" : [ "toUri", "getUri", "getFSofPath", "fixRelativePart" ],
  "org.apache.hadoop.io.file.tfile.BCFile$BlockRegion:write(java.io.DataOutput)" : [ "writeVLong" ],
  "org.apache.hadoop.security.UserGroupInformation:relogin(org.apache.hadoop.security.UserGroupInformation$HadoopLoginContext,boolean)" : [ "getSubjectLock", "getLogin", "unprotectedRelogin" ],
  "org.apache.hadoop.fs.GetSpaceUsed$Builder:getJitter()" : [ "getLong" ],
  "org.apache.hadoop.fs.FileContext:setXAttr(org.apache.hadoop.fs.Path,java.lang.String,byte[])" : [ "setXAttr" ],
  "org.apache.hadoop.fs.sftp.SFTPFileSystem:mkdirs(com.jcraft.jsch.ChannelSftp,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "<init>", "makeAbsolute", "getName", "exists", "getParent", "getDefault", "toUri", "isFile" ],
  "org.apache.hadoop.conf.Configuration$Resource:<init>(java.lang.Object,boolean)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:getDefaultReplication(org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.fs.FSDataInputStream:<init>(java.io.InputStream)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:tag(java.lang.String,java.lang.String,java.lang.String)" : [ "tag" ],
  "org.apache.hadoop.fs.shell.Command:processPathInternal(org.apache.hadoop.fs.shell.PathData)" : [ "processPath", "isPathRecursable", "postProcessPath" ],
  "org.apache.hadoop.ha.protocolPB.ZKFCProtocolClientSideTranslatorPB:<init>(java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory,int)" : [ "setProtocolEngine", "getProxy", "getProtocolVersion", "getCurrentUser" ],
  "org.apache.hadoop.conf.Configuration:<init>(org.apache.hadoop.conf.Configuration)" : [ "getProps", "setQuietMode", "getQuietMode", "getClassLoader" ],
  "org.apache.hadoop.util.functional.CommonCallableSupplier:waitForCompletion(java.util.List)" : [ "waitForCompletion" ],
  "org.apache.hadoop.security.UserGroupInformation:ensureInitialized()" : [ "<init>", "isInitialized", "initialize" ],
  "org.apache.hadoop.fs.FSBuilder:opt(java.lang.String,float)" : [ "optLong" ],
  "org.apache.hadoop.security.Groups$GroupCacheLoader:load(java.lang.String)" : [ "curThreadTracer", "newScope", "addKVAnnotation", "fetchGroupSet", "close" ],
  "org.apache.hadoop.metrics2.lib.DefaultMetricsSystem:newMBeanName(java.lang.String)" : [ "newObjectName" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Location:compareTo(org.apache.hadoop.io.file.tfile.TFile$Reader$Location)" : [ "compareTo" ],
  "org.apache.hadoop.io.retry.RetryPolicies:retryUpToMaximumCountWithFixedSleep(int,long,java.util.concurrent.TimeUnit)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.sink.GraphiteSink:close()" : [ "close" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockOperations:add(org.apache.hadoop.fs.impl.prefetch.BlockOperations$Operation)" : [ "getDebugInfo" ],
  "org.apache.hadoop.io.erasurecode.CodecUtil:hasCodec(java.lang.String)" : [ "getInstance", "getCoderNames" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker:constructRpcRequest(java.lang.reflect.Method,com.google.protobuf.Message)" : [ "<init>", "constructRpcRequestHeader" ],
  "org.apache.hadoop.fs.shell.Ls:processPathArgument(org.apache.hadoop.fs.shell.PathData)" : [ "isDisplayECPolicy", "getContentSummary", "getErasureCodingPolicy", "isDirectory" ],
  "org.apache.hadoop.security.token.delegation.web.KerberosDelegationTokenAuthenticator:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.FileSystem:getFSofPath(org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration)" : [ "checkNotSchemeWithRelative", "checkNotRelative", "get", "toUri" ],
  "org.apache.hadoop.fs.Options$CreateOpts:perms(org.apache.hadoop.fs.permission.FsPermission)" : [ "<init>" ],
  "org.apache.hadoop.io.SequenceFile:createWriter(org.apache.hadoop.conf.Configuration,org.apache.hadoop.io.SequenceFile$Writer$Option[])" : [ "<init>", "getValue", "getDefaultCompressionType", "prependOptions", "compression" ],
  "org.apache.hadoop.net.NetworkTopology:sortByDistance(org.apache.hadoop.net.Node,org.apache.hadoop.net.Node[],int,java.util.function.Consumer,boolean)" : [ "getWeightUsingNetworkLocation", "getWeight", "getRandom", "checkState" ],
  "org.apache.hadoop.io.file.tfile.Compression$Algorithm:returnCompressor(org.apache.hadoop.io.compress.Compressor)" : [ "returnCompressor" ],
  "org.apache.hadoop.fs.FileUtil:readLink(java.io.File)" : [ "execCommand", "getReadlinkCommand" ],
  "org.apache.hadoop.net.NetworkTopology:sortByDistance(org.apache.hadoop.net.Node,org.apache.hadoop.net.Node[],int,java.util.function.Consumer)" : [ "sortByDistance" ],
  "org.apache.hadoop.security.ShellBasedIdMapping:checkAndUpdateMaps()" : [ "isExpired", "updateMaps" ],
  "org.apache.hadoop.io.BloomMapFile$Reader:<init>(org.apache.hadoop.fs.FileSystem,java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.fs.LocalDirAllocator:getLocalPathForWrite(java.lang.String,long,org.apache.hadoop.conf.Configuration)" : [ "getLocalPathForWrite" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$MRNflyNode:<init>(org.apache.hadoop.fs.viewfs.NflyFSystem$NflyNode)" : [ "<init>" ],
  "org.apache.hadoop.io.DataInputByteBuffer$Buffer:read()" : [ "read" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getStoragePolicy(org.apache.hadoop.fs.Path)" : [ "getStoragePolicy", "resolve", "getUriPath" ],
  "org.apache.hadoop.io.file.tfile.TFile:getChunkBufferSize(org.apache.hadoop.conf.Configuration)" : [ "getInt" ],
  "org.apache.hadoop.util.bloom.CountingBloomFilter:<init>()" : [ "<init>" ],
  "org.apache.hadoop.io.compress.Lz4Codec:createInputStream(java.io.InputStream)" : [ "createInputStreamWithCodecPool" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyStatus:getGroup()" : [ "getGroup" ],
  "org.apache.hadoop.service.AbstractService:getServiceState()" : [ "getState" ],
  "org.apache.hadoop.io.erasurecode.coder.HHXORErasureEncoder:checkCreateXorRawEncoder()" : [ "createRawEncoder" ],
  "org.apache.hadoop.io.WritableComparator:<init>(java.lang.Class,boolean)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileUtil:setWritable(java.io.File,boolean)" : [ "chmod" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:processResult(int,java.lang.String,java.lang.Object,java.lang.String)" : [ "isStaleClient", "isSuccess", "becomeActive", "monitorActiveStatus", "reJoinElectionAfterFailureToBecomeActive", "isNodeExists", "becomeStandby", "shouldRetry", "createLockNodeAsync", "isSessionExpired", "fatalError" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:removeAclEntries(org.apache.hadoop.fs.Path,java.util.List)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner$Entry:getKeyStream()" : [ "reset" ],
  "org.apache.hadoop.fs.viewfs.ViewFsFileStatus:getModificationTime()" : [ "getModificationTime" ],
  "org.apache.hadoop.io.ArrayFile$Reader:get(long,org.apache.hadoop.io.Writable)" : [ "set" ],
  "org.apache.hadoop.io.compress.ZStandardCodec:checkNativeCodeLoaded()" : [ "isNativeCodeLoaded" ],
  "org.apache.hadoop.io.MD5Hash:digest(java.lang.String)" : [ "digest", "getBytes" ],
  "org.apache.hadoop.fs.permission.FsCreateModes:hashCode()" : [ "hashCode", "getUnmasked" ],
  "org.apache.hadoop.fs.FilterFileSystem:getHomeDirectory()" : [ "getHomeDirectory" ],
  "org.apache.hadoop.security.ssl.DelegatingSSLSocketFactory:createSocket(java.lang.String,int)" : [ "configureSocket" ],
  "org.apache.hadoop.fs.FileSystem$Cache$Key:<init>(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "<init>" ],
  "org.apache.hadoop.io.retry.RetryPolicies:calculateExponentialTime(long,int)" : [ "calculateExponentialTime" ],
  "org.apache.hadoop.io.SequenceFile$Writer$SyncIntervalOption:<init>(int)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.lib.MutableCounterInt:<init>(org.apache.hadoop.metrics2.MetricsInfo,int)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.util.SampleStat:reset()" : [ "reset" ],
  "org.apache.hadoop.fs.FilterFileSystem:removeAclEntries(org.apache.hadoop.fs.Path,java.util.List)" : [ "removeAclEntries" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner$Entry:getValue(byte[],int)" : [ "getValueStream", "isValueLengthKnown" ],
  "org.apache.hadoop.fs.viewfs.HCFSMountTableConfigLoader:load(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "<init>", "toUri", "getNewInstance", "listFiles", "getName", "logInvalidFileNameFormat", "open", "addResource", "close" ],
  "org.apache.hadoop.fs.statistics.impl.DynamicIOStatistics:addMaximumFunction(java.lang.String,java.util.function.Function)" : [ "addFunction" ],
  "org.apache.hadoop.fs.HarFileSystem$HarFSDataInputStream$HarFsInputStream:setReadahead(java.lang.Long)" : [ "setReadahead" ],
  "org.apache.hadoop.util.dynamic.DynMethods$Builder:buildChecked(java.lang.Object)" : [ "buildChecked", "bind" ],
  "org.apache.hadoop.security.ssl.DelegatingSSLSocketFactory:initializeSSLContext(org.apache.hadoop.security.ssl.DelegatingSSLSocketFactory$SSLChannelMode)" : [ "bindToOpenSSLProvider" ],
  "org.apache.hadoop.fs.FileSystem:getLocal(org.apache.hadoop.conf.Configuration)" : [ "get" ],
  "org.apache.hadoop.util.Shell:getHadoopHomeDir()" : [ "fileNotFoundException", "addOsText" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL:<init>(org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator,org.apache.hadoop.security.authentication.client.ConnectionConfigurator)" : [ "obtainDelegationTokenAuthenticator" ],
  "org.apache.hadoop.net.ScriptBasedMappingWithDependency$RawScriptBasedMappingWithDependency:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.FilterFs:getDelegationTokens(java.lang.String)" : [ "getDelegationTokens" ],
  "org.apache.hadoop.io.DataOutputBuffer:<init>(int)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileSystem:createBulkDelete(org.apache.hadoop.fs.Path)" : [ "<init>" ],
  "org.apache.hadoop.conf.StorageUnit$7:getDefault(double)" : [ "toBytes" ],
  "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker:getIOStatistics()" : [ "retrieveIOStatistics" ],
  "org.apache.hadoop.fs.FileUtil:fullyDeleteContents(java.io.File)" : [ "fullyDeleteContents" ],
  "org.apache.hadoop.net.CachedDNSToSwitchMapping:resolve(java.util.List)" : [ "normalizeHostNames", "getUncachedHosts", "cacheResolvedHosts", "getCachedHosts" ],
  "org.apache.hadoop.fs.FileContext:resolveIntermediate(org.apache.hadoop.fs.Path)" : [ "getPath" ],
  "org.apache.hadoop.metrics2.sink.ganglia.GangliaSink30:emitMetric(java.lang.String,java.lang.String,java.lang.String,java.lang.String,org.apache.hadoop.metrics2.sink.ganglia.GangliaConf,org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink$GangliaSlope)" : [ "getUnits", "getTmax", "getDmax" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedIO:streamCapabilities_hasCapability(java.lang.Object,java.lang.String)" : [ "available", "invoke" ],
  "org.apache.hadoop.tools.GetGroupsBase:<init>(org.apache.hadoop.conf.Configuration,java.io.PrintStream)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor:executeHeaderState()" : [ "checkAndCopyBytesToLocal", "processBasicHeader", "readUShortLE", "checkAndSkipBytes", "checkAndSkipBytesUntilNull", "copyBytesToLocal" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyStatus:getAccessTime()" : [ "getAccessTime" ],
  "org.apache.hadoop.fs.FilterFileSystem:truncate(org.apache.hadoop.fs.Path,long)" : [ "truncate" ],
  "org.apache.hadoop.io.nativeio.NativeIO:getOwner(java.io.FileDescriptor)" : [ "<init>", "ensureInitialized", "stripDomain" ],
  "org.apache.hadoop.fs.FileSystem$Cache:closeAll(boolean)" : [ "close", "createIOException" ],
  "org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory:createKeyManagersFromConfiguration(org.apache.hadoop.security.ssl.SSLFactory$Mode,java.lang.String,long)" : [ "<init>", "resolvePropertyName", "get", "getPassword" ],
  "org.apache.hadoop.fs.http.HttpFileSystem:getFileStatus(org.apache.hadoop.fs.Path)" : [ "getFileStatus" ],
  "org.apache.hadoop.io.file.tfile.BCFile$DataIndex:<init>(java.lang.String)" : [ "getCompressionAlgorithmByName" ],
  "org.apache.hadoop.util.GcTimeMonitor:<init>(long,long,int,org.apache.hadoop.util.GcTimeMonitor$GcTimeAlertHandler)" : [ "checkArgument" ],
  "org.apache.hadoop.conf.Configuration:setTimeDuration(java.lang.String,long,java.util.concurrent.TimeUnit)" : [ "set", "unitFor" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:reJoinElection(int)" : [ "terminateConnection", "sleepFor", "joinElectionInternal" ],
  "org.apache.hadoop.util.curator.ZKCuratorManager:getZKAuths(org.apache.hadoop.conf.Configuration)" : [ "getZKAuthInfos" ],
  "org.apache.hadoop.ipc.RPC:waitForProtocolProxy(java.lang.Class,long,java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration,int,org.apache.hadoop.io.retry.RetryPolicy,long)" : [ "now", "getProtocolProxy", "getCurrentUser", "getDefaultSocketFactory" ],
  "org.apache.hadoop.security.Credentials:readTokenStorageFile(org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getFileSystem", "open", "readTokenStorageStream", "wrapException", "toString", "cleanupWithLogger" ],
  "org.apache.hadoop.ipc.RetryCache:setState(org.apache.hadoop.ipc.RetryCache$CacheEntry,boolean)" : [ "completed" ],
  "org.apache.hadoop.security.SecurityUtil:login(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String)" : [ "login", "getLocalHostName" ],
  "org.apache.hadoop.metrics2.sink.RollingFileSystemSink:checkIfPropertyExists(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.AbstractFileSystem:clearStatistics()" : [ "reset" ],
  "org.apache.hadoop.security.UserGroupInformation:forceReloginFromTicketCache()" : [ "reloginFromTicketCache" ],
  "org.apache.hadoop.fs.impl.prefetch.CachingBlockManager:read(org.apache.hadoop.fs.impl.prefetch.BufferData)" : [ "readBlock", "getBlockNumber" ],
  "org.apache.hadoop.security.authorize.ServiceAuthorizationManager:refreshWithLoadedConfiguration(org.apache.hadoop.conf.Configuration,org.apache.hadoop.security.authorize.PolicyProvider)" : [ "<init>", "get", "getHostKey", "getServiceKey", "getProtocol" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:isIOStatistics(java.lang.Object)" : [ "ioStatisticsAvailable", "invoke" ],
  "org.apache.hadoop.fs.shell.Command:processArguments(java.util.LinkedList)" : [ "processArgument", "displayError" ],
  "org.apache.hadoop.io.erasurecode.coder.HHXORErasureEncoder:prepareEncodingStep(org.apache.hadoop.io.erasurecode.ECBlockGroup)" : [ "<init>", "checkCreateRSRawEncoder", "checkCreateXorRawEncoder" ],
  "org.apache.hadoop.fs.shell.CommandWithDestination:getLocalDestination(java.util.LinkedList)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileSystem:setXAttr(org.apache.hadoop.fs.Path,java.lang.String,byte[])" : [ "setXAttr" ],
  "org.apache.hadoop.io.wrappedio.WrappedStatistics:iostatistics_minimums(java.io.Serializable)" : [ "applyToIOStatisticsSnapshot", "minimums" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:iostatisticsSnapshot_retrieve(java.lang.Object)" : [ "checkIoStatisticsAvailable", "invoke" ],
  "org.apache.hadoop.ipc.Server$RpcCall:setDeferredError(java.lang.Throwable)" : [ "getServer", "populateResponseParamsOnError", "sendDeferedResponse" ],
  "org.apache.hadoop.io.erasurecode.coder.HHXORErasureEncodingStep:performCoding(org.apache.hadoop.io.erasurecode.ECChunk[],org.apache.hadoop.io.erasurecode.ECChunk[])" : [ "performCoding", "toBuffers" ],
  "org.apache.hadoop.io.file.tfile.Compression$Algorithm$1:isSupported()" : [ "newInstance", "getBoolean" ],
  "org.apache.hadoop.fs.FileUtil:getJarsInDirectory(java.lang.String)" : [ "getJarsInDirectory" ],
  "org.apache.hadoop.conf.Configuration:getRange(java.lang.String,java.lang.String)" : [ "<init>", "get" ],
  "org.apache.hadoop.io.retry.LossyRetryInvocationHandler:<init>(int,org.apache.hadoop.io.retry.FailoverProxyProvider,org.apache.hadoop.io.retry.RetryPolicy)" : [ "<init>" ],
  "org.apache.hadoop.io.file.tfile.Chunk$ChunkDecoder:read()" : [ "checkEOF" ],
  "org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter:init(javax.servlet.FilterConfig)" : [ "<init>" ],
  "org.apache.hadoop.io.nativeio.NativeIO:getMemlockLimit()" : [ "isAvailable" ],
  "org.apache.hadoop.fs.ChecksumFileSystem:createFile(org.apache.hadoop.fs.Path)" : [ "create", "overwrite" ],
  "org.apache.hadoop.fs.shell.find.ExpressionFactory:createExpression(java.lang.Class,org.apache.hadoop.conf.Configuration)" : [ "newInstance" ],
  "org.apache.hadoop.metrics2.lib.MutableGauge:<init>(org.apache.hadoop.metrics2.MetricsInfo)" : [ "checkNotNull" ],
  "org.apache.hadoop.security.SecurityUtil:doAsLoginUser(java.security.PrivilegedExceptionAction)" : [ "doAsUser", "getLoginUser" ],
  "org.apache.hadoop.metrics2.impl.MetricsSourceAdapter:updateInfoCache(java.lang.Iterable)" : [ "checkNotNull", "reset", "get" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:incrRequeueCalls()" : [ "incr" ],
  "org.apache.hadoop.fs.VectoredReadUtils:readVectored(org.apache.hadoop.fs.PositionedReadable,java.util.List,java.util.function.IntFunction)" : [ "validateAndSortRanges", "readRangeFrom" ],
  "org.apache.hadoop.fs.GlobFilter:hasPattern()" : [ "hasWildcard" ],
  "org.apache.hadoop.fs.HarFileSystem:getFileHarStatus(org.apache.hadoop.fs.Path)" : [ "makeQualified", "getPathInHar" ],
  "org.apache.hadoop.fs.permission.UmaskParser:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.conf.Configuration:parse(java.net.URL,boolean)" : [ "parse" ],
  "org.apache.hadoop.crypto.key.UserProvider:createKey(java.lang.String,byte[],org.apache.hadoop.crypto.key.KeyProvider$Options)" : [ "<init>", "getSecretKey", "getBitLength", "getCipher", "getDescription", "getAttributes", "addSecretKey", "serialize" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:aggregate(org.apache.hadoop.fs.statistics.IOStatistics)" : [ "getInnerStatistics" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:decryptEncryptedKey(org.apache.hadoop.crypto.key.KeyProviderCryptoExtension$EncryptedKeyVersion)" : [ "checkNotNull", "getEncryptionKeyVersionName", "getEncryptedKeyIv", "checkArgument", "getEncryptedKeyVersion", "getVersionName", "getEncryptionKeyName", "getMaterial", "createURL", "createConnection", "call", "parseJSONKeyVersion" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:read0()" : [ "setupRandPartB", "setupRandPartC", "setupNoRandPartB", "setupNoRandPartC" ],
  "org.apache.hadoop.metrics2.impl.MetricsRecordBuilderImpl:addGauge(org.apache.hadoop.metrics2.MetricsInfo,int)" : [ "<init>" ],
  "org.apache.hadoop.fs.permission.RawParser:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.RegexMountPoint:initialize()" : [ "getVarListInString", "initializeInterceptors" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine$Server:processCall(org.apache.hadoop.ipc.RPC$Server,java.lang.String,org.apache.hadoop.ipc.RpcWritable$Buffer,java.lang.String,org.apache.hadoop.ipc.RPC$Server$ProtoClassProtoImpl)" : [ "<init>", "getValue", "init", "setDetailedMetricsName", "deferResponse", "wrap" ],
  "org.apache.hadoop.metrics2.MetricStringBuilder:add(org.apache.hadoop.metrics2.AbstractMetric)" : [ "add", "info", "toString" ],
  "org.apache.hadoop.crypto.CryptoInputStream:resetStreamOffset(long)" : [ "updateDecryptor", "getPadding" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker:<init>(java.lang.Class,org.apache.hadoop.ipc.Client$ConnectionId,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory,org.apache.hadoop.ipc.AlignmentContext)" : [ "getClient", "getProtocolName", "getProtocolVersion" ],
  "org.apache.hadoop.util.functional.CommonCallableSupplier:submit(java.util.concurrent.Executor,java.util.concurrent.Callable)" : [ "<init>" ],
  "org.apache.hadoop.security.authorize.DefaultImpersonationProvider:getProxyGroups()" : [ "getGroups" ],
  "org.apache.hadoop.fs.shell.CopyCommands$Merge:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "isDirectory" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsContextImpl:<init>(long,long)" : [ "<init>" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:getEncKeyQueueSize(java.lang.String)" : [ "getSize" ],
  "org.apache.hadoop.crypto.CryptoInputStream:read(long,byte[],int,int)" : [ "checkStream", "decrypt" ],
  "org.apache.hadoop.fs.FileContext$Util:listStatus(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.PathFilter)" : [ "listStatus" ],
  "org.apache.hadoop.fs.shell.Ls:initialiseOrderComparator()" : [ "isOrderTime", "isOrderSize" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getStatus(org.apache.hadoop.fs.Path)" : [ "getStatus", "resolve", "getUriPath" ],
  "org.apache.hadoop.ipc.Server$ConnectionManager:startIdleScan()" : [ "scheduleIdleScanTask" ],
  "org.apache.hadoop.fs.impl.AbstractFSBuilderImpl:mustLong(java.lang.String,long)" : [ "must" ],
  "org.apache.hadoop.fs.permission.FsPermission:createImmutable(short)" : [ "<init>" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:zkDoWithRetries(org.apache.hadoop.ha.ActiveStandbyElector$ZKAction)" : [ "zkDoWithRetries" ],
  "org.apache.hadoop.security.ShellBasedUnixGroupsMapping:getGroupsIDForUserCommand(java.lang.String)" : [ "getGroupsIDForUserCommand" ],
  "org.apache.hadoop.util.concurrent.HadoopExecutors:newFixedThreadPool(int)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.impl.MetricsRecordBuilderImpl:addCounter(org.apache.hadoop.metrics2.MetricsInfo,long)" : [ "<init>" ],
  "org.apache.hadoop.io.retry.RetryPolicies$RemoteExceptionDependentRetry:shouldRetry(java.lang.Exception,int,int,boolean)" : [ "getClassName" ],
  "org.apache.hadoop.io.compress.ZStandardCodec:createCompressor()" : [ "<init>", "checkNativeCodeLoaded", "getCompressionLevel", "getCompressionBufferSize" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Decompressor:needsInput()" : [ "setInputFromSavedData" ],
  "org.apache.hadoop.fs.PathAccessDeniedException:<init>(java.lang.String,java.lang.String,java.lang.Throwable)" : [ "<init>" ],
  "org.apache.hadoop.io.compress.zlib.ZlibDecompressor:<init>(org.apache.hadoop.io.compress.zlib.ZlibDecompressor$CompressionHeader,int)" : [ "windowBits" ],
  "org.apache.hadoop.security.KDiag:failif(boolean,java.lang.String,java.lang.String,java.lang.Object[])" : [ "fail" ],
  "org.apache.hadoop.metrics2.sink.RollingFileSystemSink:checkAppend(org.apache.hadoop.fs.FileSystem)" : [ "append" ],
  "org.apache.hadoop.util.DiskChecker:checkDirInternal(java.io.File)" : [ "<init>", "mkdirsWithExistsCheck", "checkAccessByFileMethods" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenManager$DelegationTokenSecretManager:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.io.Text)" : [ "<init>", "getLong" ],
  "org.apache.hadoop.fs.shell.Ls:processPaths(org.apache.hadoop.fs.shell.PathData,org.apache.hadoop.fs.shell.PathData[])" : [ "getOrderComparator", "adjustColumnWidths" ],
  "org.apache.hadoop.metrics2.sink.ganglia.GangliaSink30:appendPrefix(org.apache.hadoop.metrics2.MetricsRecord,java.lang.StringBuilder)" : [ "name", "info", "value" ],
  "org.apache.hadoop.io.compress.PassthroughCodec:createInputStream(java.io.InputStream)" : [ "createInputStream" ],
  "org.apache.hadoop.metrics2.impl.MBeanInfoBuilder:newAttrInfo(org.apache.hadoop.metrics2.MetricsInfo,java.lang.String)" : [ "newAttrInfo" ],
  "org.apache.hadoop.security.Credentials:<init>(org.apache.hadoop.security.Credentials)" : [ "addAll" ],
  "org.apache.hadoop.util.WeakReferenceMap:toString()" : [ "size" ],
  "org.apache.hadoop.io.SequenceFile$Reader:nextRaw(org.apache.hadoop.io.DataOutputBuffer,org.apache.hadoop.io.SequenceFile$ValueBytes)" : [ "readRecordLength", "write", "getPos", "readBlock", "readVInt", "seekToCurrentValue" ],
  "org.apache.hadoop.metrics2.lib.MetricsRegistry:newStat(java.lang.String,java.lang.String,java.lang.String,java.lang.String)" : [ "newStat" ],
  "org.apache.hadoop.io.MD5Hash:digest(byte[])" : [ "digest" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationHandler:isManagementOperation(javax.servlet.http.HttpServletRequest)" : [ "getParameter", "toUpperCase" ],
  "org.apache.hadoop.fs.Options$CreateOpts:createParent()" : [ "<init>" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:cachedOrComputedPriorityLevel(java.lang.Object)" : [ "computePriorityLevel" ],
  "org.apache.hadoop.crypto.key.KeyProvider:generateKey(int,java.lang.String)" : [ "getAlgorithm" ],
  "org.apache.hadoop.io.MD5Hash:digest(org.apache.hadoop.io.UTF8)" : [ "digest", "getBytes", "getLength" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:minimums()" : [ "getInnerStatistics" ],
  "org.apache.hadoop.metrics2.util.SampleQuantiles:insert(long)" : [ "insertBatch", "compress" ],
  "org.apache.hadoop.security.UserGroupInformation:getRealAuthenticationMethod(org.apache.hadoop.security.UserGroupInformation)" : [ "getAuthenticationMethod", "getRealUser" ],
  "org.apache.hadoop.ipc.Server$Responder:run()" : [ "doRunLoop" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2$RpcProtobufRequest:<init>(org.apache.hadoop.ipc.protobuf.ProtobufRpcEngine2Protos$RequestHeaderProto,org.apache.hadoop.thirdparty.protobuf.Message)" : [ "<init>" ],
  "org.apache.hadoop.security.UserGroupInformation:getRealUserOrSelf(org.apache.hadoop.security.UserGroupInformation)" : [ "getRealUser" ],
  "org.apache.hadoop.io.Text:equals(java.lang.Object)" : [ "equals" ],
  "org.apache.hadoop.ipc.protocolPB.GenericRefreshProtocolClientSideTranslatorPB:isMethodSupported(java.lang.String)" : [ "isMethodSupported", "getProtocolVersion" ],
  "org.apache.hadoop.fs.shell.CopyCommands$Put:expandArgument(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.XAttrCommands$SetfattrCommand:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "setXAttr", "removeXAttr" ],
  "org.apache.hadoop.fs.impl.prefetch.CachingBlockManager:toString()" : [ "toString" ],
  "org.apache.hadoop.security.token.DtUtilShell:maybeDoLoginFromKeytabAndPrincipal(java.lang.String[])" : [ "loginUserFromKeytab" ],
  "org.apache.hadoop.io.DataOutputBuffer:<init>()" : [ "<init>" ],
  "org.apache.hadoop.ipc.Server:getRemoteAddress()" : [ "getRemoteIp" ],
  "org.apache.hadoop.service.launcher.InterruptEscalator:register(java.lang.String)" : [ "<init>", "bind" ],
  "org.apache.hadoop.security.SaslOutputStream:write(byte[],int,int)" : [ "disposeSasl" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.NativeXORRawDecoder:preferDirectBuffer()" : [ "preferDirectBuffer" ],
  "org.apache.hadoop.io.compress.PassthroughCodec:createInputStream(java.io.InputStream,org.apache.hadoop.io.compress.Decompressor)" : [ "<init>" ],
  "org.apache.hadoop.security.RuleBasedLdapGroupsMapping:getGroups(java.lang.String)" : [ "getGroups", "toLowerCase", "toUpperCase" ],
  "org.apache.hadoop.util.LineReader:readLine(org.apache.hadoop.io.Text)" : [ "readLine" ],
  "org.apache.hadoop.io.MapFile$Reader:seekInternal(org.apache.hadoop.io.WritableComparable,boolean)" : [ "readIndex", "compare", "binarySearch", "seek", "newKey", "next", "getPosition" ],
  "org.apache.hadoop.fs.impl.prefetch.SingleFilePerBlockCache:close()" : [ "getStats", "deleteCacheFiles" ],
  "org.apache.hadoop.fs.store.DataBlocks$ByteArrayBlock:write(byte[],int,int)" : [ "write", "remainingCapacity" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:invalidateCache(java.lang.String)" : [ "checkNotEmpty", "createURL", "createConnection", "call", "drain" ],
  "org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext:getLocalPathForWrite(java.lang.String,long,org.apache.hadoop.conf.Configuration,boolean)" : [ "<init>", "confChanged", "getAvailable", "getDirPath", "createPath", "getAndIncrDirNumLastAccessed" ],
  "org.apache.hadoop.fs.statistics.impl.WrappedIOStatistics:counters()" : [ "getWrapped" ],
  "org.apache.hadoop.security.ShellBasedIdMapping:updateStaticMapping()" : [ "<init>", "parseStaticMap", "clear" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RawErasureDecoder:allowChangeInputs()" : [ "allowChangeInputs" ],
  "org.apache.hadoop.ipc.Server:getNumOpenConnections()" : [ "size" ],
  "org.apache.hadoop.net.NetUtils:createSocketAddr(java.lang.String,int,java.lang.String,boolean,boolean)" : [ "createURI", "createSocketAddrForHost" ],
  "org.apache.hadoop.fs.VectoredReadUtils:readNonByteBufferPositionedReadable(org.apache.hadoop.fs.PositionedReadable,org.apache.hadoop.fs.FileRange,java.nio.ByteBuffer)" : [ "readInDirectBuffer" ],
  "org.apache.hadoop.fs.GlobFilter:<init>(java.lang.String)" : [ "init" ],
  "org.apache.hadoop.io.retry.RetryPolicies:failoverOnNetworkException(org.apache.hadoop.io.retry.RetryPolicy,int,int,long,long)" : [ "<init>" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:getProcessingMean()" : [ "mean" ],
  "org.apache.hadoop.ipc.ResponseBuffer:writeTo(java.io.OutputStream)" : [ "getFramedBuffer" ],
  "org.apache.hadoop.security.token.DtUtilShell$Get:execute()" : [ "getTokenFile" ],
  "org.apache.hadoop.util.functional.RemoteIterators$WrappingRemoteIterator:sourceNext()" : [ "sourceHasNext", "getSource", "cleanupWithLogger" ],
  "org.apache.hadoop.util.StringUtils:stringToPath(java.lang.String[])" : [ "<init>" ],
  "org.apache.hadoop.fs.ftp.FTPInputStream:read(byte[],int,int)" : [ "incrementBytesRead" ],
  "org.apache.hadoop.fs.FilterFs:getEnclosingRoot(org.apache.hadoop.fs.Path)" : [ "getEnclosingRoot" ],
  "org.apache.hadoop.fs.FSDataInputStream:releaseBuffer(java.nio.ByteBuffer)" : [ "remove" ],
  "org.apache.hadoop.ha.HAAdmin:checkHealth(org.apache.commons.cli.CommandLine)" : [ "printUsage", "getProxy", "monitorHealth", "createReqInfo" ],
  "org.apache.hadoop.util.ClassUtil:findClassLocation(java.lang.Class)" : [ "findContainingResource" ],
  "org.apache.hadoop.net.SocketIOWithTimeout:waitForIO(int)" : [ "select", "timeoutExceptionString" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:bsGetUByte()" : [ "bsR" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.util.GaloisField:add(int,int)" : [ "getFieldSize" ],
  "org.apache.hadoop.util.XMLUtils:newSecureSAXTransformerFactory()" : [ "setOptionalSecureTransformerAttributes" ],
  "org.apache.hadoop.fs.viewfs.InodeTree:resolve(java.lang.String,boolean)" : [ "<init>", "breakIntoPathComponents", "getRootDir", "getInternalDirFs", "getRootLink", "getTargetFileSystem", "checkState", "tryResolveInRegexMountpoint", "resolveInternal", "getLink", "getRemainingPath", "hasFallbackLink", "getRootFallbackLink", "isLink" ],
  "org.apache.hadoop.fs.AbstractFileSystem:resolvePath(org.apache.hadoop.fs.Path)" : [ "checkPath", "getPath" ],
  "org.apache.hadoop.util.Shell:getWinUtilsFile()" : [ "fileNotFoundException" ],
  "org.apache.hadoop.fs.BlockLocation:<init>(java.lang.String[],java.lang.String[],java.lang.String[],long,long)" : [ "<init>" ],
  "org.apache.hadoop.fs.FilterFs:supportsSymlinks()" : [ "supportsSymlinks" ],
  "org.apache.hadoop.fs.shell.Mkdir:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "isDirectory", "toString" ],
  "org.apache.hadoop.util.hash.JenkinsHash:hash(byte[],int,int)" : [ "rot" ],
  "org.apache.hadoop.fs.permission.FsPermission:setUMask(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.permission.FsPermission)" : [ "set", "toShort" ],
  "org.apache.hadoop.metrics2.lib.MutableGaugeInt:incr()" : [ "incr" ],
  "org.apache.hadoop.util.Lists:newArrayList(java.lang.Iterable)" : [ "newArrayList", "cast" ],
  "org.apache.hadoop.security.UserGroupInformation:getUGIFromTicketCache(java.lang.String,java.lang.String)" : [ "<init>", "isAuthenticationMethodEnabled", "getBestUGI", "put", "doSubjectLogin" ],
  "org.apache.hadoop.fs.FsShell:getFS()" : [ "get" ],
  "org.apache.hadoop.fs.FileContext:removeDefaultAcl(org.apache.hadoop.fs.Path)" : [ "fixRelativePart" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockOperations$End:getSummary(java.lang.StringBuilder)" : [ "getSummary" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:fullPath(org.apache.hadoop.fs.Path)" : [ "<init>", "checkPath", "isRoot", "toUri" ],
  "org.apache.hadoop.security.UserGroupInformation$RealUser:toString()" : [ "toString" ],
  "org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider:initFileSystem(java.net.URI)" : [ "unnestUri" ],
  "org.apache.hadoop.io.compress.BZip2Codec:createCompressor()" : [ "getBzip2Compressor" ],
  "org.apache.hadoop.ha.ActiveStandbyElector:toString()" : [ "byteToHexString" ],
  "org.apache.hadoop.io.file.tfile.TFile$Writer:prepareMetaBlock(java.lang.String,java.lang.String)" : [ "prepareMetaBlock", "finishDataBlock" ],
  "org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping:<init>()" : [ "<init>" ],
  "org.apache.hadoop.io.SequenceFile$Reader:openFile(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,int,long)" : [ "openFile", "awaitFuture", "build" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:getFileStatus(org.apache.hadoop.fs.Path)" : [ "<init>", "checkPathIsSlash", "getShortUserName", "getPrimaryGroupName", "makeQualified" ],
  "org.apache.hadoop.util.functional.FutureIO:raiseInnerCause(java.util.concurrent.ExecutionException)" : [ "unwrapInnerException" ],
  "org.apache.hadoop.fs.permission.ScopedAclEntries:<init>(java.util.List)" : [ "calculatePivotOnDefaultEntries" ],
  "org.apache.hadoop.security.token.Token:<init>(org.apache.hadoop.security.token.Token)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.find.Name:<init>(boolean)" : [ "setCaseSensitive" ],
  "org.apache.hadoop.conf.Configuration:getLocalPath(java.lang.String,java.lang.String)" : [ "<init>", "getTrimmedStrings", "getLocal", "getParent" ],
  "org.apache.hadoop.io.compress.zlib.ZlibDecompressor:needsInput()" : [ "setInputFromSavedData" ],
  "org.apache.hadoop.security.ShellBasedIdMapping:updateMapIncr(int,boolean)" : [ "checkSupportedPlatform", "updateStaticMapping", "updateMapInternal", "getId2NameCmdNIX", "getId2NameCmdMac", "monotonicNow" ],
  "org.apache.hadoop.crypto.JceCtrCryptoCodec$JceCtrCipher:init(byte[],byte[])" : [ "checkNotNull" ],
  "org.apache.hadoop.fs.HarFileSystem$HarFSDataInputStream$HarFsInputStream:read(long,byte[],int,int)" : [ "read" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler$MetricsProxy:getUniqueIdentityCount()" : [ "getUniqueIdentityCount" ],
  "org.apache.hadoop.fs.FileContext:createSymlink(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,boolean)" : [ "areSymlinksEnabled", "fixRelativePart" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager:removeExpiredKeys()" : [ "now", "getExpiryDate", "equals", "removeStoredMasterKey" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsContext:enabled()" : [ "isIOStatisticsThreadLevelEnabled" ],
  "org.apache.hadoop.util.functional.RemoteIterators$HaltableRemoteIterator:hasNext()" : [ "sourceHasNext" ],
  "org.apache.hadoop.ipc.Server$Call:<init>(org.apache.hadoop.ipc.Server$Call)" : [ "<init>" ],
  "org.apache.hadoop.ha.HAServiceTarget:getFencingParameters()" : [ "addFencingParameters" ],
  "org.apache.hadoop.util.SysInfoLinux:getNetworkBytesRead()" : [ "readProcNetInfoFile" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.DecodingState:checkParameters(java.lang.Object[],int[],java.lang.Object[])" : [ "<init>", "getNumParityUnits", "getNumDataUnits" ],
  "org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider:getKeys()" : [ "doOp", "nextIdx" ],
  "org.apache.hadoop.fs.statistics.impl.StorageStatisticsFromIOStatistics:getLong(java.lang.String)" : [ "counters", "gauges" ],
  "org.apache.hadoop.crypto.JceSm4CtrCryptoCodec:createEncryptor()" : [ "<init>", "getCipherSuite" ],
  "org.apache.hadoop.io.MapFile$Writer:comparator(org.apache.hadoop.io.WritableComparator)" : [ "<init>" ],
  "org.apache.hadoop.fs.FilterFs:getFileBlockLocations(org.apache.hadoop.fs.Path,long,long)" : [ "checkPath" ],
  "org.apache.hadoop.conf.Configuration:setDeprecatedProperties()" : [ "getProps", "getOverlay", "getDeprecatedKeyMap" ],
  "org.apache.hadoop.io.WritableComparator:readFloat(byte[],int)" : [ "readInt" ],
  "org.apache.hadoop.io.erasurecode.coder.ErasureDecoder:getNumErasedBlocks(org.apache.hadoop.io.erasurecode.ECBlock[])" : [ "isErased" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getXAttrs(org.apache.hadoop.fs.Path)" : [ "getXAttrs", "resolve", "getUriPath" ],
  "org.apache.hadoop.fs.DelegationTokenRenewer$RenewAction:<init>(org.apache.hadoop.fs.FileSystem)" : [ "updateRenewalTime" ],
  "org.apache.hadoop.fs.FileSystem:create(org.apache.hadoop.fs.Path,boolean)" : [ "create", "getInt", "getDefaultReplication", "getDefaultBlockSize" ],
  "org.apache.hadoop.io.wrappedio.WrappedIO:bulkDelete_delete(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,java.util.Collection)" : [ "uncheckIOExceptions" ],
  "org.apache.hadoop.ipc.Server$Connection:getMessage(org.apache.hadoop.thirdparty.protobuf.Message,org.apache.hadoop.ipc.RpcWritable$Buffer)" : [ "<init>", "getValue" ],
  "org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem:rename(org.apache.hadoop.fs.shell.PathData,org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "toString", "setOperation", "setTargetPath" ],
  "org.apache.hadoop.fs.BlockLocation:setStorageIds(java.lang.String[])" : [ "internStringsInArray" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:getAllStoragePolicies()" : [ "getAllStoragePolicies" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:listStatus(org.apache.hadoop.fs.Path)" : [ "listStatus", "connect", "disconnect" ],
  "org.apache.hadoop.fs.FileContext:modifyAclEntries(org.apache.hadoop.fs.Path,java.util.List)" : [ "fixRelativePart" ],
  "org.apache.hadoop.util.InstrumentedLock:tryLock(long,java.util.concurrent.TimeUnit)" : [ "monotonicNow", "startLockTiming", "check" ],
  "org.apache.hadoop.fs.LocalDirAllocator:getCurrentDirectoryIndex()" : [ "getCurrentDirectoryIndex", "obtainContext" ],
  "org.apache.hadoop.util.InstrumentedWriteLock:startLockTiming()" : [ "monotonicNow" ],
  "org.apache.hadoop.io.IOUtils:copyBytes(java.io.InputStream,java.io.OutputStream,org.apache.hadoop.conf.Configuration)" : [ "copyBytes", "getInt" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getFileBlockLocations(org.apache.hadoop.fs.FileStatus,long,long)" : [ "<init>", "getFileBlockLocations", "resolve", "getUriPath", "getPath" ],
  "org.apache.hadoop.io.file.tfile.BCFile$MetaIndex:<init>(java.io.DataInput)" : [ "<init>", "readVInt", "getMetaName" ],
  "org.apache.hadoop.fs.HarFileSystem:fileStatusesInIndex(org.apache.hadoop.fs.HarFileSystem$HarStatus,java.util.List)" : [ "<init>", "getName", "toFileStatus" ],
  "org.apache.hadoop.fs.FSInputChecker:skip(long)" : [ "seek", "getPos" ],
  "org.apache.hadoop.ipc.RPC:stopProxy(java.lang.Object)" : [ "<init>" ],
  "org.apache.hadoop.security.SaslPlainServer$SaslPlainServerFactory:createSaslServer(java.lang.String,java.lang.String,java.lang.String,java.util.Map,javax.security.auth.callback.CallbackHandler)" : [ "<init>" ],
  "org.apache.hadoop.service.LoggingStateChangeListener:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem:listStatus(org.apache.hadoop.fs.Path)" : [ "listStatus", "workSet", "processThrowable", "mayThrowFileNotFound", "createIOException" ],
  "org.apache.hadoop.io.MD5Hash:digest(java.io.InputStream)" : [ "<init>", "getDigester" ],
  "org.apache.hadoop.metrics2.lib.DefaultMetricsSystem:removeSourceName(java.lang.String)" : [ "removeSource" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:getDelegationToken(java.lang.String)" : [ "<init>", "createURL", "getDoAsUser", "getActualUgi", "doAs", "setService" ],
  "org.apache.hadoop.io.BloomMapFile$Reader:get(org.apache.hadoop.io.WritableComparable,org.apache.hadoop.io.Writable)" : [ "get", "probablyHasKey" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:setXAttr(org.apache.hadoop.fs.Path,java.lang.String,byte[],java.util.EnumSet)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.fs.impl.AbstractFSBuilderImpl:opt(java.lang.String,double)" : [ "optLong" ],
  "org.apache.hadoop.fs.FileUtil:unZip(java.io.File,java.io.File)" : [ "permissionsFromMode" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:listLocatedStatus(org.apache.hadoop.fs.Path)" : [ "listLocatedStatus", "fullPath" ],
  "org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL:getDelegationToken(java.net.URL,org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL$Token,java.lang.String,java.lang.String)" : [ "checkNotNull" ],
  "org.apache.hadoop.fs.BufferedFSInputStream:minSeekForVectorReads()" : [ "minSeekForVectorReads" ],
  "org.apache.hadoop.fs.FileSystem:copyFromLocalFile(boolean,boolean,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "copy", "getLocal" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:getFileChecksum(org.apache.hadoop.fs.Path)" : [ "fullPath" ],
  "org.apache.hadoop.io.IntWritable:<init>(int)" : [ "set" ],
  "org.apache.hadoop.fs.FileContext:setWorkingDirectory(org.apache.hadoop.fs.Path)" : [ "<init>", "checkNotSchemeWithRelative", "getFileStatus", "isFile" ],
  "org.apache.hadoop.fs.FileUtil:unTarUsingTar(java.io.InputStream,java.io.File,boolean)" : [ "makeSecureShellPath", "runCommandOnStream" ],
  "org.apache.hadoop.fs.ChecksumFileSystem:copyToLocalFile(boolean,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "copy" ],
  "org.apache.hadoop.util.DiskChecker:checkDir(java.io.File)" : [ "checkDirInternal" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:satisfyStoragePolicy(org.apache.hadoop.fs.Path)" : [ "satisfyStoragePolicy" ],
  "org.apache.hadoop.conf.Configuration:addResource(java.io.InputStream,java.lang.String)" : [ "<init>", "addResourceObject" ],
  "org.apache.hadoop.fs.shell.PathData:hashCode()" : [ "hashCode" ],
  "org.apache.hadoop.net.NetUtils:connect(java.net.Socket,java.net.SocketAddress,java.net.SocketAddress,int)" : [ "<init>", "connect", "checkArgument" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getFileStatus(org.apache.hadoop.fs.Path)" : [ "resolve", "getUriPath", "fixFileStatus" ],
  "org.apache.hadoop.crypto.CryptoStreamUtils:checkCodec(org.apache.hadoop.crypto.CryptoCodec)" : [ "<init>" ],
  "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer:close()" : [ "close" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:createNonRecursive(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,boolean,int,short,long,org.apache.hadoop.util.Progressable)" : [ "create" ],
  "org.apache.hadoop.ipc.ProtocolProxy:isMethodSupported(java.lang.String,java.lang.Class[])" : [ "fetchServerMethods", "getFingerprint" ],
  "org.apache.hadoop.io.retry.DefaultFailoverProxyProvider:close()" : [ "stopProxy" ],
  "org.apache.hadoop.io.MapFile$Writer:progressable(org.apache.hadoop.util.Progressable)" : [ "progressable" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.util.GaloisField:multiply(int,int)" : [ "getFieldSize" ],
  "org.apache.hadoop.fs.DU:refresh()" : [ "startRefresh" ],
  "org.apache.hadoop.metrics2.MetricsJsonBuilder:addGauge(org.apache.hadoop.metrics2.MetricsInfo,float)" : [ "tuple" ],
  "org.apache.hadoop.io.WritableComparator:readDouble(byte[],int)" : [ "readLong" ],
  "org.apache.hadoop.ipc.metrics.DecayRpcSchedulerDetailedMetrics:shutdown()" : [ "instance" ],
  "org.apache.hadoop.fs.TrashPolicyDefault:deleteCheckpointsImmediately()" : [ "deleteCheckpoint" ],
  "org.apache.hadoop.net.NetUtils:getDefaultSocketFactory(org.apache.hadoop.conf.Configuration)" : [ "get", "getSocketFactoryFromProperty" ],
  "org.apache.hadoop.fs.FileContext:checkDest(java.lang.String,org.apache.hadoop.fs.Path,boolean)" : [ "<init>", "getFileStatus", "isDirectory" ],
  "org.apache.hadoop.util.SysInfoLinux:getNumProcessors()" : [ "readProcCpuInfoFile" ],
  "org.apache.hadoop.metrics2.util.MetricsCache:<init>()" : [ "<init>" ],
  "org.apache.hadoop.ipc.Client$Connection:close()" : [ "closeStream", "disposeSasl", "cleanupCalls", "closeConnection" ],
  "org.apache.hadoop.ipc.ClientCache:stopClient(org.apache.hadoop.ipc.Client)" : [ "decAndGetCount", "getSocketFactory", "stop" ],
  "org.apache.hadoop.security.SaslRpcServer:<init>(org.apache.hadoop.security.SaslRpcServer$AuthMethod)" : [ "<init>", "getMechanismName", "getCurrentUser", "getUserName" ],
  "org.apache.hadoop.util.dynamic.DynMethods$Builder:impl(java.lang.String,java.lang.Class[])" : [ "impl" ],
  "org.apache.hadoop.fs.FileContext:open(org.apache.hadoop.fs.Path)" : [ "fixRelativePart" ],
  "org.apache.hadoop.fs.ChecksumFileSystem:setConf(org.apache.hadoop.conf.Configuration)" : [ "getInt", "checkState" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs:setTimes(org.apache.hadoop.fs.Path,long,long)" : [ "checkPathIsSlash", "readOnlyMountTable" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:open(org.apache.hadoop.fs.Path,int)" : [ "<init>", "getFileStatus" ],
  "org.apache.hadoop.util.ReflectionUtils:logThreadInfo(org.apache.commons.logging.Log,java.lang.String,long)" : [ "monotonicNow", "printThreadInfo" ],
  "org.apache.hadoop.ipc.FairCallQueue:<init>(int,int,java.lang.String,int[],boolean,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getInstance", "setDelegate" ],
  "org.apache.hadoop.crypto.JceCtrCryptoCodec:calculateIV(byte[],long,byte[],int)" : [ "checkArgument" ],
  "org.apache.hadoop.io.erasurecode.codec.HHXORErasureCodec:createDecoder()" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.find.Find:postProcessPath(org.apache.hadoop.fs.shell.PathData)" : [ "getOptions", "isDepthFirst", "applyItem" ],
  "org.apache.hadoop.ipc.DecayRpcScheduler:computePriorityLevel(long,java.lang.Object)" : [ "isServiceUser" ],
  "org.apache.hadoop.crypto.key.JavaKeyStoreProvider:noPasswordWarning()" : [ "noPasswordWarning" ],
  "org.apache.hadoop.fs.shell.Command:displayWarning(java.lang.String)" : [ "getName" ],
  "org.apache.hadoop.net.NodeBase:locationToDepth(java.lang.String)" : [ "normalize" ],
  "org.apache.hadoop.fs.FsShell:createOptionTableListing()" : [ "<init>", "addField", "wrapWidth", "build" ],
  "org.apache.hadoop.fs.FilterFileSystem:createNonRecursive(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,java.util.EnumSet,int,short,long,org.apache.hadoop.util.Progressable)" : [ "createNonRecursive" ],
  "org.apache.hadoop.security.UserGroupInformation:addToken(org.apache.hadoop.io.Text,org.apache.hadoop.security.token.Token)" : [ "addToken", "getCredentialsInternal" ],
  "org.apache.hadoop.io.compress.zlib.ZlibDecompressor:getBytesRead()" : [ "checkStream" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.util.RSUtil:encodeData(byte[],int,byte[][],int[],byte[][],int[])" : [ "gfMulTab" ],
  "org.apache.hadoop.io.erasurecode.CodecUtil:getCodecClassName(org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "get" ],
  "org.apache.hadoop.fs.ChecksumFs$ChecksumFSInputChecker:skip(long)" : [ "skip", "getFileLength" ],
  "org.apache.hadoop.fs.FSDataOutputStreamBuilder:bufferSize(int)" : [ "getThisBuilder" ],
  "org.apache.hadoop.fs.impl.FSBuilderSupport:getPositiveLong(java.lang.String,long)" : [ "getLong" ],
  "org.apache.hadoop.io.retry.AsyncCallHandler$AsyncCall:isDone()" : [ "getState", "set", "checkState" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider$KMSTokenRenewer:renew(org.apache.hadoop.security.token.Token,org.apache.hadoop.conf.Configuration)" : [ "createKeyProvider", "close" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Decompressor:setInput(byte[],int,int)" : [ "setInputFromSavedData" ],
  "org.apache.hadoop.fs.shell.Stat:registerCommands(org.apache.hadoop.fs.shell.CommandFactory)" : [ "addClass" ],
  "org.apache.hadoop.fs.FilterFs:listLocatedStatus(org.apache.hadoop.fs.Path)" : [ "listLocatedStatus", "checkPath" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Location:<init>(org.apache.hadoop.io.file.tfile.TFile$Reader$Location)" : [ "set" ],
  "org.apache.hadoop.metrics2.impl.MetricsCollectorImpl:getRecords()" : [ "newArrayListWithCapacity", "getRecord" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:incrementMinimum(java.lang.String,long)" : [ "getInnerStatistics" ],
  "org.apache.hadoop.fs.shell.find.And:apply(org.apache.hadoop.fs.shell.PathData,int)" : [ "combine", "isPass" ],
  "org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager:createCuratorClient(org.apache.hadoop.conf.Configuration,java.lang.String)" : [ "<init>", "get", "getServerPrincipal", "getInt", "getBoolean" ],
  "org.apache.hadoop.net.SocketInputStream:<init>(java.net.Socket)" : [ "<init>" ],
  "org.apache.hadoop.security.ssl.ReloadingX509TrustManager:loadFrom(java.nio.file.Path)" : [ "loadTrustManager" ],
  "org.apache.hadoop.fs.LocalFileSystem:getFileLinkStatus(org.apache.hadoop.fs.Path)" : [ "getFileLinkStatus" ],
  "org.apache.hadoop.fs.FileStatus:compareTo(java.lang.Object)" : [ "compareTo" ],
  "org.apache.hadoop.util.ConfTest:listFiles(java.io.File)" : [ "<init>" ],
  "org.apache.hadoop.security.alias.UserProvider:<init>()" : [ "getCurrentUser", "getCredentials" ],
  "org.apache.hadoop.io.file.tfile.CompareUtils$BytesComparator:compare(org.apache.hadoop.io.file.tfile.RawComparable,org.apache.hadoop.io.file.tfile.RawComparable)" : [ "compare" ],
  "org.apache.hadoop.io.retry.RetryPolicies:retryByException(org.apache.hadoop.io.retry.RetryPolicy,java.util.Map)" : [ "<init>" ],
  "org.apache.hadoop.fs.FsShellPermissions$Chown:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "getOwner", "getGroup", "setOwner" ],
  "org.apache.hadoop.fs.statistics.impl.DynamicIOStatisticsBuilder:withMutableCounter(java.lang.String,org.apache.hadoop.metrics2.lib.MutableCounterLong)" : [ "withLongFunctionCounter" ],
  "org.apache.hadoop.io.MD5Hash:hashCode()" : [ "quarterDigest" ],
  "org.apache.hadoop.security.SaslInputStream:read(byte[],int,int)" : [ "readMoreData" ],
  "org.apache.hadoop.metrics2.util.SampleStat:add(double)" : [ "add" ],
  "org.apache.hadoop.ipc.metrics.RetryCacheMetrics:incrCacheHit()" : [ "incr" ],
  "org.apache.hadoop.security.UserGroupInformation$UgiMetrics:reattach()" : [ "create" ],
  "org.apache.hadoop.crypto.key.UserProvider:getKeyVersions(java.lang.String)" : [ "getMetadata", "getVersions", "getKeyVersion" ],
  "org.apache.hadoop.fs.Options$CreateOpts:checksumParam(org.apache.hadoop.fs.Options$ChecksumOpt)" : [ "<init>" ],
  "org.apache.hadoop.security.token.delegation.SQLDelegationTokenSecretManager:getCandidateTokensForCleanup()" : [ "now", "createTokenIdent", "createTokenInfo" ],
  "org.apache.hadoop.security.LdapGroupsMapping$LdapSslSocketFactory:createKeyStore(java.lang.String,java.lang.String)" : [ "getPasswordCharArray" ],
  "org.apache.hadoop.io.compress.zstd.ZStandardCompressor:<init>(int,int,int)" : [ "reset" ],
  "org.apache.hadoop.ipc.CallerContext:<init>(org.apache.hadoop.ipc.CallerContext$Builder)" : [ "getContext", "getSignature" ],
  "org.apache.hadoop.fs.FileSystem:access(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsAction)" : [ "checkAccessPermissions" ],
  "org.apache.hadoop.fs.RawLocalFileSystem:getHomeDirectory()" : [ "<init>" ],
  "org.apache.hadoop.metrics2.sink.RollingFileSystemSink:findCurrentDirectory(java.util.Date)" : [ "<init>" ],
  "org.apache.hadoop.ipc.Server$Listener$Reader:doRunLoop()" : [ "doRead", "terminate" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:stripOutRoot(org.apache.hadoop.fs.Path)" : [ "toUri", "isRoot" ],
  "org.apache.hadoop.fs.impl.FileSystemMultipartUploaderBuilder:getReplication()" : [ "getReplication" ],
  "org.apache.hadoop.service.AbstractService:init(org.apache.hadoop.conf.Configuration)" : [ "<init>", "getName", "isInState", "enterState", "setConfig", "serviceInit", "notifyListeners", "noteFailure", "stopQuietly", "convert" ],
  "org.apache.hadoop.ipc.Server:getProtocolClass(java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "getClassByName" ],
  "org.apache.hadoop.io.file.tfile.TFile$TFileIndexEntry:write(java.io.DataOutput)" : [ "writeVInt", "writeVLong" ],
  "org.apache.hadoop.crypto.CryptoStreamUtils:freeDB(java.nio.ByteBuffer)" : [ "getCleaner" ],
  "org.apache.hadoop.util.ProtoUtil:getUgi(org.apache.hadoop.ipc.protobuf.IpcConnectionContextProtos$IpcConnectionContextProto)" : [ "getUgi" ],
  "org.apache.hadoop.ha.SshFenceByTcpPort:tryFence(org.apache.hadoop.ha.HAServiceTarget,java.lang.String)" : [ "<init>", "createSession", "getSshConnectTimeout", "doFence" ],
  "org.apache.hadoop.io.SequenceFile$Writer:init(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FSDataOutputStream,boolean,java.lang.Class,java.lang.Class,org.apache.hadoop.io.compress.CompressionCodec,org.apache.hadoop.io.SequenceFile$Metadata,int)" : [ "<init>", "getSerializer", "setConf", "getCompressor", "sync", "writeFileHeader" ],
  "org.apache.hadoop.fs.FileSystem:closeAllForUGI(org.apache.hadoop.security.UserGroupInformation)" : [ "debugLogFileSystemClose", "closeAll" ],
  "org.apache.hadoop.util.ExitUtil:halt(org.apache.hadoop.util.ExitUtil$HaltException)" : [ "getExitCode", "addSuppressed" ],
  "org.apache.hadoop.security.Credentials:writeProto(java.io.DataOutput)" : [ "getBytes", "getLength", "protoFromToken" ],
  "org.apache.hadoop.conf.Configuration:addDeprecation(java.lang.String,java.lang.String[])" : [ "addDeprecation" ],
  "org.apache.hadoop.fs.shell.Ls:<init>()" : [ "<init>" ],
  "org.apache.hadoop.ipc.protocolPB.GenericRefreshProtocolClientSideTranslatorPB:unpack(org.apache.hadoop.ipc.proto.GenericRefreshProtocolProtos$GenericRefreshResponseProto)" : [ "<init>", "setSenderName" ],
  "org.apache.hadoop.io.compress.BZip2Codec$BZip2CompressionOutputStream:internalReset()" : [ "<init>", "writeStreamHeader" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:getStatus(org.apache.hadoop.fs.Path)" : [ "getStatus", "fullPath" ],
  "org.apache.hadoop.fs.FileContext:createSnapshot(org.apache.hadoop.fs.Path,java.lang.String)" : [ "fixRelativePart" ],
  "org.apache.hadoop.util.dynamic.DynMethods$Builder:hiddenImpl(java.lang.Class,java.lang.String,java.lang.Class[])" : [ "<init>" ],
  "org.apache.hadoop.util.LightWeightCache:evictExpiredEntries()" : [ "monotonicNowNanos", "isExpired", "evict", "checkState" ],
  "org.apache.hadoop.util.ReflectionUtils$CopyInCopyOutBuffer:moveData()" : [ "reset", "getData", "getLength" ],
  "org.apache.hadoop.net.ScriptBasedMapping:<init>(org.apache.hadoop.net.DNSToSwitchMapping)" : [ "<init>" ],
  "org.apache.hadoop.util.LightWeightCache:evict()" : [ "remove", "checkState" ],
  "org.apache.hadoop.security.KDiag:title(java.lang.String,java.lang.Object[])" : [ "println" ],
  "org.apache.hadoop.fs.Globber$GlobBuilder:<init>(org.apache.hadoop.fs.FileContext)" : [ "checkNotNull" ],
  "org.apache.hadoop.io.ShortWritable$Comparator:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.WeakReferenceThreadMap:<init>(java.util.function.Function,java.util.function.Consumer)" : [ "<init>" ],
  "org.apache.hadoop.util.ShutdownHookManager:addShutdownHook(java.lang.Runnable,int,long,java.util.concurrent.TimeUnit)" : [ "<init>" ],
  "org.apache.hadoop.util.bloom.Filter:<init>(int,int,int)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.sink.ganglia.GangliaSink30:calculateSlope(org.apache.hadoop.metrics2.sink.ganglia.GangliaConf,org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink$GangliaSlope)" : [ "getSlope" ],
  "org.apache.hadoop.fs.FSDataInputStream:hasCapability(java.lang.String)" : [ "hasCapability" ],
  "org.apache.hadoop.io.compress.bzip2.CBZip2InputStream:recvDecodingTables()" : [ "bsGetBit", "makeMaps", "bsR", "createHuffmanDecodingTables" ],
  "org.apache.hadoop.io.SequenceFile$Writer:checkAndWriteSync()" : [ "getPos", "sync" ],
  "org.apache.hadoop.fs.FilterFileSystem:copyFromLocalFile(boolean,boolean,org.apache.hadoop.fs.Path[],org.apache.hadoop.fs.Path)" : [ "copyFromLocalFile" ],
  "org.apache.hadoop.io.compress.GzipCodec:createCompressor()" : [ "<init>", "isNativeZlibLoaded" ],
  "org.apache.hadoop.fs.impl.prefetch.SingleFilePerBlockCache:getCacheFilePath(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.LocalDirAllocator)" : [ "getTempFilePath" ],
  "org.apache.hadoop.io.compress.GzipCodec:createInputStream(java.io.InputStream)" : [ "createInputStreamWithCodecPool" ],
  "org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs:listStatus(org.apache.hadoop.fs.Path)" : [ "<init>", "checkPathIsSlash", "listStatusForFallbackLink", "getChildren", "makeQualified", "isLink", "getLink", "getShortUserName", "getPrimaryGroupName", "getTargetLink", "getTargetFileSystem", "getUri", "getMyFs", "getLen", "isDirectory", "getReplication", "getBlockSize", "getModificationTime", "getAccessTime", "getPermission", "getOwner", "getGroup", "merge" ],
  "org.apache.hadoop.io.compress.BZip2Codec$BZip2CompressionOutputStream:writeStreamHeader()" : [ "writeHeader" ],
  "org.apache.hadoop.io.wrappedio.impl.DynamicWrappedStatistics:ioStatisticsAvailable()" : [ "available" ],
  "org.apache.hadoop.net.InnerNodeImpl$Factory:newInnerNode(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.net.unix.DomainSocket:socketpair()" : [ "<init>" ],
  "org.apache.hadoop.conf.Configuration:addResource(org.apache.hadoop.fs.Path,boolean)" : [ "<init>", "addResourceObject" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner:inBlockAdvance(org.apache.hadoop.io.file.tfile.RawComparable,boolean)" : [ "getBlockIndex", "getBlockEntryCount", "getRecordIndex", "compareCursorKeyTo", "isClosed", "close", "incRecordIndex" ],
  "org.apache.hadoop.security.JniBasedUnixGroupsNetgroupMapping:cacheGroupsAdd(java.util.List)" : [ "isCached", "add", "getUsersForNetgroup" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:start()" : [ "<init>", "checkNotNull", "configure", "startTimer" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:drain(java.lang.String)" : [ "drain" ],
  "org.apache.hadoop.io.compress.zlib.ZlibFactory:getZlibDecompressor(org.apache.hadoop.conf.Configuration)" : [ "<init>", "isNativeZlibLoaded" ],
  "org.apache.hadoop.fs.DF:main(java.lang.String[])" : [ "<init>", "toString" ],
  "org.apache.hadoop.security.ssl.SSLHostnameVerifier$AbstractVerifier:check(java.lang.String[],java.lang.String[],java.lang.String[],boolean,boolean)" : [ "toLowerCase", "isIP4Address", "acceptableCountryWildcard", "countDots" ],
  "org.apache.hadoop.ipc.Server$Connection:doSaslReply(java.lang.Exception)" : [ "sendResponse" ],
  "org.apache.hadoop.fs.FileContext:fixRelativePart(org.apache.hadoop.fs.Path)" : [ "<init>", "checkNotNull", "isUriPathAbsolute" ],
  "org.apache.hadoop.fs.FileContext$Util:listStatus(org.apache.hadoop.fs.Path[])" : [ "listStatus" ],
  "org.apache.hadoop.util.ToolRunner:printGenericCommandUsage(java.io.PrintStream)" : [ "printGenericCommandUsage" ],
  "org.apache.hadoop.util.DurationInfo:<init>(org.slf4j.Logger,boolean,java.lang.String,java.lang.Object[])" : [ "<init>", "getFormattedText" ],
  "org.apache.hadoop.conf.Configured:<init>(org.apache.hadoop.conf.Configuration)" : [ "setConf" ],
  "org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier:setRealUser(org.apache.hadoop.io.Text)" : [ "<init>" ],
  "org.apache.hadoop.crypto.CryptoOutputStream:updateEncryptor()" : [ "getAlgorithmBlockSize" ],
  "org.apache.hadoop.fs.FileUtil:canWrite(java.io.File)" : [ "access" ],
  "org.apache.hadoop.ipc.Server$Responder:doRunLoop()" : [ "waitPending", "doAsyncWrite", "monotonicNowNanos", "doPurge" ],
  "org.apache.hadoop.util.HostsFileReader:getHostDetails(java.util.Set,java.util.Set)" : [ "getIncludedHosts", "getExcludedHosts" ],
  "org.apache.hadoop.io.ArrayFile$Writer:<init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,java.lang.String,java.lang.Class)" : [ "<init>" ],
  "org.apache.hadoop.ipc.RPC:getProtocolProxy(java.lang.Class,long,java.net.InetSocketAddress,org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory)" : [ "getProtocolProxy", "getRpcTimeout" ],
  "org.apache.hadoop.security.SecurityUtil:setSslConfiguration(org.apache.zookeeper.client.ZKClientConfig,org.apache.hadoop.security.SecurityUtil$TruststoreKeystore,org.apache.zookeeper.common.ClientX509Util)" : [ "validateSslConfiguration" ],
  "org.apache.hadoop.io.compress.zlib.ZlibCompressor:getBytesWritten()" : [ "checkStream" ],
  "org.apache.hadoop.fs.permission.AclStatus:<init>(java.lang.String,java.lang.String,boolean,java.lang.Iterable,org.apache.hadoop.fs.permission.FsPermission)" : [ "newArrayList" ],
  "org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory:resolvePropertyName(org.apache.hadoop.security.ssl.SSLFactory$Mode,java.lang.String)" : [ "toLowerCase" ],
  "org.apache.hadoop.util.hash.Hash:getInstance(org.apache.hadoop.conf.Configuration)" : [ "getInstance", "getHashType" ],
  "org.apache.hadoop.io.file.tfile.TFile:main(java.lang.String[])" : [ "<init>", "toString", "dumpInfo" ],
  "org.apache.hadoop.io.erasurecode.CodecUtil:createRawDecoder(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.hadoop.io.erasurecode.ErasureCoderOptions)" : [ "checkNotNull", "createRawDecoderWithFallback" ],
  "org.apache.hadoop.metrics2.sink.PrometheusMetricsSink:writeMetrics(java.io.Writer)" : [ "getMetricKey", "description", "name", "value" ],
  "org.apache.hadoop.service.launcher.ServiceLaunchException:<init>(int,java.lang.Throwable)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFs:setReplication(org.apache.hadoop.fs.Path,short)" : [ "fullPath" ],
  "org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue:put(org.apache.hadoop.io.SequenceFile$Sorter$SegmentDescriptor)" : [ "put", "isCompressed", "isBlockCompressed" ],
  "org.apache.hadoop.metrics2.filter.AbstractPatternFilter:accepts(java.lang.Iterable)" : [ "name", "value" ],
  "org.apache.hadoop.crypto.OpensslCipher:isSupported(org.apache.hadoop.crypto.CipherSuite)" : [ "tokenizeTransformation", "getName", "get" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2:getProxy(java.lang.Class,long,org.apache.hadoop.ipc.Client$ConnectionId,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory,org.apache.hadoop.ipc.AlignmentContext)" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.SnapshotCommands$CreateSnapshot:processArguments(java.util.LinkedList)" : [ "createSnapshot" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme:getRawFileSystem(org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration)" : [ "<init>", "resolve", "isInternalDir", "fsGetter", "get", "toUri", "getMyFs" ],
  "org.apache.hadoop.fs.shell.Delete$Rmdir:processPath(org.apache.hadoop.fs.shell.PathData)" : [ "<init>", "isDirectory", "toString" ],
  "org.apache.hadoop.io.erasurecode.rawcoder.RawErasureDecoder:getNumAllUnits()" : [ "getNumAllUnits" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:getDeferredRpcProcessingStdDev()" : [ "stddev" ],
  "org.apache.hadoop.metrics2.lib.MetricsSourceBuilder:add(java.lang.Object,java.lang.reflect.Field)" : [ "<init>", "newForField" ],
  "org.apache.hadoop.util.ZKUtil$BadAuthFormatException:<init>(java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.util.functional.FutureIO:awaitFuture(java.util.concurrent.Future,long,java.util.concurrent.TimeUnit)" : [ "raiseInnerCause" ],
  "org.apache.hadoop.ipc.CallQueueManager:add(java.lang.Object)" : [ "add" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:create(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission,boolean,int,short,long,org.apache.hadoop.util.Progressable)" : [ "create", "fullPath" ],
  "org.apache.hadoop.fs.impl.AbstractFSBuilderImpl:opt(java.lang.String,java.lang.String)" : [ "set", "getThisBuilder" ],
  "org.apache.hadoop.io.compress.ZStandardCodec:createOutputStream(java.io.OutputStream,org.apache.hadoop.io.compress.Compressor)" : [ "<init>", "checkNativeCodeLoaded", "getCompressionBufferSize" ],
  "org.apache.hadoop.ipc.ProtobufRpcEngine2:getClient(org.apache.hadoop.conf.Configuration)" : [ "getClient" ],
  "org.apache.hadoop.fs.FsTracer:get(org.apache.hadoop.conf.Configuration)" : [ "<init>", "conf", "wrapHadoopConf", "build" ],
  "org.apache.hadoop.util.ThreadUtil:getResourceAsStream(java.lang.String)" : [ "getResourceAsStream" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:resolvePath(org.apache.hadoop.fs.Path)" : [ "resolvePath", "resolve", "getUriPath", "isInternalDir" ],
  "org.apache.hadoop.io.retry.RetryPolicies$RetryUpToMaximumTimeWithFixedSleep:<init>(long,long,java.util.concurrent.TimeUnit)" : [ "<init>" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:renameSnapshot(org.apache.hadoop.fs.Path,java.lang.String,java.lang.String)" : [ "renameSnapshot" ],
  "org.apache.hadoop.util.SysInfoWindows:now()" : [ "monotonicNow" ],
  "org.apache.hadoop.fs.AbstractFileSystem:setXAttr(org.apache.hadoop.fs.Path,java.lang.String,byte[])" : [ "setXAttr" ],
  "org.apache.hadoop.fs.FileUtil:checkReturnValue(boolean,java.io.File,org.apache.hadoop.fs.permission.FsPermission)" : [ "toShort" ],
  "org.apache.hadoop.crypto.CryptoProtocolVersion:supports(org.apache.hadoop.crypto.CryptoProtocolVersion)" : [ "getVersion" ],
  "org.apache.hadoop.fs.FileContext:getFileLinkStatus(org.apache.hadoop.fs.Path)" : [ "fixRelativePart" ],
  "org.apache.hadoop.io.ObjectWritable$NullInstance:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.Stat:getExecString()" : [ "toString" ],
  "org.apache.hadoop.security.alias.CredentialShell$Command:getCredentialProvider()" : [ "getProviders", "isTransient" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsSnapshot:serializer()" : [ "<init>" ],
  "org.apache.hadoop.fs.shell.FsUsage:formatSize(long)" : [ "long2String" ],
  "org.apache.hadoop.ha.protocolPB.HAServiceProtocolClientSideTranslatorPB:getServiceStatus()" : [ "<init>", "ipc", "convert", "setReadyToBecomeActive", "setNotReadyToBecomeActive" ],
  "org.apache.hadoop.http.HttpServer2:start()" : [ "openListeners", "instance", "create" ],
  "org.apache.hadoop.fs.permission.PermissionStatus:createImmutable(java.lang.String,java.lang.String,org.apache.hadoop.fs.permission.FsPermission)" : [ "<init>" ],
  "org.apache.hadoop.net.NetworkTopology:chooseRandom(java.lang.String,java.util.Collection)" : [ "chooseRandom" ],
  "org.apache.hadoop.fs.Path:<init>(java.lang.String)" : [ "checkPathArg", "hasWindowsDrive", "initialize" ],
  "org.apache.hadoop.util.dynamic.DynConstructors$Ctor:newInstance(java.lang.Object[])" : [ "newInstanceChecked", "throwIfInstance" ],
  "org.apache.hadoop.conf.Configuration:isDeprecated(java.lang.String)" : [ "getDeprecatedKeyMap" ],
  "org.apache.hadoop.io.retry.RetryUtils$WrapperRetryPolicy:shouldRetry(java.lang.Exception,int,int,boolean)" : [ "shouldRetry", "getWrappedRetriableException", "getClassName" ],
  "org.apache.hadoop.util.StopWatch:close()" : [ "stop" ],
  "org.apache.hadoop.fs.FSDataOutputStreamBuilder:recursive()" : [ "getThisBuilder" ],
  "org.apache.hadoop.fs.ftp.FTPFileSystem:initialize(java.net.URI,org.apache.hadoop.conf.Configuration)" : [ "initialize", "get", "set", "getInt", "setInt", "checkState" ],
  "org.apache.hadoop.fs.FileContext$Util:copy(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,boolean,boolean)" : [ "<init>", "checkNotSchemeWithRelative", "makeQualified", "getName", "getFileStatus", "isDirectory", "mkdir", "getDirDefault", "listStatus", "getPath", "awaitFuture", "openFile", "getLen", "build", "create", "copyBytes", "closeStream", "delete", "close" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner$Entry:writeValue(java.io.OutputStream)" : [ "getValueStream", "getRemain", "setSize", "getBytes" ],
  "org.apache.hadoop.conf.Configuration:getClasses(java.lang.String,java.lang.Class[])" : [ "getRaw", "getTrimmedStrings", "getClassByName" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:call(java.net.HttpURLConnection,java.lang.Object,int,java.lang.Class)" : [ "call" ],
  "org.apache.hadoop.io.erasurecode.codec.HHXORErasureCodec:createEncoder()" : [ "<init>" ],
  "org.apache.hadoop.fs.impl.FutureDataInputStreamBuilderImpl:builder()" : [ "getThisBuilder" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider$KMSMetadata:<init>(java.lang.String,int,java.lang.String,java.util.Map,java.util.Date,int)" : [ "<init>" ],
  "org.apache.hadoop.fs.sftp.SFTPInputStream:<init>(com.jcraft.jsch.ChannelSftp,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.FileSystem$Statistics)" : [ "toUri", "toString" ],
  "org.apache.hadoop.service.ServiceOperations:stopQuietly(org.apache.commons.logging.Log,org.apache.hadoop.service.Service)" : [ "stop" ],
  "org.apache.hadoop.io.EnumSetWritable:<init>(java.util.EnumSet)" : [ "<init>" ],
  "org.apache.hadoop.fs.GlobPattern:set(java.lang.String)" : [ "error" ],
  "org.apache.hadoop.ipc.metrics.RpcMetrics:getTotalRequestsPerSecond()" : [ "getTotalRequestsPerSecond" ],
  "org.apache.hadoop.security.ssl.DelegatingSSLSocketFactory:createSocket(java.net.Socket,java.lang.String,int,boolean)" : [ "configureSocket" ],
  "org.apache.hadoop.fs.FilterFileSystem:checkPath(org.apache.hadoop.fs.Path)" : [ "checkPath" ],
  "org.apache.hadoop.io.BoundedByteArrayOutputStream:<init>(int)" : [ "<init>" ],
  "org.apache.hadoop.fs.FileSystem$Statistics:incrementBytesReadErasureCoded(long)" : [ "getThreadStatistics" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockOperations:prefetch(int)" : [ "<init>", "checkNotNegative", "add" ],
  "org.apache.hadoop.fs.FileUtil:canExecute(java.io.File)" : [ "access" ],
  "org.apache.hadoop.fs.DUHelper:check(java.lang.String)" : [ "getFileSize" ],
  "org.apache.hadoop.io.file.tfile.TFile$Writer:<init>(org.apache.hadoop.fs.FSDataOutputStream,int,java.lang.String,java.lang.String,org.apache.hadoop.conf.Configuration)" : [ "<init>", "getComparator" ],
  "org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreImpl:getGaugeReference(java.lang.String)" : [ "lookup" ],
  "org.apache.hadoop.util.Shell:execCommand(java.util.Map,java.lang.String[],long)" : [ "<init>", "execute", "getOutput" ],
  "org.apache.hadoop.ipc.Server:internalQueueCall(org.apache.hadoop.ipc.Server$Call,boolean)" : [ "put", "add", "monotonicNowNanos", "getProcessingDetails", "set", "incrClientBackoff", "getCause", "getRpcStatusProto", "incrClientBackoffDisconnected" ],
  "org.apache.hadoop.fs.impl.FileSystemMultipartUploaderBuilder:build()" : [ "<init>", "getFS" ],
  "org.apache.hadoop.conf.Configuration:getCredentialEntry(org.apache.hadoop.security.alias.CredentialProvider,java.lang.String)" : [ "getDeprecatedKey", "logDeprecationOnce", "getDeprecatedKeyInfo" ],
  "org.apache.hadoop.fs.statistics.IOStatisticsLogging:ioStatisticsToPrettyString(org.apache.hadoop.fs.statistics.IOStatistics)" : [ "mapToSortedString", "isEmpty" ],
  "org.apache.hadoop.fs.statistics.impl.ForwardingIOStatisticsStore:getMeanStatistic(java.lang.String)" : [ "getInnerStatistics" ],
  "org.apache.hadoop.crypto.key.kms.KMSClientProvider:getKeys()" : [ "createURL", "createConnection", "call" ],
  "org.apache.hadoop.fs.viewfs.ViewFs:access(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsAction)" : [ "access" ],
  "org.apache.hadoop.crypto.CryptoInputStream:afterDecryption(org.apache.hadoop.crypto.Decryptor,java.nio.ByteBuffer,long,byte[])" : [ "updateDecryptor", "getPadding" ],
  "org.apache.hadoop.ipc.Client:setPingInterval(org.apache.hadoop.conf.Configuration,int)" : [ "setInt" ],
  "org.apache.hadoop.fs.permission.PermissionStatus:read(java.io.DataInput)" : [ "<init>", "readFields" ],
  "org.apache.hadoop.fs.impl.prefetch.BufferData:setCaching(java.util.concurrent.Future)" : [ "checkNotNull", "throwIfStateIncorrect" ],
  "org.apache.hadoop.ha.ZKFailoverController:cedeRemoteActive(org.apache.hadoop.ha.HAServiceTarget,int)" : [ "getZKFCProxy" ],
  "org.apache.hadoop.fs.FileSystem:getTrashRoots(boolean)" : [ "<init>", "getHomeDirectory", "toUri", "getPath", "exists", "getParent", "setPath" ],
  "org.apache.hadoop.io.ByteWritable:<init>(byte)" : [ "set" ],
  "org.apache.hadoop.fs.FileSystem$DirListingIterator:fetchMore()" : [ "getToken", "listStatusBatch" ],
  "org.apache.hadoop.fs.impl.prefetch.BlockData:getState(int)" : [ "throwIfInvalidBlockNumber" ],
  "org.apache.hadoop.fs.viewfs.ChRootedFileSystem:setOwner(org.apache.hadoop.fs.Path,java.lang.String,java.lang.String)" : [ "setOwner", "fullPath" ],
  "org.apache.hadoop.fs.ChecksumFileSystem:<init>(org.apache.hadoop.fs.FileSystem)" : [ "<init>" ],
  "org.apache.hadoop.metrics2.sink.RollingFileSystemSink:createOrAppendLogFile(org.apache.hadoop.fs.Path)" : [ "create", "append" ],
  "org.apache.hadoop.ipc.RpcClientException:<init>(java.lang.String,java.lang.Throwable)" : [ "<init>" ],
  "org.apache.hadoop.util.DataChecksum:newDataChecksum(byte[],int)" : [ "<init>", "newDataChecksum", "getChecksumHeaderSize", "mapByteToChecksumType" ],
  "org.apache.hadoop.io.file.tfile.Chunk$ChunkDecoder:readLength()" : [ "readVInt" ],
  "org.apache.hadoop.io.SequenceFile:createWriter(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FSDataOutputStream,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType,org.apache.hadoop.io.compress.CompressionCodec)" : [ "createWriter", "stream", "keyClass", "valueClass", "compression" ],
  "org.apache.hadoop.ipc.Server:getSchedulerClass(java.lang.String,int,org.apache.hadoop.conf.Configuration)" : [ "getClass", "setClass", "convertSchedulerClass" ],
  "org.apache.hadoop.ipc.Client$Connection$PingInputStream:read(byte[],int,int)" : [ "handleTimeout" ],
  "org.apache.hadoop.metrics2.lib.MutableStat:<init>(java.lang.String,java.lang.String,java.lang.String,java.lang.String)" : [ "<init>" ],
  "org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue:updateProgress(long)" : [ "set" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:getServerDefaults(org.apache.hadoop.fs.Path)" : [ "<init>", "getServerDefaults", "resolve", "getUriPath" ],
  "org.apache.hadoop.fs.impl.prefetch.BufferPool:numAvailable()" : [ "releaseDoneBlocks" ],
  "org.apache.hadoop.fs.FSDataOutputStreamBuilder:<init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)" : [ "<init>", "checkNotNull", "getInt", "getDefaultReplication", "getDefaultBlockSize" ],
  "org.apache.hadoop.io.BloomMapFile:byteArrayForBloomKey(org.apache.hadoop.io.DataOutputBuffer)" : [ "getLength", "getData" ],
  "org.apache.hadoop.metrics2.impl.MetricsSystemImpl:register(java.lang.String,java.lang.String,java.lang.Object)" : [ "register", "newSourceBuilder", "build", "info", "sourceName", "registerSource" ],
  "org.apache.hadoop.security.token.delegation.DelegationKey:<init>(int,long,javax.crypto.SecretKey)" : [ "<init>" ],
  "org.apache.hadoop.security.alias.CredentialShell$CheckCommand:execute()" : [ "getPasswordReader", "readPassword", "getCredential" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$NflyOutputStream:write(int)" : [ "osException", "mayThrow" ],
  "org.apache.hadoop.service.launcher.ServiceLauncher:verifyConfigurationFilesExist(java.lang.String[])" : [ "<init>" ],
  "org.apache.hadoop.ha.HAAdmin:isOtherTargetNodeActive(java.lang.String,boolean)" : [ "getTargetIds", "checkManualStateManagementOK", "getProxy", "getState", "printUsage" ],
  "org.apache.hadoop.fs.store.DataBlocks$ByteArrayBlock:startUpload()" : [ "<init>", "startUpload", "getInputStream" ],
  "org.apache.hadoop.metrics2.impl.MetricsConfig:loadFirst(java.lang.String,java.lang.String[])" : [ "<init>", "toString" ],
  "org.apache.hadoop.util.Preconditions:checkNotNull(java.lang.Object)" : [ "checkNotNull" ],
  "org.apache.hadoop.ha.ZKFailoverController:confirmFormat()" : [ "getParentZnode", "confirmPrompt" ],
  "org.apache.hadoop.metrics2.util.SampleQuantiles:compress()" : [ "allowableError" ],
  "org.apache.hadoop.io.MapFile$Reader:getClosest(org.apache.hadoop.io.WritableComparable,org.apache.hadoop.io.Writable)" : [ "getClosest" ],
  "org.apache.hadoop.fs.BufferedFSInputStream:getIOStatistics()" : [ "retrieveIOStatistics" ],
  "org.apache.hadoop.util.KMSUtil:parseJSONMetadata(java.util.Map)" : [ "<init>", "checkNotNull" ],
  "org.apache.hadoop.fs.viewfs.RegexMountPointInterceptorFactory:create(java.lang.String)" : [ "get", "deserializeFromString" ],
  "org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner:<init>(org.apache.hadoop.io.file.tfile.TFile$Reader,long,long)" : [ "<init>", "getLocationNear" ],
  "org.apache.hadoop.conf.Configuration$Parser:handleInclude()" : [ "<init>", "getResource", "isParserRestricted", "parse" ],
  "org.apache.hadoop.fs.FileContext$FSDataInputStreamBuilder:build()" : [ "<init>", "fixRelativePart", "withMandatoryKeys", "withOptionalKeys", "withOptions", "withStatus", "withBufferSize", "getInt" ],
  "org.apache.hadoop.fs.viewfs.ViewFileSystem:append(org.apache.hadoop.fs.Path,int,org.apache.hadoop.util.Progressable)" : [ "resolve", "getUriPath" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem:open(org.apache.hadoop.fs.Path,int)" : [ "open", "workSet", "notFoundStatus", "processThrowable", "repairAndOpen", "mayThrowFileNotFound", "createIOException" ],
  "org.apache.hadoop.fs.impl.FutureIOSupport:eval(org.apache.hadoop.util.functional.CallableRaisingIOE)" : [ "eval" ],
  "org.apache.hadoop.fs.DelegateToFileSystem:setPermission(org.apache.hadoop.fs.Path,org.apache.hadoop.fs.permission.FsPermission)" : [ "setPermission" ],
  "org.apache.hadoop.util.GenericOptionsParser:<init>(org.apache.hadoop.conf.Configuration,java.lang.String[])" : [ "<init>" ],
  "org.apache.hadoop.ipc.Client$Connection:disposeSasl()" : [ "dispose" ],
  "org.apache.hadoop.io.compress.bzip2.Bzip2Decompressor:<init>()" : [ "<init>" ],
  "org.apache.hadoop.fs.statistics.impl.StorageStatisticsFromIOStatistics:iterator()" : [ "getLongStatistics" ],
  "org.apache.hadoop.fs.statistics.impl.DynamicIOStatisticsBuilder:withLongFunctionMaximum(java.lang.String,java.util.function.ToLongFunction)" : [ "activeInstance", "addMaximumFunction" ],
  "org.apache.hadoop.ha.ZKFailoverController$ServiceStateCallBacks:reportServiceStatus(org.apache.hadoop.ha.HAServiceStatus)" : [ "verifyChangedServiceState", "getState" ],
  "org.apache.hadoop.io.compress.zlib.ZlibDecompressor:reset()" : [ "checkStream" ],
  "org.apache.hadoop.io.SecureIOUtils:openForRead(java.io.File,java.lang.String,java.lang.String)" : [ "isSecurityEnabled", "forceSecureOpenForRead" ],
  "org.apache.hadoop.fs.FileContext:getFSofPath(org.apache.hadoop.fs.Path)" : [ "checkNotSchemeWithRelative", "checkNotRelative", "checkPath", "getAbstractFileSystem", "toUri" ],
  "org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping:setConf(org.apache.hadoop.conf.Configuration)" : [ "setConf", "get", "getInt" ],
  "org.apache.hadoop.fs.viewfs.NflyFSystem$MRNflyNode:equals(java.lang.Object)" : [ "compareTo" ],
  "org.apache.hadoop.fs.FileContext$Util:listStatus(java.util.ArrayList,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.PathFilter)" : [ "listStatus", "getPath" ],
  "org.apache.hadoop.security.User:<init>(java.lang.String,org.apache.hadoop.security.UserGroupInformation$AuthenticationMethod,javax.security.auth.login.LoginContext)" : [ "<init>" ],
  "org.apache.hadoop.fs.permission.PermissionStatus:write(java.io.DataOutput,java.lang.String,java.lang.String,org.apache.hadoop.fs.permission.FsPermission)" : [ "write", "writeString" ],
  "org.apache.hadoop.metrics2.sink.StatsDSink:close()" : [ "close" ],
  "org.apache.hadoop.fs.FilterFileSystem:copyToLocalFile(boolean,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)" : [ "copyToLocalFile" ],
  "org.apache.hadoop.conf.Configuration:logDeprecationOnce(java.lang.String,java.lang.String)" : [ "getDeprecatedKeyInfo", "getAndSetAccessed" ],
  "org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream:write(byte[],int,int)" : [ "flushBuffer" ]
}